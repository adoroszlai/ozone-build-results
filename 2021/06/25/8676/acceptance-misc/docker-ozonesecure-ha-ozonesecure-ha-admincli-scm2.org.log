Attaching to ozonesecure-ha_datanode1_1, ozonesecure-ha_om1_1, ozonesecure-ha_recon_1, ozonesecure-ha_kms_1, ozonesecure-ha_datanode2_1, ozonesecure-ha_om3_1, ozonesecure-ha_scm1.org_1, ozonesecure-ha_scm2.org_1, ozonesecure-ha_s3g_1, ozonesecure-ha_om2_1, ozonesecure-ha_datanode3_1, ozonesecure-ha_kdc_1, ozonesecure-ha_scm3.org_1
datanode1_1  | Sleeping for 5 seconds
datanode1_1  | Waiting for the service scm3.org:9894
datanode1_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode1_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode1_1  | 2021-06-25 13:40:27,820 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode1_1  | /************************************************************
datanode1_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode1_1  | STARTUP_MSG:   host = 9d41ca97b170/172.25.0.102
datanode1_1  | STARTUP_MSG:   args = []
datanode1_1  | STARTUP_MSG:   version = 1.2.0-SNAPSHOT
datanode1_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/javax.activation-api-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.2.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0-a398b19-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.2.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.2.0-SNAPSHOT.jar
datanode1_1  | STARTUP_MSG:   build = https://github.com/apache/ozone/450c3750335593082ae39a2d17d4a2a58090f75f ; compiled by 'runner' on 2021-06-25T12:44Z
datanode1_1  | STARTUP_MSG:   java = 11.0.10
datanode1_1  | ************************************************************/
datanode1_1  | 2021-06-25 13:40:27,921 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode1_1  | 2021-06-25 13:40:30,836 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode1_1  | 2021-06-25 13:40:31,802 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode1_1  | 2021-06-25 13:40:33,139 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode1_1  | 2021-06-25 13:40:33,142 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode1_1  | 2021-06-25 13:40:34,191 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:9d41ca97b170 ip:172.25.0.102
datanode1_1  | 2021-06-25 13:40:38,137 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/dn@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode1_1  | 2021-06-25 13:40:39,854 [main] INFO security.UserGroupInformation: Login successful for user dn/dn@EXAMPLE.COM using keytab file /etc/security/keytabs/dn.keytab
datanode1_1  | 2021-06-25 13:40:39,854 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
datanode1_1  | 2021-06-25 13:40:41,749 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
datanode1_1  | 2021-06-25 13:40:41,763 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode1_1  | 2021-06-25 13:40:41,763 [main] INFO client.DNCertificateClient: Certificate client init case: 0
datanode1_1  | 2021-06-25 13:40:41,778 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode1_1  | 2021-06-25 13:40:47,385 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
datanode1_1  | 2021-06-25 13:40:47,482 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.102,host:9d41ca97b170
datanode1_1  | 2021-06-25 13:40:47,485 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode1_1  | 2021-06-25 13:40:47,503 [main] ERROR client.DNCertificateClient: Invalid domain 9d41ca97b170
datanode1_1  | 2021-06-25 13:40:47,534 [main] INFO ozone.HddsDatanodeService: Creating csr for DN-> subject:root@9d41ca97b170
datanode1_1  | 2021-06-25 13:40:52,969 [main] INFO client.DNCertificateClient: Loading certificate from location:/data/metadata/dn/certs.
datanode1_1  | 2021-06-25 13:40:53,033 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/2981987122066.crt.
datanode1_1  | 2021-06-25 13:40:53,037 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/ROOTCA-1.crt.
datanode1_1  | 2021-06-25 13:40:53,079 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/CA-2884006640668.crt.
datanode1_1  | 2021-06-25 13:40:53,080 [main] INFO ozone.HddsDatanodeService: Successfully stored SCM signed certificate, case:GETCERT.
datanode1_1  | 2021-06-25 13:40:54,483 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode1_1  | 2021-06-25 13:40:54,588 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89311358976
datanode1_1  | 2021-06-25 13:40:54,620 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode1_1  | 2021-06-25 13:40:54,664 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode1_1  | 2021-06-25 13:40:54,952 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode1_1  | 2021-06-25 13:40:55,195 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode1_1  | 2021-06-25 13:40:55,208 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode1_1  | 2021-06-25 13:40:55,231 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode1_1  | 2021-06-25 13:40:55,448 [main] INFO ozoneimpl.ContainerReader: Running in upgrade mode:true
datanode1_1  | 2021-06-25 13:40:55,475 [Thread-8] INFO ozoneimpl.ContainerReader: Start to verify containers on volume /data/hdds/hdds
datanode1_1  | 2021-06-25 13:40:55,486 [Thread-8] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode1_1  | 2021-06-25 13:40:55,486 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode1_1  | 2021-06-25 13:41:04,596 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode1_1  | 2021-06-25 13:41:05,529 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode1_1  | 2021-06-25 13:41:06,322 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode1_1  | 2021-06-25 13:41:06,326 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode1_1  | 2021-06-25 13:41:06,329 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode1_1  | 2021-06-25 13:41:06,330 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode1_1  | 2021-06-25 13:41:06,337 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2021-06-25 13:41:06,338 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode1_1  | 2021-06-25 13:41:06,341 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode1_1  | 2021-06-25 13:41:14,273 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode1_1  | 2021-06-25 13:41:14,285 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode1_1  | 2021-06-25 13:41:14,287 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode1_1  | 2021-06-25 13:41:14,371 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode1_1  | 2021-06-25 13:41:17,673 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode1_1  | 2021-06-25 13:41:17,681 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode1_1  | 2021-06-25 13:41:17,681 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.datanode.http.auth.type = kerberos
datanode1_1  | 2021-06-25 13:41:17,888 [main] INFO util.log: Logging initialized @59682ms to org.eclipse.jetty.util.log.Slf4jLog
datanode1_1  | 2021-06-25 13:41:18,804 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode1_1  | 2021-06-25 13:41:18,877 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode1_1  | 2021-06-25 13:41:18,894 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode1_1  | 2021-06-25 13:41:18,896 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode1_1  | 2021-06-25 13:41:18,898 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode1_1  | 2021-06-25 13:41:18,918 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.datanode.http.auth.kerberos.principal keytabKey: hdds.datanode.http.auth.kerberos.keytab
datanode1_1  | 2021-06-25 13:41:19,278 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode1_1  | 2021-06-25 13:41:19,289 [main] INFO server.Server: jetty-9.4.35.v20201120; built: 2020-11-20T21:17:03.964Z; git: bdc54f03a5e0a7e280fab27f55c3c75ee8da89fb; jvm 11.0.10+9-LTS
datanode1_1  | 2021-06-25 13:41:19,554 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode1_1  | 2021-06-25 13:41:19,566 [main] INFO server.session: No SessionScavenger set, using defaults
datanode1_1  | 2021-06-25 13:41:19,588 [main] INFO server.session: node0 Scavenging every 600000ms
datanode1_1  | 2021-06-25 13:41:19,701 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode1_1  | 2021-06-25 13:41:19,725 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1f5a1ad4{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode1_1  | 2021-06-25 13:41:19,744 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@77a1df4d{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode1_1  | 2021-06-25 13:41:20,532 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode1_1  | 2021-06-25 13:41:20,654 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@7c4de811{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_2_0-SNAPSHOT_jar-_-any-3407651612875686377/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode1_1  | 2021-06-25 13:41:20,739 [main] INFO server.AbstractConnector: Started ServerConnector@85fd4b{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode1_1  | 2021-06-25 13:41:20,740 [main] INFO server.Server: Started @62533ms
datanode1_1  | 2021-06-25 13:41:20,746 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode1_1  | 2021-06-25 13:41:20,746 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode1_1  | 2021-06-25 13:41:20,763 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode1_1  | 2021-06-25 13:41:20,915 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2fe46f9c] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode1_1  | 2021-06-25 13:41:21,456 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.25.0.115:9891
datanode1_1  | 2021-06-25 13:41:25,454 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode1_1  | 2021-06-25 13:41:25,463 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode1_1  | 2021-06-25 13:41:26,136 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis ee31bb40-6981-4b57-b8d7-3be03fa0c81d
datanode1_1  | 2021-06-25 13:41:26,286 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.RaftServer: ee31bb40-6981-4b57-b8d7-3be03fa0c81d: start RPC server
datanode1_1  | 2021-06-25 13:41:26,311 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.GrpcService: ee31bb40-6981-4b57-b8d7-3be03fa0c81d: GrpcService started, listening on 9856
datanode1_1  | 2021-06-25 13:41:26,315 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.GrpcService: ee31bb40-6981-4b57-b8d7-3be03fa0c81d: GrpcService started, listening on 9857
datanode1_1  | 2021-06-25 13:41:26,319 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.GrpcService: ee31bb40-6981-4b57-b8d7-3be03fa0c81d: GrpcService started, listening on 9858
datanode1_1  | 2021-06-25 13:41:26,340 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis ee31bb40-6981-4b57-b8d7-3be03fa0c81d is started using port 9858 for RATIS
datanode1_1  | 2021-06-25 13:41:26,342 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$323/0x0000000840576840@2266476b] INFO util.JvmPauseMonitor: JvmPauseMonitor-ee31bb40-6981-4b57-b8d7-3be03fa0c81d: Started
datanode1_1  | 2021-06-25 13:41:26,342 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis ee31bb40-6981-4b57-b8d7-3be03fa0c81d is started using port 9857 for RATIS_ADMIN
datanode1_1  | 2021-06-25 13:41:26,343 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis ee31bb40-6981-4b57-b8d7-3be03fa0c81d is started using port 9856 for RATIS_SERVER
datanode1_1  | 2021-06-25 13:41:26,408 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode1_1  | 2021-06-25 13:41:26,408 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode1_1  | 2021-06-25 13:41:27,321 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:41:30,378 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:41:33,450 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:41:36,522 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:41:39,599 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:41:42,666 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:41:45,738 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:41:48,810 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:41:51,886 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:41:54,954 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:41:58,026 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:42:00,184 [Command processor thread] INFO server.RaftServer: ee31bb40-6981-4b57-b8d7-3be03fa0c81d: addNew group-BFEA630F7F68:[8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1] returns group-BFEA630F7F68:java.util.concurrent.CompletableFuture@43ef0e4d[Not completed]
datanode1_1  | 2021-06-25 13:42:00,337 [pool-23-thread-1] INFO server.RaftServer$Division: ee31bb40-6981-4b57-b8d7-3be03fa0c81d: new RaftServerImpl for group-BFEA630F7F68:[8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1] with ContainerStateMachine:uninitialized
datanode1_1  | 2021-06-25 13:42:00,346 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode1_1  | 2021-06-25 13:42:00,353 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode1_1  | 2021-06-25 13:42:00,354 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode1_1  | 2021-06-25 13:42:00,357 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode1_1  | 2021-06-25 13:42:00,358 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode1_1  | 2021-06-25 13:42:00,358 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode1_1  | 2021-06-25 13:42:00,359 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode1_1  | 2021-06-25 13:42:00,380 [pool-23-thread-1] INFO server.RaftServer$Division: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68: ConfigurationManager, init=-1: [8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode1_1  | 2021-06-25 13:42:00,386 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode1_1  | 2021-06-25 13:42:00,416 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode1_1  | 2021-06-25 13:42:00,423 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/3175bb45-44a8-4478-8980-bfea630f7f68 does not exist. Creating ...
datanode1_1  | 2021-06-25 13:42:00,452 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/3175bb45-44a8-4478-8980-bfea630f7f68/in_use.lock acquired by nodename 7@9d41ca97b170
datanode1_1  | 2021-06-25 13:42:00,491 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/3175bb45-44a8-4478-8980-bfea630f7f68 has been successfully formatted.
datanode1_1  | 2021-06-25 13:42:00,598 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-BFEA630F7F68: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode1_1  | 2021-06-25 13:42:00,620 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode1_1  | 2021-06-25 13:42:00,624 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode1_1  | 2021-06-25 13:42:00,883 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode1_1  | 2021-06-25 13:42:00,889 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2021-06-25 13:42:00,943 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68
datanode1_1  | 2021-06-25 13:42:01,110 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:42:01,138 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2021-06-25 13:42:01,251 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode1_1  | 2021-06-25 13:42:01,252 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode1_1  | 2021-06-25 13:42:01,324 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/3175bb45-44a8-4478-8980-bfea630f7f68
datanode1_1  | 2021-06-25 13:42:01,326 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode1_1  | 2021-06-25 13:42:01,330 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode1_1  | 2021-06-25 13:42:01,342 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2021-06-25 13:42:01,342 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode1_1  | 2021-06-25 13:42:01,346 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode1_1  | 2021-06-25 13:42:01,359 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode1_1  | 2021-06-25 13:42:01,362 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode1_1  | 2021-06-25 13:42:01,364 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode1_1  | 2021-06-25 13:42:01,435 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode1_1  | 2021-06-25 13:42:01,451 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode1_1  | 2021-06-25 13:42:01,531 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode1_1  | 2021-06-25 13:42:01,531 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode1_1  | 2021-06-25 13:42:01,589 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode1_1  | 2021-06-25 13:42:01,590 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode1_1  | 2021-06-25 13:42:01,591 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode1_1  | 2021-06-25 13:42:01,592 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode1_1  | 2021-06-25 13:42:01,599 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode1_1  | 2021-06-25 13:42:01,602 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode1_1  | 2021-06-25 13:42:01,734 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68
datanode1_1  | 2021-06-25 13:42:01,744 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68
datanode1_1  | 2021-06-25 13:42:01,798 [pool-23-thread-1] INFO server.RaftServer$Division: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68: start as a follower, conf=-1: [8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode1_1  | 2021-06-25 13:42:01,806 [pool-23-thread-1] INFO server.RaftServer$Division: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode1_1  | 2021-06-25 13:42:01,813 [pool-23-thread-1] INFO impl.RoleInfo: ee31bb40-6981-4b57-b8d7-3be03fa0c81d: start ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68-FollowerState
datanode1_1  | 2021-06-25 13:42:01,871 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-BFEA630F7F68,id=ee31bb40-6981-4b57-b8d7-3be03fa0c81d
datanode1_1  | 2021-06-25 13:42:01,909 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68
datanode1_1  | 2021-06-25 13:42:02,074 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=3175bb45-44a8-4478-8980-bfea630f7f68
datanode1_1  | 2021-06-25 13:42:02,297 [Command processor thread] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-A6C197F59B5E->8dca9ea8-5191-4cce-a34e-3d546f33f7b1
datanode1_1  | 2021-06-25 13:42:04,186 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:42:04,412 [Command processor thread] WARN commandhandler.CreatePipelineCommandHandler: Add group failed for 8dca9ea8-5191-4cce-a34e-3d546f33f7b1{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
datanode1_1  | java.io.IOException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode1_1  | 	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:92)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:217)
datanode2_1  | Sleeping for 5 seconds
datanode2_1  | Waiting for the service scm3.org:9894
datanode2_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode2_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode2_1  | 2021-06-25 13:40:29,603 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode2_1  | /************************************************************
datanode2_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode2_1  | STARTUP_MSG:   host = 2c32953938b8/172.25.0.103
datanode2_1  | STARTUP_MSG:   args = []
datanode2_1  | STARTUP_MSG:   version = 1.2.0-SNAPSHOT
datanode2_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/javax.activation-api-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.2.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0-a398b19-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.2.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.2.0-SNAPSHOT.jar
datanode2_1  | STARTUP_MSG:   build = https://github.com/apache/ozone/450c3750335593082ae39a2d17d4a2a58090f75f ; compiled by 'runner' on 2021-06-25T12:44Z
datanode2_1  | STARTUP_MSG:   java = 11.0.10
datanode2_1  | ************************************************************/
datanode2_1  | 2021-06-25 13:40:29,755 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode2_1  | 2021-06-25 13:40:32,437 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode2_1  | 2021-06-25 13:40:33,314 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode2_1  | 2021-06-25 13:40:34,346 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode2_1  | 2021-06-25 13:40:34,346 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode2_1  | 2021-06-25 13:40:35,369 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:2c32953938b8 ip:172.25.0.103
datanode2_1  | 2021-06-25 13:40:39,686 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/dn@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode2_1  | 2021-06-25 13:40:41,336 [main] INFO security.UserGroupInformation: Login successful for user dn/dn@EXAMPLE.COM using keytab file /etc/security/keytabs/dn.keytab
datanode2_1  | 2021-06-25 13:40:41,345 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
datanode2_1  | 2021-06-25 13:40:43,278 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
datanode2_1  | 2021-06-25 13:40:43,282 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode2_1  | 2021-06-25 13:40:43,282 [main] INFO client.DNCertificateClient: Certificate client init case: 0
datanode2_1  | 2021-06-25 13:40:43,287 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode2_1  | 2021-06-25 13:40:48,316 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
datanode2_1  | 2021-06-25 13:40:48,658 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.103,host:2c32953938b8
datanode2_1  | 2021-06-25 13:40:48,662 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode2_1  | 2021-06-25 13:40:48,705 [main] ERROR client.DNCertificateClient: Invalid domain 2c32953938b8
datanode2_1  | 2021-06-25 13:40:48,722 [main] INFO ozone.HddsDatanodeService: Creating csr for DN-> subject:root@2c32953938b8
datanode2_1  | 2021-06-25 13:40:53,416 [main] INFO client.DNCertificateClient: Loading certificate from location:/data/metadata/dn/certs.
datanode2_1  | 2021-06-25 13:40:53,466 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/ROOTCA-1.crt.
datanode2_1  | 2021-06-25 13:40:53,519 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/CA-2884006640668.crt.
datanode2_1  | 2021-06-25 13:40:53,542 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/2982768810642.crt.
datanode2_1  | 2021-06-25 13:40:53,544 [main] INFO ozone.HddsDatanodeService: Successfully stored SCM signed certificate, case:GETCERT.
datanode2_1  | 2021-06-25 13:40:55,019 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode2_1  | 2021-06-25 13:40:55,127 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89311358976
datanode2_1  | 2021-06-25 13:40:55,141 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode2_1  | 2021-06-25 13:40:55,177 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode2_1  | 2021-06-25 13:40:55,453 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode2_1  | 2021-06-25 13:40:55,754 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode2_1  | 2021-06-25 13:40:55,757 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode2_1  | 2021-06-25 13:40:55,782 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode2_1  | 2021-06-25 13:40:56,000 [main] INFO ozoneimpl.ContainerReader: Running in upgrade mode:true
datanode2_1  | 2021-06-25 13:40:56,055 [Thread-8] INFO ozoneimpl.ContainerReader: Start to verify containers on volume /data/hdds/hdds
datanode2_1  | 2021-06-25 13:40:56,081 [Thread-8] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode2_1  | 2021-06-25 13:40:56,081 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode2_1  | 2021-06-25 13:41:05,731 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode2_1  | 2021-06-25 13:41:06,278 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode2_1  | 2021-06-25 13:41:07,694 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode2_1  | 2021-06-25 13:41:07,695 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode2_1  | 2021-06-25 13:41:07,698 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode2_1  | 2021-06-25 13:41:07,701 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode2_1  | 2021-06-25 13:41:07,723 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2021-06-25 13:41:07,724 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode2_1  | 2021-06-25 13:41:07,728 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode2_1  | 2021-06-25 13:41:16,510 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode2_1  | 2021-06-25 13:41:16,520 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode2_1  | 2021-06-25 13:41:16,534 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode2_1  | 2021-06-25 13:41:16,661 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2021-06-25 13:41:19,691 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode2_1  | 2021-06-25 13:41:19,691 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode2_1  | 2021-06-25 13:41:19,691 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.datanode.http.auth.type = kerberos
datanode2_1  | 2021-06-25 13:41:19,906 [main] INFO util.log: Logging initialized @61030ms to org.eclipse.jetty.util.log.Slf4jLog
datanode2_1  | 2021-06-25 13:41:20,901 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode2_1  | 2021-06-25 13:41:20,959 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode2_1  | 2021-06-25 13:41:20,967 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode2_1  | 2021-06-25 13:41:20,974 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode2_1  | 2021-06-25 13:41:20,974 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode2_1  | 2021-06-25 13:41:20,991 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.datanode.http.auth.kerberos.principal keytabKey: hdds.datanode.http.auth.kerberos.keytab
datanode2_1  | 2021-06-25 13:41:21,246 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode2_1  | 2021-06-25 13:41:21,260 [main] INFO server.Server: jetty-9.4.35.v20201120; built: 2020-11-20T21:17:03.964Z; git: bdc54f03a5e0a7e280fab27f55c3c75ee8da89fb; jvm 11.0.10+9-LTS
datanode2_1  | 2021-06-25 13:41:21,549 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode2_1  | 2021-06-25 13:41:21,562 [main] INFO server.session: No SessionScavenger set, using defaults
datanode2_1  | 2021-06-25 13:41:21,564 [main] INFO server.session: node0 Scavenging every 600000ms
datanode2_1  | 2021-06-25 13:41:21,716 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode2_1  | 2021-06-25 13:41:21,741 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@68aa1164{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode2_1  | 2021-06-25 13:41:21,752 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5345552f{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode2_1  | 2021-06-25 13:41:22,257 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode2_1  | 2021-06-25 13:41:22,358 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@79aa675b{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_2_0-SNAPSHOT_jar-_-any-13447676649370976133/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode2_1  | 2021-06-25 13:41:22,412 [main] INFO server.AbstractConnector: Started ServerConnector@5b5e45bc{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode2_1  | 2021-06-25 13:41:22,412 [main] INFO server.Server: Started @63536ms
datanode2_1  | 2021-06-25 13:41:22,434 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode2_1  | 2021-06-25 13:41:22,434 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode2_1  | 2021-06-25 13:41:22,437 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode2_1  | 2021-06-25 13:41:22,563 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7bf48f8e] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode2_1  | 2021-06-25 13:41:23,151 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.25.0.115:9891
datanode2_1  | 2021-06-25 13:41:25,704 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode2_1  | 2021-06-25 13:41:25,713 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode2_1  | 2021-06-25 13:41:26,230 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 8dca9ea8-5191-4cce-a34e-3d546f33f7b1
datanode2_1  | 2021-06-25 13:41:26,347 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.RaftServer: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1: start RPC server
datanode2_1  | 2021-06-25 13:41:26,356 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.GrpcService: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1: GrpcService started, listening on 9856
datanode2_1  | 2021-06-25 13:41:26,363 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.GrpcService: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1: GrpcService started, listening on 9857
datanode2_1  | 2021-06-25 13:41:26,368 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.GrpcService: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1: GrpcService started, listening on 9858
datanode2_1  | 2021-06-25 13:41:26,381 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 8dca9ea8-5191-4cce-a34e-3d546f33f7b1 is started using port 9858 for RATIS
datanode2_1  | 2021-06-25 13:41:26,381 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 8dca9ea8-5191-4cce-a34e-3d546f33f7b1 is started using port 9857 for RATIS_ADMIN
datanode2_1  | 2021-06-25 13:41:26,393 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 8dca9ea8-5191-4cce-a34e-3d546f33f7b1 is started using port 9856 for RATIS_SERVER
datanode2_1  | 2021-06-25 13:41:26,425 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$323/0x0000000840576840@4ac53eae] INFO util.JvmPauseMonitor: JvmPauseMonitor-8dca9ea8-5191-4cce-a34e-3d546f33f7b1: Started
datanode2_1  | 2021-06-25 13:41:26,456 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode2_1  | 2021-06-25 13:41:26,456 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode2_1  | 2021-06-25 13:41:28,947 [Datanode State Machine Thread - 0] ERROR datanode.RunningDatanodeState: Error in executing end point task.
datanode2_1  | java.util.concurrent.ExecutionException: java.util.concurrent.TimeoutException
datanode2_1  | 	at java.base/java.util.concurrent.FutureTask.report(FutureTask.java:122)
datanode2_1  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:191)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:191)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:231)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:50)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:629)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:244)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:429)
datanode2_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode2_1  | Caused by: java.util.concurrent.TimeoutException
datanode2_1  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:204)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.lambda$execute$0(RunningDatanodeState.java:149)
datanode2_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode2_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode2_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode2_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode2_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode2_1  | 	... 1 more
datanode2_1  | 2021-06-25 13:41:29,041 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:41:32,134 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:41:35,178 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:41:38,251 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:41:41,322 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:41:44,396 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:41:47,468 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:41:50,542 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:41:53,614 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:41:56,682 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:41:59,754 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:42:00,011 [Command processor thread] INFO server.RaftServer: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1: addNew group-A0D73E1F71D5:[8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1] returns group-A0D73E1F71D5:java.util.concurrent.CompletableFuture@2188c975[Not completed]
datanode2_1  | 2021-06-25 13:42:00,177 [pool-23-thread-1] INFO server.RaftServer$Division: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1: new RaftServerImpl for group-A0D73E1F71D5:[8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1] with ContainerStateMachine:uninitialized
datanode2_1  | 2021-06-25 13:42:00,198 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode2_1  | 2021-06-25 13:42:00,206 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode2_1  | 2021-06-25 13:42:00,206 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode2_1  | 2021-06-25 13:42:00,206 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode2_1  | 2021-06-25 13:42:00,208 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode2_1  | 2021-06-25 13:42:00,209 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode2_1  | 2021-06-25 13:42:00,210 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | 2021-06-25 13:42:00,241 [pool-23-thread-1] INFO server.RaftServer$Division: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-A0D73E1F71D5: ConfigurationManager, init=-1: [8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode2_1  | 2021-06-25 13:42:00,241 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2021-06-25 13:42:00,253 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode2_1  | 2021-06-25 13:42:00,267 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/33fecaa5-f059-4c14-a3bf-a0d73e1f71d5 does not exist. Creating ...
datanode2_1  | 2021-06-25 13:42:00,302 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/33fecaa5-f059-4c14-a3bf-a0d73e1f71d5/in_use.lock acquired by nodename 8@2c32953938b8
datanode2_1  | 2021-06-25 13:42:00,325 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/33fecaa5-f059-4c14-a3bf-a0d73e1f71d5 has been successfully formatted.
datanode2_1  | 2021-06-25 13:42:00,404 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-A0D73E1F71D5: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode2_1  | 2021-06-25 13:42:00,416 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode2_1  | 2021-06-25 13:42:00,429 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode2_1  | 2021-06-25 13:42:00,468 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode2_1  | 2021-06-25 13:42:00,476 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2021-06-25 13:42:00,599 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-A0D73E1F71D5
datanode2_1  | 2021-06-25 13:42:00,742 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2021-06-25 13:42:00,815 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode2_1  | 2021-06-25 13:42:00,824 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode2_1  | 2021-06-25 13:42:00,860 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-A0D73E1F71D5-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/33fecaa5-f059-4c14-a3bf-a0d73e1f71d5
datanode2_1  | 2021-06-25 13:42:00,868 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode2_1  | 2021-06-25 13:42:00,882 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode2_1  | 2021-06-25 13:42:00,889 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2021-06-25 13:42:00,895 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode2_1  | 2021-06-25 13:42:00,905 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode2_1  | 2021-06-25 13:42:00,911 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode2_1  | 2021-06-25 13:42:00,928 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode2_1  | 2021-06-25 13:42:00,929 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode2_1  | 2021-06-25 13:42:01,030 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode2_1  | 2021-06-25 13:42:01,037 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode2_1  | 2021-06-25 13:42:01,108 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-A0D73E1F71D5-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode2_1  | 2021-06-25 13:42:01,117 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-A0D73E1F71D5-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode2_1  | 2021-06-25 13:42:01,121 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode2_1  | 2021-06-25 13:42:01,142 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode2_1  | 2021-06-25 13:42:01,143 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode2_1  | 2021-06-25 13:42:01,149 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode2_1  | 2021-06-25 13:42:01,155 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode2_1  | 2021-06-25 13:42:01,166 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode2_1  | 2021-06-25 13:42:01,354 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-A0D73E1F71D5
datanode2_1  | 2021-06-25 13:42:01,401 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-A0D73E1F71D5
datanode2_1  | 2021-06-25 13:42:01,462 [pool-23-thread-1] INFO server.RaftServer$Division: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-A0D73E1F71D5: start as a follower, conf=-1: [8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1], old=null
datanode2_1  | 2021-06-25 13:42:01,470 [pool-23-thread-1] INFO server.RaftServer$Division: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-A0D73E1F71D5: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode2_1  | 2021-06-25 13:42:01,471 [pool-23-thread-1] INFO impl.RoleInfo: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1: start 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-A0D73E1F71D5-FollowerState
datanode2_1  | 2021-06-25 13:42:01,551 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A0D73E1F71D5,id=8dca9ea8-5191-4cce-a34e-3d546f33f7b1
datanode2_1  | 2021-06-25 13:42:01,553 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-A0D73E1F71D5
datanode2_1  | 2021-06-25 13:42:01,701 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=33fecaa5-f059-4c14-a3bf-a0d73e1f71d5
datanode2_1  | 2021-06-25 13:42:01,715 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=33fecaa5-f059-4c14-a3bf-a0d73e1f71d5.
datanode2_1  | 2021-06-25 13:42:01,718 [Command processor thread] INFO server.RaftServer: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1: addNew group-BFEA630F7F68:[8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1] returns group-BFEA630F7F68:java.util.concurrent.CompletableFuture@38f9eb6d[Not completed]
datanode2_1  | 2021-06-25 13:42:01,736 [pool-23-thread-1] INFO server.RaftServer$Division: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1: new RaftServerImpl for group-BFEA630F7F68:[8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1] with ContainerStateMachine:uninitialized
datanode2_1  | 2021-06-25 13:42:01,745 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode2_1  | 2021-06-25 13:42:01,745 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode2_1  | 2021-06-25 13:42:01,745 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode2_1  | 2021-06-25 13:42:01,745 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode2_1  | 2021-06-25 13:42:01,746 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode2_1  | 2021-06-25 13:42:01,755 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode2_1  | 2021-06-25 13:42:01,756 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | 2021-06-25 13:42:01,756 [pool-23-thread-1] INFO server.RaftServer$Division: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68: ConfigurationManager, init=-1: [8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode2_1  | 2021-06-25 13:42:01,758 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2021-06-25 13:42:01,759 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode2_1  | 2021-06-25 13:42:01,759 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/3175bb45-44a8-4478-8980-bfea630f7f68 does not exist. Creating ...
datanode2_1  | 2021-06-25 13:42:01,761 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/3175bb45-44a8-4478-8980-bfea630f7f68/in_use.lock acquired by nodename 8@2c32953938b8
datanode2_1  | 2021-06-25 13:42:01,766 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/3175bb45-44a8-4478-8980-bfea630f7f68 has been successfully formatted.
datanode2_1  | 2021-06-25 13:42:01,767 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-BFEA630F7F68: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode2_1  | 2021-06-25 13:42:01,803 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode2_1  | 2021-06-25 13:42:01,816 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode2_1  | 2021-06-25 13:42:01,819 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode2_1  | 2021-06-25 13:42:01,828 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2021-06-25 13:42:01,833 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68
datanode2_1  | 2021-06-25 13:42:01,834 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2021-06-25 13:42:01,836 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode2_1  | 2021-06-25 13:42:01,838 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode2_1  | 2021-06-25 13:42:01,838 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/3175bb45-44a8-4478-8980-bfea630f7f68
datanode2_1  | 2021-06-25 13:42:01,841 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode2_1  | 2021-06-25 13:42:01,844 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode2_1  | 2021-06-25 13:42:01,844 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2021-06-25 13:42:01,845 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode2_1  | 2021-06-25 13:42:01,849 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode2_1  | 2021-06-25 13:42:01,850 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode2_1  | 2021-06-25 13:42:01,851 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode2_1  | 2021-06-25 13:42:01,852 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode2_1  | 2021-06-25 13:42:01,860 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode2_1  | 2021-06-25 13:42:01,879 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode2_1  | 2021-06-25 13:42:01,881 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode2_1  | 2021-06-25 13:42:01,886 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode2_1  | 2021-06-25 13:42:01,890 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode2_1  | 2021-06-25 13:42:01,894 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode2_1  | 2021-06-25 13:42:01,898 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode2_1  | 2021-06-25 13:42:01,898 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode2_1  | 2021-06-25 13:42:01,898 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode2_1  | 2021-06-25 13:42:01,898 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode2_1  | 2021-06-25 13:42:01,899 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68
datanode2_1  | 2021-06-25 13:42:01,899 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68
datanode2_1  | 2021-06-25 13:42:01,900 [pool-23-thread-1] INFO server.RaftServer$Division: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68: start as a follower, conf=-1: [8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode2_1  | 2021-06-25 13:42:01,902 [pool-23-thread-1] INFO server.RaftServer$Division: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode2_1  | 2021-06-25 13:42:01,904 [pool-23-thread-1] INFO impl.RoleInfo: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1: start 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-FollowerState
datanode2_1  | 2021-06-25 13:42:01,907 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-BFEA630F7F68,id=8dca9ea8-5191-4cce-a34e-3d546f33f7b1
datanode2_1  | 2021-06-25 13:42:01,907 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68
datanode2_1  | 2021-06-25 13:42:01,920 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=3175bb45-44a8-4478-8980-bfea630f7f68
datanode2_1  | 2021-06-25 13:42:02,206 [Command processor thread] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-6C25A7B57905->ee31bb40-6981-4b57-b8d7-3be03fa0c81d
datanode2_1  | 2021-06-25 13:42:02,829 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:42:04,506 [Command processor thread] WARN commandhandler.CreatePipelineCommandHandler: Add group failed for ee31bb40-6981-4b57-b8d7-3be03fa0c81d{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
datanode2_1  | java.io.IOException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode2_1  | 	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:92)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:217)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:178)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:96)
datanode2_1  | 	at org.apache.ratis.client.impl.BlockingImpl.sendRequest(BlockingImpl.java:130)
datanode2_1  | 	at org.apache.ratis.client.impl.GroupManagementImpl.add(GroupManagementImpl.java:51)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.lambda$handle$1(CreatePipelineCommandHandler.java:99)
datanode2_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
datanode2_1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:178)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:96)
datanode1_1  | 	at org.apache.ratis.client.impl.BlockingImpl.sendRequest(BlockingImpl.java:130)
datanode1_1  | 	at org.apache.ratis.client.impl.GroupManagementImpl.add(GroupManagementImpl.java:51)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.lambda$handle$1(CreatePipelineCommandHandler.java:99)
datanode1_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
datanode1_1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
datanode1_1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655)
datanode1_1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
datanode1_1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
datanode1_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
datanode1_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
datanode1_1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
datanode1_1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:95)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$2(DatanodeStateMachine.java:525)
datanode1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode1_1  | Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:262)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:243)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:156)
datanode1_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:413)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$5(GrpcClientProtocolClient.java:180)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:215)
datanode1_1  | 	... 18 more
datanode1_1  | 2021-06-25 13:42:04,444 [Command processor thread] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-624595E6C1F0->d7f71981-d306-415b-992d-ee4808a385fa
datanode1_1  | 2021-06-25 13:42:05,311 [Command processor thread] WARN commandhandler.CreatePipelineCommandHandler: Add group failed for d7f71981-d306-415b-992d-ee4808a385fa{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
datanode1_1  | java.io.IOException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode1_1  | 	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:92)
kdc_1        | Jun 25 13:38:44 kdc krb5kdc[8](info): Loaded
kdc_1        | Jun 25 13:38:44 kdc krb5kdc[8](Error): preauth spake failed to initialize: No SPAKE preauth groups configured
kdc_1        | Jun 25 13:38:44 kdc krb5kdc[8](info): setting up network...
kdc_1        | Jun 25 13:38:44 kdc krb5kdc[8](info): setsockopt(8,IPV6_V6ONLY,1) worked
kdc_1        | Jun 25 13:38:44 kdc krb5kdc[8](info): setsockopt(10,IPV6_V6ONLY,1) worked
kdc_1        | Jun 25 13:38:44 kdc krb5kdc[8](info): set up 4 sockets
kdc_1        | Jun 25 13:38:44 kdc krb5kdc[8](info): commencing operation
kdc_1        | krb5kdc: starting...
kdc_1        | Jun 25 13:38:50 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624628330, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:39:09 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624628349, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:39:21 kdc krb5kdc[8](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.117: ISSUE: authtime 1624628361, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:39:26 kdc krb5kdc[8](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.116: ISSUE: authtime 1624628366, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:39:32 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628349, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:39:33 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624628361, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:39:42 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624628382, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:39:49 kdc krb5kdc[8](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.117: ISSUE: authtime 1624628389, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:39:49 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628382, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:39:53 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624628393, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:39:54 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624628389, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:40:00 kdc krb5kdc[8](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.118: ISSUE: authtime 1624628400, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:40:02 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.118: ISSUE: authtime 1624628400, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:40:04 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628393, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:40:08 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624628408, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:40:10 kdc krb5kdc[8](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.118: ISSUE: authtime 1624628410, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:40:16 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628408, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:40:20 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624628420, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:40:20 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.118: ISSUE: authtime 1624628410, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:40:39 kdc krb5kdc[8](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.102: ISSUE: authtime 1624628439, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:40:39 kdc krb5kdc[8](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.104: ISSUE: authtime 1624628439, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:40:40 kdc krb5kdc[8](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.103: ISSUE: authtime 1624628440, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:40:43 kdc krb5kdc[8](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.113: ISSUE: authtime 1624628443, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:40:44 kdc krb5kdc[8](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.112: ISSUE: authtime 1624628444, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:40:44 kdc krb5kdc[8](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.111: ISSUE: authtime 1624628444, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:40:48 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.113: ISSUE: authtime 1624628443, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:40:48 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.112: ISSUE: authtime 1624628444, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:40:49 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.111: ISSUE: authtime 1624628444, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:40:51 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.102: ISSUE: authtime 1624628439, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:40:52 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.103: ISSUE: authtime 1624628440, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:40:52 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.104: ISSUE: authtime 1624628439, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:40:56 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628420, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:41:04 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624628464, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:41:26 kdc krb5kdc[8](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.113: ISSUE: authtime 1624628486, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:41:28 kdc krb5kdc[8](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.111: ISSUE: authtime 1624628488, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:41:29 kdc krb5kdc[8](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.112: ISSUE: authtime 1624628489, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:41:32 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.113: ISSUE: authtime 1624628486, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
datanode3_1  | Sleeping for 5 seconds
datanode3_1  | Waiting for the service scm3.org:9894
datanode3_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode3_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode3_1  | 2021-06-25 13:40:28,327 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode3_1  | /************************************************************
datanode3_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode3_1  | STARTUP_MSG:   host = 7b9eb44ecf31/172.25.0.104
datanode3_1  | STARTUP_MSG:   args = []
datanode3_1  | STARTUP_MSG:   version = 1.2.0-SNAPSHOT
datanode2_1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655)
datanode2_1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
datanode2_1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
datanode2_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
datanode2_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
datanode2_1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
datanode2_1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:95)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$2(DatanodeStateMachine.java:525)
datanode2_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode2_1  | Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:262)
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:243)
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:156)
datanode2_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:413)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$5(GrpcClientProtocolClient.java:180)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:215)
datanode2_1  | 	... 18 more
datanode2_1  | 2021-06-25 13:42:04,515 [Command processor thread] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-0B1FA96C1AD4->d7f71981-d306-415b-992d-ee4808a385fa
datanode2_1  | 2021-06-25 13:42:05,309 [Command processor thread] WARN commandhandler.CreatePipelineCommandHandler: Add group failed for d7f71981-d306-415b-992d-ee4808a385fa{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
datanode2_1  | java.io.IOException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode2_1  | 	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:92)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:217)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:178)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:96)
datanode2_1  | 	at org.apache.ratis.client.impl.BlockingImpl.sendRequest(BlockingImpl.java:130)
datanode2_1  | 	at org.apache.ratis.client.impl.GroupManagementImpl.add(GroupManagementImpl.java:51)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.lambda$handle$1(CreatePipelineCommandHandler.java:99)
datanode2_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
datanode2_1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
datanode2_1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655)
datanode2_1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
datanode2_1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
datanode2_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
datanode2_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
datanode2_1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
datanode2_1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:95)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$2(DatanodeStateMachine.java:525)
datanode2_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode2_1  | Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:262)
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:243)
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:156)
datanode2_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:413)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$5(GrpcClientProtocolClient.java:180)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:215)
datanode2_1  | 	... 18 more
datanode2_1  | 2021-06-25 13:42:05,325 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=3175bb45-44a8-4478-8980-bfea630f7f68.
datanode2_1  | 2021-06-25 13:42:05,334 [pool-23-thread-1] INFO server.RaftServer$Division: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1: new RaftServerImpl for group-5191BE84CAB1:[8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1, d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0] with ContainerStateMachine:uninitialized
datanode2_1  | 2021-06-25 13:42:05,340 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode2_1  | 2021-06-25 13:42:05,342 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode2_1  | 2021-06-25 13:42:05,343 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode2_1  | 2021-06-25 13:42:05,343 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode2_1  | 2021-06-25 13:42:05,344 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode2_1  | 2021-06-25 13:42:05,344 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode2_1  | 2021-06-25 13:42:05,344 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:217)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:178)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:96)
datanode1_1  | 	at org.apache.ratis.client.impl.BlockingImpl.sendRequest(BlockingImpl.java:130)
datanode1_1  | 	at org.apache.ratis.client.impl.GroupManagementImpl.add(GroupManagementImpl.java:51)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.lambda$handle$1(CreatePipelineCommandHandler.java:99)
datanode1_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
datanode1_1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
datanode1_1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655)
datanode1_1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
datanode1_1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
datanode1_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
datanode1_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
datanode1_1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
datanode1_1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:95)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$2(DatanodeStateMachine.java:525)
datanode1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode1_1  | Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:262)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:243)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:156)
datanode1_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:413)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$5(GrpcClientProtocolClient.java:180)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:215)
datanode1_1  | 	... 18 more
datanode1_1  | 2021-06-25 13:42:05,312 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=3175bb45-44a8-4478-8980-bfea630f7f68.
datanode1_1  | 2021-06-25 13:42:05,314 [pool-23-thread-1] INFO server.RaftServer$Division: ee31bb40-6981-4b57-b8d7-3be03fa0c81d: new RaftServerImpl for group-5191BE84CAB1:[8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1, d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0] with ContainerStateMachine:uninitialized
datanode1_1  | 2021-06-25 13:42:05,314 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode1_1  | 2021-06-25 13:42:05,315 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode1_1  | 2021-06-25 13:42:05,315 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode1_1  | 2021-06-25 13:42:05,315 [Command processor thread] INFO server.RaftServer: ee31bb40-6981-4b57-b8d7-3be03fa0c81d: addNew group-5191BE84CAB1:[8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1, d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0] returns group-5191BE84CAB1:java.util.concurrent.CompletableFuture@1719a0ca[Not completed]
datanode1_1  | 2021-06-25 13:42:05,318 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode1_1  | 2021-06-25 13:42:05,318 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode1_1  | 2021-06-25 13:42:05,318 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode1_1  | 2021-06-25 13:42:05,318 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode1_1  | 2021-06-25 13:42:05,318 [pool-23-thread-1] INFO server.RaftServer$Division: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1: ConfigurationManager, init=-1: [8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1, d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0], old=null, confs=<EMPTY_MAP>
datanode1_1  | 2021-06-25 13:42:05,319 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode1_1  | 2021-06-25 13:42:05,319 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode1_1  | 2021-06-25 13:42:05,320 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/949dd475-00f3-4295-9774-5191be84cab1 does not exist. Creating ...
datanode1_1  | 2021-06-25 13:42:05,328 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/949dd475-00f3-4295-9774-5191be84cab1/in_use.lock acquired by nodename 7@9d41ca97b170
datanode1_1  | 2021-06-25 13:42:05,331 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/949dd475-00f3-4295-9774-5191be84cab1 has been successfully formatted.
datanode1_1  | 2021-06-25 13:42:05,332 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-5191BE84CAB1: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode1_1  | 2021-06-25 13:42:05,358 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode1_1  | 2021-06-25 13:42:05,362 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode1_1  | 2021-06-25 13:42:05,368 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode1_1  | 2021-06-25 13:42:05,368 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2021-06-25 13:42:05,369 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1
datanode1_1  | 2021-06-25 13:42:05,369 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2021-06-25 13:42:05,373 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
kdc_1        | Jun 25 13:41:33 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.111: ISSUE: authtime 1624628488, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:41:33 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.112: ISSUE: authtime 1624628489, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:41:35 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628464, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:41:40 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624628500, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:41:52 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628500, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:41:56 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624628516, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:42:05 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628516, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:42:09 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624628529, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:42:14 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628529, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:42:18 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624628538, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:42:22 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628538, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:42:26 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624628546, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:42:31 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628546, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:42:33 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624628553, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:42:38 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628553, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:42:45 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624628565, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:42:57 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628565, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode2_1  | 2021-06-25 13:42:05,344 [pool-23-thread-1] INFO server.RaftServer$Division: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-5191BE84CAB1: ConfigurationManager, init=-1: [8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1, d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0], old=null, confs=<EMPTY_MAP>
datanode2_1  | 2021-06-25 13:42:05,345 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2021-06-25 13:42:05,345 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode2_1  | 2021-06-25 13:42:05,348 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/949dd475-00f3-4295-9774-5191be84cab1 does not exist. Creating ...
datanode2_1  | 2021-06-25 13:42:05,349 [Command processor thread] INFO server.RaftServer: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1: addNew group-5191BE84CAB1:[8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1, d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0] returns group-5191BE84CAB1:java.util.concurrent.CompletableFuture@5d4288df[Not completed]
datanode2_1  | 2021-06-25 13:42:05,360 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/949dd475-00f3-4295-9774-5191be84cab1/in_use.lock acquired by nodename 8@2c32953938b8
datanode2_1  | 2021-06-25 13:42:05,364 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/949dd475-00f3-4295-9774-5191be84cab1 has been successfully formatted.
datanode2_1  | 2021-06-25 13:42:05,365 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-5191BE84CAB1: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode2_1  | 2021-06-25 13:42:05,365 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode2_1  | 2021-06-25 13:42:05,365 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode2_1  | 2021-06-25 13:42:05,365 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode2_1  | 2021-06-25 13:42:05,365 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2021-06-25 13:42:05,365 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-5191BE84CAB1
datanode2_1  | 2021-06-25 13:42:05,366 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2021-06-25 13:42:05,366 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode2_1  | 2021-06-25 13:42:05,366 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode2_1  | 2021-06-25 13:42:05,366 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-5191BE84CAB1-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/949dd475-00f3-4295-9774-5191be84cab1
datanode2_1  | 2021-06-25 13:42:05,366 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode2_1  | 2021-06-25 13:42:05,366 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode2_1  | 2021-06-25 13:42:05,366 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2021-06-25 13:42:05,366 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode2_1  | 2021-06-25 13:42:05,366 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode2_1  | 2021-06-25 13:42:05,367 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode2_1  | 2021-06-25 13:42:05,367 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode2_1  | 2021-06-25 13:42:05,367 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode2_1  | 2021-06-25 13:42:05,367 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode2_1  | 2021-06-25 13:42:05,376 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode2_1  | 2021-06-25 13:42:05,378 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-5191BE84CAB1-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode2_1  | 2021-06-25 13:42:05,380 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-5191BE84CAB1-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode2_1  | 2021-06-25 13:42:05,380 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode2_1  | 2021-06-25 13:42:05,380 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode2_1  | 2021-06-25 13:42:05,380 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode2_1  | 2021-06-25 13:42:05,380 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode2_1  | 2021-06-25 13:42:05,380 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode2_1  | 2021-06-25 13:42:05,380 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode2_1  | 2021-06-25 13:42:05,381 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-5191BE84CAB1
datanode2_1  | 2021-06-25 13:42:05,388 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-5191BE84CAB1
datanode2_1  | 2021-06-25 13:42:05,389 [pool-23-thread-1] INFO server.RaftServer$Division: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-5191BE84CAB1: start as a follower, conf=-1: [8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1, d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0], old=null
datanode2_1  | 2021-06-25 13:42:05,389 [pool-23-thread-1] INFO server.RaftServer$Division: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-5191BE84CAB1: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode2_1  | 2021-06-25 13:42:05,389 [pool-23-thread-1] INFO impl.RoleInfo: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1: start 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-5191BE84CAB1-FollowerState
datanode2_1  | 2021-06-25 13:42:05,402 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-5191BE84CAB1,id=8dca9ea8-5191-4cce-a34e-3d546f33f7b1
datanode2_1  | 2021-06-25 13:42:05,403 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-5191BE84CAB1
datanode2_1  | 2021-06-25 13:42:05,406 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=949dd475-00f3-4295-9774-5191be84cab1
kdc_1        | Jun 25 13:43:10 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628565, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:43:16 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628565, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:43:23 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628565, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:43:32 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628565, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:43:39 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628565, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:43:45 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628565, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:43:51 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628565, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:44:08 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628565, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:44:13 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628565, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:44:18 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628565, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:44:23 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628565, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:44:32 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628565, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:44:38 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628565, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:44:42 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628565, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:44:47 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628565, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:44:52 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628565, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:44:58 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628565, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:45:03 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628565, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode3_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/javax.activation-api-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.2.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0-a398b19-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.2.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.2.0-SNAPSHOT.jar
datanode3_1  | STARTUP_MSG:   build = https://github.com/apache/ozone/450c3750335593082ae39a2d17d4a2a58090f75f ; compiled by 'runner' on 2021-06-25T12:44Z
datanode3_1  | STARTUP_MSG:   java = 11.0.10
datanode3_1  | ************************************************************/
datanode3_1  | 2021-06-25 13:40:28,430 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode3_1  | 2021-06-25 13:40:31,263 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode3_1  | 2021-06-25 13:40:32,190 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode3_1  | 2021-06-25 13:40:33,417 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode3_1  | 2021-06-25 13:40:33,421 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode3_1  | 2021-06-25 13:40:34,535 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:7b9eb44ecf31 ip:172.25.0.104
datanode3_1  | 2021-06-25 13:40:38,438 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/dn@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode3_1  | 2021-06-25 13:40:40,165 [main] INFO security.UserGroupInformation: Login successful for user dn/dn@EXAMPLE.COM using keytab file /etc/security/keytabs/dn.keytab
datanode3_1  | 2021-06-25 13:40:40,182 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
datanode3_1  | 2021-06-25 13:40:42,032 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
datanode3_1  | 2021-06-25 13:40:42,032 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode3_1  | 2021-06-25 13:40:42,032 [main] INFO client.DNCertificateClient: Certificate client init case: 0
datanode3_1  | 2021-06-25 13:40:42,071 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode3_1  | 2021-06-25 13:40:50,079 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
datanode3_1  | 2021-06-25 13:40:50,210 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.104,host:7b9eb44ecf31
datanode3_1  | 2021-06-25 13:40:50,210 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode3_1  | 2021-06-25 13:40:50,235 [main] ERROR client.DNCertificateClient: Invalid domain 7b9eb44ecf31
datanode3_1  | 2021-06-25 13:40:50,236 [main] INFO ozone.HddsDatanodeService: Creating csr for DN-> subject:root@7b9eb44ecf31
datanode3_1  | 2021-06-25 13:40:54,480 [main] INFO client.DNCertificateClient: Loading certificate from location:/data/metadata/dn/certs.
datanode3_1  | 2021-06-25 13:40:54,587 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/ROOTCA-1.crt.
datanode3_1  | 2021-06-25 13:40:54,604 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/CA-2884006640668.crt.
datanode3_1  | 2021-06-25 13:40:54,628 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/2983272084503.crt.
datanode3_1  | 2021-06-25 13:40:54,634 [main] INFO ozone.HddsDatanodeService: Successfully stored SCM signed certificate, case:GETCERT.
datanode3_1  | 2021-06-25 13:40:55,997 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode3_1  | 2021-06-25 13:40:56,090 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89311358976
datanode3_1  | 2021-06-25 13:40:56,127 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode3_1  | 2021-06-25 13:40:56,208 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode3_1  | 2021-06-25 13:40:56,483 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode3_1  | 2021-06-25 13:40:57,044 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode3_1  | 2021-06-25 13:40:57,074 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode3_1  | 2021-06-25 13:40:57,086 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode3_1  | 2021-06-25 13:40:57,347 [main] INFO ozoneimpl.ContainerReader: Running in upgrade mode:true
datanode3_1  | 2021-06-25 13:40:57,373 [Thread-8] INFO ozoneimpl.ContainerReader: Start to verify containers on volume /data/hdds/hdds
datanode3_1  | 2021-06-25 13:40:57,378 [Thread-8] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode3_1  | 2021-06-25 13:40:57,382 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode3_1  | 2021-06-25 13:41:06,404 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode3_1  | 2021-06-25 13:41:07,324 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode3_1  | 2021-06-25 13:41:08,015 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode3_1  | 2021-06-25 13:41:08,024 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode3_1  | 2021-06-25 13:41:08,041 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode3_1  | 2021-06-25 13:41:08,042 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode3_1  | 2021-06-25 13:41:08,044 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2021-06-25 13:41:08,045 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode3_1  | 2021-06-25 13:41:08,059 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode3_1  | 2021-06-25 13:41:15,140 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode2_1  | 2021-06-25 13:42:05,421 [Command processor thread] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-F56DD875BFF6->ee31bb40-6981-4b57-b8d7-3be03fa0c81d
datanode2_1  | 2021-06-25 13:42:05,912 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:42:06,001 [Command processor thread] WARN commandhandler.CreatePipelineCommandHandler: Add group failed for ee31bb40-6981-4b57-b8d7-3be03fa0c81d{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
datanode2_1  | java.io.IOException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode2_1  | 	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:92)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:217)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:178)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:96)
datanode2_1  | 	at org.apache.ratis.client.impl.BlockingImpl.sendRequest(BlockingImpl.java:130)
datanode2_1  | 	at org.apache.ratis.client.impl.GroupManagementImpl.add(GroupManagementImpl.java:51)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.lambda$handle$1(CreatePipelineCommandHandler.java:99)
datanode2_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
datanode2_1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
datanode2_1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655)
datanode2_1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
datanode2_1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
datanode2_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
datanode2_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
datanode2_1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
datanode2_1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:95)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$2(DatanodeStateMachine.java:525)
datanode2_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode2_1  | Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:262)
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:243)
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:156)
datanode2_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:413)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$5(GrpcClientProtocolClient.java:180)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:215)
datanode2_1  | 	... 18 more
datanode2_1  | 2021-06-25 13:42:06,004 [Command processor thread] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-4953502A1FEC->d7f71981-d306-415b-992d-ee4808a385fa
datanode2_1  | 2021-06-25 13:42:06,258 [Command processor thread] WARN commandhandler.CreatePipelineCommandHandler: Add group failed for d7f71981-d306-415b-992d-ee4808a385fa{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
datanode2_1  | java.io.IOException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode2_1  | 	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:92)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:217)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:178)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:96)
datanode2_1  | 	at org.apache.ratis.client.impl.BlockingImpl.sendRequest(BlockingImpl.java:130)
datanode2_1  | 	at org.apache.ratis.client.impl.GroupManagementImpl.add(GroupManagementImpl.java:51)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.lambda$handle$1(CreatePipelineCommandHandler.java:99)
datanode2_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
datanode2_1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
datanode2_1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655)
datanode2_1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
datanode2_1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
datanode2_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
datanode2_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
datanode2_1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
datanode2_1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
kdc_1        | Jun 25 13:45:07 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628565, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:45:12 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628565, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:45:13 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624628713, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:45:18 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628713, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:45:23 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628713, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:45:24 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624628724, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:45:29 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628724, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:45:34 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628724, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:45:40 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628724, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:45:48 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628724, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:45:52 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624628752, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:45:56 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628752, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:46:05 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628752, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:46:09 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624628769, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:46:13 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628769, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:46:18 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628769, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:46:19 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624628779, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:46:23 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628779, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:46:29 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628779, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:46:30 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624628790, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:46:34 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628790, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:46:35 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624628795, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:46:40 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628795, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:46:41 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624628801, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:46:45 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628801, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:46:50 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628801, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:46:55 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628801, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:47:01 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628801, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:47:06 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628801, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:47:11 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628801, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:47:12 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624628832, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:47:16 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628832, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:47:21 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628832, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:47:26 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628832, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:47:31 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628832, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode3_1  | 2021-06-25 13:41:15,155 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode3_1  | 2021-06-25 13:41:15,155 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode3_1  | 2021-06-25 13:41:15,240 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode3_1  | 2021-06-25 13:41:18,148 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode3_1  | 2021-06-25 13:41:18,148 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode3_1  | 2021-06-25 13:41:18,148 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.datanode.http.auth.type = kerberos
datanode3_1  | 2021-06-25 13:41:18,376 [main] INFO util.log: Logging initialized @60117ms to org.eclipse.jetty.util.log.Slf4jLog
datanode3_1  | 2021-06-25 13:41:19,116 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode3_1  | 2021-06-25 13:41:19,160 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode1_1  | 2021-06-25 13:42:05,376 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode1_1  | 2021-06-25 13:42:05,376 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/949dd475-00f3-4295-9774-5191be84cab1
datanode1_1  | 2021-06-25 13:42:05,376 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode1_1  | 2021-06-25 13:42:05,376 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode1_1  | 2021-06-25 13:42:05,377 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2021-06-25 13:42:05,377 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode1_1  | 2021-06-25 13:42:05,378 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode1_1  | 2021-06-25 13:42:05,378 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode1_1  | 2021-06-25 13:42:05,381 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode1_1  | 2021-06-25 13:42:05,388 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode1_1  | 2021-06-25 13:42:05,391 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode1_1  | 2021-06-25 13:42:05,392 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode1_1  | 2021-06-25 13:42:05,396 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode1_1  | 2021-06-25 13:42:05,401 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode1_1  | 2021-06-25 13:42:05,403 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode1_1  | 2021-06-25 13:42:05,403 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode1_1  | 2021-06-25 13:42:05,404 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode1_1  | 2021-06-25 13:42:05,404 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode1_1  | 2021-06-25 13:42:05,404 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode1_1  | 2021-06-25 13:42:05,404 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode1_1  | 2021-06-25 13:42:05,405 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1
datanode1_1  | 2021-06-25 13:42:05,405 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1
datanode1_1  | 2021-06-25 13:42:05,408 [pool-23-thread-1] INFO server.RaftServer$Division: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1: start as a follower, conf=-1: [8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1, d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0], old=null
datanode1_1  | 2021-06-25 13:42:05,412 [pool-23-thread-1] INFO server.RaftServer$Division: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode1_1  | 2021-06-25 13:42:05,415 [pool-23-thread-1] INFO impl.RoleInfo: ee31bb40-6981-4b57-b8d7-3be03fa0c81d: start ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1-FollowerState
datanode1_1  | 2021-06-25 13:42:05,416 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-5191BE84CAB1,id=ee31bb40-6981-4b57-b8d7-3be03fa0c81d
datanode1_1  | 2021-06-25 13:42:05,417 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1
datanode1_1  | 2021-06-25 13:42:05,426 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=949dd475-00f3-4295-9774-5191be84cab1
datanode1_1  | 2021-06-25 13:42:05,437 [Command processor thread] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-A055A4865C9A->8dca9ea8-5191-4cce-a34e-3d546f33f7b1
datanode1_1  | 2021-06-25 13:42:05,855 [Command processor thread] WARN commandhandler.CreatePipelineCommandHandler: Add group failed for 8dca9ea8-5191-4cce-a34e-3d546f33f7b1{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
datanode1_1  | java.io.IOException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode1_1  | 	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:92)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:217)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:178)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:96)
datanode1_1  | 	at org.apache.ratis.client.impl.BlockingImpl.sendRequest(BlockingImpl.java:130)
datanode1_1  | 	at org.apache.ratis.client.impl.GroupManagementImpl.add(GroupManagementImpl.java:51)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.lambda$handle$1(CreatePipelineCommandHandler.java:99)
datanode1_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
datanode1_1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
datanode1_1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655)
datanode1_1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
datanode1_1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
datanode1_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
datanode1_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
datanode1_1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
datanode1_1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:95)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:95)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$2(DatanodeStateMachine.java:525)
datanode2_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode2_1  | Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:262)
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:243)
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:156)
datanode2_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:413)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$5(GrpcClientProtocolClient.java:180)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:215)
datanode2_1  | 	... 18 more
kdc_1        | Jun 25 13:47:32 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624628852, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:47:32 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624628852, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:47:36 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628852, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:47:37 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624628857, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:47:37 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624628857, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:47:41 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628857, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:47:42 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624628862, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:47:42 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624628862, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:47:46 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628862, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:47:52 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628862, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:47:52 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624628872, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:47:56 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628872, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:48:02 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628872, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:48:07 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628872, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:48:12 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628872, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:48:13 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624628893, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:48:16 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628893, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode2_1  | 2021-06-25 13:42:06,259 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=949dd475-00f3-4295-9774-5191be84cab1.
datanode2_1  | 2021-06-25 13:42:06,682 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-A0D73E1F71D5-FollowerState] INFO impl.FollowerState: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-A0D73E1F71D5-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5210405527ns, electionTimeout:5197ms
datanode2_1  | 2021-06-25 13:42:06,682 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-A0D73E1F71D5-FollowerState] INFO impl.RoleInfo: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1: shutdown 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-A0D73E1F71D5-FollowerState
datanode2_1  | 2021-06-25 13:42:06,683 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-A0D73E1F71D5-FollowerState] INFO server.RaftServer$Division: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-A0D73E1F71D5: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode2_1  | 2021-06-25 13:42:06,689 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-A0D73E1F71D5-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode2_1  | 2021-06-25 13:42:06,689 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-A0D73E1F71D5-FollowerState] INFO impl.RoleInfo: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1: start 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-A0D73E1F71D5-LeaderElection1
datanode2_1  | 2021-06-25 13:42:06,699 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-A0D73E1F71D5-LeaderElection1] INFO impl.LeaderElection: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-A0D73E1F71D5-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1], old=null
datanode2_1  | 2021-06-25 13:42:06,700 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-A0D73E1F71D5-LeaderElection1] INFO impl.LeaderElection: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-A0D73E1F71D5-LeaderElection1 ELECTION round 0: result PASSED (term=1)
datanode2_1  | 2021-06-25 13:42:06,701 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-A0D73E1F71D5-LeaderElection1] INFO impl.RoleInfo: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1: shutdown 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-A0D73E1F71D5-LeaderElection1
datanode2_1  | 2021-06-25 13:42:06,701 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-A0D73E1F71D5-LeaderElection1] INFO server.RaftServer$Division: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-A0D73E1F71D5: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode2_1  | 2021-06-25 13:42:06,701 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-A0D73E1F71D5-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-A0D73E1F71D5 with new leaderId: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1
datanode2_1  | 2021-06-25 13:42:06,702 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-A0D73E1F71D5-LeaderElection1] INFO server.RaftServer$Division: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-A0D73E1F71D5: change Leader from null to 8dca9ea8-5191-4cce-a34e-3d546f33f7b1 at term 1 for becomeLeader, leader elected after 6291ms
datanode2_1  | 2021-06-25 13:42:06,707 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-A0D73E1F71D5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode2_1  | 2021-06-25 13:42:06,710 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-A0D73E1F71D5-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-A0D73E1F71D5
datanode2_1  | 2021-06-25 13:42:06,712 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-A0D73E1F71D5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode2_1  | 2021-06-25 13:42:06,713 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-A0D73E1F71D5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode2_1  | 2021-06-25 13:42:06,718 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-A0D73E1F71D5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode2_1  | 2021-06-25 13:42:06,718 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-A0D73E1F71D5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode2_1  | 2021-06-25 13:42:06,719 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-A0D73E1F71D5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode2_1  | 2021-06-25 13:42:06,727 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-A0D73E1F71D5-LeaderElection1] INFO impl.RoleInfo: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1: start 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-A0D73E1F71D5-LeaderStateImpl
datanode2_1  | 2021-06-25 13:42:06,742 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-A0D73E1F71D5-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-A0D73E1F71D5-SegmentedRaftLogWorker: Starting segment from index:0
datanode2_1  | 2021-06-25 13:42:06,814 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-A0D73E1F71D5-LeaderElection1] INFO server.RaftServer$Division: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-A0D73E1F71D5: set configuration 0: [8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1], old=null
datanode2_1  | 2021-06-25 13:42:06,847 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-A0D73E1F71D5-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-A0D73E1F71D5-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/33fecaa5-f059-4c14-a3bf-a0d73e1f71d5/current/log_inprogress_0
datanode2_1  | 2021-06-25 13:42:07,091 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-FollowerState] INFO impl.FollowerState: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5186871263ns, electionTimeout:5173ms
datanode2_1  | 2021-06-25 13:42:07,092 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-FollowerState] INFO impl.RoleInfo: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1: shutdown 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-FollowerState
datanode2_1  | 2021-06-25 13:42:07,092 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-FollowerState] INFO server.RaftServer$Division: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode2_1  | 2021-06-25 13:42:07,094 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode2_1  | 2021-06-25 13:42:07,094 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-FollowerState] INFO impl.RoleInfo: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1: start 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-LeaderElection2
datanode2_1  | 2021-06-25 13:42:07,104 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-LeaderElection2] INFO impl.LeaderElection: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-LeaderElection2 ELECTION round 0: submit vote requests at term 1 for -1: [8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode2_1  | 2021-06-25 13:42:07,814 [grpc-default-executor-0] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server_message_metrics.8dca9ea8-5191-4cce-a34e-3d546f33f7b1
datanode2_1  | 2021-06-25 13:42:07,842 [grpc-default-executor-0] INFO server.RaftServer$Division: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68: receive requestVote(ELECTION, ee31bb40-6981-4b57-b8d7-3be03fa0c81d, group-BFEA630F7F68, 1, (t:0, i:0))
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$2(DatanodeStateMachine.java:525)
datanode1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode3_1  | 2021-06-25 13:41:19,161 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode3_1  | 2021-06-25 13:41:19,162 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode3_1  | 2021-06-25 13:41:19,178 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode3_1  | 2021-06-25 13:41:19,192 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.datanode.http.auth.kerberos.principal keytabKey: hdds.datanode.http.auth.kerberos.keytab
datanode3_1  | 2021-06-25 13:41:19,611 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode3_1  | 2021-06-25 13:41:19,615 [main] INFO server.Server: jetty-9.4.35.v20201120; built: 2020-11-20T21:17:03.964Z; git: bdc54f03a5e0a7e280fab27f55c3c75ee8da89fb; jvm 11.0.10+9-LTS
datanode3_1  | 2021-06-25 13:41:19,992 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode3_1  | 2021-06-25 13:41:19,992 [main] INFO server.session: No SessionScavenger set, using defaults
datanode3_1  | 2021-06-25 13:41:19,997 [main] INFO server.session: node0 Scavenging every 600000ms
datanode3_1  | 2021-06-25 13:41:20,143 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode3_1  | 2021-06-25 13:41:20,151 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@30a79476{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode3_1  | 2021-06-25 13:41:20,151 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5de6c7d7{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode3_1  | 2021-06-25 13:41:20,962 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode3_1  | 2021-06-25 13:41:21,085 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@373fb666{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_2_0-SNAPSHOT_jar-_-any-15047826440459494092/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode3_1  | 2021-06-25 13:41:21,145 [main] INFO server.AbstractConnector: Started ServerConnector@3c7f8c25{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode3_1  | 2021-06-25 13:41:21,156 [main] INFO server.Server: Started @62897ms
datanode3_1  | 2021-06-25 13:41:21,186 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode3_1  | 2021-06-25 13:41:21,187 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode3_1  | 2021-06-25 13:41:21,189 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode3_1  | 2021-06-25 13:41:21,309 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@64f6966d] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode3_1  | 2021-06-25 13:41:21,629 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.25.0.115:9891
datanode3_1  | 2021-06-25 13:41:25,406 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode3_1  | 2021-06-25 13:41:25,600 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode3_1  | 2021-06-25 13:41:26,274 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis d7f71981-d306-415b-992d-ee4808a385fa
datanode3_1  | 2021-06-25 13:41:26,502 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.RaftServer: d7f71981-d306-415b-992d-ee4808a385fa: start RPC server
datanode3_1  | 2021-06-25 13:41:26,519 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.GrpcService: d7f71981-d306-415b-992d-ee4808a385fa: GrpcService started, listening on 9856
datanode3_1  | 2021-06-25 13:41:26,523 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.GrpcService: d7f71981-d306-415b-992d-ee4808a385fa: GrpcService started, listening on 9857
datanode3_1  | 2021-06-25 13:41:26,530 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.GrpcService: d7f71981-d306-415b-992d-ee4808a385fa: GrpcService started, listening on 9858
datanode3_1  | 2021-06-25 13:41:26,564 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis d7f71981-d306-415b-992d-ee4808a385fa is started using port 9858 for RATIS
datanode3_1  | 2021-06-25 13:41:26,564 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis d7f71981-d306-415b-992d-ee4808a385fa is started using port 9857 for RATIS_ADMIN
datanode3_1  | 2021-06-25 13:41:26,564 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis d7f71981-d306-415b-992d-ee4808a385fa is started using port 9856 for RATIS_SERVER
datanode3_1  | 2021-06-25 13:41:26,587 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$324/0x0000000840576c40@667ee932] INFO util.JvmPauseMonitor: JvmPauseMonitor-d7f71981-d306-415b-992d-ee4808a385fa: Started
datanode3_1  | 2021-06-25 13:41:26,634 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode3_1  | 2021-06-25 13:41:26,638 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode3_1  | 2021-06-25 13:41:27,725 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:41:30,826 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:41:33,866 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:41:36,939 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:41:40,014 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:41:43,082 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:41:46,154 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:262)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:243)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:156)
datanode1_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:413)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$5(GrpcClientProtocolClient.java:180)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:215)
datanode1_1  | 	... 18 more
datanode1_1  | 2021-06-25 13:42:05,878 [Command processor thread] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-42EA75E440E0->d7f71981-d306-415b-992d-ee4808a385fa
datanode1_1  | 2021-06-25 13:42:06,278 [Command processor thread] WARN commandhandler.CreatePipelineCommandHandler: Add group failed for d7f71981-d306-415b-992d-ee4808a385fa{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
datanode1_1  | java.io.IOException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode1_1  | 	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:92)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:217)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:178)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:96)
datanode1_1  | 	at org.apache.ratis.client.impl.BlockingImpl.sendRequest(BlockingImpl.java:130)
datanode1_1  | 	at org.apache.ratis.client.impl.GroupManagementImpl.add(GroupManagementImpl.java:51)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.lambda$handle$1(CreatePipelineCommandHandler.java:99)
datanode1_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
datanode1_1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
datanode1_1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655)
datanode1_1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
datanode1_1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
datanode1_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
datanode1_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
datanode1_1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
datanode1_1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:95)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$2(DatanodeStateMachine.java:525)
datanode1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode1_1  | Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:262)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:243)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:156)
datanode1_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:413)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$5(GrpcClientProtocolClient.java:180)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:215)
datanode1_1  | 	... 18 more
datanode1_1  | 2021-06-25 13:42:06,279 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=949dd475-00f3-4295-9774-5191be84cab1.
datanode1_1  | 2021-06-25 13:42:06,282 [pool-23-thread-1] INFO server.RaftServer$Division: ee31bb40-6981-4b57-b8d7-3be03fa0c81d: new RaftServerImpl for group-BF6D91D43FA5:[ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1] with ContainerStateMachine:uninitialized
datanode1_1  | 2021-06-25 13:42:06,284 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode1_1  | 2021-06-25 13:42:06,285 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode1_1  | 2021-06-25 13:42:06,285 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode1_1  | 2021-06-25 13:42:06,285 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode1_1  | 2021-06-25 13:42:06,285 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode1_1  | 2021-06-25 13:42:06,285 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode1_1  | 2021-06-25 13:42:06,286 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode1_1  | 2021-06-25 13:42:06,286 [pool-23-thread-1] INFO server.RaftServer$Division: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BF6D91D43FA5: ConfigurationManager, init=-1: [ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode1_1  | 2021-06-25 13:42:06,286 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode1_1  | 2021-06-25 13:42:06,287 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode1_1  | 2021-06-25 13:42:06,287 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/145b110b-f1b2-4a24-b4ba-bf6d91d43fa5 does not exist. Creating ...
datanode1_1  | 2021-06-25 13:42:06,290 [Command processor thread] INFO server.RaftServer: ee31bb40-6981-4b57-b8d7-3be03fa0c81d: addNew group-BF6D91D43FA5:[ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1] returns group-BF6D91D43FA5:java.util.concurrent.CompletableFuture@1a5c0d4a[Not completed]
datanode1_1  | 2021-06-25 13:42:06,291 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/145b110b-f1b2-4a24-b4ba-bf6d91d43fa5/in_use.lock acquired by nodename 7@9d41ca97b170
datanode1_1  | 2021-06-25 13:42:06,299 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/145b110b-f1b2-4a24-b4ba-bf6d91d43fa5 has been successfully formatted.
datanode1_1  | 2021-06-25 13:42:06,299 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-BF6D91D43FA5: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode1_1  | 2021-06-25 13:42:06,300 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode2_1  | 2021-06-25 13:42:07,847 [grpc-default-executor-0] INFO impl.VoteContext: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-CANDIDATE: reject ELECTION from ee31bb40-6981-4b57-b8d7-3be03fa0c81d: already has voted for 8dca9ea8-5191-4cce-a34e-3d546f33f7b1 at current term 1
datanode2_1  | 2021-06-25 13:42:07,868 [grpc-default-executor-0] INFO server.RaftServer$Division: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68 replies to ELECTION vote request: ee31bb40-6981-4b57-b8d7-3be03fa0c81d<-8dca9ea8-5191-4cce-a34e-3d546f33f7b1#0:FAIL-t1. Peer's state: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68:t1, leader=null, voted=8dca9ea8-5191-4cce-a34e-3d546f33f7b1, raftlog=8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode2_1  | 2021-06-25 13:42:08,073 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-LeaderElection2] INFO impl.LeaderElection: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-LeaderElection2: ELECTION REJECTED received 2 response(s) and 0 exception(s):
datanode2_1  | 2021-06-25 13:42:08,075 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-LeaderElection2] INFO impl.LeaderElection:   Response 0: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1<-ee31bb40-6981-4b57-b8d7-3be03fa0c81d#0:FAIL-t1
datanode2_1  | 2021-06-25 13:42:08,075 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-LeaderElection2] INFO impl.LeaderElection:   Response 1: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1<-d7f71981-d306-415b-992d-ee4808a385fa#0:FAIL-t1
datanode2_1  | 2021-06-25 13:42:08,076 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-LeaderElection2] INFO impl.LeaderElection: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-LeaderElection2 ELECTION round 0: result REJECTED
datanode2_1  | 2021-06-25 13:42:08,078 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-LeaderElection2] INFO server.RaftServer$Division: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
datanode2_1  | 2021-06-25 13:42:08,078 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-LeaderElection2] INFO impl.RoleInfo: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1: shutdown 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-LeaderElection2
datanode2_1  | 2021-06-25 13:42:08,078 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-LeaderElection2] INFO impl.RoleInfo: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1: start 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-FollowerState
datanode2_1  | 2021-06-25 13:42:08,192 [grpc-default-executor-0] INFO server.RaftServer$Division: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68: receive requestVote(ELECTION, d7f71981-d306-415b-992d-ee4808a385fa, group-BFEA630F7F68, 1, (t:0, i:0))
datanode2_1  | 2021-06-25 13:42:08,195 [grpc-default-executor-0] INFO impl.VoteContext: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-FOLLOWER: reject ELECTION from d7f71981-d306-415b-992d-ee4808a385fa: already has voted for 8dca9ea8-5191-4cce-a34e-3d546f33f7b1 at current term 1
datanode2_1  | 2021-06-25 13:42:08,196 [grpc-default-executor-0] INFO server.RaftServer$Division: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68 replies to ELECTION vote request: d7f71981-d306-415b-992d-ee4808a385fa<-8dca9ea8-5191-4cce-a34e-3d546f33f7b1#0:FAIL-t1. Peer's state: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68:t1, leader=null, voted=8dca9ea8-5191-4cce-a34e-3d546f33f7b1, raftlog=8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode2_1  | 2021-06-25 13:42:08,970 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:42:10,280 [grpc-default-executor-0] INFO server.RaftServer$Division: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-5191BE84CAB1: receive requestVote(ELECTION, d7f71981-d306-415b-992d-ee4808a385fa, group-5191BE84CAB1, 1, (t:0, i:0))
datanode2_1  | 2021-06-25 13:42:10,281 [grpc-default-executor-0] INFO impl.VoteContext: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-5191BE84CAB1-FOLLOWER: accept ELECTION from d7f71981-d306-415b-992d-ee4808a385fa: our priority 0 <= candidate's priority 0
datanode2_1  | 2021-06-25 13:42:10,281 [grpc-default-executor-0] INFO server.RaftServer$Division: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-5191BE84CAB1: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:d7f71981-d306-415b-992d-ee4808a385fa
datanode2_1  | 2021-06-25 13:42:10,281 [grpc-default-executor-0] INFO impl.RoleInfo: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1: shutdown 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-5191BE84CAB1-FollowerState
datanode2_1  | 2021-06-25 13:42:10,282 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-5191BE84CAB1-FollowerState] INFO impl.FollowerState: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-5191BE84CAB1-FollowerState was interrupted: {}
datanode2_1  | java.lang.InterruptedException: sleep interrupted
datanode2_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode2_1  | 	at java.base/java.lang.Thread.sleep(Thread.java:339)
datanode2_1  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode2_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
datanode2_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode2_1  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
datanode2_1  | 2021-06-25 13:42:10,282 [grpc-default-executor-0] INFO impl.RoleInfo: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1: start 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-5191BE84CAB1-FollowerState
datanode2_1  | 2021-06-25 13:42:10,296 [grpc-default-executor-0] INFO server.RaftServer$Division: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-5191BE84CAB1 replies to ELECTION vote request: d7f71981-d306-415b-992d-ee4808a385fa<-8dca9ea8-5191-4cce-a34e-3d546f33f7b1#0:OK-t1. Peer's state: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-5191BE84CAB1:t1, leader=null, voted=d7f71981-d306-415b-992d-ee4808a385fa, raftlog=8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-5191BE84CAB1-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1, d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0], old=null
datanode2_1  | 2021-06-25 13:42:12,043 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:42:13,094 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-FollowerState] INFO impl.FollowerState: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5015704410ns, electionTimeout:5008ms
datanode2_1  | 2021-06-25 13:42:13,094 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-FollowerState] INFO impl.RoleInfo: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1: shutdown 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-FollowerState
datanode2_1  | 2021-06-25 13:42:13,095 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-FollowerState] INFO server.RaftServer$Division: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
datanode2_1  | 2021-06-25 13:42:13,095 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode2_1  | 2021-06-25 13:42:13,095 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-FollowerState] INFO impl.RoleInfo: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1: start 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-LeaderElection3
datanode2_1  | 2021-06-25 13:42:13,100 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-LeaderElection3] INFO impl.LeaderElection: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-LeaderElection3 ELECTION round 0: submit vote requests at term 2 for -1: [8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode2_1  | 2021-06-25 13:42:13,131 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-LeaderElection3] INFO impl.LeaderElection: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-LeaderElection3: ELECTION REJECTED received 1 response(s) and 0 exception(s):
datanode2_1  | 2021-06-25 13:42:13,131 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-LeaderElection3] INFO impl.LeaderElection:   Response 0: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1<-d7f71981-d306-415b-992d-ee4808a385fa#0:FAIL-t2
datanode2_1  | 2021-06-25 13:42:13,131 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-LeaderElection3] INFO impl.LeaderElection: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-LeaderElection3 ELECTION round 0: result REJECTED
datanode2_1  | 2021-06-25 13:42:13,131 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-LeaderElection3] INFO server.RaftServer$Division: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68: changes role from CANDIDATE to FOLLOWER at term 2 for REJECTED
datanode2_1  | 2021-06-25 13:42:13,131 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-LeaderElection3] INFO impl.RoleInfo: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1: shutdown 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-LeaderElection3
datanode2_1  | 2021-06-25 13:42:13,131 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-LeaderElection3] INFO impl.RoleInfo: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1: start 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-FollowerState
datanode2_1  | 2021-06-25 13:42:14,115 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] WARN statemachine.EndpointStateMachine: Unable to communicate to Recon server at recon:9891 for past 0 seconds.
datanode2_1  | java.net.NoRouteToHostException: No Route to Host from  2c32953938b8/172.25.0.103 to recon:9891 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
datanode2_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode2_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode2_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode2_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode2_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:836)
datanode2_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:787)
datanode2_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1566)
datanode2_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
datanode2_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
datanode2_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
kms_1        | Sleeping for 5 seconds
kms_1        | WARNING: /opt/hadoop/temp does not exist. Creating.
om1_1        | Sleeping for 5 seconds
om1_1        | Waiting for the service scm3.org:9894
om1_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om1_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om1_1        | 2021-06-25 13:40:30,128 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om1_1        | /************************************************************
om1_1        | STARTUP_MSG: Starting OzoneManager
om1_1        | STARTUP_MSG:   host = om1/172.25.0.111
om1_1        | STARTUP_MSG:   args = [--init]
om1_1        | STARTUP_MSG:   version = 1.2.0-SNAPSHOT
om1_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/javax.activation-api-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.2.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0-a398b19-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.2.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.2.0-SNAPSHOT.jar
om1_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/450c3750335593082ae39a2d17d4a2a58090f75f ; compiled by 'runner' on 2021-06-25T12:44Z
om1_1        | STARTUP_MSG:   java = 11.0.10
om1_1        | ************************************************************/
om1_1        | 2021-06-25 13:40:30,222 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om1_1        | 2021-06-25 13:40:42,340 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om1_1        | 2021-06-25 13:40:43,330 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om1, RPC Address: om1:9862 and Ratis port: 9872
om1_1        | 2021-06-25 13:40:43,331 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om1: om1
om1_1        | 2021-06-25 13:40:43,340 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om1: om1
om1_1        | 2021-06-25 13:40:44,868 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file /etc/security/keytabs/om.keytab
om1_1        | 2021-06-25 13:40:44,875 [main] INFO om.OzoneManager: Ozone Manager login successful.
om1_1        | 2021-06-25 13:40:44,951 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2021-06-25 13:40:49,746 [main] INFO om.OzoneManager: Initializing secure OzoneManager.
om1_1        | 2021-06-25 13:40:53,247 [main] ERROR client.OMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
om1_1        | 2021-06-25 13:40:53,248 [main] INFO client.OMCertificateClient: Certificate client init case: 0
om1_1        | 2021-06-25 13:40:53,249 [main] INFO client.OMCertificateClient: Creating keypair for client as keypair and certificate not found.
om1_1        | 2021-06-25 13:40:58,275 [main] INFO om.OzoneManager: Init response: GETCERT
om1_1        | 2021-06-25 13:40:58,816 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.111,host:om1
om1_1        | 2021-06-25 13:40:58,816 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
om1_1        | 2021-06-25 13:40:58,851 [main] ERROR client.OMCertificateClient: Invalid domain om1
om1_1        | 2021-06-25 13:40:58,865 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om1_1        | 2021-06-25 13:40:58,866 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om1, RPC Address: om1:9862 and Ratis port: 9872
om1_1        | 2021-06-25 13:40:58,866 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om1: om1
om1_1        | 2021-06-25 13:40:58,867 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om1: om1
om1_1        | 2021-06-25 13:40:58,904 [main] INFO om.OzoneManager: Creating csr for OM->dns:om1,ip:172.25.0.111,scmId:76093931-f232-4415-806f-239960e589cb,clusterId:CID-8e5d7696-3ffc-40b4-8848-61155fd5a026,subject:om1
om1_1        | 2021-06-25 13:41:00,399 [main] INFO om.OzoneManager: OzoneManager ports added:[name: "RPC"
om1_1        | value: 9862
om1_1        | ]
om1_1        | 2021-06-25 13:41:02,985 [main] INFO om.OzoneManager: Successfully stored SCM signed certificate.
om1_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-8e5d7696-3ffc-40b4-8848-61155fd5a026;layoutVersion=0
om1_1        | 2021-06-25 13:41:03,286 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om1_1        | /************************************************************
om1_1        | SHUTDOWN_MSG: Shutting down OzoneManager at om1/172.25.0.111
om1_1        | ************************************************************/
om1_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om1_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om1_1        | 2021-06-25 13:41:13,758 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om1_1        | /************************************************************
om1_1        | STARTUP_MSG: Starting OzoneManager
om1_1        | STARTUP_MSG:   host = om1/172.25.0.111
om1_1        | STARTUP_MSG:   args = []
om1_1        | STARTUP_MSG:   version = 1.2.0-SNAPSHOT
om1_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/javax.activation-api-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.2.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0-a398b19-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.2.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.2.0-SNAPSHOT.jar
om1_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/450c3750335593082ae39a2d17d4a2a58090f75f ; compiled by 'runner' on 2021-06-25T12:44Z
om1_1        | STARTUP_MSG:   java = 11.0.10
om1_1        | ************************************************************/
om1_1        | 2021-06-25 13:41:13,828 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om1_1        | 2021-06-25 13:41:25,584 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om1_1        | 2021-06-25 13:41:26,404 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om1, RPC Address: om1:9862 and Ratis port: 9872
om1_1        | 2021-06-25 13:41:26,425 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om1: om1
om1_1        | 2021-06-25 13:41:26,427 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om1: om1
om1_1        | 2021-06-25 13:41:26,582 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2021-06-25 13:41:29,482 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file /etc/security/keytabs/om.keytab
om1_1        | 2021-06-25 13:41:29,483 [main] INFO om.OzoneManager: Ozone Manager login successful.
om1_1        | 2021-06-25 13:41:29,490 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2021-06-25 13:41:35,842 [main] INFO client.OMCertificateClient: Loading certificate from location:/data/metadata/om/certs.
om1_1        | 2021-06-25 13:41:36,436 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/2992542929807.crt.
om1_1        | 2021-06-25 13:41:36,464 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/ROOTCA-1.crt.
om1_1        | 2021-06-25 13:41:36,483 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/CA-2884006640668.crt.
om1_1        | 2021-06-25 13:41:36,671 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2021-06-25 13:41:37,398 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om1_1        | 2021-06-25 13:41:37,412 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om1_1        | 2021-06-25 13:41:38,275 [main] INFO Configuration.deprecation: No unit for ozone.manager.delegation.remover.scan.interval(3600000) assuming MILLISECONDS
om1_1        | 2021-06-25 13:41:38,290 [main] INFO security.OzoneSecretStore: Loaded 0 tokens
om1_1        | 2021-06-25 13:41:38,290 [main] INFO security.OzoneDelegationTokenSecretManager: Loading token state into token manager.
om1_1        | 2021-06-25 13:41:38,665 [main] INFO om.OzoneManager: Created Volume s3v With Owner root required for S3Gateway operations.
om1_1        | 2021-06-25 13:41:38,700 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om1_1        | 2021-06-25 13:41:38,707 [main] WARN ratis.OzoneManagerRatisServer: ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
om1_1        | 2021-06-25 13:41:38,711 [main] INFO snapshot.OzoneManagerSnapshotProvider: Initializing OM Snapshot Provider
om1_1        | 2021-06-25 13:41:39,255 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om1_1        | 2021-06-25 13:41:39,531 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om1_1        | 2021-06-25 13:41:39,787 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with GroupID: id1 and Raft Peers: om1:9872, om2:9872, om3:9872
kdc_1        | Jun 25 13:48:21 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628893, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:48:30 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628893, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:48:34 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624628914, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:48:39 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628914, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:48:44 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628914, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:48:49 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628914, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:49:11 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624628951, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:49:15 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628951, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:49:21 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624628961, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:49:25 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628961, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:49:36 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624628976, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:49:39 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624628976, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:50:00 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624629000, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:50:04 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624629000, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:50:10 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624629010, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:50:14 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624629010, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:50:20 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624629020, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:50:23 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624629020, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om2_1        | Sleeping for 5 seconds
om2_1        | Waiting for the service scm3.org:9894
om2_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om2_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om2_1        | 2021-06-25 13:40:29,961 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om2_1        | /************************************************************
om2_1        | STARTUP_MSG: Starting OzoneManager
om2_1        | STARTUP_MSG:   host = om2/172.25.0.112
om2_1        | STARTUP_MSG:   args = [--init]
om2_1        | STARTUP_MSG:   version = 1.2.0-SNAPSHOT
om2_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/javax.activation-api-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.2.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0-a398b19-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.2.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.2.0-SNAPSHOT.jar
om2_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/450c3750335593082ae39a2d17d4a2a58090f75f ; compiled by 'runner' on 2021-06-25T12:44Z
om2_1        | STARTUP_MSG:   java = 11.0.10
om2_1        | ************************************************************/
om2_1        | 2021-06-25 13:40:30,029 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om2_1        | 2021-06-25 13:40:42,063 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om2_1        | 2021-06-25 13:40:42,842 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om2, RPC Address: om2:9862 and Ratis port: 9872
om2_1        | 2021-06-25 13:40:42,843 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om2: om2
om2_1        | 2021-06-25 13:40:42,844 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om2: om2
om2_1        | 2021-06-25 13:40:45,100 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file /etc/security/keytabs/om.keytab
om2_1        | 2021-06-25 13:40:45,118 [main] INFO om.OzoneManager: Ozone Manager login successful.
om2_1        | 2021-06-25 13:40:45,332 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2021-06-25 13:40:49,172 [main] INFO om.OzoneManager: Initializing secure OzoneManager.
om2_1        | 2021-06-25 13:40:52,716 [main] ERROR client.OMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
om2_1        | 2021-06-25 13:40:52,718 [main] INFO client.OMCertificateClient: Certificate client init case: 0
om2_1        | 2021-06-25 13:40:52,720 [main] INFO client.OMCertificateClient: Creating keypair for client as keypair and certificate not found.
om2_1        | 2021-06-25 13:41:00,099 [main] INFO om.OzoneManager: Init response: GETCERT
om2_1        | 2021-06-25 13:41:00,396 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.112,host:om2
om2_1        | 2021-06-25 13:41:00,413 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
om2_1        | 2021-06-25 13:41:00,440 [main] ERROR client.OMCertificateClient: Invalid domain om2
om2_1        | 2021-06-25 13:41:00,453 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om2_1        | 2021-06-25 13:41:00,463 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om2, RPC Address: om2:9862 and Ratis port: 9872
om2_1        | 2021-06-25 13:41:00,465 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om2: om2
om2_1        | 2021-06-25 13:41:00,471 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om2: om2
om2_1        | 2021-06-25 13:41:00,479 [main] INFO om.OzoneManager: Creating csr for OM->dns:om2,ip:172.25.0.112,scmId:76093931-f232-4415-806f-239960e589cb,clusterId:CID-8e5d7696-3ffc-40b4-8848-61155fd5a026,subject:om2
om2_1        | 2021-06-25 13:41:02,105 [main] INFO om.OzoneManager: OzoneManager ports added:[name: "RPC"
om2_1        | value: 9862
om2_1        | ]
om2_1        | 2021-06-25 13:41:04,616 [main] INFO om.OzoneManager: Successfully stored SCM signed certificate.
datanode1_1  | 2021-06-25 13:42:06,300 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode1_1  | 2021-06-25 13:42:06,300 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode1_1  | 2021-06-25 13:42:06,310 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2021-06-25 13:42:06,310 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BF6D91D43FA5
datanode1_1  | 2021-06-25 13:42:06,311 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2021-06-25 13:42:06,312 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode1_1  | 2021-06-25 13:42:06,312 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode1_1  | 2021-06-25 13:42:06,312 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BF6D91D43FA5-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/145b110b-f1b2-4a24-b4ba-bf6d91d43fa5
datanode1_1  | 2021-06-25 13:42:06,312 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode1_1  | 2021-06-25 13:42:06,313 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode1_1  | 2021-06-25 13:42:06,313 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2021-06-25 13:42:06,313 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode1_1  | 2021-06-25 13:42:06,313 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode1_1  | 2021-06-25 13:42:06,314 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode1_1  | 2021-06-25 13:42:06,314 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode1_1  | 2021-06-25 13:42:06,314 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode1_1  | 2021-06-25 13:42:06,315 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode1_1  | 2021-06-25 13:42:06,325 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode1_1  | 2021-06-25 13:42:06,326 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BF6D91D43FA5-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode1_1  | 2021-06-25 13:42:06,326 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BF6D91D43FA5-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode1_1  | 2021-06-25 13:42:06,355 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode1_1  | 2021-06-25 13:42:06,356 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode1_1  | 2021-06-25 13:42:06,356 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode1_1  | 2021-06-25 13:42:06,356 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode1_1  | 2021-06-25 13:42:06,357 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode1_1  | 2021-06-25 13:42:06,357 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode1_1  | 2021-06-25 13:42:06,357 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BF6D91D43FA5
datanode1_1  | 2021-06-25 13:42:06,361 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BF6D91D43FA5
datanode1_1  | 2021-06-25 13:42:06,362 [pool-23-thread-1] INFO server.RaftServer$Division: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BF6D91D43FA5: start as a follower, conf=-1: [ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1], old=null
datanode1_1  | 2021-06-25 13:42:06,363 [pool-23-thread-1] INFO server.RaftServer$Division: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BF6D91D43FA5: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode1_1  | 2021-06-25 13:42:06,364 [pool-23-thread-1] INFO impl.RoleInfo: ee31bb40-6981-4b57-b8d7-3be03fa0c81d: start ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BF6D91D43FA5-FollowerState
datanode1_1  | 2021-06-25 13:42:06,375 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-BF6D91D43FA5,id=ee31bb40-6981-4b57-b8d7-3be03fa0c81d
datanode1_1  | 2021-06-25 13:42:06,375 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BF6D91D43FA5
datanode1_1  | 2021-06-25 13:42:06,376 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=145b110b-f1b2-4a24-b4ba-bf6d91d43fa5
datanode1_1  | 2021-06-25 13:42:06,377 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=145b110b-f1b2-4a24-b4ba-bf6d91d43fa5.
datanode1_1  | 2021-06-25 13:42:07,054 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68-FollowerState] INFO impl.FollowerState: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5242060826ns, electionTimeout:5187ms
datanode1_1  | 2021-06-25 13:42:07,055 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68-FollowerState] INFO impl.RoleInfo: ee31bb40-6981-4b57-b8d7-3be03fa0c81d: shutdown ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68-FollowerState
datanode1_1  | 2021-06-25 13:42:07,056 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68-FollowerState] INFO server.RaftServer$Division: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode1_1  | 2021-06-25 13:42:07,061 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode1_1  | 2021-06-25 13:42:07,061 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68-FollowerState] INFO impl.RoleInfo: ee31bb40-6981-4b57-b8d7-3be03fa0c81d: start ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68-LeaderElection1
datanode1_1  | 2021-06-25 13:42:07,068 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68-LeaderElection1] INFO impl.LeaderElection: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode1_1  | 2021-06-25 13:42:07,242 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
kdc_1        | Jun 25 13:50:28 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624629028, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:50:32 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624629028, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:50:37 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624629037, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:50:41 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624629037, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:51:49 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624629109, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:51:52 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624629109, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:52:05 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624629125, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:52:08 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624629125, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:52:25 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624629145, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:52:27 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624629145, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:52:36 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624629156, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:52:39 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624629156, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:52:57 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624629177, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:53:01 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624629177, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:53:04 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624629184, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:53:04 kdc krb5kdc[8](info): TGS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624629184, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for HTTP/s3g@EXAMPLE.COM
kdc_1        | Jun 25 13:53:16 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624629196, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:53:21 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624629196, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:53:29 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624629196, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:53:37 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624629196, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:53:42 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624629196, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:53:47 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624629196, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:53:52 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624629196, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:53:57 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624629196, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:54:01 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624629196, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:54:05 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624629196, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:54:10 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624629196, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:54:14 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624629196, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:54:29 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624629196, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:54:43 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624629196, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:54:46 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624629286, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:54:50 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624629286, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:54:51 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624629291, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:54:55 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624629291, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
om1_1        | 2021-06-25 13:41:39,905 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
om1_1        | 2021-06-25 13:41:41,205 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
om1_1        | 2021-06-25 13:41:41,649 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
om1_1        | 2021-06-25 13:41:41,658 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om1_1        | 2021-06-25 13:41:41,659 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
om1_1        | 2021-06-25 13:41:41,665 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om1_1        | 2021-06-25 13:41:41,666 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om1_1        | 2021-06-25 13:41:41,667 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om1_1        | 2021-06-25 13:41:41,670 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om1_1        | 2021-06-25 13:41:41,677 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om1_1        | 2021-06-25 13:41:41,688 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om1_1        | 2021-06-25 13:41:44,686 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om1_1        | 2021-06-25 13:41:44,700 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om1_1        | 2021-06-25 13:41:44,703 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om1_1        | 2021-06-25 13:41:44,775 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om1_1        | 2021-06-25 13:41:44,832 [main] INFO server.RaftServer: om1: addNew group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] returns group-562213E44849:java.util.concurrent.CompletableFuture@5d51203b[Not completed]
om1_1        | 2021-06-25 13:41:44,837 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om1_1        | 2021-06-25 13:41:44,992 [pool-22-thread-1] INFO server.RaftServer$Division: om1: new RaftServerImpl for group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] with OzoneManagerStateMachine:uninitialized
om1_1        | 2021-06-25 13:41:45,039 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om1_1        | 2021-06-25 13:41:45,046 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om1_1        | 2021-06-25 13:41:45,050 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om1_1        | 2021-06-25 13:41:45,050 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om1_1        | 2021-06-25 13:41:45,051 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om1_1        | 2021-06-25 13:41:45,052 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om1_1        | 2021-06-25 13:41:45,067 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om1_1        | 2021-06-25 13:41:45,110 [pool-22-thread-1] INFO server.RaftServer$Division: om1@group-562213E44849: ConfigurationManager, init=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null, confs=<EMPTY_MAP>
om1_1        | 2021-06-25 13:41:45,112 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om1_1        | 2021-06-25 13:41:45,167 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om1_1        | 2021-06-25 13:41:45,173 [pool-22-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 does not exist. Creating ...
om1_1        | 2021-06-25 13:41:45,188 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om1_1        | 2021-06-25 13:41:45,254 [pool-22-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/in_use.lock acquired by nodename 7@om1
om1_1        | 2021-06-25 13:41:45,293 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om1_1        | 2021-06-25 13:41:45,468 [pool-22-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 has been successfully formatted.
om1_1        | 2021-06-25 13:41:45,485 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om1_1        | 2021-06-25 13:41:45,519 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om1_1        | 2021-06-25 13:41:45,636 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om1_1        | 2021-06-25 13:41:45,636 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om1_1        | 2021-06-25 13:41:45,721 [pool-22-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.om1@group-562213E44849
om1_1        | 2021-06-25 13:41:45,872 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om1_1        | 2021-06-25 13:41:45,919 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om1_1        | 2021-06-25 13:41:46,019 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om1_1        | 2021-06-25 13:41:46,089 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: new om1@group-562213E44849-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849
om1_1        | 2021-06-25 13:41:46,104 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om1_1        | 2021-06-25 13:41:46,106 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om1_1        | 2021-06-25 13:41:46,116 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om1_1        | 2021-06-25 13:41:46,130 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om1_1        | 2021-06-25 13:41:46,137 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om1_1        | 2021-06-25 13:41:46,170 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om1_1        | 2021-06-25 13:41:46,172 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om1_1        | 2021-06-25 13:41:46,173 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om1_1        | 2021-06-25 13:41:46,371 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
datanode2_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
datanode2_1  | 	at com.sun.proxy.$Proxy40.submitRequest(Unknown Source)
datanode2_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
datanode2_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:133)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:71)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:42)
datanode2_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode2_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode2_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode2_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode2_1  | Caused by: java.net.NoRouteToHostException: No route to host
datanode2_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
datanode2_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:779)
datanode2_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
datanode2_1  | 	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:534)
datanode2_1  | 	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:699)
datanode2_1  | 	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:812)
datanode2_1  | 	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:413)
datanode2_1  | 	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1636)
datanode2_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1452)
datanode2_1  | 	... 12 more
datanode2_1  | 2021-06-25 13:42:15,329 [grpc-default-executor-0] INFO server.RaftServer$Division: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-5191BE84CAB1: receive requestVote(ELECTION, ee31bb40-6981-4b57-b8d7-3be03fa0c81d, group-5191BE84CAB1, 2, (t:0, i:0))
datanode2_1  | 2021-06-25 13:42:15,329 [grpc-default-executor-0] INFO impl.VoteContext: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-5191BE84CAB1-FOLLOWER: accept ELECTION from ee31bb40-6981-4b57-b8d7-3be03fa0c81d: our priority 0 <= candidate's priority 1
datanode2_1  | 2021-06-25 13:42:15,329 [grpc-default-executor-0] INFO server.RaftServer$Division: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-5191BE84CAB1: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:ee31bb40-6981-4b57-b8d7-3be03fa0c81d
datanode2_1  | 2021-06-25 13:42:15,329 [grpc-default-executor-0] INFO impl.RoleInfo: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1: shutdown 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-5191BE84CAB1-FollowerState
datanode2_1  | 2021-06-25 13:42:15,329 [grpc-default-executor-0] INFO impl.RoleInfo: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1: start 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-5191BE84CAB1-FollowerState
datanode2_1  | 2021-06-25 13:42:15,330 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-5191BE84CAB1-FollowerState] INFO impl.FollowerState: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-5191BE84CAB1-FollowerState was interrupted: {}
datanode2_1  | java.lang.InterruptedException: sleep interrupted
datanode2_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode2_1  | 	at java.base/java.lang.Thread.sleep(Thread.java:339)
datanode2_1  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode2_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
datanode2_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode2_1  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
datanode3_1  | 2021-06-25 13:41:49,226 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:41:52,298 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:41:55,370 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:41:58,442 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:42:00,693 [Command processor thread] INFO server.RaftServer: d7f71981-d306-415b-992d-ee4808a385fa: addNew group-BFEA630F7F68:[8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1] returns group-BFEA630F7F68:java.util.concurrent.CompletableFuture@4bcd5fad[Not completed]
datanode3_1  | 2021-06-25 13:42:00,969 [pool-23-thread-1] INFO server.RaftServer$Division: d7f71981-d306-415b-992d-ee4808a385fa: new RaftServerImpl for group-BFEA630F7F68:[8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1] with ContainerStateMachine:uninitialized
datanode3_1  | 2021-06-25 13:42:00,990 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode3_1  | 2021-06-25 13:42:01,014 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode3_1  | 2021-06-25 13:42:01,014 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode3_1  | 2021-06-25 13:42:01,016 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode3_1  | 2021-06-25 13:42:01,016 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode3_1  | 2021-06-25 13:42:01,016 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode3_1  | 2021-06-25 13:42:01,017 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2021-06-25 13:42:01,134 [pool-23-thread-1] INFO server.RaftServer$Division: d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68: ConfigurationManager, init=-1: [8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode3_1  | 2021-06-25 13:42:01,138 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode3_1  | 2021-06-25 13:42:01,197 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode3_1  | 2021-06-25 13:42:01,222 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/3175bb45-44a8-4478-8980-bfea630f7f68 does not exist. Creating ...
datanode3_1  | 2021-06-25 13:42:01,271 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/3175bb45-44a8-4478-8980-bfea630f7f68/in_use.lock acquired by nodename 8@7b9eb44ecf31
datanode3_1  | 2021-06-25 13:42:01,318 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/3175bb45-44a8-4478-8980-bfea630f7f68 has been successfully formatted.
datanode3_1  | 2021-06-25 13:42:01,463 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-BFEA630F7F68: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode3_1  | 2021-06-25 13:42:01,485 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode3_1  | 2021-06-25 13:42:01,500 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode3_1  | 2021-06-25 13:42:01,522 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:42:01,671 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode3_1  | 2021-06-25 13:42:01,671 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2021-06-25 13:42:01,709 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68
datanode3_1  | 2021-06-25 13:42:01,799 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2021-06-25 13:42:01,870 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode3_1  | 2021-06-25 13:42:01,875 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode3_1  | 2021-06-25 13:42:01,942 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/3175bb45-44a8-4478-8980-bfea630f7f68
datanode3_1  | 2021-06-25 13:42:01,945 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode3_1  | 2021-06-25 13:42:01,947 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode3_1  | 2021-06-25 13:42:01,961 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2021-06-25 13:42:01,970 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode3_1  | 2021-06-25 13:42:01,978 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode3_1  | 2021-06-25 13:42:01,980 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode3_1  | 2021-06-25 13:42:01,981 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode3_1  | 2021-06-25 13:42:01,984 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode3_1  | 2021-06-25 13:42:02,069 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
kdc_1        | Jun 25 13:54:55 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624629295, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:55:00 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624629295, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:55:04 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624629295, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:55:09 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624629295, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:55:13 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624629295, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:55:17 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624629317, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:55:20 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624629317, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:55:25 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624629317, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:55:29 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624629317, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:55:34 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624629317, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:55:37 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624629317, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:55:41 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624629317, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:55:46 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624629317, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:55:50 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624629317, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:55:55 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624629317, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:55:58 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624629358, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:56:03 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624629358, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:56:07 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624629358, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
om1_1        | 2021-06-25 13:41:46,387 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om1_1        | 2021-06-25 13:41:46,445 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode3_1  | 2021-06-25 13:42:02,078 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode3_1  | 2021-06-25 13:42:02,101 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode3_1  | 2021-06-25 13:42:02,101 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode3_1  | 2021-06-25 13:42:02,121 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode3_1  | 2021-06-25 13:42:02,121 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode3_1  | 2021-06-25 13:42:02,124 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode3_1  | 2021-06-25 13:42:02,127 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode3_1  | 2021-06-25 13:42:02,131 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode3_1  | 2021-06-25 13:42:02,131 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode3_1  | 2021-06-25 13:42:02,256 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68
datanode3_1  | 2021-06-25 13:42:02,278 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68
datanode3_1  | 2021-06-25 13:42:02,296 [pool-23-thread-1] INFO server.RaftServer$Division: d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68: start as a follower, conf=-1: [8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode3_1  | 2021-06-25 13:42:02,302 [pool-23-thread-1] INFO server.RaftServer$Division: d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode3_1  | 2021-06-25 13:42:02,309 [pool-23-thread-1] INFO impl.RoleInfo: d7f71981-d306-415b-992d-ee4808a385fa: start d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-FollowerState
datanode3_1  | 2021-06-25 13:42:02,369 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-BFEA630F7F68,id=d7f71981-d306-415b-992d-ee4808a385fa
datanode3_1  | 2021-06-25 13:42:02,374 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68
datanode3_1  | 2021-06-25 13:42:02,483 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=3175bb45-44a8-4478-8980-bfea630f7f68
datanode3_1  | 2021-06-25 13:42:02,696 [Command processor thread] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-7B1CFD20ABD4->ee31bb40-6981-4b57-b8d7-3be03fa0c81d
datanode3_1  | 2021-06-25 13:42:04,415 [Command processor thread] WARN commandhandler.CreatePipelineCommandHandler: Add group failed for ee31bb40-6981-4b57-b8d7-3be03fa0c81d{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
datanode3_1  | java.io.IOException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode3_1  | 	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:92)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:217)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:178)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:96)
datanode3_1  | 	at org.apache.ratis.client.impl.BlockingImpl.sendRequest(BlockingImpl.java:130)
datanode3_1  | 	at org.apache.ratis.client.impl.GroupManagementImpl.add(GroupManagementImpl.java:51)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.lambda$handle$1(CreatePipelineCommandHandler.java:99)
datanode3_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
datanode3_1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
datanode3_1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655)
datanode3_1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
datanode3_1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
datanode3_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
datanode3_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
datanode3_1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
datanode3_1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:95)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$2(DatanodeStateMachine.java:525)
datanode3_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode3_1  | Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:262)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:243)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:156)
om1_1        | 2021-06-25 13:41:46,482 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om1_1        | 2021-06-25 13:41:46,572 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om1_1        | 2021-06-25 13:41:46,573 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om1_1        | 2021-06-25 13:41:46,589 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om1_1        | 2021-06-25 13:41:46,590 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om1_1        | 2021-06-25 13:41:46,592 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
om1_1        | 2021-06-25 13:41:46,594 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om1_1        | 2021-06-25 13:41:47,033 [pool-22-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.om1@group-562213E44849
om1_1        | 2021-06-25 13:41:47,112 [pool-22-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.om1@group-562213E44849
om1_1        | 2021-06-25 13:41:47,246 [Listener at om1/9862] INFO om.OzoneManager: Configured ozone.om.metadata.layout=SIMPLE and disabled optimized OM FS operations
om1_1        | 2021-06-25 13:41:47,745 [Listener at om1/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om1_1        | 2021-06-25 13:41:47,833 [Listener at om1/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om1_1        | 2021-06-25 13:41:47,835 [Listener at om1/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om1_1        | 2021-06-25 13:41:47,972 [Listener at om1/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om1/172.25.0.111:9862
om1_1        | 2021-06-25 13:41:47,979 [Listener at om1/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om1 at port 9872
om1_1        | 2021-06-25 13:41:47,981 [Listener at om1/9862] INFO server.RaftServer$Division: om1@group-562213E44849: start as a follower, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1        | 2021-06-25 13:41:47,998 [Listener at om1/9862] INFO server.RaftServer$Division: om1@group-562213E44849: changes role from      null to FOLLOWER at term 0 for startAsFollower
om1_1        | 2021-06-25 13:41:48,003 [Listener at om1/9862] INFO impl.RoleInfo: om1: start om1@group-562213E44849-FollowerState
om1_1        | 2021-06-25 13:41:48,024 [Listener at om1/9862] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-562213E44849,id=om1
om1_1        | 2021-06-25 13:41:48,033 [Listener at om1/9862] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.om1@group-562213E44849
om1_1        | 2021-06-25 13:41:48,083 [Listener at om1/9862] INFO server.RaftServer: om1: start RPC server
om1_1        | 2021-06-25 13:41:48,337 [Listener at om1/9862] INFO server.GrpcService: om1: GrpcService started, listening on 9872
om1_1        | 2021-06-25 13:41:48,370 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$387/0x000000084058fc40@5ceeab0c] INFO util.JvmPauseMonitor: JvmPauseMonitor-om1: Started
om1_1        | 2021-06-25 13:41:48,374 [Listener at om1/9862] INFO om.OzoneManager: Starting OM block token secret manager
om1_1        | 2021-06-25 13:41:48,382 [Listener at om1/9862] INFO security.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
om1_1        | 2021-06-25 13:41:48,384 [Listener at om1/9862] INFO om.OzoneManager: Starting OM delegation token secret manager
om1_1        | 2021-06-25 13:41:48,386 [Listener at om1/9862] INFO security.OzoneDelegationTokenSecretManager: Updating the current master key for generating tokens
om1_1        | 2021-06-25 13:41:48,412 [Thread[Thread-15,5,main]] INFO security.OzoneDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
om1_1        | 2021-06-25 13:41:48,600 [Listener at om1/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om1_1        | 2021-06-25 13:41:48,600 [Listener at om1/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
om1_1        | 2021-06-25 13:41:48,600 [Listener at om1/9862] INFO http.BaseHttpServer: HttpAuthType: ozone.om.http.auth.type = kerberos
om1_1        | 2021-06-25 13:41:48,711 [Listener at om1/9862] INFO util.log: Logging initialized @43828ms to org.eclipse.jetty.util.log.Slf4jLog
om1_1        | 2021-06-25 13:41:49,209 [Listener at om1/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om1_1        | 2021-06-25 13:41:49,235 [Listener at om1/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om1_1        | 2021-06-25 13:41:49,237 [Listener at om1/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context ozoneManager
om1_1        | 2021-06-25 13:41:49,237 [Listener at om1/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode3_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:413)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$5(GrpcClientProtocolClient.java:180)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:215)
datanode3_1  | 	... 18 more
datanode3_1  | 2021-06-25 13:42:04,447 [Command processor thread] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-AE62C1E0029A->8dca9ea8-5191-4cce-a34e-3d546f33f7b1
datanode3_1  | 2021-06-25 13:42:04,619 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:42:04,911 [Command processor thread] WARN commandhandler.CreatePipelineCommandHandler: Add group failed for 8dca9ea8-5191-4cce-a34e-3d546f33f7b1{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
om2_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-8e5d7696-3ffc-40b4-8848-61155fd5a026;layoutVersion=0
om2_1        | 2021-06-25 13:41:04,855 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om2_1        | /************************************************************
om2_1        | SHUTDOWN_MSG: Shutting down OzoneManager at om2/172.25.0.112
om2_1        | ************************************************************/
om2_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om2_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om2_1        | 2021-06-25 13:41:15,758 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om2_1        | /************************************************************
om2_1        | STARTUP_MSG: Starting OzoneManager
om2_1        | STARTUP_MSG:   host = om2/172.25.0.112
om2_1        | STARTUP_MSG:   args = []
om2_1        | STARTUP_MSG:   version = 1.2.0-SNAPSHOT
kdc_1        | Jun 25 13:56:12 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624629358, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:56:17 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624629358, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:56:22 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624629358, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:56:26 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624629358, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:56:34 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624629358, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:56:38 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624629358, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:56:42 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624629358, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:56:49 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624629358, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:57:01 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.117: ISSUE: authtime 1624629421, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:57:05 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624629421, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 25 13:57:13 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624629421, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:57:21 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624629421, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:57:25 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624629421, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:57:30 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624629421, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:57:35 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624629421, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:57:39 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624629421, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:57:43 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624629421, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:57:47 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624629421, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
datanode1_1  | 2021-06-25 13:42:07,821 [grpc-default-executor-0] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server_message_metrics.ee31bb40-6981-4b57-b8d7-3be03fa0c81d
datanode1_1  | 2021-06-25 13:42:07,890 [grpc-default-executor-0] INFO server.RaftServer$Division: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68: receive requestVote(ELECTION, 8dca9ea8-5191-4cce-a34e-3d546f33f7b1, group-BFEA630F7F68, 1, (t:0, i:0))
datanode1_1  | 2021-06-25 13:42:07,910 [grpc-default-executor-0] INFO impl.VoteContext: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68-CANDIDATE: reject ELECTION from 8dca9ea8-5191-4cce-a34e-3d546f33f7b1: already has voted for ee31bb40-6981-4b57-b8d7-3be03fa0c81d at current term 1
datanode1_1  | 2021-06-25 13:42:07,928 [grpc-default-executor-0] INFO server.RaftServer$Division: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68 replies to ELECTION vote request: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1<-ee31bb40-6981-4b57-b8d7-3be03fa0c81d#0:FAIL-t1. Peer's state: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68:t1, leader=null, voted=ee31bb40-6981-4b57-b8d7-3be03fa0c81d, raftlog=ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode1_1  | 2021-06-25 13:42:08,071 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68-LeaderElection1] INFO impl.LeaderElection: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68-LeaderElection1: ELECTION REJECTED received 2 response(s) and 0 exception(s):
datanode1_1  | 2021-06-25 13:42:08,074 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68-LeaderElection1] INFO impl.LeaderElection:   Response 0: ee31bb40-6981-4b57-b8d7-3be03fa0c81d<-8dca9ea8-5191-4cce-a34e-3d546f33f7b1#0:FAIL-t1
datanode1_1  | 2021-06-25 13:42:08,074 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68-LeaderElection1] INFO impl.LeaderElection:   Response 1: ee31bb40-6981-4b57-b8d7-3be03fa0c81d<-d7f71981-d306-415b-992d-ee4808a385fa#0:FAIL-t1
datanode1_1  | 2021-06-25 13:42:08,074 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68-LeaderElection1] INFO impl.LeaderElection: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68-LeaderElection1 ELECTION round 0: result REJECTED
datanode1_1  | 2021-06-25 13:42:08,077 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68-LeaderElection1] INFO server.RaftServer$Division: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
datanode1_1  | 2021-06-25 13:42:08,077 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68-LeaderElection1] INFO impl.RoleInfo: ee31bb40-6981-4b57-b8d7-3be03fa0c81d: shutdown ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68-LeaderElection1
datanode1_1  | 2021-06-25 13:42:08,078 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68-LeaderElection1] INFO impl.RoleInfo: ee31bb40-6981-4b57-b8d7-3be03fa0c81d: start ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68-FollowerState
datanode1_1  | 2021-06-25 13:42:08,196 [grpc-default-executor-0] INFO server.RaftServer$Division: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68: receive requestVote(ELECTION, d7f71981-d306-415b-992d-ee4808a385fa, group-BFEA630F7F68, 1, (t:0, i:0))
datanode1_1  | 2021-06-25 13:42:08,196 [grpc-default-executor-0] INFO impl.VoteContext: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68-FOLLOWER: reject ELECTION from d7f71981-d306-415b-992d-ee4808a385fa: already has voted for ee31bb40-6981-4b57-b8d7-3be03fa0c81d at current term 1
datanode1_1  | 2021-06-25 13:42:08,197 [grpc-default-executor-0] INFO server.RaftServer$Division: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68 replies to ELECTION vote request: d7f71981-d306-415b-992d-ee4808a385fa<-ee31bb40-6981-4b57-b8d7-3be03fa0c81d#0:FAIL-t1. Peer's state: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68:t1, leader=null, voted=ee31bb40-6981-4b57-b8d7-3be03fa0c81d, raftlog=ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode1_1  | 2021-06-25 13:42:10,267 [grpc-default-executor-0] INFO server.RaftServer$Division: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1: receive requestVote(ELECTION, d7f71981-d306-415b-992d-ee4808a385fa, group-5191BE84CAB1, 1, (t:0, i:0))
datanode1_1  | 2021-06-25 13:42:10,267 [grpc-default-executor-0] INFO impl.VoteContext: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1-FOLLOWER: reject ELECTION from d7f71981-d306-415b-992d-ee4808a385fa: our priority 1 > candidate's priority 0
datanode1_1  | 2021-06-25 13:42:10,267 [grpc-default-executor-0] INFO server.RaftServer$Division: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:d7f71981-d306-415b-992d-ee4808a385fa
datanode1_1  | 2021-06-25 13:42:10,267 [grpc-default-executor-0] INFO impl.RoleInfo: ee31bb40-6981-4b57-b8d7-3be03fa0c81d: shutdown ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1-FollowerState
datanode1_1  | 2021-06-25 13:42:10,267 [grpc-default-executor-0] INFO impl.RoleInfo: ee31bb40-6981-4b57-b8d7-3be03fa0c81d: start ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1-FollowerState
datanode1_1  | 2021-06-25 13:42:10,267 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1-FollowerState] INFO impl.FollowerState: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1-FollowerState was interrupted: {}
datanode1_1  | java.lang.InterruptedException: sleep interrupted
datanode1_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode1_1  | 	at java.base/java.lang.Thread.sleep(Thread.java:339)
datanode1_1  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode1_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
datanode1_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode1_1  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
datanode1_1  | 2021-06-25 13:42:10,272 [grpc-default-executor-0] INFO server.RaftServer$Division: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1 replies to ELECTION vote request: d7f71981-d306-415b-992d-ee4808a385fa<-ee31bb40-6981-4b57-b8d7-3be03fa0c81d#0:FAIL-t1. Peer's state: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1:t1, leader=null, voted=null, raftlog=ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1, d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0], old=null
datanode1_1  | 2021-06-25 13:42:10,315 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:42:11,422 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BF6D91D43FA5-FollowerState] INFO impl.FollowerState: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BF6D91D43FA5-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5058517126ns, electionTimeout:5046ms
datanode1_1  | 2021-06-25 13:42:11,423 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BF6D91D43FA5-FollowerState] INFO impl.RoleInfo: ee31bb40-6981-4b57-b8d7-3be03fa0c81d: shutdown ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BF6D91D43FA5-FollowerState
datanode1_1  | 2021-06-25 13:42:11,423 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BF6D91D43FA5-FollowerState] INFO server.RaftServer$Division: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BF6D91D43FA5: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode1_1  | 2021-06-25 13:42:11,424 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BF6D91D43FA5-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode1_1  | 2021-06-25 13:42:11,424 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BF6D91D43FA5-FollowerState] INFO impl.RoleInfo: ee31bb40-6981-4b57-b8d7-3be03fa0c81d: start ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BF6D91D43FA5-LeaderElection2
datanode1_1  | 2021-06-25 13:42:11,428 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BF6D91D43FA5-LeaderElection2] INFO impl.LeaderElection: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BF6D91D43FA5-LeaderElection2 ELECTION round 0: submit vote requests at term 1 for -1: [ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1], old=null
datanode1_1  | 2021-06-25 13:42:11,428 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BF6D91D43FA5-LeaderElection2] INFO impl.LeaderElection: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BF6D91D43FA5-LeaderElection2 ELECTION round 0: result PASSED (term=1)
datanode1_1  | 2021-06-25 13:42:11,429 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BF6D91D43FA5-LeaderElection2] INFO impl.RoleInfo: ee31bb40-6981-4b57-b8d7-3be03fa0c81d: shutdown ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BF6D91D43FA5-LeaderElection2
datanode1_1  | 2021-06-25 13:42:11,429 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BF6D91D43FA5-LeaderElection2] INFO server.RaftServer$Division: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BF6D91D43FA5: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode1_1  | 2021-06-25 13:42:11,430 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BF6D91D43FA5-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-BF6D91D43FA5 with new leaderId: ee31bb40-6981-4b57-b8d7-3be03fa0c81d
datanode1_1  | 2021-06-25 13:42:11,431 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BF6D91D43FA5-LeaderElection2] INFO server.RaftServer$Division: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BF6D91D43FA5: change Leader from null to ee31bb40-6981-4b57-b8d7-3be03fa0c81d at term 1 for becomeLeader, leader elected after 5129ms
datanode1_1  | 2021-06-25 13:42:11,439 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BF6D91D43FA5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode1_1  | 2021-06-25 13:42:11,443 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BF6D91D43FA5-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BF6D91D43FA5
datanode1_1  | 2021-06-25 13:42:11,447 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BF6D91D43FA5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode1_1  | 2021-06-25 13:42:11,447 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BF6D91D43FA5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
om1_1        | 2021-06-25 13:41:49,237 [Listener at om1/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
om1_1        | 2021-06-25 13:41:49,246 [Listener at om1/9862] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.om.http.auth.kerberos.principal keytabKey: ozone.om.http.auth.kerberos.keytab
om1_1        | 2021-06-25 13:41:49,434 [Listener at om1/9862] INFO http.HttpServer2: Jetty bound to port 9874
om1_1        | 2021-06-25 13:41:49,435 [Listener at om1/9862] INFO server.Server: jetty-9.4.35.v20201120; built: 2020-11-20T21:17:03.964Z; git: bdc54f03a5e0a7e280fab27f55c3c75ee8da89fb; jvm 11.0.10+9-LTS
om1_1        | 2021-06-25 13:41:49,717 [Listener at om1/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om1_1        | 2021-06-25 13:41:49,728 [Listener at om1/9862] INFO server.session: No SessionScavenger set, using defaults
om1_1        | 2021-06-25 13:41:49,736 [Listener at om1/9862] INFO server.session: node0 Scavenging every 600000ms
om1_1        | 2021-06-25 13:41:49,804 [Listener at om1/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om1_1        | 2021-06-25 13:41:49,808 [Listener at om1/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4f2ab774{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om1_1        | 2021-06-25 13:41:49,826 [Listener at om1/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5479abd8{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.2.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om1_1        | 2021-06-25 13:41:50,113 [Listener at om1/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om1_1        | 2021-06-25 13:41:50,156 [Listener at om1/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@1f9e42d2{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-ozone-manager-1_2_0-SNAPSHOT_jar-_-any-11402585612783485544/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.2.0-SNAPSHOT.jar!/webapps/ozoneManager}
om1_1        | 2021-06-25 13:41:50,199 [Listener at om1/9862] INFO server.AbstractConnector: Started ServerConnector@446d7669{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
om1_1        | 2021-06-25 13:41:50,203 [Listener at om1/9862] INFO server.Server: Started @45323ms
datanode3_1  | java.io.IOException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode3_1  | 	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:92)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:217)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:178)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:96)
datanode3_1  | 	at org.apache.ratis.client.impl.BlockingImpl.sendRequest(BlockingImpl.java:130)
datanode3_1  | 	at org.apache.ratis.client.impl.GroupManagementImpl.add(GroupManagementImpl.java:51)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.lambda$handle$1(CreatePipelineCommandHandler.java:99)
datanode3_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
datanode3_1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
datanode3_1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655)
datanode3_1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
datanode3_1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
datanode3_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
datanode3_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
datanode3_1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
datanode3_1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:95)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$2(DatanodeStateMachine.java:525)
datanode3_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode3_1  | Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:262)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:243)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:156)
datanode3_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:413)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$5(GrpcClientProtocolClient.java:180)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:215)
datanode3_1  | 	... 18 more
datanode3_1  | 2021-06-25 13:42:04,912 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=3175bb45-44a8-4478-8980-bfea630f7f68.
datanode3_1  | 2021-06-25 13:42:04,914 [pool-23-thread-1] INFO server.RaftServer$Division: d7f71981-d306-415b-992d-ee4808a385fa: new RaftServerImpl for group-6EB5E5ADD68D:[d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1] with ContainerStateMachine:uninitialized
datanode3_1  | 2021-06-25 13:42:04,915 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode3_1  | 2021-06-25 13:42:04,915 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode3_1  | 2021-06-25 13:42:04,915 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode3_1  | 2021-06-25 13:42:04,915 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode3_1  | 2021-06-25 13:42:04,916 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode3_1  | 2021-06-25 13:42:04,916 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode3_1  | 2021-06-25 13:42:04,916 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2021-06-25 13:42:04,917 [pool-23-thread-1] INFO server.RaftServer$Division: d7f71981-d306-415b-992d-ee4808a385fa@group-6EB5E5ADD68D: ConfigurationManager, init=-1: [d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode3_1  | 2021-06-25 13:42:04,922 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode3_1  | 2021-06-25 13:42:04,922 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode3_1  | 2021-06-25 13:42:04,922 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/8a55befb-80cf-4326-9d11-6eb5e5add68d does not exist. Creating ...
datanode3_1  | 2021-06-25 13:42:04,924 [Command processor thread] INFO server.RaftServer: d7f71981-d306-415b-992d-ee4808a385fa: addNew group-6EB5E5ADD68D:[d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1] returns group-6EB5E5ADD68D:java.util.concurrent.CompletableFuture@678fe559[Not completed]
datanode3_1  | 2021-06-25 13:42:04,930 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/8a55befb-80cf-4326-9d11-6eb5e5add68d/in_use.lock acquired by nodename 8@7b9eb44ecf31
datanode3_1  | 2021-06-25 13:42:04,934 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/8a55befb-80cf-4326-9d11-6eb5e5add68d has been successfully formatted.
datanode3_1  | 2021-06-25 13:42:04,936 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-6EB5E5ADD68D: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode3_1  | 2021-06-25 13:42:04,937 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode3_1  | 2021-06-25 13:42:04,937 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode3_1  | 2021-06-25 13:42:04,938 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode3_1  | 2021-06-25 13:42:04,938 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2021-06-25 13:42:04,941 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.d7f71981-d306-415b-992d-ee4808a385fa@group-6EB5E5ADD68D
datanode3_1  | 2021-06-25 13:42:04,942 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
om1_1        | 2021-06-25 13:41:50,206 [Listener at om1/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om1_1        | 2021-06-25 13:41:50,210 [Listener at om1/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om1_1        | 2021-06-25 13:41:50,212 [Listener at om1/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om1_1        | 2021-06-25 13:41:50,219 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om1_1        | 2021-06-25 13:41:50,223 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om1_1        | 2021-06-25 13:41:50,531 [Listener at om1/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted will not move to trash
om1_1        | 2021-06-25 13:41:50,554 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@595713f3] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om1_1        | 2021-06-25 13:41:53,104 [om1@group-562213E44849-FollowerState] INFO impl.FollowerState: om1@group-562213E44849-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5101407730ns, electionTimeout:5091ms
om1_1        | 2021-06-25 13:41:53,113 [om1@group-562213E44849-FollowerState] INFO impl.RoleInfo: om1: shutdown om1@group-562213E44849-FollowerState
om1_1        | 2021-06-25 13:41:53,114 [om1@group-562213E44849-FollowerState] INFO server.RaftServer$Division: om1@group-562213E44849: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
om1_1        | 2021-06-25 13:41:53,117 [om1@group-562213E44849-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om1_1        | 2021-06-25 13:41:53,117 [om1@group-562213E44849-FollowerState] INFO impl.RoleInfo: om1: start om1@group-562213E44849-LeaderElection1
om1_1        | 2021-06-25 13:41:53,130 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1        | 2021-06-25 13:41:54,837 [grpc-default-executor-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server_message_metrics.om1
om1_1        | 2021-06-25 13:41:54,837 [grpc-default-executor-0] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server_message_metrics.om1
om1_1        | 2021-06-25 13:41:54,867 [grpc-default-executor-0] INFO server.RaftServer$Division: om1@group-562213E44849: receive requestVote(ELECTION, om3, group-562213E44849, 1, (t:0, i:~))
om1_1        | 2021-06-25 13:41:54,868 [grpc-default-executor-0] INFO impl.VoteContext: om1@group-562213E44849-CANDIDATE: reject ELECTION from om3: already has voted for om1 at current term 1
om1_1        | 2021-06-25 13:41:54,868 [grpc-default-executor-1] INFO server.RaftServer$Division: om1@group-562213E44849: receive requestVote(ELECTION, om2, group-562213E44849, 1, (t:0, i:~))
om1_1        | 2021-06-25 13:41:54,888 [grpc-default-executor-0] INFO server.RaftServer$Division: om1@group-562213E44849 replies to ELECTION vote request: om3<-om1#0:FAIL-t1. Peer's state: om1@group-562213E44849:t1, leader=null, voted=om1, raftlog=om1@group-562213E44849-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1        | 2021-06-25 13:41:54,913 [grpc-default-executor-1] INFO impl.VoteContext: om1@group-562213E44849-CANDIDATE: reject ELECTION from om2: already has voted for om1 at current term 1
om1_1        | 2021-06-25 13:41:54,915 [grpc-default-executor-1] INFO server.RaftServer$Division: om1@group-562213E44849 replies to ELECTION vote request: om2<-om1#0:FAIL-t1. Peer's state: om1@group-562213E44849:t1, leader=null, voted=om1, raftlog=om1@group-562213E44849-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1        | 2021-06-25 13:41:54,949 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection1: ELECTION REJECTED received 2 response(s) and 0 exception(s):
om1_1        | 2021-06-25 13:41:54,949 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 0: om1<-om3#0:FAIL-t1
om1_1        | 2021-06-25 13:41:54,949 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 1: om1<-om2#0:FAIL-t1
om1_1        | 2021-06-25 13:41:54,949 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection1 ELECTION round 0: result REJECTED
om1_1        | 2021-06-25 13:41:54,952 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServer$Division: om1@group-562213E44849: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
om1_1        | 2021-06-25 13:41:54,952 [om1@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om1: shutdown om1@group-562213E44849-LeaderElection1
om1_1        | 2021-06-25 13:41:54,953 [om1@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om1: start om1@group-562213E44849-FollowerState
om1_1        | 2021-06-25 13:42:00,052 [grpc-default-executor-0] INFO server.RaftServer$Division: om1@group-562213E44849: receive requestVote(ELECTION, om3, group-562213E44849, 2, (t:0, i:~))
om1_1        | 2021-06-25 13:42:00,057 [grpc-default-executor-0] INFO impl.VoteContext: om1@group-562213E44849-FOLLOWER: accept ELECTION from om3: our priority 0 <= candidate's priority 0
om1_1        | 2021-06-25 13:42:00,063 [grpc-default-executor-0] INFO server.RaftServer$Division: om1@group-562213E44849: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:om3
om1_1        | 2021-06-25 13:42:00,063 [grpc-default-executor-0] INFO impl.RoleInfo: om1: shutdown om1@group-562213E44849-FollowerState
om1_1        | 2021-06-25 13:42:00,070 [om1@group-562213E44849-FollowerState] INFO impl.FollowerState: om1@group-562213E44849-FollowerState was interrupted: {}
om1_1        | java.lang.InterruptedException: sleep interrupted
om1_1        | 	at java.base/java.lang.Thread.sleep(Native Method)
om1_1        | 	at java.base/java.lang.Thread.sleep(Thread.java:339)
om1_1        | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
om1_1        | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
om1_1        | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
om1_1        | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
om1_1        | 2021-06-25 13:42:00,081 [grpc-default-executor-0] INFO impl.RoleInfo: om1: start om1@group-562213E44849-FollowerState
om1_1        | 2021-06-25 13:42:00,094 [grpc-default-executor-0] INFO server.RaftServer$Division: om1@group-562213E44849 replies to ELECTION vote request: om3<-om1#0:OK-t2. Peer's state: om1@group-562213E44849:t2, leader=null, voted=om3, raftlog=om1@group-562213E44849-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1        | 2021-06-25 13:42:00,949 [grpc-default-executor-0] INFO server.RaftServer$Division: om1@group-562213E44849: change Leader from null to om3 at term 2 for appendEntries, leader elected after 15464ms
om1_1        | 2021-06-25 13:42:01,199 [grpc-default-executor-0] INFO server.RaftServer$Division: om1@group-562213E44849: set configuration 0: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om1_1        | 2021-06-25 13:42:01,250 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: Starting segment from index:0
om1_1        | 2021-06-25 13:42:02,166 [om1@group-562213E44849-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/current/log_inprogress_0
datanode3_1  | 2021-06-25 13:42:04,943 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode3_1  | 2021-06-25 13:42:04,944 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode3_1  | 2021-06-25 13:42:04,951 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new d7f71981-d306-415b-992d-ee4808a385fa@group-6EB5E5ADD68D-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/8a55befb-80cf-4326-9d11-6eb5e5add68d
datanode3_1  | 2021-06-25 13:42:04,951 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode3_1  | 2021-06-25 13:42:04,955 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode3_1  | 2021-06-25 13:42:04,956 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2021-06-25 13:42:04,956 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode3_1  | 2021-06-25 13:42:04,957 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode3_1  | 2021-06-25 13:42:04,958 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode3_1  | 2021-06-25 13:42:04,959 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode3_1  | 2021-06-25 13:42:04,960 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode3_1  | 2021-06-25 13:42:04,969 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode3_1  | 2021-06-25 13:42:04,971 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode3_1  | 2021-06-25 13:42:04,978 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: d7f71981-d306-415b-992d-ee4808a385fa@group-6EB5E5ADD68D-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode3_1  | 2021-06-25 13:42:04,979 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: d7f71981-d306-415b-992d-ee4808a385fa@group-6EB5E5ADD68D-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode3_1  | 2021-06-25 13:42:04,980 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode3_1  | 2021-06-25 13:42:04,982 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode3_1  | 2021-06-25 13:42:04,984 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode3_1  | 2021-06-25 13:42:04,985 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode3_1  | 2021-06-25 13:42:04,990 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode3_1  | 2021-06-25 13:42:04,991 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode3_1  | 2021-06-25 13:42:04,993 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.d7f71981-d306-415b-992d-ee4808a385fa@group-6EB5E5ADD68D
datanode3_1  | 2021-06-25 13:42:04,994 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.d7f71981-d306-415b-992d-ee4808a385fa@group-6EB5E5ADD68D
datanode3_1  | 2021-06-25 13:42:04,997 [pool-23-thread-1] INFO server.RaftServer$Division: d7f71981-d306-415b-992d-ee4808a385fa@group-6EB5E5ADD68D: start as a follower, conf=-1: [d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode3_1  | 2021-06-25 13:42:04,998 [pool-23-thread-1] INFO server.RaftServer$Division: d7f71981-d306-415b-992d-ee4808a385fa@group-6EB5E5ADD68D: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode3_1  | 2021-06-25 13:42:04,998 [pool-23-thread-1] INFO impl.RoleInfo: d7f71981-d306-415b-992d-ee4808a385fa: start d7f71981-d306-415b-992d-ee4808a385fa@group-6EB5E5ADD68D-FollowerState
datanode3_1  | 2021-06-25 13:42:05,029 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-6EB5E5ADD68D,id=d7f71981-d306-415b-992d-ee4808a385fa
datanode3_1  | 2021-06-25 13:42:05,030 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.d7f71981-d306-415b-992d-ee4808a385fa@group-6EB5E5ADD68D
datanode3_1  | 2021-06-25 13:42:05,031 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=8a55befb-80cf-4326-9d11-6eb5e5add68d
datanode3_1  | 2021-06-25 13:42:05,033 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=8a55befb-80cf-4326-9d11-6eb5e5add68d.
datanode3_1  | 2021-06-25 13:42:05,042 [Command processor thread] INFO server.RaftServer: d7f71981-d306-415b-992d-ee4808a385fa: addNew group-5191BE84CAB1:[8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1, d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0] returns group-5191BE84CAB1:java.util.concurrent.CompletableFuture@5c2832f3[Not completed]
datanode3_1  | 2021-06-25 13:42:05,044 [pool-23-thread-1] INFO server.RaftServer$Division: d7f71981-d306-415b-992d-ee4808a385fa: new RaftServerImpl for group-5191BE84CAB1:[8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1, d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0] with ContainerStateMachine:uninitialized
datanode3_1  | 2021-06-25 13:42:05,045 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode3_1  | 2021-06-25 13:42:05,045 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode3_1  | 2021-06-25 13:42:05,045 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode3_1  | 2021-06-25 13:42:05,046 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode3_1  | 2021-06-25 13:42:05,046 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode3_1  | 2021-06-25 13:42:05,047 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode3_1  | 2021-06-25 13:42:05,047 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2021-06-25 13:42:05,048 [pool-23-thread-1] INFO server.RaftServer$Division: d7f71981-d306-415b-992d-ee4808a385fa@group-5191BE84CAB1: ConfigurationManager, init=-1: [8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1, d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0], old=null, confs=<EMPTY_MAP>
datanode3_1  | 2021-06-25 13:42:05,048 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode3_1  | 2021-06-25 13:42:05,049 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode3_1  | 2021-06-25 13:42:05,049 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/949dd475-00f3-4295-9774-5191be84cab1 does not exist. Creating ...
datanode3_1  | 2021-06-25 13:42:05,054 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/949dd475-00f3-4295-9774-5191be84cab1/in_use.lock acquired by nodename 8@7b9eb44ecf31
om1_1        | 2021-06-25 13:42:38,563 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:56236
om1_1        | 2021-06-25 13:42:38,594 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:42:57,548 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:56322
om1_1        | 2021-06-25 13:42:57,566 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:42:59,276 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:vol1 for user:testuser/scm@EXAMPLE.COM
om1_1        | 2021-06-25 13:43:10,488 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:56398
om1_1        | 2021-06-25 13:43:10,503 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:43:11,276 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:56406
om1_1        | 2021-06-25 13:43:11,285 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:43:16,779 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:56436
om1_1        | 2021-06-25 13:43:16,793 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:43:17,471 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:56442
om1_1        | 2021-06-25 13:43:17,479 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:43:23,405 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:56470
om1_1        | 2021-06-25 13:43:23,431 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:43:33,007 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:56518
om1_1        | 2021-06-25 13:43:33,031 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:43:39,763 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:56574
om1_1        | 2021-06-25 13:43:39,773 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:43:40,405 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:56582
om1_1        | 2021-06-25 13:43:40,414 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:43:45,614 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:56606
om1_1        | 2021-06-25 13:43:45,631 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:43:51,523 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:56642
om1_1        | 2021-06-25 13:43:51,537 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:44:08,384 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:56718
om1_1        | 2021-06-25 13:44:08,439 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:44:09,203 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:05944-source for user:testuser/scm@EXAMPLE.COM
om1_1        | 2021-06-25 13:44:13,317 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:56742
om1_1        | 2021-06-25 13:44:13,347 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:44:14,139 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:05944-target for user:testuser/scm@EXAMPLE.COM
om1_1        | 2021-06-25 13:44:18,777 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:56770
om1_1        | 2021-06-25 13:44:18,792 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:44:23,873 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:56796
om1_1        | 2021-06-25 13:44:23,915 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:44:32,642 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:56844
om1_1        | 2021-06-25 13:44:32,689 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:44:38,069 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:56888
datanode3_1  | 2021-06-25 13:42:05,057 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/949dd475-00f3-4295-9774-5191be84cab1 has been successfully formatted.
kdc_1        | Jun 25 13:57:52 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624629421, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:57:57 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624629421, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:58:12 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624629421, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:58:15 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.117: ISSUE: authtime 1624629495, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:58:20 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624629495, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:58:20 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.117: ISSUE: authtime 1624629500, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:58:24 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624629500, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:58:25 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.117: ISSUE: authtime 1624629505, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:58:29 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624629505, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:58:33 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624629505, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:58:38 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624629505, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:58:43 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624629505, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:58:45 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.117: ISSUE: authtime 1624629525, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:58:49 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624629525, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:58:53 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624629525, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:58:57 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624629525, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:59:02 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624629525, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
om2_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/javax.activation-api-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.2.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0-a398b19-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.2.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.2.0-SNAPSHOT.jar
om2_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/450c3750335593082ae39a2d17d4a2a58090f75f ; compiled by 'runner' on 2021-06-25T12:44Z
om2_1        | STARTUP_MSG:   java = 11.0.10
om2_1        | ************************************************************/
om2_1        | 2021-06-25 13:41:15,866 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om2_1        | 2021-06-25 13:41:26,764 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om2_1        | 2021-06-25 13:41:27,706 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om2, RPC Address: om2:9862 and Ratis port: 9872
om2_1        | 2021-06-25 13:41:27,711 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om2: om2
om2_1        | 2021-06-25 13:41:27,716 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om2: om2
om2_1        | 2021-06-25 13:41:27,837 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2021-06-25 13:41:30,431 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file /etc/security/keytabs/om.keytab
om2_1        | 2021-06-25 13:41:30,453 [main] INFO om.OzoneManager: Ozone Manager login successful.
om2_1        | 2021-06-25 13:41:30,453 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2021-06-25 13:41:36,626 [main] INFO client.OMCertificateClient: Loading certificate from location:/data/metadata/om/certs.
om2_1        | 2021-06-25 13:41:37,092 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/ROOTCA-1.crt.
om2_1        | 2021-06-25 13:41:37,115 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/CA-2884006640668.crt.
om2_1        | 2021-06-25 13:41:37,126 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/2994024836317.crt.
om2_1        | 2021-06-25 13:41:37,317 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2021-06-25 13:41:37,904 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om2_1        | 2021-06-25 13:41:37,910 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om2_1        | 2021-06-25 13:41:38,704 [main] INFO Configuration.deprecation: No unit for ozone.manager.delegation.remover.scan.interval(3600000) assuming MILLISECONDS
om2_1        | 2021-06-25 13:41:38,726 [main] INFO security.OzoneSecretStore: Loaded 0 tokens
om2_1        | 2021-06-25 13:41:38,728 [main] INFO security.OzoneDelegationTokenSecretManager: Loading token state into token manager.
om2_1        | 2021-06-25 13:41:39,208 [main] INFO om.OzoneManager: Created Volume s3v With Owner root required for S3Gateway operations.
om2_1        | 2021-06-25 13:41:39,229 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om2_1        | 2021-06-25 13:41:39,229 [main] WARN ratis.OzoneManagerRatisServer: ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
om2_1        | 2021-06-25 13:41:39,254 [main] INFO snapshot.OzoneManagerSnapshotProvider: Initializing OM Snapshot Provider
om2_1        | 2021-06-25 13:41:40,230 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om2_1        | 2021-06-25 13:41:40,459 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om2_1        | 2021-06-25 13:41:40,669 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with GroupID: id1 and Raft Peers: om2:9872, om1:9872, om3:9872
om2_1        | 2021-06-25 13:41:40,864 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
om2_1        | 2021-06-25 13:41:41,700 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
om2_1        | 2021-06-25 13:41:42,003 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
om2_1        | 2021-06-25 13:41:42,007 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om2_1        | 2021-06-25 13:41:42,009 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
om2_1        | 2021-06-25 13:41:42,009 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om2_1        | 2021-06-25 13:41:42,014 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om2_1        | 2021-06-25 13:41:42,015 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om2_1        | 2021-06-25 13:41:42,036 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om2_1        | 2021-06-25 13:41:42,038 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om2_1        | 2021-06-25 13:41:42,045 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om2_1        | 2021-06-25 13:41:44,670 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om2_1        | 2021-06-25 13:41:44,674 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om2_1        | 2021-06-25 13:41:44,675 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om2_1        | 2021-06-25 13:41:44,700 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om2_1        | 2021-06-25 13:41:44,736 [main] INFO server.RaftServer: om2: addNew group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] returns group-562213E44849:java.util.concurrent.CompletableFuture@32be672d[Not completed]
om2_1        | 2021-06-25 13:41:44,738 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om2_1        | 2021-06-25 13:41:44,919 [pool-22-thread-1] INFO server.RaftServer$Division: om2: new RaftServerImpl for group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] with OzoneManagerStateMachine:uninitialized
om2_1        | 2021-06-25 13:41:44,937 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om2_1        | 2021-06-25 13:41:44,951 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om2_1        | 2021-06-25 13:41:44,951 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om2_1        | 2021-06-25 13:41:44,956 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om2_1        | 2021-06-25 13:41:44,962 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om2_1        | 2021-06-25 13:41:44,963 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om2_1        | 2021-06-25 13:41:44,974 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om2_1        | 2021-06-25 13:41:45,018 [pool-22-thread-1] INFO server.RaftServer$Division: om2@group-562213E44849: ConfigurationManager, init=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null, confs=<EMPTY_MAP>
om2_1        | 2021-06-25 13:41:45,030 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om2_1        | 2021-06-25 13:41:45,087 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om2_1        | 2021-06-25 13:41:45,099 [pool-22-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 does not exist. Creating ...
om2_1        | 2021-06-25 13:41:45,118 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om2_1        | 2021-06-25 13:41:45,182 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om2_1        | 2021-06-25 13:41:45,214 [pool-22-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/in_use.lock acquired by nodename 7@om2
om2_1        | 2021-06-25 13:41:45,384 [pool-22-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 has been successfully formatted.
om2_1        | 2021-06-25 13:41:45,387 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om2_1        | 2021-06-25 13:41:45,404 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om2_1        | 2021-06-25 13:41:45,481 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om2_1        | 2021-06-25 13:41:45,513 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om2_1        | 2021-06-25 13:41:45,642 [pool-22-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.om2@group-562213E44849
om2_1        | 2021-06-25 13:41:45,762 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om2_1        | 2021-06-25 13:41:45,850 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om2_1        | 2021-06-25 13:41:45,857 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om2_1        | 2021-06-25 13:41:45,987 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: new om2@group-562213E44849-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849
om2_1        | 2021-06-25 13:41:45,993 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om2_1        | 2021-06-25 13:41:45,994 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om2_1        | 2021-06-25 13:41:45,999 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om2_1        | 2021-06-25 13:41:46,018 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om2_1        | 2021-06-25 13:41:46,021 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om2_1        | 2021-06-25 13:41:46,031 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om2_1        | 2021-06-25 13:41:46,045 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om2_1        | 2021-06-25 13:41:46,046 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om2_1        | 2021-06-25 13:41:46,157 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om2_1        | 2021-06-25 13:41:46,181 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om2_1        | 2021-06-25 13:41:46,235 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
kdc_1        | Jun 25 13:59:06 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624629525, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:59:11 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624629525, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:59:16 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624629525, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:59:20 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624629525, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:59:25 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624629525, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:59:28 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.117: ISSUE: authtime 1624629568, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 25 13:59:32 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624629568, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:59:36 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624629568, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:59:40 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624629568, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:59:44 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624629568, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:59:48 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624629568, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:59:52 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624629568, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 13:59:59 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624629568, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 14:00:04 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624629568, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 14:00:08 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624629568, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 25 14:00:15 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624629568, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
datanode2_1  | 2021-06-25 13:42:15,341 [grpc-default-executor-0] INFO server.RaftServer$Division: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-5191BE84CAB1 replies to ELECTION vote request: ee31bb40-6981-4b57-b8d7-3be03fa0c81d<-8dca9ea8-5191-4cce-a34e-3d546f33f7b1#0:OK-t2. Peer's state: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-5191BE84CAB1:t2, leader=null, voted=ee31bb40-6981-4b57-b8d7-3be03fa0c81d, raftlog=8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-5191BE84CAB1-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1, d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0], old=null
datanode2_1  | 2021-06-25 13:42:15,450 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-5191BE84CAB1 with new leaderId: ee31bb40-6981-4b57-b8d7-3be03fa0c81d
datanode2_1  | 2021-06-25 13:42:15,450 [grpc-default-executor-0] INFO server.RaftServer$Division: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-5191BE84CAB1: change Leader from null to ee31bb40-6981-4b57-b8d7-3be03fa0c81d at term 2 for appendEntries, leader elected after 10085ms
datanode2_1  | 2021-06-25 13:42:15,498 [grpc-default-executor-0] INFO server.RaftServer$Division: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-5191BE84CAB1: set configuration 0: [8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode2_1  | 2021-06-25 13:42:15,498 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-5191BE84CAB1-SegmentedRaftLogWorker: Starting segment from index:0
datanode2_1  | 2021-06-25 13:42:15,500 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-5191BE84CAB1-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-5191BE84CAB1-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/949dd475-00f3-4295-9774-5191be84cab1/current/log_inprogress_0
datanode2_1  | 2021-06-25 13:42:18,186 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:42:18,261 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-FollowerState] INFO impl.FollowerState: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5130359039ns, electionTimeout:5124ms
datanode2_1  | 2021-06-25 13:42:18,262 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-FollowerState] INFO impl.RoleInfo: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1: shutdown 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-FollowerState
datanode2_1  | 2021-06-25 13:42:18,262 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-FollowerState] INFO server.RaftServer$Division: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68: changes role from  FOLLOWER to CANDIDATE at term 2 for changeToCandidate
datanode2_1  | 2021-06-25 13:42:18,262 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode2_1  | 2021-06-25 13:42:18,263 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-FollowerState] INFO impl.RoleInfo: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1: start 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-LeaderElection4
datanode2_1  | 2021-06-25 13:42:18,278 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-LeaderElection4] INFO impl.LeaderElection: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-LeaderElection4 ELECTION round 0: submit vote requests at term 3 for -1: [8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode2_1  | 2021-06-25 13:42:18,302 [grpc-default-executor-0] INFO server.RaftServer$Division: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68: receive requestVote(ELECTION, d7f71981-d306-415b-992d-ee4808a385fa, group-BFEA630F7F68, 3, (t:0, i:0))
datanode2_1  | 2021-06-25 13:42:18,303 [grpc-default-executor-0] INFO impl.VoteContext: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-CANDIDATE: reject ELECTION from d7f71981-d306-415b-992d-ee4808a385fa: already has voted for 8dca9ea8-5191-4cce-a34e-3d546f33f7b1 at current term 3
datanode2_1  | 2021-06-25 13:42:18,303 [grpc-default-executor-0] INFO server.RaftServer$Division: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68 replies to ELECTION vote request: d7f71981-d306-415b-992d-ee4808a385fa<-8dca9ea8-5191-4cce-a34e-3d546f33f7b1#0:FAIL-t3. Peer's state: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68:t3, leader=null, voted=8dca9ea8-5191-4cce-a34e-3d546f33f7b1, raftlog=8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode2_1  | 2021-06-25 13:42:18,326 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-LeaderElection4] INFO impl.LeaderElection: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-LeaderElection4: ELECTION REJECTED received 1 response(s) and 0 exception(s):
datanode2_1  | 2021-06-25 13:42:18,326 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-LeaderElection4] INFO impl.LeaderElection:   Response 0: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1<-d7f71981-d306-415b-992d-ee4808a385fa#0:FAIL-t3
datanode2_1  | 2021-06-25 13:42:18,326 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-LeaderElection4] INFO impl.LeaderElection: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-LeaderElection4 ELECTION round 0: result REJECTED
datanode2_1  | 2021-06-25 13:42:18,326 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-LeaderElection4] INFO server.RaftServer$Division: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68: changes role from CANDIDATE to FOLLOWER at term 3 for REJECTED
datanode2_1  | 2021-06-25 13:42:18,327 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-LeaderElection4] INFO impl.RoleInfo: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1: shutdown 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-LeaderElection4
datanode2_1  | 2021-06-25 13:42:18,327 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-LeaderElection4] INFO impl.RoleInfo: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1: start 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-FollowerState
datanode2_1  | 2021-06-25 13:42:21,258 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | Sleeping for 5 seconds
om3_1        | Waiting for the service scm3.org:9894
om3_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om3_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om3_1        | 2021-06-25 13:40:29,707 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om3_1        | /************************************************************
om3_1        | STARTUP_MSG: Starting OzoneManager
om3_1        | STARTUP_MSG:   host = om3/172.25.0.113
om3_1        | STARTUP_MSG:   args = [--init]
om3_1        | STARTUP_MSG:   version = 1.2.0-SNAPSHOT
om3_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/javax.activation-api-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.2.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0-a398b19-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.2.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.2.0-SNAPSHOT.jar
om3_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/450c3750335593082ae39a2d17d4a2a58090f75f ; compiled by 'runner' on 2021-06-25T12:44Z
om3_1        | STARTUP_MSG:   java = 11.0.10
om3_1        | ************************************************************/
om3_1        | 2021-06-25 13:40:29,772 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om3_1        | 2021-06-25 13:40:41,504 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om3_1        | 2021-06-25 13:40:42,348 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om3, RPC Address: om3:9862 and Ratis port: 9872
om3_1        | 2021-06-25 13:40:42,360 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om3: om3
om3_1        | 2021-06-25 13:40:42,362 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om3: om3
om3_1        | 2021-06-25 13:40:44,097 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file /etc/security/keytabs/om.keytab
om3_1        | 2021-06-25 13:40:44,114 [main] INFO om.OzoneManager: Ozone Manager login successful.
om3_1        | 2021-06-25 13:40:44,297 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2021-06-25 13:40:48,868 [main] INFO om.OzoneManager: Initializing secure OzoneManager.
om3_1        | 2021-06-25 13:40:52,772 [main] ERROR client.OMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
om3_1        | 2021-06-25 13:40:52,785 [main] INFO client.OMCertificateClient: Certificate client init case: 0
om3_1        | 2021-06-25 13:40:52,786 [main] INFO client.OMCertificateClient: Creating keypair for client as keypair and certificate not found.
om3_1        | 2021-06-25 13:40:59,157 [main] INFO om.OzoneManager: Init response: GETCERT
om3_1        | 2021-06-25 13:40:59,821 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.113,host:om3
om3_1        | 2021-06-25 13:40:59,835 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
om3_1        | 2021-06-25 13:40:59,838 [main] ERROR client.OMCertificateClient: Invalid domain om3
om3_1        | 2021-06-25 13:40:59,859 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om3_1        | 2021-06-25 13:40:59,863 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om3, RPC Address: om3:9862 and Ratis port: 9872
om3_1        | 2021-06-25 13:40:59,864 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om3: om3
om3_1        | 2021-06-25 13:40:59,865 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om3: om3
om3_1        | 2021-06-25 13:40:59,873 [main] INFO om.OzoneManager: Creating csr for OM->dns:om3,ip:172.25.0.113,scmId:76093931-f232-4415-806f-239960e589cb,clusterId:CID-8e5d7696-3ffc-40b4-8848-61155fd5a026,subject:om3
om3_1        | 2021-06-25 13:41:00,960 [main] INFO om.OzoneManager: OzoneManager ports added:[name: "RPC"
om3_1        | value: 9862
om3_1        | ]
om3_1        | 2021-06-25 13:41:02,745 [main] INFO om.OzoneManager: Successfully stored SCM signed certificate.
om3_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-8e5d7696-3ffc-40b4-8848-61155fd5a026;layoutVersion=0
om3_1        | 2021-06-25 13:41:02,937 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om3_1        | /************************************************************
om3_1        | SHUTDOWN_MSG: Shutting down OzoneManager at om3/172.25.0.113
om3_1        | ************************************************************/
om3_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om3_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om3_1        | 2021-06-25 13:41:13,931 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om3_1        | /************************************************************
om3_1        | STARTUP_MSG: Starting OzoneManager
om3_1        | STARTUP_MSG:   host = om3/172.25.0.113
om3_1        | STARTUP_MSG:   args = []
om3_1        | STARTUP_MSG:   version = 1.2.0-SNAPSHOT
om3_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/javax.activation-api-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.2.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0-a398b19-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.2.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.2.0-SNAPSHOT.jar
om3_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/450c3750335593082ae39a2d17d4a2a58090f75f ; compiled by 'runner' on 2021-06-25T12:44Z
om3_1        | STARTUP_MSG:   java = 11.0.10
om3_1        | ************************************************************/
om3_1        | 2021-06-25 13:41:14,056 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om3_1        | 2021-06-25 13:41:24,292 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om3_1        | 2021-06-25 13:41:25,262 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om3, RPC Address: om3:9862 and Ratis port: 9872
om3_1        | 2021-06-25 13:41:25,263 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om3: om3
om3_1        | 2021-06-25 13:41:25,264 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om3: om3
om3_1        | 2021-06-25 13:41:25,405 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
datanode1_1  | 2021-06-25 13:42:11,459 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BF6D91D43FA5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode1_1  | 2021-06-25 13:42:11,460 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BF6D91D43FA5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode1_1  | 2021-06-25 13:42:11,461 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BF6D91D43FA5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode1_1  | 2021-06-25 13:42:11,505 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BF6D91D43FA5-LeaderElection2] INFO impl.RoleInfo: ee31bb40-6981-4b57-b8d7-3be03fa0c81d: start ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BF6D91D43FA5-LeaderStateImpl
datanode1_1  | 2021-06-25 13:42:11,535 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BF6D91D43FA5-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BF6D91D43FA5-SegmentedRaftLogWorker: Starting segment from index:0
datanode1_1  | 2021-06-25 13:42:11,598 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BF6D91D43FA5-LeaderElection2] INFO server.RaftServer$Division: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BF6D91D43FA5: set configuration 0: [ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1], old=null
datanode1_1  | 2021-06-25 13:42:11,711 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BF6D91D43FA5-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BF6D91D43FA5-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/145b110b-f1b2-4a24-b4ba-bf6d91d43fa5/current/log_inprogress_0
datanode1_1  | 2021-06-25 13:42:12,392 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] WARN statemachine.EndpointStateMachine: Unable to communicate to Recon server at recon:9891 for past 0 seconds.
datanode1_1  | java.net.NoRouteToHostException: No Route to Host from  9d41ca97b170/172.25.0.102 to recon:9891 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
datanode1_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode1_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode1_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode1_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode1_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:836)
datanode1_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:787)
datanode1_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1566)
datanode1_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
datanode1_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
datanode1_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
datanode1_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
datanode1_1  | 	at com.sun.proxy.$Proxy40.submitRequest(Unknown Source)
datanode1_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
datanode1_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:133)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:71)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:42)
datanode1_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode1_1  | Caused by: java.net.NoRouteToHostException: No route to host
datanode1_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
datanode1_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:779)
datanode1_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
datanode1_1  | 	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:534)
datanode1_1  | 	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:699)
datanode1_1  | 	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:812)
datanode1_1  | 	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:413)
datanode1_1  | 	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1636)
datanode1_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1452)
datanode1_1  | 	... 12 more
datanode1_1  | 2021-06-25 13:42:13,108 [grpc-default-executor-0] INFO server.RaftServer$Division: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68: receive requestVote(ELECTION, 8dca9ea8-5191-4cce-a34e-3d546f33f7b1, group-BFEA630F7F68, 2, (t:0, i:0))
datanode1_1  | 2021-06-25 13:42:13,108 [grpc-default-executor-0] INFO impl.VoteContext: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68-FOLLOWER: accept ELECTION from 8dca9ea8-5191-4cce-a34e-3d546f33f7b1: our priority 0 <= candidate's priority 0
datanode1_1  | 2021-06-25 13:42:13,108 [grpc-default-executor-0] INFO server.RaftServer$Division: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:8dca9ea8-5191-4cce-a34e-3d546f33f7b1
datanode1_1  | 2021-06-25 13:42:13,108 [grpc-default-executor-0] INFO impl.RoleInfo: ee31bb40-6981-4b57-b8d7-3be03fa0c81d: shutdown ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68-FollowerState
datanode1_1  | 2021-06-25 13:42:13,108 [grpc-default-executor-0] INFO impl.RoleInfo: ee31bb40-6981-4b57-b8d7-3be03fa0c81d: start ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68-FollowerState
datanode1_1  | 2021-06-25 13:42:13,109 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68-FollowerState] INFO impl.FollowerState: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68-FollowerState was interrupted: {}
datanode1_1  | java.lang.InterruptedException: sleep interrupted
datanode1_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode1_1  | 	at java.base/java.lang.Thread.sleep(Thread.java:339)
datanode1_1  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode1_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
datanode1_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode1_1  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
datanode1_1  | 2021-06-25 13:42:13,124 [grpc-default-executor-0] INFO server.RaftServer$Division: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68 replies to ELECTION vote request: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1<-ee31bb40-6981-4b57-b8d7-3be03fa0c81d#0:OK-t2. Peer's state: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68:t2, leader=null, voted=8dca9ea8-5191-4cce-a34e-3d546f33f7b1, raftlog=ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode1_1  | 2021-06-25 13:42:15,285 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1-FollowerState] INFO impl.FollowerState: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5017370371ns, electionTimeout:5014ms
datanode1_1  | 2021-06-25 13:42:15,285 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1-FollowerState] INFO impl.RoleInfo: ee31bb40-6981-4b57-b8d7-3be03fa0c81d: shutdown ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1-FollowerState
datanode1_1  | 2021-06-25 13:42:15,286 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1-FollowerState] INFO server.RaftServer$Division: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
datanode1_1  | 2021-06-25 13:42:15,286 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode1_1  | 2021-06-25 13:42:15,286 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1-FollowerState] INFO impl.RoleInfo: ee31bb40-6981-4b57-b8d7-3be03fa0c81d: start ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1-LeaderElection3
datanode1_1  | 2021-06-25 13:42:15,299 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1-LeaderElection3] INFO impl.LeaderElection: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1-LeaderElection3 ELECTION round 0: submit vote requests at term 2 for -1: [8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1, d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0], old=null
datanode1_1  | 2021-06-25 13:42:15,339 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1-LeaderElection3] INFO impl.LeaderElection: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1-LeaderElection3: ELECTION PASSED received 1 response(s) and 0 exception(s):
datanode1_1  | 2021-06-25 13:42:15,339 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1-LeaderElection3] INFO impl.LeaderElection:   Response 0: ee31bb40-6981-4b57-b8d7-3be03fa0c81d<-d7f71981-d306-415b-992d-ee4808a385fa#0:OK-t2
datanode1_1  | 2021-06-25 13:42:15,340 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1-LeaderElection3] INFO impl.LeaderElection: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1-LeaderElection3 ELECTION round 0: result PASSED
datanode1_1  | 2021-06-25 13:42:15,340 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1-LeaderElection3] INFO impl.RoleInfo: ee31bb40-6981-4b57-b8d7-3be03fa0c81d: shutdown ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1-LeaderElection3
datanode1_1  | 2021-06-25 13:42:15,340 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1-LeaderElection3] INFO server.RaftServer$Division: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
datanode1_1  | 2021-06-25 13:42:15,340 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1-LeaderElection3] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-5191BE84CAB1 with new leaderId: ee31bb40-6981-4b57-b8d7-3be03fa0c81d
datanode1_1  | 2021-06-25 13:42:15,341 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1-LeaderElection3] INFO server.RaftServer$Division: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1: change Leader from null to ee31bb40-6981-4b57-b8d7-3be03fa0c81d at term 2 for becomeLeader, leader elected after 9982ms
datanode1_1  | 2021-06-25 13:42:15,341 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode1_1  | 2021-06-25 13:42:15,341 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1-LeaderElection3] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1
datanode1_1  | 2021-06-25 13:42:15,342 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode1_1  | 2021-06-25 13:42:15,342 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode1_1  | 2021-06-25 13:42:15,342 [Datanode State Machine Thread - 0] WARN statemachine.StateContext: No available thread in pool for past 30 seconds.
om2_1        | 2021-06-25 13:41:46,237 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om2_1        | 2021-06-25 13:41:46,271 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om2_1        | 2021-06-25 13:41:46,287 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om2_1        | 2021-06-25 13:41:46,298 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om2_1        | 2021-06-25 13:41:46,308 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om2_1        | 2021-06-25 13:41:46,310 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
om2_1        | 2021-06-25 13:41:46,320 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om2_1        | 2021-06-25 13:41:46,669 [pool-22-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.om2@group-562213E44849
om2_1        | 2021-06-25 13:41:46,743 [pool-22-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.om2@group-562213E44849
om2_1        | 2021-06-25 13:41:46,944 [Listener at om2/9862] INFO om.OzoneManager: Configured ozone.om.metadata.layout=SIMPLE and disabled optimized OM FS operations
om2_1        | 2021-06-25 13:41:47,384 [Listener at om2/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om2_1        | 2021-06-25 13:41:47,484 [Listener at om2/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om2_1        | 2021-06-25 13:41:47,485 [Listener at om2/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om2_1        | 2021-06-25 13:41:47,679 [Listener at om2/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om2/172.25.0.112:9862
om2_1        | 2021-06-25 13:41:47,679 [Listener at om2/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om2 at port 9872
om2_1        | 2021-06-25 13:41:47,681 [Listener at om2/9862] INFO server.RaftServer$Division: om2@group-562213E44849: start as a follower, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om2_1        | 2021-06-25 13:41:47,691 [Listener at om2/9862] INFO server.RaftServer$Division: om2@group-562213E44849: changes role from      null to FOLLOWER at term 0 for startAsFollower
om2_1        | 2021-06-25 13:41:47,692 [Listener at om2/9862] INFO impl.RoleInfo: om2: start om2@group-562213E44849-FollowerState
om2_1        | 2021-06-25 13:41:47,713 [Listener at om2/9862] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-562213E44849,id=om2
om2_1        | 2021-06-25 13:41:47,715 [Listener at om2/9862] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.om2@group-562213E44849
om2_1        | 2021-06-25 13:41:47,749 [Listener at om2/9862] INFO server.RaftServer: om2: start RPC server
om2_1        | 2021-06-25 13:41:48,000 [Listener at om2/9862] INFO server.GrpcService: om2: GrpcService started, listening on 9872
om2_1        | 2021-06-25 13:41:48,014 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$387/0x000000084058fc40@7194f5b] INFO util.JvmPauseMonitor: JvmPauseMonitor-om2: Started
om2_1        | 2021-06-25 13:41:48,015 [Listener at om2/9862] INFO om.OzoneManager: Starting OM block token secret manager
om2_1        | 2021-06-25 13:41:48,016 [Listener at om2/9862] INFO security.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
om2_1        | 2021-06-25 13:41:48,018 [Listener at om2/9862] INFO om.OzoneManager: Starting OM delegation token secret manager
om2_1        | 2021-06-25 13:41:48,018 [Listener at om2/9862] INFO security.OzoneDelegationTokenSecretManager: Updating the current master key for generating tokens
om2_1        | 2021-06-25 13:41:48,042 [Thread[Thread-15,5,main]] INFO security.OzoneDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
om2_1        | 2021-06-25 13:41:48,210 [Listener at om2/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om2_1        | 2021-06-25 13:41:48,210 [Listener at om2/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
om2_1        | 2021-06-25 13:41:48,210 [Listener at om2/9862] INFO http.BaseHttpServer: HttpAuthType: ozone.om.http.auth.type = kerberos
om2_1        | 2021-06-25 13:41:48,308 [Listener at om2/9862] INFO util.log: Logging initialized @42092ms to org.eclipse.jetty.util.log.Slf4jLog
om2_1        | 2021-06-25 13:41:48,713 [Listener at om2/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om2_1        | 2021-06-25 13:41:48,726 [Listener at om2/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om2_1        | 2021-06-25 13:41:48,731 [Listener at om2/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context ozoneManager
om2_1        | 2021-06-25 13:41:48,731 [Listener at om2/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
om2_1        | 2021-06-25 13:41:48,731 [Listener at om2/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
om2_1        | 2021-06-25 13:41:48,739 [Listener at om2/9862] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.om.http.auth.kerberos.principal keytabKey: ozone.om.http.auth.kerberos.keytab
om2_1        | 2021-06-25 13:41:48,863 [Listener at om2/9862] INFO http.HttpServer2: Jetty bound to port 9874
om2_1        | 2021-06-25 13:41:48,871 [Listener at om2/9862] INFO server.Server: jetty-9.4.35.v20201120; built: 2020-11-20T21:17:03.964Z; git: bdc54f03a5e0a7e280fab27f55c3c75ee8da89fb; jvm 11.0.10+9-LTS
om2_1        | 2021-06-25 13:41:49,022 [Listener at om2/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om2_1        | 2021-06-25 13:41:49,023 [Listener at om2/9862] INFO server.session: No SessionScavenger set, using defaults
om2_1        | 2021-06-25 13:41:49,036 [Listener at om2/9862] INFO server.session: node0 Scavenging every 600000ms
om2_1        | 2021-06-25 13:41:49,109 [Listener at om2/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om2_1        | 2021-06-25 13:41:49,113 [Listener at om2/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@f57ced1{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om2_1        | 2021-06-25 13:41:49,114 [Listener at om2/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2004f99{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.2.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om2_1        | 2021-06-25 13:41:49,660 [Listener at om2/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om2_1        | 2021-06-25 13:41:49,711 [Listener at om2/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@4f1fb8fc{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-ozone-manager-1_2_0-SNAPSHOT_jar-_-any-12976834906747794659/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.2.0-SNAPSHOT.jar!/webapps/ozoneManager}
om2_1        | 2021-06-25 13:41:49,757 [Listener at om2/9862] INFO server.AbstractConnector: Started ServerConnector@e1f17e6{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
om2_1        | 2021-06-25 13:41:49,766 [Listener at om2/9862] INFO server.Server: Started @43541ms
om2_1        | 2021-06-25 13:41:49,768 [Listener at om2/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om2_1        | 2021-06-25 13:41:49,774 [Listener at om2/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om1_1        | 2021-06-25 13:44:38,087 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:44:42,898 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:56914
om1_1        | 2021-06-25 13:44:42,916 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:44:47,908 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:56940
om1_1        | 2021-06-25 13:44:47,931 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:44:52,958 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:56966
om1_1        | 2021-06-25 13:44:52,976 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:44:58,143 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:56994
om1_1        | 2021-06-25 13:44:58,171 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:45:03,226 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:57012
om1_1        | 2021-06-25 13:45:03,246 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:45:07,628 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:57054
om1_1        | 2021-06-25 13:45:07,647 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:45:12,755 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:57080
om1_1        | 2021-06-25 13:45:12,777 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:45:18,277 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:57106
om1_1        | 2021-06-25 13:45:18,291 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:45:23,871 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:57132
om1_1        | 2021-06-25 13:45:23,892 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:45:29,270 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:57162
om1_1        | 2021-06-25 13:45:29,298 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:45:34,968 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:57216
om1_1        | 2021-06-25 13:45:35,000 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:45:40,239 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:57244
om1_1        | 2021-06-25 13:45:40,253 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:45:48,328 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:57278
om1_1        | 2021-06-25 13:45:48,343 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:45:56,493 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:57316
om1_1        | 2021-06-25 13:45:56,527 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:46:05,776 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:57382
om1_1        | 2021-06-25 13:46:05,795 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:46:13,158 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:57414
om1_1        | 2021-06-25 13:46:13,176 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:46:18,485 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:57444
om1_1        | 2021-06-25 13:46:18,510 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:46:23,804 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:57468
om1_1        | 2021-06-25 13:46:23,825 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:46:29,094 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:57496
datanode3_1  | 2021-06-25 13:42:05,059 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-5191BE84CAB1: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode3_1  | 2021-06-25 13:42:05,060 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode3_1  | 2021-06-25 13:42:05,060 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode3_1  | 2021-06-25 13:42:05,061 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode3_1  | 2021-06-25 13:42:05,061 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2021-06-25 13:42:05,062 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.d7f71981-d306-415b-992d-ee4808a385fa@group-5191BE84CAB1
datanode3_1  | 2021-06-25 13:42:05,062 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2021-06-25 13:42:05,065 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode3_1  | 2021-06-25 13:42:05,065 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode3_1  | 2021-06-25 13:42:05,066 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new d7f71981-d306-415b-992d-ee4808a385fa@group-5191BE84CAB1-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/949dd475-00f3-4295-9774-5191be84cab1
datanode3_1  | 2021-06-25 13:42:05,066 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode3_1  | 2021-06-25 13:42:05,066 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode3_1  | 2021-06-25 13:42:05,067 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2021-06-25 13:42:05,067 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode3_1  | 2021-06-25 13:42:05,067 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode3_1  | 2021-06-25 13:42:05,067 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode3_1  | 2021-06-25 13:42:05,068 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode3_1  | 2021-06-25 13:42:05,068 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode3_1  | 2021-06-25 13:42:05,069 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode3_1  | 2021-06-25 13:42:05,090 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode3_1  | 2021-06-25 13:42:05,092 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: d7f71981-d306-415b-992d-ee4808a385fa@group-5191BE84CAB1-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode3_1  | 2021-06-25 13:42:05,095 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: d7f71981-d306-415b-992d-ee4808a385fa@group-5191BE84CAB1-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode3_1  | 2021-06-25 13:42:05,095 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode3_1  | 2021-06-25 13:42:05,096 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode3_1  | 2021-06-25 13:42:05,096 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode3_1  | 2021-06-25 13:42:05,098 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode3_1  | 2021-06-25 13:42:05,098 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode3_1  | 2021-06-25 13:42:05,098 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode3_1  | 2021-06-25 13:42:05,099 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.d7f71981-d306-415b-992d-ee4808a385fa@group-5191BE84CAB1
datanode3_1  | 2021-06-25 13:42:05,101 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.d7f71981-d306-415b-992d-ee4808a385fa@group-5191BE84CAB1
datanode3_1  | 2021-06-25 13:42:05,135 [pool-23-thread-1] INFO server.RaftServer$Division: d7f71981-d306-415b-992d-ee4808a385fa@group-5191BE84CAB1: start as a follower, conf=-1: [8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1, d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0], old=null
datanode3_1  | 2021-06-25 13:42:05,136 [pool-23-thread-1] INFO server.RaftServer$Division: d7f71981-d306-415b-992d-ee4808a385fa@group-5191BE84CAB1: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode3_1  | 2021-06-25 13:42:05,136 [pool-23-thread-1] INFO impl.RoleInfo: d7f71981-d306-415b-992d-ee4808a385fa: start d7f71981-d306-415b-992d-ee4808a385fa@group-5191BE84CAB1-FollowerState
datanode3_1  | 2021-06-25 13:42:05,154 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-5191BE84CAB1,id=d7f71981-d306-415b-992d-ee4808a385fa
datanode3_1  | 2021-06-25 13:42:05,155 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.d7f71981-d306-415b-992d-ee4808a385fa@group-5191BE84CAB1
datanode3_1  | 2021-06-25 13:42:05,181 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=949dd475-00f3-4295-9774-5191be84cab1
datanode3_1  | 2021-06-25 13:42:05,197 [Command processor thread] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-C949E1F79948->8dca9ea8-5191-4cce-a34e-3d546f33f7b1
datanode3_1  | 2021-06-25 13:42:05,642 [Command processor thread] WARN commandhandler.CreatePipelineCommandHandler: Add group failed for 8dca9ea8-5191-4cce-a34e-3d546f33f7b1{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
datanode3_1  | java.io.IOException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode3_1  | 	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:92)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:217)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:178)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:96)
datanode3_1  | 	at org.apache.ratis.client.impl.BlockingImpl.sendRequest(BlockingImpl.java:130)
datanode3_1  | 	at org.apache.ratis.client.impl.GroupManagementImpl.add(GroupManagementImpl.java:51)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.lambda$handle$1(CreatePipelineCommandHandler.java:99)
datanode3_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
datanode3_1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
datanode3_1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655)
om3_1        | 2021-06-25 13:41:27,316 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file /etc/security/keytabs/om.keytab
om3_1        | 2021-06-25 13:41:27,346 [main] INFO om.OzoneManager: Ozone Manager login successful.
om3_1        | 2021-06-25 13:41:27,352 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2021-06-25 13:41:35,602 [main] INFO client.OMCertificateClient: Loading certificate from location:/data/metadata/om/certs.
om3_1        | 2021-06-25 13:41:36,194 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/2992319514082.crt.
om3_1        | 2021-06-25 13:41:36,215 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/ROOTCA-1.crt.
om3_1        | 2021-06-25 13:41:36,225 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/CA-2884006640668.crt.
om3_1        | 2021-06-25 13:41:36,397 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2021-06-25 13:41:37,144 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om3_1        | 2021-06-25 13:41:37,146 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om3_1        | 2021-06-25 13:41:37,973 [main] INFO Configuration.deprecation: No unit for ozone.manager.delegation.remover.scan.interval(3600000) assuming MILLISECONDS
om3_1        | 2021-06-25 13:41:37,995 [main] INFO security.OzoneSecretStore: Loaded 0 tokens
om3_1        | 2021-06-25 13:41:37,999 [main] INFO security.OzoneDelegationTokenSecretManager: Loading token state into token manager.
om3_1        | 2021-06-25 13:41:38,584 [main] INFO om.OzoneManager: Created Volume s3v With Owner root required for S3Gateway operations.
om3_1        | 2021-06-25 13:41:38,618 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om3_1        | 2021-06-25 13:41:38,619 [main] WARN ratis.OzoneManagerRatisServer: ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
om3_1        | 2021-06-25 13:41:38,624 [main] INFO snapshot.OzoneManagerSnapshotProvider: Initializing OM Snapshot Provider
om3_1        | 2021-06-25 13:41:39,160 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om3_1        | 2021-06-25 13:41:39,276 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om3_1        | 2021-06-25 13:41:39,526 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with GroupID: id1 and Raft Peers: om3:9872, om1:9872, om2:9872
om3_1        | 2021-06-25 13:41:39,738 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
om3_1        | 2021-06-25 13:41:41,037 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
om3_1        | 2021-06-25 13:41:41,409 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
om3_1        | 2021-06-25 13:41:41,433 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om3_1        | 2021-06-25 13:41:41,435 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
om3_1        | 2021-06-25 13:41:41,438 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om3_1        | 2021-06-25 13:41:41,439 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om3_1        | 2021-06-25 13:41:41,440 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om3_1        | 2021-06-25 13:41:41,442 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om3_1        | 2021-06-25 13:41:41,462 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om3_1        | 2021-06-25 13:41:41,463 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om3_1        | 2021-06-25 13:41:44,867 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om3_1        | 2021-06-25 13:41:44,878 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om3_1        | 2021-06-25 13:41:44,879 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om3_1        | 2021-06-25 13:41:44,956 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om3_1        | 2021-06-25 13:41:45,012 [main] INFO server.RaftServer: om3: addNew group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] returns group-562213E44849:java.util.concurrent.CompletableFuture@b3c7c75[Not completed]
om3_1        | 2021-06-25 13:41:45,021 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om3_1        | 2021-06-25 13:41:45,178 [pool-22-thread-1] INFO server.RaftServer$Division: om3: new RaftServerImpl for group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] with OzoneManagerStateMachine:uninitialized
om3_1        | 2021-06-25 13:41:45,189 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om3_1        | 2021-06-25 13:41:45,192 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om3_1        | 2021-06-25 13:41:45,192 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om3_1        | 2021-06-25 13:41:45,198 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om3_1        | 2021-06-25 13:41:45,198 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om3_1        | 2021-06-25 13:41:45,198 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om1_1        | 2021-06-25 13:46:29,115 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:46:34,688 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:57550
om1_1        | 2021-06-25 13:46:34,704 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:46:40,125 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:57570
om1_1        | 2021-06-25 13:46:40,141 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:46:45,494 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:57596
om1_1        | 2021-06-25 13:46:45,514 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:46:50,662 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:57626
om1_1        | 2021-06-25 13:46:50,698 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:46:55,738 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:57652
om1_1        | 2021-06-25 13:46:55,763 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:47:01,313 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:57698
om1_1        | 2021-06-25 13:47:01,334 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:47:06,517 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:57724
om1_1        | 2021-06-25 13:47:06,534 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:47:11,305 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:57748
om1_1        | 2021-06-25 13:47:11,318 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:47:16,062 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:57766
om1_1        | 2021-06-25 13:47:16,074 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:47:21,138 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:57792
om1_1        | 2021-06-25 13:47:21,152 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:47:21,932 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:link2 in volume:05944-target
om1_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om1_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:198)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1        | 2021-06-25 13:47:26,165 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:57818
om1_1        | 2021-06-25 13:47:26,176 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:47:31,405 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:57872
om1_1        | 2021-06-25 13:47:31,421 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:47:32,327 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket3 in volume:05944-target
om1_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om1_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:198)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1        | 2021-06-25 13:47:36,639 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:57900
datanode3_1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
datanode3_1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
datanode3_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
datanode3_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
datanode3_1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
datanode3_1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:95)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$2(DatanodeStateMachine.java:525)
datanode3_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode3_1  | Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:262)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:243)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:156)
datanode3_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:413)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$5(GrpcClientProtocolClient.java:180)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:215)
datanode3_1  | 	... 18 more
datanode3_1  | 2021-06-25 13:42:05,666 [Command processor thread] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-1BC2BC7F1B20->ee31bb40-6981-4b57-b8d7-3be03fa0c81d
datanode3_1  | 2021-06-25 13:42:06,045 [Command processor thread] WARN commandhandler.CreatePipelineCommandHandler: Add group failed for ee31bb40-6981-4b57-b8d7-3be03fa0c81d{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
datanode3_1  | java.io.IOException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode3_1  | 	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:92)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:217)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:178)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:96)
datanode3_1  | 	at org.apache.ratis.client.impl.BlockingImpl.sendRequest(BlockingImpl.java:130)
datanode3_1  | 	at org.apache.ratis.client.impl.GroupManagementImpl.add(GroupManagementImpl.java:51)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.lambda$handle$1(CreatePipelineCommandHandler.java:99)
datanode3_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
datanode3_1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
datanode3_1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655)
datanode3_1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
datanode3_1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
datanode3_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
datanode3_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
datanode3_1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
datanode3_1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:95)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$2(DatanodeStateMachine.java:525)
datanode3_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode3_1  | Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
om1_1        | 2021-06-25 13:47:36,661 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:47:41,969 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:57924
om1_1        | 2021-06-25 13:47:42,009 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:47:46,836 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:57942
om1_1        | 2021-06-25 13:47:46,855 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:47:52,061 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:57970
om1_1        | 2021-06-25 13:47:52,083 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:47:56,937 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:57998
om1_1        | 2021-06-25 13:47:56,958 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:48:02,335 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:58040
om1_1        | 2021-06-25 13:48:02,349 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:48:07,339 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:58068
om1_1        | 2021-06-25 13:48:07,358 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:48:12,658 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:58092
om1_1        | 2021-06-25 13:48:12,675 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:48:16,832 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:58110
om1_1        | 2021-06-25 13:48:16,849 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:48:22,012 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:58134
om1_1        | 2021-06-25 13:48:22,030 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:48:30,361 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:58188
om1_1        | 2021-06-25 13:48:30,383 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:48:39,098 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:58244
om1_1        | 2021-06-25 13:48:39,113 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:48:44,283 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:58272
om1_1        | 2021-06-25 13:48:44,296 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:48:49,874 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:58296
om1_1        | 2021-06-25 13:48:49,891 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:49:15,728 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:58542
om1_1        | 2021-06-25 13:49:15,756 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:49:19,960 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:49:19,963 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38466
om1_1        | 2021-06-25 13:49:20,022 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:49:25,054 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:58592
om1_1        | 2021-06-25 13:49:25,068 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:49:28,331 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:49:28,332 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38508
om1_1        | 2021-06-25 13:49:28,343 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:49:29,141 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:41:49,776 [Listener at om2/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om2_1        | 2021-06-25 13:41:49,777 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om2_1        | 2021-06-25 13:41:49,833 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om2_1        | 2021-06-25 13:41:49,983 [Listener at om2/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted will not move to trash
om2_1        | 2021-06-25 13:41:50,019 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7bbd133c] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om2_1        | 2021-06-25 13:41:52,869 [om2@group-562213E44849-FollowerState] INFO impl.FollowerState: om2@group-562213E44849-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5177483538ns, electionTimeout:5162ms
om2_1        | 2021-06-25 13:41:52,871 [om2@group-562213E44849-FollowerState] INFO impl.RoleInfo: om2: shutdown om2@group-562213E44849-FollowerState
om2_1        | 2021-06-25 13:41:52,871 [om2@group-562213E44849-FollowerState] INFO server.RaftServer$Division: om2@group-562213E44849: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
om2_1        | 2021-06-25 13:41:52,875 [om2@group-562213E44849-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om2_1        | 2021-06-25 13:41:52,875 [om2@group-562213E44849-FollowerState] INFO impl.RoleInfo: om2: start om2@group-562213E44849-LeaderElection1
om2_1        | 2021-06-25 13:41:52,890 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om2@group-562213E44849-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om2_1        | 2021-06-25 13:41:54,799 [grpc-default-executor-0] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server_message_metrics.om2
om2_1        | 2021-06-25 13:41:54,822 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-562213E44849: receive requestVote(ELECTION, om3, group-562213E44849, 1, (t:0, i:~))
om2_1        | 2021-06-25 13:41:54,823 [grpc-default-executor-0] INFO impl.VoteContext: om2@group-562213E44849-CANDIDATE: reject ELECTION from om3: already has voted for om2 at current term 1
om2_1        | 2021-06-25 13:41:54,838 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-562213E44849 replies to ELECTION vote request: om3<-om2#0:FAIL-t1. Peer's state: om2@group-562213E44849:t1, leader=null, voted=om2, raftlog=om2@group-562213E44849-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om2_1        | 2021-06-25 13:41:54,908 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-562213E44849: receive requestVote(ELECTION, om1, group-562213E44849, 1, (t:0, i:~))
om2_1        | 2021-06-25 13:41:54,908 [grpc-default-executor-0] INFO impl.VoteContext: om2@group-562213E44849-CANDIDATE: reject ELECTION from om1: already has voted for om2 at current term 1
om2_1        | 2021-06-25 13:41:54,908 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-562213E44849 replies to ELECTION vote request: om1<-om2#0:FAIL-t1. Peer's state: om2@group-562213E44849:t1, leader=null, voted=om2, raftlog=om2@group-562213E44849-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om2_1        | 2021-06-25 13:41:54,929 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om2@group-562213E44849-LeaderElection1: ELECTION REJECTED received 2 response(s) and 0 exception(s):
om2_1        | 2021-06-25 13:41:54,930 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 0: om2<-om1#0:FAIL-t1
om2_1        | 2021-06-25 13:41:54,930 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 1: om2<-om3#0:FAIL-t1
om2_1        | 2021-06-25 13:41:54,930 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om2@group-562213E44849-LeaderElection1 ELECTION round 0: result REJECTED
om2_1        | 2021-06-25 13:41:54,944 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServer$Division: om2@group-562213E44849: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
om2_1        | 2021-06-25 13:41:54,944 [om2@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om2: shutdown om2@group-562213E44849-LeaderElection1
om2_1        | 2021-06-25 13:41:54,944 [om2@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om2: start om2@group-562213E44849-FollowerState
om2_1        | 2021-06-25 13:42:00,060 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-562213E44849: receive requestVote(ELECTION, om3, group-562213E44849, 2, (t:0, i:~))
om2_1        | 2021-06-25 13:42:00,062 [grpc-default-executor-0] INFO impl.VoteContext: om2@group-562213E44849-FOLLOWER: accept ELECTION from om3: our priority 0 <= candidate's priority 0
om2_1        | 2021-06-25 13:42:00,062 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-562213E44849: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:om3
om2_1        | 2021-06-25 13:42:00,062 [grpc-default-executor-0] INFO impl.RoleInfo: om2: shutdown om2@group-562213E44849-FollowerState
om2_1        | 2021-06-25 13:42:00,088 [om2@group-562213E44849-FollowerState] INFO impl.FollowerState: om2@group-562213E44849-FollowerState was interrupted: {}
om2_1        | java.lang.InterruptedException: sleep interrupted
om2_1        | 	at java.base/java.lang.Thread.sleep(Native Method)
om2_1        | 	at java.base/java.lang.Thread.sleep(Thread.java:339)
om2_1        | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
om2_1        | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
om2_1        | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
om2_1        | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
om2_1        | 2021-06-25 13:42:00,090 [grpc-default-executor-0] INFO impl.RoleInfo: om2: start om2@group-562213E44849-FollowerState
om2_1        | 2021-06-25 13:42:00,114 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-562213E44849 replies to ELECTION vote request: om3<-om2#0:OK-t2. Peer's state: om2@group-562213E44849:t2, leader=null, voted=om3, raftlog=om2@group-562213E44849-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om2_1        | 2021-06-25 13:42:01,042 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-562213E44849: change Leader from null to om3 at term 2 for appendEntries, leader elected after 15655ms
om2_1        | 2021-06-25 13:42:01,248 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-562213E44849: set configuration 0: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om2_1        | 2021-06-25 13:42:01,270 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: Starting segment from index:0
om2_1        | 2021-06-25 13:42:01,693 [om2@group-562213E44849-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/current/log_inprogress_0
om2_1        | 2021-06-25 13:42:39,332 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53936
om1_1        | 2021-06-25 13:49:29,142 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38516
om1_1        | 2021-06-25 13:49:29,146 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:49:32,912 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:49:32,913 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38570
om1_1        | 2021-06-25 13:49:32,919 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:49:33,804 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:49:33,805 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38582
om1_1        | 2021-06-25 13:49:33,812 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:49:34,567 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:49:34,568 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38592
om1_1        | 2021-06-25 13:49:34,583 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:49:35,225 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:49:35,226 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38604
om1_1        | 2021-06-25 13:49:35,238 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:49:39,399 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:58724
om1_1        | 2021-06-25 13:49:39,422 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:49:42,715 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:49:42,718 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38648
om1_1        | 2021-06-25 13:49:42,722 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:49:43,524 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:49:43,525 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38656
om1_1        | 2021-06-25 13:49:43,534 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:49:43,628 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:49:43,635 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38662
om1_1        | 2021-06-25 13:49:43,639 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:49:44,078 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:49:44,080 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38676
om1_1        | 2021-06-25 13:49:44,088 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:49:44,397 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:49:44,398 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38684
om1_1        | 2021-06-25 13:49:44,411 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:49:44,685 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:49:44,686 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38692
om1_1        | 2021-06-25 13:49:44,694 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:49:44,912 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:49:44,913 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38698
om1_1        | 2021-06-25 13:49:44,926 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:49:45,021 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:49:45,022 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38708
om1_1        | 2021-06-25 13:49:45,027 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:42:39,355 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:42:57,594 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54012
om2_1        | 2021-06-25 13:42:57,602 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:42:59,350 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:vol1 for user:testuser/scm@EXAMPLE.COM
om2_1        | 2021-06-25 13:43:10,538 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54090
om2_1        | 2021-06-25 13:43:10,550 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:43:11,313 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54096
om2_1        | 2021-06-25 13:43:11,318 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:43:16,851 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54126
om2_1        | 2021-06-25 13:43:16,859 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:43:17,522 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54132
om2_1        | 2021-06-25 13:43:17,530 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:43:23,487 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54160
om2_1        | 2021-06-25 13:43:23,500 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:43:33,063 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54208
om2_1        | 2021-06-25 13:43:33,072 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:43:39,812 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54264
om2_1        | 2021-06-25 13:43:39,827 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:43:40,455 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54272
om2_1        | 2021-06-25 13:43:40,461 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:43:45,670 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54298
om2_1        | 2021-06-25 13:43:45,676 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:43:51,578 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54332
om2_1        | 2021-06-25 13:43:51,587 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:44:08,494 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54408
om2_1        | 2021-06-25 13:44:08,502 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:44:09,211 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:05944-source for user:testuser/scm@EXAMPLE.COM
om2_1        | 2021-06-25 13:44:13,400 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54434
om2_1        | 2021-06-25 13:44:13,403 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:44:14,128 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:05944-target for user:testuser/scm@EXAMPLE.COM
om2_1        | 2021-06-25 13:44:18,843 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54460
om2_1        | 2021-06-25 13:44:18,855 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:44:23,960 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54486
om2_1        | 2021-06-25 13:44:23,970 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:44:32,729 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54534
om2_1        | 2021-06-25 13:44:32,742 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:44:38,142 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54578
om2_1        | 2021-06-25 13:44:38,154 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode1_1  | 2021-06-25 13:42:15,343 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode1_1  | 2021-06-25 13:42:15,348 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode1_1  | 2021-06-25 13:42:15,348 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode1_1  | 2021-06-25 13:42:15,354 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode1_1  | 2021-06-25 13:42:15,354 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2021-06-25 13:42:15,355 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode1_1  | 2021-06-25 13:42:15,358 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1-LeaderElection3] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode1_1  | 2021-06-25 13:42:15,359 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode1_1  | 2021-06-25 13:42:15,359 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode1_1  | 2021-06-25 13:42:15,360 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1-LeaderElection3] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis_grpc.log_appender.ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1
datanode1_1  | 2021-06-25 13:42:15,364 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode1_1  | 2021-06-25 13:42:15,364 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2021-06-25 13:42:15,364 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode1_1  | 2021-06-25 13:42:15,364 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1-LeaderElection3] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode1_1  | 2021-06-25 13:42:15,364 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode1_1  | 2021-06-25 13:42:15,365 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode1_1  | 2021-06-25 13:42:15,366 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1-LeaderElection3] INFO impl.RoleInfo: ee31bb40-6981-4b57-b8d7-3be03fa0c81d: start ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1-LeaderStateImpl
datanode1_1  | 2021-06-25 13:42:15,367 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1-LeaderElection3] INFO segmented.SegmentedRaftLogWorker: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1-SegmentedRaftLogWorker: Starting segment from index:0
datanode1_1  | 2021-06-25 13:42:15,369 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/949dd475-00f3-4295-9774-5191be84cab1/current/log_inprogress_0
datanode1_1  | 2021-06-25 13:42:15,374 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1-LeaderElection3] INFO server.RaftServer$Division: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-5191BE84CAB1: set configuration 0: [8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode1_1  | 2021-06-25 13:42:16,468 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:42:18,306 [grpc-default-executor-1] INFO server.RaftServer$Division: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68: receive requestVote(ELECTION, 8dca9ea8-5191-4cce-a34e-3d546f33f7b1, group-BFEA630F7F68, 3, (t:0, i:0))
datanode1_1  | 2021-06-25 13:42:18,306 [grpc-default-executor-1] INFO impl.VoteContext: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68-FOLLOWER: accept ELECTION from 8dca9ea8-5191-4cce-a34e-3d546f33f7b1: our priority 0 <= candidate's priority 0
datanode1_1  | 2021-06-25 13:42:18,307 [grpc-default-executor-1] INFO server.RaftServer$Division: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68: changes role from  FOLLOWER to FOLLOWER at term 3 for candidate:8dca9ea8-5191-4cce-a34e-3d546f33f7b1
datanode1_1  | 2021-06-25 13:42:18,307 [grpc-default-executor-1] INFO impl.RoleInfo: ee31bb40-6981-4b57-b8d7-3be03fa0c81d: shutdown ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68-FollowerState
datanode1_1  | 2021-06-25 13:42:18,307 [grpc-default-executor-1] INFO impl.RoleInfo: ee31bb40-6981-4b57-b8d7-3be03fa0c81d: start ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68-FollowerState
datanode1_1  | 2021-06-25 13:42:18,307 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68-FollowerState] INFO impl.FollowerState: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68-FollowerState was interrupted: {}
datanode1_1  | java.lang.InterruptedException: sleep interrupted
datanode1_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode1_1  | 	at java.base/java.lang.Thread.sleep(Thread.java:339)
datanode1_1  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode1_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
datanode1_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode1_1  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
datanode1_1  | 2021-06-25 13:42:18,310 [grpc-default-executor-1] INFO server.RaftServer$Division: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68 replies to ELECTION vote request: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1<-ee31bb40-6981-4b57-b8d7-3be03fa0c81d#0:OK-t3. Peer's state: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68:t3, leader=null, voted=8dca9ea8-5191-4cce-a34e-3d546f33f7b1, raftlog=ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode1_1  | 2021-06-25 13:42:18,334 [grpc-default-executor-1] INFO server.RaftServer$Division: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68: receive requestVote(ELECTION, d7f71981-d306-415b-992d-ee4808a385fa, group-BFEA630F7F68, 3, (t:0, i:0))
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:262)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:243)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:156)
datanode3_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:413)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$5(GrpcClientProtocolClient.java:180)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:215)
datanode3_1  | 	... 18 more
datanode3_1  | 2021-06-25 13:42:06,062 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=949dd475-00f3-4295-9774-5191be84cab1.
datanode3_1  | 2021-06-25 13:42:07,487 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-FollowerState] INFO impl.FollowerState: d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5178819902ns, electionTimeout:5175ms
datanode3_1  | 2021-06-25 13:42:07,491 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-FollowerState] INFO impl.RoleInfo: d7f71981-d306-415b-992d-ee4808a385fa: shutdown d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-FollowerState
datanode3_1  | 2021-06-25 13:42:07,493 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-FollowerState] INFO server.RaftServer$Division: d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode3_1  | 2021-06-25 13:42:07,508 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode3_1  | 2021-06-25 13:42:07,509 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-FollowerState] INFO impl.RoleInfo: d7f71981-d306-415b-992d-ee4808a385fa: start d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection1
datanode3_1  | 2021-06-25 13:42:07,529 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection1] INFO impl.LeaderElection: d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode2_1  | 2021-06-25 13:42:23,366 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-FollowerState] INFO impl.FollowerState: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5039250735ns, electionTimeout:5022ms
datanode2_1  | 2021-06-25 13:42:23,366 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-FollowerState] INFO impl.RoleInfo: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1: shutdown 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-FollowerState
datanode2_1  | 2021-06-25 13:42:23,366 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-FollowerState] INFO server.RaftServer$Division: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68: changes role from  FOLLOWER to CANDIDATE at term 3 for changeToCandidate
datanode2_1  | 2021-06-25 13:42:23,366 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode2_1  | 2021-06-25 13:42:23,366 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-FollowerState] INFO impl.RoleInfo: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1: start 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-LeaderElection5
datanode2_1  | 2021-06-25 13:42:23,374 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-LeaderElection5] INFO impl.LeaderElection: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-LeaderElection5 ELECTION round 0: submit vote requests at term 4 for -1: [8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode2_1  | 2021-06-25 13:42:23,408 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-LeaderElection5] INFO impl.LeaderElection: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-LeaderElection5: ELECTION REJECTED received 2 response(s) and 0 exception(s):
datanode2_1  | 2021-06-25 13:42:23,409 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-LeaderElection5] INFO impl.LeaderElection:   Response 0: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1<-ee31bb40-6981-4b57-b8d7-3be03fa0c81d#0:OK-t4
datanode2_1  | 2021-06-25 13:42:23,409 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-LeaderElection5] INFO impl.LeaderElection:   Response 1: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1<-d7f71981-d306-415b-992d-ee4808a385fa#0:FAIL-t4
datanode2_1  | 2021-06-25 13:42:23,409 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-LeaderElection5] INFO impl.LeaderElection: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-LeaderElection5 ELECTION round 0: result REJECTED
datanode2_1  | 2021-06-25 13:42:23,409 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-LeaderElection5] INFO server.RaftServer$Division: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68: changes role from CANDIDATE to FOLLOWER at term 4 for REJECTED
datanode2_1  | 2021-06-25 13:42:23,409 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-LeaderElection5] INFO impl.RoleInfo: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1: shutdown 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-LeaderElection5
datanode2_1  | 2021-06-25 13:42:23,409 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-LeaderElection5] INFO impl.RoleInfo: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1: start 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-FollowerState
datanode2_1  | 2021-06-25 13:42:24,330 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:42:27,403 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:42:28,422 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-FollowerState] INFO impl.FollowerState: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5012527552ns, electionTimeout:5011ms
datanode2_1  | 2021-06-25 13:42:28,422 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-FollowerState] INFO impl.RoleInfo: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1: shutdown 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-FollowerState
datanode2_1  | 2021-06-25 13:42:28,422 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-FollowerState] INFO server.RaftServer$Division: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68: changes role from  FOLLOWER to CANDIDATE at term 4 for changeToCandidate
datanode2_1  | 2021-06-25 13:42:28,423 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode2_1  | 2021-06-25 13:42:28,423 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-FollowerState] INFO impl.RoleInfo: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1: start 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-LeaderElection6
datanode2_1  | 2021-06-25 13:42:28,434 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-LeaderElection6] INFO impl.LeaderElection: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-LeaderElection6 ELECTION round 0: submit vote requests at term 5 for -1: [8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode2_1  | 2021-06-25 13:42:28,479 [grpc-default-executor-0] INFO server.RaftServer$Division: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68: receive requestVote(ELECTION, d7f71981-d306-415b-992d-ee4808a385fa, group-BFEA630F7F68, 5, (t:0, i:0))
datanode2_1  | 2021-06-25 13:42:28,482 [grpc-default-executor-0] INFO impl.VoteContext: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-CANDIDATE: reject ELECTION from d7f71981-d306-415b-992d-ee4808a385fa: already has voted for 8dca9ea8-5191-4cce-a34e-3d546f33f7b1 at current term 5
datanode2_1  | 2021-06-25 13:42:28,482 [grpc-default-executor-0] INFO server.RaftServer$Division: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68 replies to ELECTION vote request: d7f71981-d306-415b-992d-ee4808a385fa<-8dca9ea8-5191-4cce-a34e-3d546f33f7b1#0:FAIL-t5. Peer's state: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68:t5, leader=null, voted=8dca9ea8-5191-4cce-a34e-3d546f33f7b1, raftlog=8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode2_1  | 2021-06-25 13:42:28,488 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-LeaderElection6] INFO impl.LeaderElection: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-LeaderElection6: ELECTION REJECTED received 2 response(s) and 0 exception(s):
datanode2_1  | 2021-06-25 13:42:28,492 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-LeaderElection6] INFO impl.LeaderElection:   Response 0: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1<-ee31bb40-6981-4b57-b8d7-3be03fa0c81d#0:OK-t5
datanode2_1  | 2021-06-25 13:42:28,494 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-LeaderElection6] INFO impl.LeaderElection:   Response 1: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1<-d7f71981-d306-415b-992d-ee4808a385fa#0:FAIL-t5
datanode1_1  | 2021-06-25 13:42:18,334 [grpc-default-executor-1] INFO impl.VoteContext: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68-FOLLOWER: reject ELECTION from d7f71981-d306-415b-992d-ee4808a385fa: already has voted for 8dca9ea8-5191-4cce-a34e-3d546f33f7b1 at current term 3
datanode1_1  | 2021-06-25 13:42:18,335 [grpc-default-executor-1] INFO server.RaftServer$Division: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68 replies to ELECTION vote request: d7f71981-d306-415b-992d-ee4808a385fa<-ee31bb40-6981-4b57-b8d7-3be03fa0c81d#0:FAIL-t3. Peer's state: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68:t3, leader=null, voted=8dca9ea8-5191-4cce-a34e-3d546f33f7b1, raftlog=ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode1_1  | 2021-06-25 13:42:19,530 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:42:22,602 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:42:23,382 [grpc-default-executor-1] INFO server.RaftServer$Division: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68: receive requestVote(ELECTION, 8dca9ea8-5191-4cce-a34e-3d546f33f7b1, group-BFEA630F7F68, 4, (t:0, i:0))
datanode1_1  | 2021-06-25 13:42:23,383 [grpc-default-executor-1] INFO impl.VoteContext: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68-FOLLOWER: accept ELECTION from 8dca9ea8-5191-4cce-a34e-3d546f33f7b1: our priority 0 <= candidate's priority 0
datanode1_1  | 2021-06-25 13:42:23,383 [grpc-default-executor-1] INFO server.RaftServer$Division: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68: changes role from  FOLLOWER to FOLLOWER at term 4 for candidate:8dca9ea8-5191-4cce-a34e-3d546f33f7b1
datanode1_1  | 2021-06-25 13:42:23,383 [grpc-default-executor-1] INFO impl.RoleInfo: ee31bb40-6981-4b57-b8d7-3be03fa0c81d: shutdown ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68-FollowerState
datanode1_1  | 2021-06-25 13:42:23,383 [grpc-default-executor-1] INFO impl.RoleInfo: ee31bb40-6981-4b57-b8d7-3be03fa0c81d: start ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68-FollowerState
datanode1_1  | 2021-06-25 13:42:23,383 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68-FollowerState] INFO impl.FollowerState: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68-FollowerState was interrupted: {}
datanode1_1  | java.lang.InterruptedException: sleep interrupted
datanode1_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode1_1  | 	at java.base/java.lang.Thread.sleep(Thread.java:339)
datanode1_1  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode1_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
datanode1_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode1_1  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
datanode1_1  | 2021-06-25 13:42:23,395 [grpc-default-executor-1] INFO server.RaftServer$Division: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68 replies to ELECTION vote request: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1<-ee31bb40-6981-4b57-b8d7-3be03fa0c81d#0:OK-t4. Peer's state: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68:t4, leader=null, voted=8dca9ea8-5191-4cce-a34e-3d546f33f7b1, raftlog=ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode1_1  | 2021-06-25 13:42:25,674 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:42:28,449 [grpc-default-executor-1] INFO server.RaftServer$Division: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68: receive requestVote(ELECTION, 8dca9ea8-5191-4cce-a34e-3d546f33f7b1, group-BFEA630F7F68, 5, (t:0, i:0))
datanode1_1  | 2021-06-25 13:42:28,450 [grpc-default-executor-1] INFO impl.VoteContext: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68-FOLLOWER: accept ELECTION from 8dca9ea8-5191-4cce-a34e-3d546f33f7b1: our priority 0 <= candidate's priority 0
datanode1_1  | 2021-06-25 13:42:28,450 [grpc-default-executor-1] INFO server.RaftServer$Division: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68: changes role from  FOLLOWER to FOLLOWER at term 5 for candidate:8dca9ea8-5191-4cce-a34e-3d546f33f7b1
datanode1_1  | 2021-06-25 13:42:28,450 [grpc-default-executor-1] INFO impl.RoleInfo: ee31bb40-6981-4b57-b8d7-3be03fa0c81d: shutdown ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68-FollowerState
datanode1_1  | 2021-06-25 13:42:28,450 [grpc-default-executor-1] INFO impl.RoleInfo: ee31bb40-6981-4b57-b8d7-3be03fa0c81d: start ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68-FollowerState
datanode1_1  | 2021-06-25 13:42:28,451 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68-FollowerState] INFO impl.FollowerState: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68-FollowerState was interrupted: {}
datanode1_1  | java.lang.InterruptedException: sleep interrupted
datanode1_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode1_1  | 	at java.base/java.lang.Thread.sleep(Thread.java:339)
datanode1_1  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode1_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
datanode1_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode1_1  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
datanode1_1  | 2021-06-25 13:42:28,454 [grpc-default-executor-1] INFO server.RaftServer$Division: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68 replies to ELECTION vote request: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1<-ee31bb40-6981-4b57-b8d7-3be03fa0c81d#0:OK-t5. Peer's state: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68:t5, leader=null, voted=8dca9ea8-5191-4cce-a34e-3d546f33f7b1, raftlog=ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode1_1  | 2021-06-25 13:42:28,474 [grpc-default-executor-1] INFO server.RaftServer$Division: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68: receive requestVote(ELECTION, d7f71981-d306-415b-992d-ee4808a385fa, group-BFEA630F7F68, 5, (t:0, i:0))
datanode1_1  | 2021-06-25 13:42:28,475 [grpc-default-executor-1] INFO impl.VoteContext: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68-FOLLOWER: reject ELECTION from d7f71981-d306-415b-992d-ee4808a385fa: already has voted for 8dca9ea8-5191-4cce-a34e-3d546f33f7b1 at current term 5
om2_1        | 2021-06-25 13:44:42,980 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54604
om2_1        | 2021-06-25 13:44:42,988 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:44:47,985 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54630
om2_1        | 2021-06-25 13:44:47,994 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:44:53,023 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54656
om2_1        | 2021-06-25 13:44:53,029 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:44:58,213 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54684
om2_1        | 2021-06-25 13:44:58,223 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:45:03,284 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54702
om2_1        | 2021-06-25 13:45:03,290 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:45:07,693 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54744
om2_1        | 2021-06-25 13:45:07,696 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:45:12,825 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54770
om2_1        | 2021-06-25 13:45:12,831 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:45:18,332 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54798
om2_1        | 2021-06-25 13:45:18,338 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:45:23,938 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54824
om2_1        | 2021-06-25 13:45:23,943 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:45:29,364 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54854
om2_1        | 2021-06-25 13:45:29,377 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:45:35,046 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54908
om2_1        | 2021-06-25 13:45:35,055 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:45:40,283 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54934
om2_1        | 2021-06-25 13:45:40,289 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:45:48,375 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54968
om2_1        | 2021-06-25 13:45:48,384 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:45:56,592 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55008
om2_1        | 2021-06-25 13:45:56,600 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:46:05,861 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55072
om2_1        | 2021-06-25 13:46:05,868 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:46:13,217 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55106
om2_1        | 2021-06-25 13:46:13,224 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:46:18,559 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55134
om2_1        | 2021-06-25 13:46:18,561 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:46:23,880 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55158
om2_1        | 2021-06-25 13:46:23,893 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:46:29,160 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55186
s3g_1        | Sleeping for 5 seconds
s3g_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
s3g_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
s3g_1        | 2021-06-25 13:38:52,946 [main] INFO http.BaseHttpServer: Starting Web-server for s3gateway at: http://0.0.0.0:9878
s3g_1        | 2021-06-25 13:38:52,966 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
s3g_1        | 2021-06-25 13:38:52,970 [main] INFO http.BaseHttpServer: HttpAuthType: ozone.s3g.http.auth.type = kerberos
s3g_1        | 2021-06-25 13:38:53,195 [main] INFO util.log: Logging initialized @3545ms to org.eclipse.jetty.util.log.Slf4jLog
s3g_1        | 2021-06-25 13:38:53,941 [main] INFO http.HttpRequestLog: Http request log for http.requests.s3gateway is not defined
s3g_1        | 2021-06-25 13:38:53,983 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
s3g_1        | 2021-06-25 13:38:53,992 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context s3gateway
s3g_1        | 2021-06-25 13:38:53,992 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
s3g_1        | 2021-06-25 13:38:53,993 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
s3g_1        | 2021-06-25 13:38:54,026 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.s3g.http.auth.kerberos.principal keytabKey: ozone.s3g.http.auth.kerberos.keytab
s3g_1        | 2021-06-25 13:38:54,399 [main] INFO s3.Gateway: STARTUP_MSG: 
s3g_1        | /************************************************************
s3g_1        | STARTUP_MSG: Starting Gateway
s3g_1        | STARTUP_MSG:   host = s3g/172.25.0.114
s3g_1        | STARTUP_MSG:   args = []
s3g_1        | STARTUP_MSG:   version = 1.2.0-SNAPSHOT
om1_1        | 2021-06-25 13:49:49,266 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:49:49,267 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38734
om1_1        | 2021-06-25 13:49:49,278 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:49:49,558 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:49:49,560 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38740
om1_1        | 2021-06-25 13:49:49,574 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:49:49,762 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:49:49,763 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38746
om1_1        | 2021-06-25 13:49:49,771 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:49:49,811 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:49:49,812 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38756
om1_1        | 2021-06-25 13:49:49,823 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:49:51,294 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:49:51,295 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38768
om1_1        | 2021-06-25 13:49:51,297 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:49:51,431 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:49:51,431 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38776
om1_1        | 2021-06-25 13:49:51,456 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:49:51,570 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:49:51,571 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38784
om1_1        | 2021-06-25 13:49:51,577 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:49:51,654 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:49:51,655 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38790
om1_1        | 2021-06-25 13:49:51,657 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:49:51,707 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:49:51,708 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38796
om1_1        | 2021-06-25 13:49:51,710 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:49:51,807 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:49:51,809 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38802
om1_1        | 2021-06-25 13:49:51,813 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:49:52,039 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:49:52,040 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38810
om1_1        | 2021-06-25 13:49:52,043 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:49:52,199 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:49:52,200 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38818
om1_1        | 2021-06-25 13:49:52,206 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:49:52,267 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:49:52,268 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38824
om1_1        | 2021-06-25 13:49:52,277 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:49:52,564 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:49:52,566 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38832
datanode1_1  | 2021-06-25 13:42:28,476 [grpc-default-executor-1] INFO server.RaftServer$Division: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68 replies to ELECTION vote request: d7f71981-d306-415b-992d-ee4808a385fa<-ee31bb40-6981-4b57-b8d7-3be03fa0c81d#0:FAIL-t5. Peer's state: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68:t5, leader=null, voted=8dca9ea8-5191-4cce-a34e-3d546f33f7b1, raftlog=ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode1_1  | 2021-06-25 13:42:28,746 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:42:31,822 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:42:33,589 [grpc-default-executor-1] INFO server.RaftServer$Division: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68: receive requestVote(ELECTION, d7f71981-d306-415b-992d-ee4808a385fa, group-BFEA630F7F68, 6, (t:0, i:0))
datanode1_1  | 2021-06-25 13:42:33,590 [grpc-default-executor-1] INFO impl.VoteContext: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68-FOLLOWER: accept ELECTION from d7f71981-d306-415b-992d-ee4808a385fa: our priority 0 <= candidate's priority 1
datanode1_1  | 2021-06-25 13:42:33,590 [grpc-default-executor-1] INFO server.RaftServer$Division: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68: changes role from  FOLLOWER to FOLLOWER at term 6 for candidate:d7f71981-d306-415b-992d-ee4808a385fa
datanode1_1  | 2021-06-25 13:42:33,590 [grpc-default-executor-1] INFO impl.RoleInfo: ee31bb40-6981-4b57-b8d7-3be03fa0c81d: shutdown ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68-FollowerState
datanode1_1  | 2021-06-25 13:42:33,590 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68-FollowerState] INFO impl.FollowerState: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68-FollowerState was interrupted: {}
datanode1_1  | java.lang.InterruptedException: sleep interrupted
datanode1_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode1_1  | 	at java.base/java.lang.Thread.sleep(Thread.java:339)
datanode1_1  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode1_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
datanode1_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode1_1  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
datanode1_1  | 2021-06-25 13:42:33,591 [grpc-default-executor-1] INFO impl.RoleInfo: ee31bb40-6981-4b57-b8d7-3be03fa0c81d: start ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68-FollowerState
datanode1_1  | 2021-06-25 13:42:33,610 [grpc-default-executor-1] INFO server.RaftServer$Division: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68 replies to ELECTION vote request: d7f71981-d306-415b-992d-ee4808a385fa<-ee31bb40-6981-4b57-b8d7-3be03fa0c81d#0:OK-t6. Peer's state: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68:t6, leader=null, voted=d7f71981-d306-415b-992d-ee4808a385fa, raftlog=ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode1_1  | 2021-06-25 13:42:33,755 [grpc-default-executor-1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-BFEA630F7F68 with new leaderId: d7f71981-d306-415b-992d-ee4808a385fa
datanode1_1  | 2021-06-25 13:42:33,755 [grpc-default-executor-1] INFO server.RaftServer$Division: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68: change Leader from null to d7f71981-d306-415b-992d-ee4808a385fa at term 6 for appendEntries, leader elected after 33150ms
datanode1_1  | 2021-06-25 13:42:33,823 [grpc-default-executor-1] INFO server.RaftServer$Division: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68: set configuration 0: [8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1], old=null
datanode1_1  | 2021-06-25 13:42:33,824 [grpc-default-executor-1] INFO segmented.SegmentedRaftLogWorker: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68-SegmentedRaftLogWorker: Starting segment from index:0
datanode1_1  | 2021-06-25 13:42:33,826 [ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: ee31bb40-6981-4b57-b8d7-3be03fa0c81d@group-BFEA630F7F68-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/3175bb45-44a8-4478-8980-bfea630f7f68/current/log_inprogress_0
datanode1_1  | 2021-06-25 13:42:34,890 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:42:37,962 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:42:41,034 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:42:44,106 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:42:47,178 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:42:50,250 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:42:53,322 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:42:07,664 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:42:07,846 [grpc-default-executor-0] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server_message_metrics.d7f71981-d306-415b-992d-ee4808a385fa
datanode3_1  | 2021-06-25 13:42:07,973 [grpc-default-executor-0] INFO server.RaftServer$Division: d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68: receive requestVote(ELECTION, 8dca9ea8-5191-4cce-a34e-3d546f33f7b1, group-BFEA630F7F68, 1, (t:0, i:0))
datanode3_1  | 2021-06-25 13:42:07,974 [grpc-default-executor-1] INFO server.RaftServer$Division: d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68: receive requestVote(ELECTION, ee31bb40-6981-4b57-b8d7-3be03fa0c81d, group-BFEA630F7F68, 1, (t:0, i:0))
datanode3_1  | 2021-06-25 13:42:07,975 [grpc-default-executor-1] INFO impl.VoteContext: d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-CANDIDATE: reject ELECTION from ee31bb40-6981-4b57-b8d7-3be03fa0c81d: already has voted for d7f71981-d306-415b-992d-ee4808a385fa at current term 1
datanode3_1  | 2021-06-25 13:42:07,997 [grpc-default-executor-1] INFO server.RaftServer$Division: d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68 replies to ELECTION vote request: ee31bb40-6981-4b57-b8d7-3be03fa0c81d<-d7f71981-d306-415b-992d-ee4808a385fa#0:FAIL-t1. Peer's state: d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68:t1, leader=null, voted=d7f71981-d306-415b-992d-ee4808a385fa, raftlog=d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode3_1  | 2021-06-25 13:42:08,005 [grpc-default-executor-0] INFO impl.VoteContext: d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-CANDIDATE: reject ELECTION from 8dca9ea8-5191-4cce-a34e-3d546f33f7b1: already has voted for d7f71981-d306-415b-992d-ee4808a385fa at current term 1
datanode3_1  | 2021-06-25 13:42:08,012 [grpc-default-executor-0] INFO server.RaftServer$Division: d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68 replies to ELECTION vote request: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1<-d7f71981-d306-415b-992d-ee4808a385fa#0:FAIL-t1. Peer's state: d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68:t1, leader=null, voted=d7f71981-d306-415b-992d-ee4808a385fa, raftlog=d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode3_1  | 2021-06-25 13:42:08,211 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection1] INFO impl.LeaderElection: d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection1: ELECTION REJECTED received 2 response(s) and 0 exception(s):
datanode3_1  | 2021-06-25 13:42:08,211 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection1] INFO impl.LeaderElection:   Response 0: d7f71981-d306-415b-992d-ee4808a385fa<-8dca9ea8-5191-4cce-a34e-3d546f33f7b1#0:FAIL-t1
datanode3_1  | 2021-06-25 13:42:08,211 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection1] INFO impl.LeaderElection:   Response 1: d7f71981-d306-415b-992d-ee4808a385fa<-ee31bb40-6981-4b57-b8d7-3be03fa0c81d#0:FAIL-t1
datanode3_1  | 2021-06-25 13:42:08,211 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection1] INFO impl.LeaderElection: d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection1 ELECTION round 0: result REJECTED
datanode3_1  | 2021-06-25 13:42:08,212 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection1] INFO server.RaftServer$Division: d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
datanode3_1  | 2021-06-25 13:42:08,212 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection1] INFO impl.RoleInfo: d7f71981-d306-415b-992d-ee4808a385fa: shutdown d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection1
datanode3_1  | 2021-06-25 13:42:08,213 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection1] INFO impl.RoleInfo: d7f71981-d306-415b-992d-ee4808a385fa: start d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-FollowerState
datanode3_1  | 2021-06-25 13:42:10,100 [d7f71981-d306-415b-992d-ee4808a385fa@group-6EB5E5ADD68D-FollowerState] INFO impl.FollowerState: d7f71981-d306-415b-992d-ee4808a385fa@group-6EB5E5ADD68D-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5102313642ns, electionTimeout:5071ms
datanode3_1  | 2021-06-25 13:42:10,101 [d7f71981-d306-415b-992d-ee4808a385fa@group-6EB5E5ADD68D-FollowerState] INFO impl.RoleInfo: d7f71981-d306-415b-992d-ee4808a385fa: shutdown d7f71981-d306-415b-992d-ee4808a385fa@group-6EB5E5ADD68D-FollowerState
datanode3_1  | 2021-06-25 13:42:10,102 [d7f71981-d306-415b-992d-ee4808a385fa@group-6EB5E5ADD68D-FollowerState] INFO server.RaftServer$Division: d7f71981-d306-415b-992d-ee4808a385fa@group-6EB5E5ADD68D: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode3_1  | 2021-06-25 13:42:10,102 [d7f71981-d306-415b-992d-ee4808a385fa@group-6EB5E5ADD68D-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode3_1  | 2021-06-25 13:42:10,103 [d7f71981-d306-415b-992d-ee4808a385fa@group-6EB5E5ADD68D-FollowerState] INFO impl.RoleInfo: d7f71981-d306-415b-992d-ee4808a385fa: start d7f71981-d306-415b-992d-ee4808a385fa@group-6EB5E5ADD68D-LeaderElection2
datanode3_1  | 2021-06-25 13:42:10,125 [d7f71981-d306-415b-992d-ee4808a385fa@group-6EB5E5ADD68D-LeaderElection2] INFO impl.LeaderElection: d7f71981-d306-415b-992d-ee4808a385fa@group-6EB5E5ADD68D-LeaderElection2 ELECTION round 0: submit vote requests at term 1 for -1: [d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode3_1  | 2021-06-25 13:42:10,126 [d7f71981-d306-415b-992d-ee4808a385fa@group-6EB5E5ADD68D-LeaderElection2] INFO impl.LeaderElection: d7f71981-d306-415b-992d-ee4808a385fa@group-6EB5E5ADD68D-LeaderElection2 ELECTION round 0: result PASSED (term=1)
datanode3_1  | 2021-06-25 13:42:10,126 [d7f71981-d306-415b-992d-ee4808a385fa@group-6EB5E5ADD68D-LeaderElection2] INFO impl.RoleInfo: d7f71981-d306-415b-992d-ee4808a385fa: shutdown d7f71981-d306-415b-992d-ee4808a385fa@group-6EB5E5ADD68D-LeaderElection2
datanode3_1  | 2021-06-25 13:42:10,126 [d7f71981-d306-415b-992d-ee4808a385fa@group-6EB5E5ADD68D-LeaderElection2] INFO server.RaftServer$Division: d7f71981-d306-415b-992d-ee4808a385fa@group-6EB5E5ADD68D: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode3_1  | 2021-06-25 13:42:10,127 [d7f71981-d306-415b-992d-ee4808a385fa@group-6EB5E5ADD68D-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-6EB5E5ADD68D with new leaderId: d7f71981-d306-415b-992d-ee4808a385fa
datanode3_1  | 2021-06-25 13:42:10,127 [d7f71981-d306-415b-992d-ee4808a385fa@group-6EB5E5ADD68D-LeaderElection2] INFO server.RaftServer$Division: d7f71981-d306-415b-992d-ee4808a385fa@group-6EB5E5ADD68D: change Leader from null to d7f71981-d306-415b-992d-ee4808a385fa at term 1 for becomeLeader, leader elected after 5189ms
datanode3_1  | 2021-06-25 13:42:10,139 [d7f71981-d306-415b-992d-ee4808a385fa@group-6EB5E5ADD68D-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode3_1  | 2021-06-25 13:42:10,144 [d7f71981-d306-415b-992d-ee4808a385fa@group-6EB5E5ADD68D-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.d7f71981-d306-415b-992d-ee4808a385fa@group-6EB5E5ADD68D
datanode3_1  | 2021-06-25 13:42:10,151 [d7f71981-d306-415b-992d-ee4808a385fa@group-6EB5E5ADD68D-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode3_1  | 2021-06-25 13:42:10,152 [d7f71981-d306-415b-992d-ee4808a385fa@group-6EB5E5ADD68D-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode3_1  | 2021-06-25 13:42:10,159 [d7f71981-d306-415b-992d-ee4808a385fa@group-6EB5E5ADD68D-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode3_1  | 2021-06-25 13:42:10,163 [d7f71981-d306-415b-992d-ee4808a385fa@group-6EB5E5ADD68D-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode3_1  | 2021-06-25 13:42:10,164 [d7f71981-d306-415b-992d-ee4808a385fa@group-6EB5E5ADD68D-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode3_1  | 2021-06-25 13:42:10,177 [d7f71981-d306-415b-992d-ee4808a385fa@group-6EB5E5ADD68D-LeaderElection2] INFO impl.RoleInfo: d7f71981-d306-415b-992d-ee4808a385fa: start d7f71981-d306-415b-992d-ee4808a385fa@group-6EB5E5ADD68D-LeaderStateImpl
datanode3_1  | 2021-06-25 13:42:10,199 [d7f71981-d306-415b-992d-ee4808a385fa@group-6EB5E5ADD68D-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: d7f71981-d306-415b-992d-ee4808a385fa@group-6EB5E5ADD68D-SegmentedRaftLogWorker: Starting segment from index:0
datanode3_1  | 2021-06-25 13:42:10,237 [d7f71981-d306-415b-992d-ee4808a385fa@group-6EB5E5ADD68D-LeaderElection2] INFO server.RaftServer$Division: d7f71981-d306-415b-992d-ee4808a385fa@group-6EB5E5ADD68D: set configuration 0: [d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1], old=null
datanode3_1  | 2021-06-25 13:42:10,250 [d7f71981-d306-415b-992d-ee4808a385fa@group-5191BE84CAB1-FollowerState] INFO impl.FollowerState: d7f71981-d306-415b-992d-ee4808a385fa@group-5191BE84CAB1-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5113767513ns, electionTimeout:5082ms
datanode3_1  | 2021-06-25 13:42:10,251 [d7f71981-d306-415b-992d-ee4808a385fa@group-5191BE84CAB1-FollowerState] INFO impl.RoleInfo: d7f71981-d306-415b-992d-ee4808a385fa: shutdown d7f71981-d306-415b-992d-ee4808a385fa@group-5191BE84CAB1-FollowerState
datanode3_1  | 2021-06-25 13:42:10,251 [d7f71981-d306-415b-992d-ee4808a385fa@group-5191BE84CAB1-FollowerState] INFO server.RaftServer$Division: d7f71981-d306-415b-992d-ee4808a385fa@group-5191BE84CAB1: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode3_1  | 2021-06-25 13:42:10,251 [d7f71981-d306-415b-992d-ee4808a385fa@group-5191BE84CAB1-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode3_1  | 2021-06-25 13:42:10,251 [d7f71981-d306-415b-992d-ee4808a385fa@group-5191BE84CAB1-FollowerState] INFO impl.RoleInfo: d7f71981-d306-415b-992d-ee4808a385fa: start d7f71981-d306-415b-992d-ee4808a385fa@group-5191BE84CAB1-LeaderElection3
datanode3_1  | 2021-06-25 13:42:10,259 [d7f71981-d306-415b-992d-ee4808a385fa@group-5191BE84CAB1-LeaderElection3] INFO impl.LeaderElection: d7f71981-d306-415b-992d-ee4808a385fa@group-5191BE84CAB1-LeaderElection3 ELECTION round 0: submit vote requests at term 1 for -1: [8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1, d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0], old=null
datanode3_1  | 2021-06-25 13:42:10,286 [d7f71981-d306-415b-992d-ee4808a385fa@group-5191BE84CAB1-LeaderElection3] INFO impl.LeaderElection: d7f71981-d306-415b-992d-ee4808a385fa@group-5191BE84CAB1-LeaderElection3: ELECTION REJECTED received 1 response(s) and 0 exception(s):
datanode3_1  | 2021-06-25 13:42:10,286 [d7f71981-d306-415b-992d-ee4808a385fa@group-5191BE84CAB1-LeaderElection3] INFO impl.LeaderElection:   Response 0: d7f71981-d306-415b-992d-ee4808a385fa<-ee31bb40-6981-4b57-b8d7-3be03fa0c81d#0:FAIL-t1
datanode3_1  | 2021-06-25 13:42:10,287 [d7f71981-d306-415b-992d-ee4808a385fa@group-5191BE84CAB1-LeaderElection3] INFO impl.LeaderElection: d7f71981-d306-415b-992d-ee4808a385fa@group-5191BE84CAB1-LeaderElection3 ELECTION round 0: result REJECTED
om1_1        | 2021-06-25 13:49:52,568 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:49:52,732 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:49:52,733 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38838
om1_1        | 2021-06-25 13:49:52,742 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:49:52,822 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:49:52,823 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38844
om1_1        | 2021-06-25 13:49:52,827 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:49:52,907 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:49:52,910 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38852
om1_1        | 2021-06-25 13:49:52,919 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:49:57,003 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:49:57,004 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38880
om1_1        | 2021-06-25 13:49:57,010 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:49:58,664 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:49:58,664 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38894
om1_1        | 2021-06-25 13:49:58,679 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:50:04,483 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:59040
om1_1        | 2021-06-25 13:50:04,512 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:50:07,592 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:50:07,593 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38962
om1_1        | 2021-06-25 13:50:07,595 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:50:08,271 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:50:08,272 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38972
om1_1        | 2021-06-25 13:50:08,273 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:50:08,967 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:50:08,968 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38980
om1_1        | 2021-06-25 13:50:08,972 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:50:09,029 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket-25047 in volume:s3v
om1_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om1_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:198)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1        | 2021-06-25 13:50:09,649 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:50:09,649 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38990
om1_1        | 2021-06-25 13:50:09,653 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:50:14,342 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:59114
om1_1        | 2021-06-25 13:50:14,356 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:50:17,600 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:50:17,601 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39030
om3_1        | 2021-06-25 13:41:45,200 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om3_1        | 2021-06-25 13:41:45,258 [pool-22-thread-1] INFO server.RaftServer$Division: om3@group-562213E44849: ConfigurationManager, init=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null, confs=<EMPTY_MAP>
om3_1        | 2021-06-25 13:41:45,258 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om3_1        | 2021-06-25 13:41:45,358 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om3_1        | 2021-06-25 13:41:45,366 [pool-22-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 does not exist. Creating ...
om3_1        | 2021-06-25 13:41:45,420 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om3_1        | 2021-06-25 13:41:45,469 [pool-22-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/in_use.lock acquired by nodename 8@om3
om3_1        | 2021-06-25 13:41:45,519 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om3_1        | 2021-06-25 13:41:45,599 [pool-22-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 has been successfully formatted.
om3_1        | 2021-06-25 13:41:45,622 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om3_1        | 2021-06-25 13:41:45,648 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om3_1        | 2021-06-25 13:41:45,762 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om3_1        | 2021-06-25 13:41:45,763 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om3_1        | 2021-06-25 13:41:45,826 [pool-22-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.om3@group-562213E44849
om3_1        | 2021-06-25 13:41:45,927 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om3_1        | 2021-06-25 13:41:46,020 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om3_1        | 2021-06-25 13:41:46,021 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om3_1        | 2021-06-25 13:41:46,098 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: new om3@group-562213E44849-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849
om3_1        | 2021-06-25 13:41:46,105 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om3_1        | 2021-06-25 13:41:46,107 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om3_1        | 2021-06-25 13:41:46,122 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om3_1        | 2021-06-25 13:41:46,125 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om3_1        | 2021-06-25 13:41:46,127 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om3_1        | 2021-06-25 13:41:46,129 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om3_1        | 2021-06-25 13:41:46,141 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om3_1        | 2021-06-25 13:41:46,141 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om3_1        | 2021-06-25 13:41:46,226 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om3_1        | 2021-06-25 13:41:46,242 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om3_1        | 2021-06-25 13:41:46,273 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode2_1  | 2021-06-25 13:42:28,494 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-LeaderElection6] INFO impl.LeaderElection: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-LeaderElection6 ELECTION round 0: result REJECTED
datanode2_1  | 2021-06-25 13:42:28,501 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-LeaderElection6] INFO server.RaftServer$Division: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68: changes role from CANDIDATE to FOLLOWER at term 5 for REJECTED
datanode2_1  | 2021-06-25 13:42:28,502 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-LeaderElection6] INFO impl.RoleInfo: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1: shutdown 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-LeaderElection6
datanode2_1  | 2021-06-25 13:42:28,502 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-LeaderElection6] INFO impl.RoleInfo: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1: start 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-FollowerState
datanode2_1  | 2021-06-25 13:42:30,474 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:42:33,546 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:42:33,598 [grpc-default-executor-0] INFO server.RaftServer$Division: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68: receive requestVote(ELECTION, d7f71981-d306-415b-992d-ee4808a385fa, group-BFEA630F7F68, 6, (t:0, i:0))
datanode2_1  | 2021-06-25 13:42:33,598 [grpc-default-executor-0] INFO impl.VoteContext: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-FOLLOWER: accept ELECTION from d7f71981-d306-415b-992d-ee4808a385fa: our priority 0 <= candidate's priority 1
datanode2_1  | 2021-06-25 13:42:33,599 [grpc-default-executor-0] INFO server.RaftServer$Division: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68: changes role from  FOLLOWER to FOLLOWER at term 6 for candidate:d7f71981-d306-415b-992d-ee4808a385fa
datanode2_1  | 2021-06-25 13:42:33,599 [grpc-default-executor-0] INFO impl.RoleInfo: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1: shutdown 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-FollowerState
datanode2_1  | 2021-06-25 13:42:33,599 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-FollowerState] INFO impl.FollowerState: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-FollowerState was interrupted: {}
datanode2_1  | java.lang.InterruptedException: sleep interrupted
datanode2_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode2_1  | 	at java.base/java.lang.Thread.sleep(Thread.java:339)
datanode2_1  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode2_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
datanode2_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode2_1  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
datanode2_1  | 2021-06-25 13:42:33,601 [grpc-default-executor-0] INFO impl.RoleInfo: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1: start 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-FollowerState
datanode2_1  | 2021-06-25 13:42:33,614 [grpc-default-executor-0] INFO server.RaftServer$Division: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68 replies to ELECTION vote request: d7f71981-d306-415b-992d-ee4808a385fa<-8dca9ea8-5191-4cce-a34e-3d546f33f7b1#0:OK-t6. Peer's state: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68:t6, leader=null, voted=d7f71981-d306-415b-992d-ee4808a385fa, raftlog=8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode2_1  | 2021-06-25 13:42:33,747 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-BFEA630F7F68 with new leaderId: d7f71981-d306-415b-992d-ee4808a385fa
datanode2_1  | 2021-06-25 13:42:33,747 [grpc-default-executor-0] INFO server.RaftServer$Division: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68: change Leader from null to d7f71981-d306-415b-992d-ee4808a385fa at term 6 for appendEntries, leader elected after 31943ms
datanode2_1  | 2021-06-25 13:42:33,802 [grpc-default-executor-0] INFO server.RaftServer$Division: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68: set configuration 0: [8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1], old=null
datanode2_1  | 2021-06-25 13:42:33,802 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-SegmentedRaftLogWorker: Starting segment from index:0
datanode2_1  | 2021-06-25 13:42:33,805 [8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1@group-BFEA630F7F68-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/3175bb45-44a8-4478-8980-bfea630f7f68/current/log_inprogress_0
datanode2_1  | 2021-06-25 13:42:36,619 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:42:39,690 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:42:42,762 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:42:45,834 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:42:48,911 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:42:51,978 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:42:55,050 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:42:10,287 [d7f71981-d306-415b-992d-ee4808a385fa@group-5191BE84CAB1-LeaderElection3] INFO server.RaftServer$Division: d7f71981-d306-415b-992d-ee4808a385fa@group-5191BE84CAB1: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
datanode3_1  | 2021-06-25 13:42:10,287 [d7f71981-d306-415b-992d-ee4808a385fa@group-5191BE84CAB1-LeaderElection3] INFO impl.RoleInfo: d7f71981-d306-415b-992d-ee4808a385fa: shutdown d7f71981-d306-415b-992d-ee4808a385fa@group-5191BE84CAB1-LeaderElection3
datanode3_1  | 2021-06-25 13:42:10,287 [d7f71981-d306-415b-992d-ee4808a385fa@group-5191BE84CAB1-LeaderElection3] INFO impl.RoleInfo: d7f71981-d306-415b-992d-ee4808a385fa: start d7f71981-d306-415b-992d-ee4808a385fa@group-5191BE84CAB1-FollowerState
datanode3_1  | 2021-06-25 13:42:10,361 [d7f71981-d306-415b-992d-ee4808a385fa@group-6EB5E5ADD68D-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: d7f71981-d306-415b-992d-ee4808a385fa@group-6EB5E5ADD68D-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/8a55befb-80cf-4326-9d11-6eb5e5add68d/current/log_inprogress_0
datanode3_1  | 2021-06-25 13:42:10,731 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:42:12,803 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] WARN statemachine.EndpointStateMachine: Unable to communicate to Recon server at recon:9891 for past 0 seconds.
datanode3_1  | java.net.NoRouteToHostException: No Route to Host from  7b9eb44ecf31/172.25.0.104 to recon:9891 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
datanode3_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode3_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode3_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode3_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode3_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:836)
datanode3_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:787)
datanode3_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1566)
datanode3_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
datanode3_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
datanode3_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
datanode3_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
datanode3_1  | 	at com.sun.proxy.$Proxy40.submitRequest(Unknown Source)
datanode3_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
datanode3_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:133)
om3_1        | 2021-06-25 13:41:46,276 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om3_1        | 2021-06-25 13:41:46,302 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om3_1        | 2021-06-25 13:41:46,304 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om3_1        | 2021-06-25 13:41:46,307 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om3_1        | 2021-06-25 13:41:46,321 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om3_1        | 2021-06-25 13:41:46,324 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
om3_1        | 2021-06-25 13:41:46,329 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om3_1        | 2021-06-25 13:41:46,512 [pool-22-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.om3@group-562213E44849
om3_1        | 2021-06-25 13:41:46,544 [pool-22-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.om3@group-562213E44849
om3_1        | 2021-06-25 13:41:46,638 [Listener at om3/9862] INFO om.OzoneManager: Configured ozone.om.metadata.layout=SIMPLE and disabled optimized OM FS operations
om3_1        | 2021-06-25 13:41:47,148 [Listener at om3/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om3_1        | 2021-06-25 13:41:47,303 [Listener at om3/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om3_1        | 2021-06-25 13:41:47,304 [Listener at om3/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om3_1        | 2021-06-25 13:41:47,472 [Listener at om3/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om3/172.25.0.113:9862
om3_1        | 2021-06-25 13:41:47,480 [Listener at om3/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om3 at port 9872
om3_1        | 2021-06-25 13:41:47,483 [Listener at om3/9862] INFO server.RaftServer$Division: om3@group-562213E44849: start as a follower, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1        | 2021-06-25 13:41:47,494 [Listener at om3/9862] INFO server.RaftServer$Division: om3@group-562213E44849: changes role from      null to FOLLOWER at term 0 for startAsFollower
om3_1        | 2021-06-25 13:41:47,496 [Listener at om3/9862] INFO impl.RoleInfo: om3: start om3@group-562213E44849-FollowerState
om3_1        | 2021-06-25 13:41:47,512 [Listener at om3/9862] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-562213E44849,id=om3
om3_1        | 2021-06-25 13:41:47,519 [Listener at om3/9862] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.om3@group-562213E44849
om3_1        | 2021-06-25 13:41:47,540 [Listener at om3/9862] INFO server.RaftServer: om3: start RPC server
om3_1        | 2021-06-25 13:41:47,810 [Listener at om3/9862] INFO server.GrpcService: om3: GrpcService started, listening on 9872
om3_1        | 2021-06-25 13:41:47,813 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$387/0x000000084058fc40@3808bdfc] INFO util.JvmPauseMonitor: JvmPauseMonitor-om3: Started
om3_1        | 2021-06-25 13:41:47,817 [Listener at om3/9862] INFO om.OzoneManager: Starting OM block token secret manager
om3_1        | 2021-06-25 13:41:47,823 [Listener at om3/9862] INFO security.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
om3_1        | 2021-06-25 13:41:47,825 [Listener at om3/9862] INFO om.OzoneManager: Starting OM delegation token secret manager
om3_1        | 2021-06-25 13:41:47,833 [Listener at om3/9862] INFO security.OzoneDelegationTokenSecretManager: Updating the current master key for generating tokens
om3_1        | 2021-06-25 13:41:47,850 [Thread[Thread-15,5,main]] INFO security.OzoneDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
om3_1        | 2021-06-25 13:41:48,013 [Listener at om3/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om3_1        | 2021-06-25 13:41:48,015 [Listener at om3/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
om3_1        | 2021-06-25 13:41:48,016 [Listener at om3/9862] INFO http.BaseHttpServer: HttpAuthType: ozone.om.http.auth.type = kerberos
om3_1        | 2021-06-25 13:41:48,181 [Listener at om3/9862] INFO util.log: Logging initialized @43396ms to org.eclipse.jetty.util.log.Slf4jLog
om3_1        | 2021-06-25 13:41:48,709 [Listener at om3/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om3_1        | 2021-06-25 13:41:48,720 [Listener at om3/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om3_1        | 2021-06-25 13:41:48,734 [Listener at om3/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context ozoneManager
om3_1        | 2021-06-25 13:41:48,734 [Listener at om3/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
om3_1        | 2021-06-25 13:41:48,734 [Listener at om3/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
om3_1        | 2021-06-25 13:41:48,746 [Listener at om3/9862] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.om.http.auth.kerberos.principal keytabKey: ozone.om.http.auth.kerberos.keytab
om3_1        | 2021-06-25 13:41:48,888 [Listener at om3/9862] INFO http.HttpServer2: Jetty bound to port 9874
om3_1        | 2021-06-25 13:41:48,891 [Listener at om3/9862] INFO server.Server: jetty-9.4.35.v20201120; built: 2020-11-20T21:17:03.964Z; git: bdc54f03a5e0a7e280fab27f55c3c75ee8da89fb; jvm 11.0.10+9-LTS
om3_1        | 2021-06-25 13:41:49,019 [Listener at om3/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om3_1        | 2021-06-25 13:41:49,019 [Listener at om3/9862] INFO server.session: No SessionScavenger set, using defaults
om3_1        | 2021-06-25 13:41:49,028 [Listener at om3/9862] INFO server.session: node0 Scavenging every 660000ms
om3_1        | 2021-06-25 13:41:49,140 [Listener at om3/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om3_1        | 2021-06-25 13:41:49,157 [Listener at om3/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1ab6a093{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om3_1        | 2021-06-25 13:41:49,161 [Listener at om3/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5e774546{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.2.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om3_1        | 2021-06-25 13:41:49,702 [Listener at om3/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om3_1        | 2021-06-25 13:41:49,779 [Listener at om3/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@3ffa3cdb{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-ozone-manager-1_2_0-SNAPSHOT_jar-_-any-17045985179025799977/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.2.0-SNAPSHOT.jar!/webapps/ozoneManager}
om3_1        | 2021-06-25 13:41:49,822 [Listener at om3/9862] INFO server.AbstractConnector: Started ServerConnector@21cb907d{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
om3_1        | 2021-06-25 13:41:49,822 [Listener at om3/9862] INFO server.Server: Started @45038ms
om3_1        | 2021-06-25 13:41:49,846 [Listener at om3/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om3_1        | 2021-06-25 13:41:49,846 [Listener at om3/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om2_1        | 2021-06-25 13:46:29,167 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:46:34,753 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55242
om2_1        | 2021-06-25 13:46:34,755 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:46:40,182 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55260
om2_1        | 2021-06-25 13:46:40,189 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:46:45,575 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55288
om2_1        | 2021-06-25 13:46:45,584 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:46:50,739 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55316
om2_1        | 2021-06-25 13:46:50,745 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:46:55,795 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55342
om2_1        | 2021-06-25 13:46:55,802 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:47:01,367 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55388
om2_1        | 2021-06-25 13:47:01,377 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:47:06,580 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55414
om2_1        | 2021-06-25 13:47:06,606 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:47:11,352 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55438
om2_1        | 2021-06-25 13:47:11,357 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:47:16,111 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55456
om2_1        | 2021-06-25 13:47:16,119 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:47:21,184 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55484
om2_1        | 2021-06-25 13:47:21,188 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:47:21,942 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:link2 in volume:05944-target
om2_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om2_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:198)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om2_1        | 2021-06-25 13:47:26,210 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55508
om2_1        | 2021-06-25 13:47:26,223 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:47:31,467 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55562
om2_1        | 2021-06-25 13:47:31,471 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:47:32,332 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket3 in volume:05944-target
om2_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om2_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:198)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om2_1        | 2021-06-25 13:47:36,708 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55590
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:71)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:42)
datanode3_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode3_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode3_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode3_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode3_1  | Caused by: java.net.NoRouteToHostException: No route to host
datanode3_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
datanode3_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:779)
datanode3_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
datanode3_1  | 	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:534)
datanode3_1  | 	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:699)
datanode3_1  | 	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:812)
datanode3_1  | 	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:413)
datanode3_1  | 	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1636)
datanode3_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1452)
datanode3_1  | 	... 12 more
datanode3_1  | 2021-06-25 13:42:13,120 [grpc-default-executor-0] INFO server.RaftServer$Division: d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68: receive requestVote(ELECTION, 8dca9ea8-5191-4cce-a34e-3d546f33f7b1, group-BFEA630F7F68, 2, (t:0, i:0))
datanode3_1  | 2021-06-25 13:42:13,121 [grpc-default-executor-0] INFO impl.VoteContext: d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-FOLLOWER: reject ELECTION from 8dca9ea8-5191-4cce-a34e-3d546f33f7b1: our priority 1 > candidate's priority 0
datanode3_1  | 2021-06-25 13:42:13,121 [grpc-default-executor-0] INFO server.RaftServer$Division: d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:8dca9ea8-5191-4cce-a34e-3d546f33f7b1
datanode3_1  | 2021-06-25 13:42:13,121 [grpc-default-executor-0] INFO impl.RoleInfo: d7f71981-d306-415b-992d-ee4808a385fa: shutdown d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-FollowerState
datanode3_1  | 2021-06-25 13:42:13,121 [grpc-default-executor-0] INFO impl.RoleInfo: d7f71981-d306-415b-992d-ee4808a385fa: start d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-FollowerState
datanode3_1  | 2021-06-25 13:42:13,122 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-FollowerState] INFO impl.FollowerState: d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-FollowerState was interrupted: {}
datanode3_1  | java.lang.InterruptedException: sleep interrupted
datanode3_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode3_1  | 	at java.base/java.lang.Thread.sleep(Thread.java:339)
datanode3_1  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode3_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
datanode3_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode3_1  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
datanode3_1  | 2021-06-25 13:42:13,127 [grpc-default-executor-0] INFO server.RaftServer$Division: d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68 replies to ELECTION vote request: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1<-d7f71981-d306-415b-992d-ee4808a385fa#0:FAIL-t2. Peer's state: d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68:t2, leader=null, voted=null, raftlog=d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode3_1  | 2021-06-25 13:42:15,317 [grpc-default-executor-0] INFO server.RaftServer$Division: d7f71981-d306-415b-992d-ee4808a385fa@group-5191BE84CAB1: receive requestVote(ELECTION, ee31bb40-6981-4b57-b8d7-3be03fa0c81d, group-5191BE84CAB1, 2, (t:0, i:0))
datanode3_1  | 2021-06-25 13:42:15,317 [grpc-default-executor-0] INFO impl.VoteContext: d7f71981-d306-415b-992d-ee4808a385fa@group-5191BE84CAB1-FOLLOWER: accept ELECTION from ee31bb40-6981-4b57-b8d7-3be03fa0c81d: our priority 0 <= candidate's priority 1
datanode3_1  | 2021-06-25 13:42:15,317 [grpc-default-executor-0] INFO server.RaftServer$Division: d7f71981-d306-415b-992d-ee4808a385fa@group-5191BE84CAB1: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:ee31bb40-6981-4b57-b8d7-3be03fa0c81d
datanode3_1  | 2021-06-25 13:42:15,317 [grpc-default-executor-0] INFO impl.RoleInfo: d7f71981-d306-415b-992d-ee4808a385fa: shutdown d7f71981-d306-415b-992d-ee4808a385fa@group-5191BE84CAB1-FollowerState
datanode3_1  | 2021-06-25 13:42:15,317 [grpc-default-executor-0] INFO impl.RoleInfo: d7f71981-d306-415b-992d-ee4808a385fa: start d7f71981-d306-415b-992d-ee4808a385fa@group-5191BE84CAB1-FollowerState
datanode3_1  | 2021-06-25 13:42:15,317 [d7f71981-d306-415b-992d-ee4808a385fa@group-5191BE84CAB1-FollowerState] INFO impl.FollowerState: d7f71981-d306-415b-992d-ee4808a385fa@group-5191BE84CAB1-FollowerState was interrupted: {}
datanode3_1  | java.lang.InterruptedException: sleep interrupted
datanode3_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode3_1  | 	at java.base/java.lang.Thread.sleep(Thread.java:339)
datanode3_1  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode3_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
datanode3_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode3_1  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
datanode3_1  | 2021-06-25 13:42:15,326 [grpc-default-executor-0] INFO server.RaftServer$Division: d7f71981-d306-415b-992d-ee4808a385fa@group-5191BE84CAB1 replies to ELECTION vote request: ee31bb40-6981-4b57-b8d7-3be03fa0c81d<-d7f71981-d306-415b-992d-ee4808a385fa#0:OK-t2. Peer's state: d7f71981-d306-415b-992d-ee4808a385fa@group-5191BE84CAB1:t2, leader=null, voted=ee31bb40-6981-4b57-b8d7-3be03fa0c81d, raftlog=d7f71981-d306-415b-992d-ee4808a385fa@group-5191BE84CAB1-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1, d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0], old=null
datanode3_1  | 2021-06-25 13:42:15,431 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-5191BE84CAB1 with new leaderId: ee31bb40-6981-4b57-b8d7-3be03fa0c81d
datanode3_1  | 2021-06-25 13:42:15,431 [grpc-default-executor-0] INFO server.RaftServer$Division: d7f71981-d306-415b-992d-ee4808a385fa@group-5191BE84CAB1: change Leader from null to ee31bb40-6981-4b57-b8d7-3be03fa0c81d at term 2 for appendEntries, leader elected after 10370ms
datanode3_1  | 2021-06-25 13:42:15,469 [grpc-default-executor-0] INFO server.RaftServer$Division: d7f71981-d306-415b-992d-ee4808a385fa@group-5191BE84CAB1: set configuration 0: [8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
om2_1        | 2021-06-25 13:47:36,711 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:47:42,040 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55614
om2_1        | 2021-06-25 13:47:42,046 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:47:46,897 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55640
om2_1        | 2021-06-25 13:47:46,907 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:47:52,116 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55660
om2_1        | 2021-06-25 13:47:52,122 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:47:56,999 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55690
om2_1        | 2021-06-25 13:47:57,004 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:48:02,400 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55732
om2_1        | 2021-06-25 13:48:02,408 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:48:07,403 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55758
om2_1        | 2021-06-25 13:48:07,411 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:48:12,714 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55782
om2_1        | 2021-06-25 13:48:12,722 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:48:16,889 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55800
om2_1        | 2021-06-25 13:48:16,891 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:48:22,070 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55826
om2_1        | 2021-06-25 13:48:22,081 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:48:30,425 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55880
om2_1        | 2021-06-25 13:48:30,430 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:48:39,154 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55936
om2_1        | 2021-06-25 13:48:39,162 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:48:44,333 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55962
om2_1        | 2021-06-25 13:48:44,339 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:48:49,940 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55988
om2_1        | 2021-06-25 13:48:49,946 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:49:15,804 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:56232
om2_1        | 2021-06-25 13:49:15,813 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:49:20,116 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:49:20,119 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:37394
om2_1        | 2021-06-25 13:49:20,129 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:49:25,098 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:56282
om2_1        | 2021-06-25 13:49:25,100 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:49:28,365 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:49:28,366 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:37436
om2_1        | 2021-06-25 13:49:28,371 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:49:29,155 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:49:29,157 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:37444
om3_1        | 2021-06-25 13:41:49,848 [Listener at om3/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om3_1        | 2021-06-25 13:41:49,849 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om3_1        | 2021-06-25 13:41:49,875 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om3_1        | 2021-06-25 13:41:49,985 [Listener at om3/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted will not move to trash
om3_1        | 2021-06-25 13:41:50,031 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@532860c7] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om3_1        | 2021-06-25 13:41:52,699 [om3@group-562213E44849-FollowerState] INFO impl.FollowerState: om3@group-562213E44849-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5203639815ns, electionTimeout:5188ms
om3_1        | 2021-06-25 13:41:52,700 [om3@group-562213E44849-FollowerState] INFO impl.RoleInfo: om3: shutdown om3@group-562213E44849-FollowerState
om3_1        | 2021-06-25 13:41:52,701 [om3@group-562213E44849-FollowerState] INFO server.RaftServer$Division: om3@group-562213E44849: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
om3_1        | 2021-06-25 13:41:52,705 [om3@group-562213E44849-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om3_1        | 2021-06-25 13:41:52,705 [om3@group-562213E44849-FollowerState] INFO impl.RoleInfo: om3: start om3@group-562213E44849-LeaderElection1
om3_1        | 2021-06-25 13:41:52,721 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om3@group-562213E44849-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1        | 2021-06-25 13:41:54,831 [grpc-default-executor-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server_message_metrics.om3
om3_1        | 2021-06-25 13:41:54,848 [grpc-default-executor-1] INFO server.RaftServer$Division: om3@group-562213E44849: receive requestVote(ELECTION, om2, group-562213E44849, 1, (t:0, i:~))
om3_1        | 2021-06-25 13:41:54,855 [grpc-default-executor-1] INFO impl.VoteContext: om3@group-562213E44849-CANDIDATE: reject ELECTION from om2: already has voted for om3 at current term 1
om3_1        | 2021-06-25 13:41:54,866 [grpc-default-executor-1] INFO server.RaftServer$Division: om3@group-562213E44849 replies to ELECTION vote request: om2<-om3#0:FAIL-t1. Peer's state: om3@group-562213E44849:t1, leader=null, voted=om3, raftlog=om3@group-562213E44849-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1        | 2021-06-25 13:41:54,906 [grpc-default-executor-1] INFO server.RaftServer$Division: om3@group-562213E44849: receive requestVote(ELECTION, om1, group-562213E44849, 1, (t:0, i:~))
om3_1        | 2021-06-25 13:41:54,906 [grpc-default-executor-1] INFO impl.VoteContext: om3@group-562213E44849-CANDIDATE: reject ELECTION from om1: already has voted for om3 at current term 1
om3_1        | 2021-06-25 13:41:54,907 [grpc-default-executor-1] INFO server.RaftServer$Division: om3@group-562213E44849 replies to ELECTION vote request: om1<-om3#0:FAIL-t1. Peer's state: om3@group-562213E44849:t1, leader=null, voted=om3, raftlog=om3@group-562213E44849-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1        | 2021-06-25 13:41:54,932 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om3@group-562213E44849-LeaderElection1: ELECTION REJECTED received 2 response(s) and 0 exception(s):
om3_1        | 2021-06-25 13:41:54,932 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 0: om3<-om1#0:FAIL-t1
om3_1        | 2021-06-25 13:41:54,932 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 1: om3<-om2#0:FAIL-t1
om3_1        | 2021-06-25 13:41:54,932 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om3@group-562213E44849-LeaderElection1 ELECTION round 0: result REJECTED
om3_1        | 2021-06-25 13:41:54,934 [om3@group-562213E44849-LeaderElection1] INFO server.RaftServer$Division: om3@group-562213E44849: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
om3_1        | 2021-06-25 13:41:54,935 [om3@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om3: shutdown om3@group-562213E44849-LeaderElection1
om3_1        | 2021-06-25 13:41:54,936 [om3@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om3: start om3@group-562213E44849-FollowerState
om3_1        | 2021-06-25 13:42:00,018 [om3@group-562213E44849-FollowerState] INFO impl.FollowerState: om3@group-562213E44849-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5082533944ns, electionTimeout:5082ms
om3_1        | 2021-06-25 13:42:00,019 [om3@group-562213E44849-FollowerState] INFO impl.RoleInfo: om3: shutdown om3@group-562213E44849-FollowerState
om3_1        | 2021-06-25 13:42:00,020 [om3@group-562213E44849-FollowerState] INFO server.RaftServer$Division: om3@group-562213E44849: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
om3_1        | 2021-06-25 13:42:00,020 [om3@group-562213E44849-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om3_1        | 2021-06-25 13:42:00,020 [om3@group-562213E44849-FollowerState] INFO impl.RoleInfo: om3: start om3@group-562213E44849-LeaderElection2
om3_1        | 2021-06-25 13:42:00,025 [om3@group-562213E44849-LeaderElection2] INFO impl.LeaderElection: om3@group-562213E44849-LeaderElection2 ELECTION round 0: submit vote requests at term 2 for -1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1        | 2021-06-25 13:42:00,115 [om3@group-562213E44849-LeaderElection2] INFO impl.LeaderElection: om3@group-562213E44849-LeaderElection2: ELECTION PASSED received 1 response(s) and 0 exception(s):
om3_1        | 2021-06-25 13:42:00,115 [om3@group-562213E44849-LeaderElection2] INFO impl.LeaderElection:   Response 0: om3<-om1#0:OK-t2
om3_1        | 2021-06-25 13:42:00,116 [om3@group-562213E44849-LeaderElection2] INFO impl.LeaderElection: om3@group-562213E44849-LeaderElection2 ELECTION round 0: result PASSED
om3_1        | 2021-06-25 13:42:00,116 [om3@group-562213E44849-LeaderElection2] INFO impl.RoleInfo: om3: shutdown om3@group-562213E44849-LeaderElection2
om3_1        | 2021-06-25 13:42:00,117 [om3@group-562213E44849-LeaderElection2] INFO server.RaftServer$Division: om3@group-562213E44849: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
om3_1        | 2021-06-25 13:42:00,118 [om3@group-562213E44849-LeaderElection2] INFO server.RaftServer$Division: om3@group-562213E44849: change Leader from null to om3 at term 2 for becomeLeader, leader elected after 14494ms
om3_1        | 2021-06-25 13:42:00,145 [om3@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
om3_1        | 2021-06-25 13:42:00,165 [om3@group-562213E44849-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.om3@group-562213E44849
om3_1        | 2021-06-25 13:42:00,183 [om3@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
om3_1        | 2021-06-25 13:42:00,191 [om3@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
om3_1        | 2021-06-25 13:42:00,206 [om3@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
om3_1        | 2021-06-25 13:42:00,232 [om3@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
om3_1        | 2021-06-25 13:42:00,240 [om3@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
om3_1        | 2021-06-25 13:42:00,294 [om3@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
om3_1        | 2021-06-25 13:42:00,294 [om3@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om3_1        | 2021-06-25 13:42:00,295 [om3@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
om3_1        | 2021-06-25 13:42:00,311 [om3@group-562213E44849-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
om3_1        | 2021-06-25 13:42:00,312 [om3@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om3_1        | 2021-06-25 13:42:00,313 [om3@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om3_1        | 2021-06-25 13:42:00,314 [om3@group-562213E44849-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis_grpc.log_appender.om3@group-562213E44849
om3_1        | 2021-06-25 13:42:00,324 [om3@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode3_1  | 2021-06-25 13:42:15,469 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: d7f71981-d306-415b-992d-ee4808a385fa@group-5191BE84CAB1-SegmentedRaftLogWorker: Starting segment from index:0
datanode3_1  | 2021-06-25 13:42:15,472 [d7f71981-d306-415b-992d-ee4808a385fa@group-5191BE84CAB1-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: d7f71981-d306-415b-992d-ee4808a385fa@group-5191BE84CAB1-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/949dd475-00f3-4295-9774-5191be84cab1/current/log_inprogress_0
datanode3_1  | 2021-06-25 13:42:16,874 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:42:18,265 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-FollowerState] INFO impl.FollowerState: d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5144112728ns, electionTimeout:5140ms
datanode3_1  | 2021-06-25 13:42:18,266 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-FollowerState] INFO impl.RoleInfo: d7f71981-d306-415b-992d-ee4808a385fa: shutdown d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-FollowerState
datanode3_1  | 2021-06-25 13:42:18,266 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-FollowerState] INFO server.RaftServer$Division: d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68: changes role from  FOLLOWER to CANDIDATE at term 2 for changeToCandidate
datanode3_1  | 2021-06-25 13:42:18,266 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode3_1  | 2021-06-25 13:42:18,266 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-FollowerState] INFO impl.RoleInfo: d7f71981-d306-415b-992d-ee4808a385fa: start d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection4
datanode3_1  | 2021-06-25 13:42:18,282 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection4] INFO impl.LeaderElection: d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection4 ELECTION round 0: submit vote requests at term 3 for -1: [8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode3_1  | 2021-06-25 13:42:18,304 [grpc-default-executor-0] INFO server.RaftServer$Division: d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68: receive requestVote(ELECTION, 8dca9ea8-5191-4cce-a34e-3d546f33f7b1, group-BFEA630F7F68, 3, (t:0, i:0))
datanode3_1  | 2021-06-25 13:42:18,304 [grpc-default-executor-0] INFO impl.VoteContext: d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-CANDIDATE: reject ELECTION from 8dca9ea8-5191-4cce-a34e-3d546f33f7b1: already has voted for d7f71981-d306-415b-992d-ee4808a385fa at current term 3
datanode3_1  | 2021-06-25 13:42:18,306 [grpc-default-executor-0] INFO server.RaftServer$Division: d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68 replies to ELECTION vote request: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1<-d7f71981-d306-415b-992d-ee4808a385fa#0:FAIL-t3. Peer's state: d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68:t3, leader=null, voted=d7f71981-d306-415b-992d-ee4808a385fa, raftlog=d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode3_1  | 2021-06-25 13:42:18,339 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection4] INFO impl.LeaderElection: d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection4: ELECTION REJECTED received 2 response(s) and 0 exception(s):
datanode3_1  | 2021-06-25 13:42:18,341 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection4] INFO impl.LeaderElection:   Response 0: d7f71981-d306-415b-992d-ee4808a385fa<-8dca9ea8-5191-4cce-a34e-3d546f33f7b1#0:FAIL-t3
datanode3_1  | 2021-06-25 13:42:18,341 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection4] INFO impl.LeaderElection:   Response 1: d7f71981-d306-415b-992d-ee4808a385fa<-ee31bb40-6981-4b57-b8d7-3be03fa0c81d#0:FAIL-t3
datanode3_1  | 2021-06-25 13:42:18,341 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection4] INFO impl.LeaderElection: d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection4 ELECTION round 0: result REJECTED
datanode3_1  | 2021-06-25 13:42:18,341 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection4] INFO server.RaftServer$Division: d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68: changes role from CANDIDATE to FOLLOWER at term 3 for REJECTED
datanode3_1  | 2021-06-25 13:42:18,341 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection4] INFO impl.RoleInfo: d7f71981-d306-415b-992d-ee4808a385fa: shutdown d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection4
datanode3_1  | 2021-06-25 13:42:18,342 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection4] INFO impl.RoleInfo: d7f71981-d306-415b-992d-ee4808a385fa: start d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-FollowerState
datanode3_1  | 2021-06-25 13:42:19,946 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:42:23,018 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:42:23,394 [grpc-default-executor-0] INFO server.RaftServer$Division: d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68: receive requestVote(ELECTION, 8dca9ea8-5191-4cce-a34e-3d546f33f7b1, group-BFEA630F7F68, 4, (t:0, i:0))
datanode3_1  | 2021-06-25 13:42:23,394 [grpc-default-executor-0] INFO impl.VoteContext: d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-FOLLOWER: reject ELECTION from 8dca9ea8-5191-4cce-a34e-3d546f33f7b1: our priority 1 > candidate's priority 0
datanode3_1  | 2021-06-25 13:42:23,394 [grpc-default-executor-0] INFO server.RaftServer$Division: d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68: changes role from  FOLLOWER to FOLLOWER at term 4 for candidate:8dca9ea8-5191-4cce-a34e-3d546f33f7b1
datanode3_1  | 2021-06-25 13:42:23,394 [grpc-default-executor-0] INFO impl.RoleInfo: d7f71981-d306-415b-992d-ee4808a385fa: shutdown d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-FollowerState
datanode3_1  | 2021-06-25 13:42:23,394 [grpc-default-executor-0] INFO impl.RoleInfo: d7f71981-d306-415b-992d-ee4808a385fa: start d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-FollowerState
datanode3_1  | 2021-06-25 13:42:23,394 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-FollowerState] INFO impl.FollowerState: d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-FollowerState was interrupted: {}
datanode3_1  | java.lang.InterruptedException: sleep interrupted
datanode3_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode3_1  | 	at java.base/java.lang.Thread.sleep(Thread.java:339)
datanode3_1  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode3_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
om1_1        | 2021-06-25 13:50:17,602 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:50:18,255 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:50:18,256 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39046
om1_1        | 2021-06-25 13:50:18,258 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:50:18,936 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:50:18,937 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39056
om1_1        | 2021-06-25 13:50:18,943 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:50:19,499 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:50:19,500 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39066
om1_1        | 2021-06-25 13:50:19,501 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:50:19,539 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketDeleteRequest: Delete bucket failed for bucket:nosuchbucket in volume:s3v
om1_1        | BUCKET_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Bucket not exists
om1_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketDeleteRequest.validateAndUpdateCache(OMBucketDeleteRequest.java:119)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1        | 2021-06-25 13:50:23,344 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:59180
om1_1        | 2021-06-25 13:50:23,354 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:50:26,532 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:50:26,533 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39104
om1_1        | 2021-06-25 13:50:26,550 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:50:27,258 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:50:27,259 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39112
om1_1        | 2021-06-25 13:50:27,260 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:50:27,886 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:50:27,888 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39120
om1_1        | 2021-06-25 13:50:27,890 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:50:32,731 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:59274
om1_1        | 2021-06-25 13:50:32,771 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:50:36,055 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:50:36,056 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39198
datanode2_1  | 2021-06-25 13:42:58,122 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:43:01,194 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:43:03,328 [ChunkWriter-0-0] INFO client.DNCertificateClient: Getting certificate with certSerialId:2992319514082.
datanode2_1  | 2021-06-25 13:43:07,338 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:43:10,410 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:43:13,482 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:43:16,554 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:43:19,626 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:43:22,702 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:43:25,770 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:43:28,843 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:43:31,914 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
recon_1      | Sleeping for 5 seconds
recon_1      | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
recon_1      | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
recon_1      | 2021-06-25 13:38:56,468 [main] INFO recon.ReconServer: STARTUP_MSG: 
recon_1      | /************************************************************
recon_1      | STARTUP_MSG: Starting ReconServer
recon_1      | STARTUP_MSG:   host = recon/172.25.0.115
recon_1      | STARTUP_MSG:   args = []
recon_1      | STARTUP_MSG:   version = 1.2.0-SNAPSHOT
recon_1      | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.6.1.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.6.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/aopalliance-1.0.jar:/opt/hadoop/share/ozone/lib/sqlite-jdbc-3.25.2.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/spring-beans-5.2.11.RELEASE.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/guice-4.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/spring-jdbc-5.2.11.RELEASE.jar:/opt/hadoop/share/ozone/lib/jakarta.ws.rs-api-2.1.6.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-2.33.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/javax.activation-api-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/spring-core-5.2.11.RELEASE.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.33.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.2.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guice-multibindings-4.0.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0-a398b19-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/bonecp-0.8.0.RELEASE.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ozone-reconcodegen-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jakarta.validation-api-2.0.2.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.33.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.33.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.33.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-tools-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/jooq-3.11.10.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.5.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.33.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.3.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/derby-10.14.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/jooq-codegen-3.11.10.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/jersey-entity-filtering-2.33.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/spring-tx-5.2.11.RELEASE.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/guice-assistedinject-4.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.2.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-media-json-jackson-2.33.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/javassist-3.25.0-GA.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/guice-servlet-4.0.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guice-bridge-2.5.0.jar:/opt/hadoop/share/ozone/lib/jooq-meta-3.11.10.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/ozone-manager-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/spring-jcl-5.2.11.RELEASE.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.33.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-recon-1.2.0-SNAPSHOT.jar
recon_1      | STARTUP_MSG:   build = https://github.com/apache/ozone/450c3750335593082ae39a2d17d4a2a58090f75f ; compiled by 'runner' on 2021-06-25T12:44Z
recon_1      | STARTUP_MSG:   java = 11.0.10
recon_1      | ************************************************************/
recon_1      | 2021-06-25 13:38:56,555 [main] INFO recon.ReconServer: registered UNIX signal handlers for [TERM, HUP, INT]
recon_1      | 2021-06-25 13:38:59,661 [main] INFO recon.ReconRestServletModule: rest([/api/v1/*]).packages(org.apache.hadoop.ozone.recon.api)
recon_1      | 2021-06-25 13:39:01,224 [main] INFO recon.ReconServer: Initializing Recon server...
recon_1      | 2021-06-25 13:39:01,835 [main] INFO recon.ReconServer: Ozone security is enabled. Attempting login for Recon service. Principal: recon/recon@EXAMPLE.COM, keytab: /etc/security/keytabs/recon.keytab
recon_1      | 2021-06-25 13:39:02,714 [main] ERROR recon.ReconServer: Error login in as Recon service. 
recon_1      | org.apache.hadoop.security.KerberosAuthException: failure to login: for principal: recon/recon@EXAMPLE.COM from keytab /etc/security/keytabs/recon.keytab javax.security.auth.login.LoginException: Unable to obtain password from user
recon_1      | 
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doSubjectLogin(UserGroupInformation.java:1880)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.loginUserFromKeytabAndReturnUGI(UserGroupInformation.java:1247)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.loginUserFromKeytab(UserGroupInformation.java:1016)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.login(SecurityUtil.java:315)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconServer.loginReconUser(ReconServer.java:209)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconServer.loginReconUserIfSecurityEnabled(ReconServer.java:184)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconServer.call(ReconServer.java:95)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconServer.call(ReconServer.java:53)
recon_1      | 	at picocli.CommandLine.executeUserObject(CommandLine.java:1933)
recon_1      | 	at picocli.CommandLine.access$1100(CommandLine.java:145)
recon_1      | 	at picocli.CommandLine$RunLast.executeUserObjectOfLastSubcommandWithSameParent(CommandLine.java:2332)
recon_1      | 	at picocli.CommandLine$RunLast.handle(CommandLine.java:2326)
recon_1      | 	at picocli.CommandLine$RunLast.handle(CommandLine.java:2291)
recon_1      | 	at picocli.CommandLine$AbstractParseResultHandler.handleParseResult(CommandLine.java:2152)
recon_1      | 	at picocli.CommandLine.parseWithHandlers(CommandLine.java:2530)
recon_1      | 	at picocli.CommandLine.parseWithHandler(CommandLine.java:2465)
recon_1      | 	at org.apache.hadoop.hdds.cli.GenericCli.execute(GenericCli.java:96)
recon_1      | 	at org.apache.hadoop.hdds.cli.GenericCli.run(GenericCli.java:87)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconServer.main(ReconServer.java:67)
recon_1      | Caused by: javax.security.auth.login.LoginException: Unable to obtain password from user
recon_1      | 
recon_1      | 	at jdk.security.auth/com.sun.security.auth.module.Krb5LoginModule.promptForPass(Krb5LoginModule.java:875)
recon_1      | 	at jdk.security.auth/com.sun.security.auth.module.Krb5LoginModule.attemptAuthentication(Krb5LoginModule.java:738)
recon_1      | 	at jdk.security.auth/com.sun.security.auth.module.Krb5LoginModule.login(Krb5LoginModule.java:592)
recon_1      | 	at java.base/javax.security.auth.login.LoginContext.invoke(LoginContext.java:726)
recon_1      | 	at java.base/javax.security.auth.login.LoginContext$4.run(LoginContext.java:665)
recon_1      | 	at java.base/javax.security.auth.login.LoginContext$4.run(LoginContext.java:663)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.login.LoginContext.invokePriv(LoginContext.java:663)
datanode3_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode3_1  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
datanode3_1  | 2021-06-25 13:42:23,401 [grpc-default-executor-0] INFO server.RaftServer$Division: d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68 replies to ELECTION vote request: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1<-d7f71981-d306-415b-992d-ee4808a385fa#0:FAIL-t4. Peer's state: d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68:t4, leader=null, voted=null, raftlog=d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode3_1  | 2021-06-25 13:42:26,091 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:42:28,428 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-FollowerState] INFO impl.FollowerState: d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5033760589ns, electionTimeout:5027ms
datanode3_1  | 2021-06-25 13:42:28,429 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-FollowerState] INFO impl.RoleInfo: d7f71981-d306-415b-992d-ee4808a385fa: shutdown d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-FollowerState
datanode3_1  | 2021-06-25 13:42:28,429 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-FollowerState] INFO server.RaftServer$Division: d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68: changes role from  FOLLOWER to CANDIDATE at term 4 for changeToCandidate
datanode3_1  | 2021-06-25 13:42:28,430 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode3_1  | 2021-06-25 13:42:28,430 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-FollowerState] INFO impl.RoleInfo: d7f71981-d306-415b-992d-ee4808a385fa: start d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection5
datanode3_1  | 2021-06-25 13:42:28,445 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection5] INFO impl.LeaderElection: d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection5 ELECTION round 0: submit vote requests at term 5 for -1: [8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode3_1  | 2021-06-25 13:42:28,469 [grpc-default-executor-0] INFO server.RaftServer$Division: d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68: receive requestVote(ELECTION, 8dca9ea8-5191-4cce-a34e-3d546f33f7b1, group-BFEA630F7F68, 5, (t:0, i:0))
datanode3_1  | 2021-06-25 13:42:28,470 [grpc-default-executor-0] INFO impl.VoteContext: d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-CANDIDATE: reject ELECTION from 8dca9ea8-5191-4cce-a34e-3d546f33f7b1: already has voted for d7f71981-d306-415b-992d-ee4808a385fa at current term 5
datanode3_1  | 2021-06-25 13:42:28,470 [grpc-default-executor-0] INFO server.RaftServer$Division: d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68 replies to ELECTION vote request: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1<-d7f71981-d306-415b-992d-ee4808a385fa#0:FAIL-t5. Peer's state: d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68:t5, leader=null, voted=d7f71981-d306-415b-992d-ee4808a385fa, raftlog=d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode3_1  | 2021-06-25 13:42:28,485 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection5] INFO impl.LeaderElection: d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection5: ELECTION REJECTED received 2 response(s) and 0 exception(s):
datanode3_1  | 2021-06-25 13:42:28,485 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection5] INFO impl.LeaderElection:   Response 0: d7f71981-d306-415b-992d-ee4808a385fa<-8dca9ea8-5191-4cce-a34e-3d546f33f7b1#0:FAIL-t5
datanode3_1  | 2021-06-25 13:42:28,486 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection5] INFO impl.LeaderElection:   Response 1: d7f71981-d306-415b-992d-ee4808a385fa<-ee31bb40-6981-4b57-b8d7-3be03fa0c81d#0:FAIL-t5
datanode3_1  | 2021-06-25 13:42:28,486 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection5] INFO impl.LeaderElection: d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection5 ELECTION round 0: result REJECTED
datanode3_1  | 2021-06-25 13:42:28,486 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection5] INFO server.RaftServer$Division: d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68: changes role from CANDIDATE to FOLLOWER at term 5 for REJECTED
datanode3_1  | 2021-06-25 13:42:28,486 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection5] INFO impl.RoleInfo: d7f71981-d306-415b-992d-ee4808a385fa: shutdown d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection5
datanode3_1  | 2021-06-25 13:42:28,486 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection5] INFO impl.RoleInfo: d7f71981-d306-415b-992d-ee4808a385fa: start d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-FollowerState
datanode3_1  | 2021-06-25 13:42:29,162 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:42:32,234 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:42:33,576 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-FollowerState] INFO impl.FollowerState: d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5089671238ns, electionTimeout:5077ms
datanode3_1  | 2021-06-25 13:42:33,576 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-FollowerState] INFO impl.RoleInfo: d7f71981-d306-415b-992d-ee4808a385fa: shutdown d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-FollowerState
datanode3_1  | 2021-06-25 13:42:33,577 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-FollowerState] INFO server.RaftServer$Division: d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68: changes role from  FOLLOWER to CANDIDATE at term 5 for changeToCandidate
datanode3_1  | 2021-06-25 13:42:33,577 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode1_1  | 2021-06-25 13:42:56,395 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:42:59,466 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:43:03,069 [ChunkWriter-3-0] INFO client.DNCertificateClient: Getting certificate with certSerialId:2992319514082.
datanode1_1  | 2021-06-25 13:43:05,612 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:43:08,682 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:43:11,754 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:43:14,826 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:43:17,898 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:43:20,974 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:43:24,042 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:43:27,114 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:43:30,186 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:43:33,262 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:43:36,330 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:43:39,402 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:43:42,474 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:43:45,546 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:43:48,622 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:43:54,763 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:43:57,838 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:44:00,906 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:44:03,980 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:44:07,050 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:44:10,122 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:44:13,194 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:44:16,267 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:44:19,338 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:44:22,411 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:42:33,577 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-FollowerState] INFO impl.RoleInfo: d7f71981-d306-415b-992d-ee4808a385fa: start d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection6
datanode3_1  | 2021-06-25 13:42:33,582 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection6] INFO impl.LeaderElection: d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection6 ELECTION round 0: submit vote requests at term 6 for -1: [8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode3_1  | 2021-06-25 13:42:33,613 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection6] INFO impl.LeaderElection: d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection6: ELECTION PASSED received 1 response(s) and 0 exception(s):
datanode3_1  | 2021-06-25 13:42:33,614 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection6] INFO impl.LeaderElection:   Response 0: d7f71981-d306-415b-992d-ee4808a385fa<-ee31bb40-6981-4b57-b8d7-3be03fa0c81d#0:OK-t6
datanode3_1  | 2021-06-25 13:42:33,614 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection6] INFO impl.LeaderElection: d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection6 ELECTION round 0: result PASSED
datanode3_1  | 2021-06-25 13:42:33,615 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection6] INFO impl.RoleInfo: d7f71981-d306-415b-992d-ee4808a385fa: shutdown d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection6
datanode3_1  | 2021-06-25 13:42:33,615 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection6] INFO server.RaftServer$Division: d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68: changes role from CANDIDATE to LEADER at term 6 for changeToLeader
datanode3_1  | 2021-06-25 13:42:33,615 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection6] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-BFEA630F7F68 with new leaderId: d7f71981-d306-415b-992d-ee4808a385fa
datanode3_1  | 2021-06-25 13:42:33,616 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection6] INFO server.RaftServer$Division: d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68: change Leader from null to d7f71981-d306-415b-992d-ee4808a385fa at term 6 for becomeLeader, leader elected after 32137ms
datanode3_1  | 2021-06-25 13:42:33,616 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode3_1  | 2021-06-25 13:42:33,618 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection6] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68
datanode3_1  | 2021-06-25 13:42:33,619 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode3_1  | 2021-06-25 13:42:33,621 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode3_1  | 2021-06-25 13:42:33,632 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode3_1  | 2021-06-25 13:42:33,632 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode3_1  | 2021-06-25 13:42:33,632 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode3_1  | 2021-06-25 13:42:33,654 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode3_1  | 2021-06-25 13:42:33,655 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2021-06-25 13:42:33,656 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode3_1  | 2021-06-25 13:42:33,664 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection6] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode3_1  | 2021-06-25 13:42:33,665 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode3_1  | 2021-06-25 13:42:33,666 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2021-06-25 13:42:33,668 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection6] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis_grpc.log_appender.d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68
datanode3_1  | 2021-06-25 13:42:33,699 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode3_1  | 2021-06-25 13:42:33,699 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2021-06-25 13:42:33,699 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode3_1  | 2021-06-25 13:42:33,700 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection6] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode3_1  | 2021-06-25 13:42:33,700 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode3_1  | 2021-06-25 13:42:33,700 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2021-06-25 13:42:33,704 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection6] INFO impl.RoleInfo: d7f71981-d306-415b-992d-ee4808a385fa: start d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderStateImpl
datanode3_1  | 2021-06-25 13:42:33,704 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection6] INFO segmented.SegmentedRaftLogWorker: d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-SegmentedRaftLogWorker: Starting segment from index:0
datanode3_1  | 2021-06-25 13:42:33,706 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/3175bb45-44a8-4478-8980-bfea630f7f68/current/log_inprogress_0
datanode3_1  | 2021-06-25 13:42:33,708 [d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68-LeaderElection6] INFO server.RaftServer$Division: d7f71981-d306-415b-992d-ee4808a385fa@group-BFEA630F7F68: set configuration 0: [8dca9ea8-5191-4cce-a34e-3d546f33f7b1|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, ee31bb40-6981-4b57-b8d7-3be03fa0c81d|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, d7f71981-d306-415b-992d-ee4808a385fa|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1], old=null
s3g_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.6.1.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.6.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/javax.interceptor-api-1.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/javax.el-api-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.ws.rs-api-2.1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/jackson-dataformat-xml-2.12.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/javax.activation-api-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.33.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.2.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0-a398b19-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/cdi-api-1.2.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jakarta.validation-api-2.0.2.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.33.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.33.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.33.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.5.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.33.jar:/opt/hadoop/share/ozone/lib/jersey-cdi1x-2.33.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.2.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/javassist-3.25.0-GA.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.2.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.33.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.2.0-SNAPSHOT.jar
s3g_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/450c3750335593082ae39a2d17d4a2a58090f75f ; compiled by 'runner' on 2021-06-25T12:44Z
s3g_1        | STARTUP_MSG:   java = 11.0.10
s3g_1        | ************************************************************/
s3g_1        | 2021-06-25 13:38:54,436 [main] INFO s3.Gateway: registered UNIX signal handlers for [TERM, HUP, INT]
s3g_1        | 2021-06-25 13:38:54,764 [main] INFO s3.Gateway: Starting Ozone S3 gateway
s3g_1        | 2021-06-25 13:38:54,822 [main] INFO http.HttpServer2: Jetty bound to port 9878
s3g_1        | 2021-06-25 13:38:54,824 [main] INFO server.Server: jetty-9.4.35.v20201120; built: 2020-11-20T21:17:03.964Z; git: bdc54f03a5e0a7e280fab27f55c3c75ee8da89fb; jvm 11.0.10+9-LTS
s3g_1        | 2021-06-25 13:38:55,018 [main] INFO server.session: DefaultSessionIdManager workerName=node0
s3g_1        | 2021-06-25 13:38:55,020 [main] INFO server.session: No SessionScavenger set, using defaults
s3g_1        | 2021-06-25 13:38:55,028 [main] INFO server.session: node0 Scavenging every 660000ms
s3g_1        | 2021-06-25 13:38:55,183 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/s3g@EXAMPLE.COM
s3g_1        | 2021-06-25 13:38:55,298 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@488eb7f2{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
s3g_1        | 2021-06-25 13:38:55,307 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@abf688e{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.2.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
s3g_1        | WARNING: An illegal reflective access operation has occurred
s3g_1        | WARNING: Illegal reflective access by org.jboss.weld.util.reflection.Formats (file:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar) to constructor com.sun.org.apache.bcel.internal.classfile.ClassParser(java.io.InputStream,java.lang.String)
s3g_1        | WARNING: Please consider reporting this to the maintainers of org.jboss.weld.util.reflection.Formats
s3g_1        | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
s3g_1        | WARNING: All illegal access operations will be denied in a future release
s3g_1        | 2021-06-25 13:39:05,334 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/s3g@EXAMPLE.COM
s3g_1        | Jun 25, 2021 1:39:09 PM org.glassfish.jersey.internal.Errors logErrors
s3g_1        | WARNING: The following warnings have been detected: WARNING: A HTTP GET method, public javax.ws.rs.core.Response org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.get(java.lang.String,java.lang.String,java.lang.String,int,java.lang.String,java.io.InputStream) throws java.io.IOException,org.apache.hadoop.ozone.s3.exception.OS3Exception, should not consume any entity.
s3g_1        | 
s3g_1        | 2021-06-25 13:39:09,542 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@4ab66127{s3gateway,/,file:///tmp/jetty-0_0_0_0-9878-ozone-s3gateway-1_2_0-SNAPSHOT_jar-_-any-2396238674103304821/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.2.0-SNAPSHOT.jar!/webapps/s3gateway}
s3g_1        | 2021-06-25 13:39:09,591 [main] INFO server.AbstractConnector: Started ServerConnector@51cd7ffc{HTTP/1.1, (http/1.1)}{0.0.0.0:9878}
s3g_1        | 2021-06-25 13:39:09,592 [main] INFO server.Server: Started @19945ms
s3g_1        | 2021-06-25 13:39:09,595 [main] INFO http.BaseHttpServer: HTTP server of s3gateway listening at http://0.0.0.0:9878
s3g_1        | 2021-06-25 13:49:20,133 [qtp382627885-19] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
datanode3_1  | 2021-06-25 13:42:35,308 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:42:38,379 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:42:41,450 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:42:44,522 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:42:47,594 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:42:50,667 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:42:53,738 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:42:56,810 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:42:59,882 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:43:02,758 [ChunkWriter-3-0] INFO client.DNCertificateClient: Getting certificate with certSerialId:2992319514082.
datanode3_1  | 2021-06-25 13:43:06,027 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:43:09,098 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:43:12,170 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:43:15,242 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:43:18,315 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:43:21,387 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:43:24,462 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:43:27,530 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:43:30,602 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:43:33,674 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:43:36,746 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:43:39,818 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:43:42,890 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:43:45,963 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:43:49,034 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:43:55,179 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:43:58,251 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:44:01,322 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:44:04,394 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:44:07,470 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:44:10,538 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:44:13,610 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:44:16,682 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:44:19,758 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:44:22,830 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:44:25,898 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:44:28,971 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:44:32,042 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:44:35,115 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:44:38,186 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:44:44,330 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:44:47,402 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:44:50,474 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:44:53,554 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:44:56,618 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:44:59,690 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:45:02,762 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:45:05,834 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
recon_1      | 	at java.base/javax.security.auth.login.LoginContext.login(LoginContext.java:574)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation$HadoopLoginContext.login(UserGroupInformation.java:1959)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doSubjectLogin(UserGroupInformation.java:1869)
recon_1      | 	... 18 more
recon_1      | 2021-06-25 13:39:03,953 [main] INFO persistence.DefaultDataSourceProvider: JDBC Url for Recon : jdbc:derby:/data/metadata/recon/ozone_recon_derby.db 
recon_1      | 2021-06-25 13:39:07,738 [main] INFO codegen.SqlDbUtils: Created derby database at jdbc:derby:/data/metadata/recon/ozone_recon_derby.db.
recon_1      | WARNING: An illegal reflective access operation has occurred
recon_1      | WARNING: Illegal reflective access by org.jooq.tools.reflect.Reflect (file:/opt/hadoop/share/ozone/lib/jooq-3.11.10.jar) to constructor java.lang.invoke.MethodHandles$Lookup(java.lang.Class)
recon_1      | WARNING: Please consider reporting this to the maintainers of org.jooq.tools.reflect.Reflect
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:49:20,741 [qtp382627885-19] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-92322, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2021-06-25 13:49:20,815 [qtp382627885-19] INFO endpoint.BucketEndpoint: Location is /bucket-92322
s3g_1        | 2021-06-25 13:49:28,378 [qtp382627885-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:49:28,429 [qtp382627885-17] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-36694, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2021-06-25 13:49:28,454 [qtp382627885-17] INFO endpoint.BucketEndpoint: Location is /bucket-36694
s3g_1        | 2021-06-25 13:49:29,176 [qtp382627885-22] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:49:30,260 [qtp382627885-22] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
s3g_1        | 2021-06-25 13:49:30,274 [qtp382627885-22] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
s3g_1        | 2021-06-25 13:49:30,274 [qtp382627885-22] INFO impl.MetricsSystemImpl: XceiverClientMetrics metrics system started
om2_1        | 2021-06-25 13:49:29,173 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:49:32,939 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:49:32,940 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:37498
om2_1        | 2021-06-25 13:49:32,943 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:49:33,822 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:49:33,823 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:37510
om2_1        | 2021-06-25 13:49:33,826 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:49:34,591 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:49:34,592 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:37520
om2_1        | 2021-06-25 13:49:34,599 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:49:35,245 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:49:35,246 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:37532
om2_1        | 2021-06-25 13:49:35,252 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:49:39,480 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:56416
om2_1        | 2021-06-25 13:49:39,493 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:49:42,730 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:49:42,732 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:37576
om2_1        | 2021-06-25 13:49:42,742 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:49:43,540 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:49:43,541 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:37584
om2_1        | 2021-06-25 13:49:43,547 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:49:43,646 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:49:43,647 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:37592
om2_1        | 2021-06-25 13:49:43,655 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:49:44,096 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:49:44,097 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:37604
om2_1        | 2021-06-25 13:49:44,108 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:49:44,420 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:49:44,420 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:37612
om2_1        | 2021-06-25 13:49:44,423 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:49:44,699 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:49:44,700 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:37620
om2_1        | 2021-06-25 13:49:44,706 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:49:44,933 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:49:44,934 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:37626
om2_1        | 2021-06-25 13:49:44,936 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:49:45,034 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:49:45,035 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:37636
om2_1        | 2021-06-25 13:49:45,039 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:49:49,284 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
datanode1_1  | 2021-06-25 13:44:25,486 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:44:28,554 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:44:31,630 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:44:34,698 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:44:37,774 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:44:43,914 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:44:46,986 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:44:50,058 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:44:53,130 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:44:56,203 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:44:59,274 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:45:02,346 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:45:05,418 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:45:08,490 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:45:11,562 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:45:14,634 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:45:17,706 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:45:20,778 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:45:23,850 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:45:26,922 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:45:33,066 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:45:36,138 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:45:39,210 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:45:42,282 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:45:45,355 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:45:48,426 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:45:51,498 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:45:54,570 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-06-25 13:42:00,324 [om3@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om3_1        | 2021-06-25 13:42:00,328 [om3@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
om3_1        | 2021-06-25 13:42:00,328 [om3@group-562213E44849-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
om3_1        | 2021-06-25 13:42:00,329 [om3@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om3_1        | 2021-06-25 13:42:00,329 [om3@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om3_1        | 2021-06-25 13:42:00,349 [om3@group-562213E44849-LeaderElection2] INFO impl.RoleInfo: om3: start om3@group-562213E44849-LeaderStateImpl
om3_1        | 2021-06-25 13:42:00,435 [om3@group-562213E44849-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: Starting segment from index:0
om3_1        | 2021-06-25 13:42:00,795 [om3@group-562213E44849-LeaderElection2] INFO server.RaftServer$Division: om3@group-562213E44849: set configuration 0: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om3_1        | 2021-06-25 13:42:01,560 [om3@group-562213E44849-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/current/log_inprogress_0
om3_1        | 2021-06-25 13:42:40,334 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54202
om3_1        | 2021-06-25 13:42:40,342 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:42:57,624 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54276
om3_1        | 2021-06-25 13:42:57,639 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:42:58,589 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:vol1 for user:testuser/scm@EXAMPLE.COM
om3_1        | 2021-06-25 13:43:10,577 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54354
om3_1        | 2021-06-25 13:43:10,590 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:43:11,339 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54360
om3_1        | 2021-06-25 13:43:11,347 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:43:16,893 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54390
om3_1        | 2021-06-25 13:43:16,903 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:43:17,555 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54396
om3_1        | 2021-06-25 13:43:17,564 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:43:23,536 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54424
om3_1        | 2021-06-25 13:43:23,553 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:43:33,093 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54472
om3_1        | 2021-06-25 13:43:33,099 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:43:39,877 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54530
om3_1        | 2021-06-25 13:43:39,896 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:43:40,482 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54536
om3_1        | 2021-06-25 13:43:40,487 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:43:45,718 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54562
om3_1        | 2021-06-25 13:43:45,730 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:43:51,630 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54596
om3_1        | 2021-06-25 13:43:51,642 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:44:08,533 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54672
om3_1        | 2021-06-25 13:44:08,543 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:44:09,191 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:05944-source for user:testuser/scm@EXAMPLE.COM
om3_1        | 2021-06-25 13:44:13,449 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54698
om3_1        | 2021-06-25 13:44:13,461 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:44:14,123 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:05944-target for user:testuser/scm@EXAMPLE.COM
om3_1        | 2021-06-25 13:44:18,882 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54724
om3_1        | 2021-06-25 13:44:18,887 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:44:24,004 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54750
om3_1        | 2021-06-25 13:44:24,015 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:44:32,769 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54798
om3_1        | 2021-06-25 13:44:32,780 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:44:38,185 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54842
om3_1        | 2021-06-25 13:44:38,198 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:49:49,285 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:37662
om2_1        | 2021-06-25 13:49:49,289 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:49:49,595 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:49:49,596 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:37668
om2_1        | 2021-06-25 13:49:49,603 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:49:49,779 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:49:49,780 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:37676
om2_1        | 2021-06-25 13:49:49,785 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:49:49,839 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:49:49,840 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:37684
om2_1        | 2021-06-25 13:49:49,874 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:49:51,308 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:49:51,308 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:37696
om2_1        | 2021-06-25 13:49:51,319 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:49:51,465 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:49:51,466 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:37704
om2_1        | 2021-06-25 13:49:51,470 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:49:51,582 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:49:51,583 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:37712
om2_1        | 2021-06-25 13:49:51,584 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:49:51,667 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:49:51,668 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:37718
om2_1        | 2021-06-25 13:49:51,670 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:49:51,715 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:49:51,716 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:37724
om2_1        | 2021-06-25 13:49:51,721 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:49:51,820 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:49:51,821 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:37730
om2_1        | 2021-06-25 13:49:51,824 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:49:52,054 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:49:52,055 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:37738
om2_1        | 2021-06-25 13:49:52,056 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:49:52,211 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:49:52,212 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:37746
om2_1        | 2021-06-25 13:49:52,213 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:49:52,283 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:49:52,284 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:37752
om2_1        | 2021-06-25 13:49:52,286 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:49:52,576 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:49:52,577 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:37760
om2_1        | 2021-06-25 13:49:52,582 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode1_1  | 2021-06-25 13:45:57,642 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:46:00,735 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:46:03,787 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:46:06,858 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:46:09,930 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:46:13,002 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:46:16,074 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:46:22,218 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:46:25,290 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:46:28,362 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:46:31,434 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:46:34,506 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:46:37,578 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:46:40,650 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:46:43,726 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:46:46,794 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:46:49,866 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:46:52,938 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:46:56,010 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:46:59,082 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:47:02,154 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:47:05,226 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:47:11,376 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:47:14,442 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:47:17,514 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:47:20,586 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:47:23,658 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-06-25 13:49:52,747 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:49:52,747 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:37766
om2_1        | 2021-06-25 13:49:52,750 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:49:52,833 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:49:52,833 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:37772
om2_1        | 2021-06-25 13:49:52,843 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:49:52,925 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:49:52,926 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:37780
om2_1        | 2021-06-25 13:49:52,930 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:49:57,017 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:49:57,017 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:37808
om2_1        | 2021-06-25 13:49:57,022 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:49:58,686 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:49:58,687 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:37822
om2_1        | 2021-06-25 13:49:58,694 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:50:04,570 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:56730
om2_1        | 2021-06-25 13:50:04,582 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:50:07,602 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:50:07,603 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:37890
om2_1        | 2021-06-25 13:50:07,604 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:50:08,278 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:50:08,279 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:37900
om2_1        | 2021-06-25 13:50:08,280 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:50:08,978 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:50:08,978 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:37908
om2_1        | 2021-06-25 13:50:08,988 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:50:09,025 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket-25047 in volume:s3v
om2_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om2_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:198)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om2_1        | 2021-06-25 13:50:09,659 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:50:09,659 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:37918
om2_1        | 2021-06-25 13:50:09,668 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:50:14,388 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:56806
om2_1        | 2021-06-25 13:50:14,395 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:50:17,607 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:50:17,608 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:37958
om2_1        | 2021-06-25 13:50:17,610 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode3_1  | 2021-06-25 13:45:08,906 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:45:11,978 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:45:15,050 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:45:18,122 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:45:21,195 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:45:24,270 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:45:27,338 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:45:33,486 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:45:36,554 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:45:39,626 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:45:42,698 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:45:45,770 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:45:48,842 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:45:51,914 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:45:54,988 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:45:58,058 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:46:01,131 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:46:04,202 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:46:07,274 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:46:10,346 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:46:13,419 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:46:16,490 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:46:22,634 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:46:25,706 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:46:28,778 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:46:31,851 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:46:34,922 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:46:37,994 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:46:41,066 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:46:44,138 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:46:47,214 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:46:50,286 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:46:53,354 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:46:56,430 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:46:59,500 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:43:34,986 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:43:38,062 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:43:41,130 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:43:44,202 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:43:47,274 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:43:50,346 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:43:56,490 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:43:59,563 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:44:02,634 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:44:05,706 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:44:08,778 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:44:11,852 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:44:14,922 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:44:17,998 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:44:21,067 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:44:24,138 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:44:27,210 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:44:30,283 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:44:33,354 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:44:36,426 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:44:39,498 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:44:45,642 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:44:48,714 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:44:51,790 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:44:54,858 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:44:57,930 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:45:01,002 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:45:04,077 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:45:07,146 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:45:10,219 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:45:13,293 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:45:16,362 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:45:19,434 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:45:22,506 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:45:25,578 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:45:28,650 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:45:34,798 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:45:37,867 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:45:40,943 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:45:44,010 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:45:47,082 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:45:50,154 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:45:53,226 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-06-25 13:50:18,262 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:50:18,262 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:37974
om2_1        | 2021-06-25 13:50:18,270 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:50:18,950 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:50:18,950 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:37984
om2_1        | 2021-06-25 13:50:18,961 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:50:19,505 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:50:19,506 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:37994
om2_1        | 2021-06-25 13:50:19,506 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:50:19,542 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketDeleteRequest: Delete bucket failed for bucket:nosuchbucket in volume:s3v
om2_1        | BUCKET_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Bucket not exists
om2_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketDeleteRequest.validateAndUpdateCache(OMBucketDeleteRequest.java:119)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om2_1        | 2021-06-25 13:50:23,397 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:56870
om2_1        | 2021-06-25 13:50:23,403 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:50:26,559 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:50:26,559 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38032
om2_1        | 2021-06-25 13:50:26,562 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:50:27,264 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:50:27,265 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38040
om2_1        | 2021-06-25 13:50:27,266 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:50:27,894 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:50:27,895 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38048
om2_1        | 2021-06-25 13:50:27,900 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:50:32,807 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:56966
om2_1        | 2021-06-25 13:50:32,810 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:50:36,076 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:50:36,076 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38126
om2_1        | 2021-06-25 13:50:36,090 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:50:36,765 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:50:36,765 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38134
om2_1        | 2021-06-25 13:50:36,766 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:50:41,426 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:57014
om2_1        | 2021-06-25 13:50:41,440 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:50:44,750 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:50:44,752 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38174
om2_1        | 2021-06-25 13:50:44,753 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:50:45,448 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:50:45,449 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38184
recon_1      | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
recon_1      | WARNING: All illegal access operations will be denied in a future release
recon_1      | 2021-06-25 13:39:09,630 [main] INFO persistence.DefaultDataSourceProvider: JDBC Url for Recon : jdbc:derby:/data/metadata/recon/ozone_recon_derby.db 
recon_1      | 2021-06-25 13:39:09,690 [main] INFO codegen.SqlDbUtils: Created derby database at jdbc:derby:/data/metadata/recon/ozone_recon_derby.db.
recon_1      | 2021-06-25 13:39:09,692 [main] INFO recon.ReconServer: Creating Recon Schema.
recon_1      | 2021-06-25 13:39:11,487 [main] INFO http.BaseHttpServer: Starting Web-server for recon at: http://0.0.0.0:9888
recon_1      | 2021-06-25 13:39:11,488 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
recon_1      | 2021-06-25 13:39:11,490 [main] INFO http.BaseHttpServer: HttpAuthType: ozone.recon.http.auth.type = kerberos
recon_1      | 2021-06-25 13:39:11,516 [main] INFO util.log: Logging initialized @19279ms to org.eclipse.jetty.util.log.Slf4jLog
recon_1      | 2021-06-25 13:39:11,858 [main] WARN http.HttpRequestLog: Jetty request log can only be enabled using Log4j
recon_1      | 2021-06-25 13:39:11,887 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
recon_1      | 2021-06-25 13:39:11,889 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context recon
recon_1      | 2021-06-25 13:39:11,889 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
recon_1      | 2021-06-25 13:39:11,889 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
recon_1      | 2021-06-25 13:39:11,893 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.recon.http.auth.kerberos.principal keytabKey: ozone.recon.http.auth.kerberos.keytab
recon_1      | 2021-06-25 13:39:12,150 [main] INFO tasks.ReconTaskControllerImpl: Registered task ContainerKeyMapperTask with controller.
recon_1      | 2021-06-25 13:39:12,567 [main] INFO tasks.ReconTaskControllerImpl: Registered task FileSizeCountTask with controller.
recon_1      | 2021-06-25 13:39:12,579 [main] INFO tasks.ReconTaskControllerImpl: Registered task TableCountTask with controller.
recon_1      | 2021-06-25 13:39:12,644 [main] INFO ozone.OmUtils: Using OzoneManager ServiceID 'id1'.
recon_1      | 2021-06-25 13:39:13,811 [main] INFO Configuration.deprecation: No unit for ozone.recon.om.connection.request.timeout(5000) assuming MILLISECONDS
recon_1      | 2021-06-25 13:39:14,203 [main] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 2021-06-25 13:39:14,794 [main] WARN recon.ReconUtils: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 2021-06-25 13:39:14,900 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar!/network-topology-default.xml]
recon_1      | 2021-06-25 13:39:14,907 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
recon_1      | 2021-06-25 13:39:15,098 [main] WARN db.DBStoreBuilder: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 2021-06-25 13:39:15,338 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
recon_1      | 2021-06-25 13:39:15,419 [main] INFO node.SCMNodeManager: Entering startup safe mode.
recon_1      | 2021-06-25 13:39:15,471 [main] INFO scm.ReconNodeManager: Loaded 0 nodes from node DB.
recon_1      | 2021-06-25 13:39:15,486 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
recon_1      | 2021-06-25 13:39:15,590 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
recon_1      | 2021-06-25 13:39:15,652 [Socket Reader #1 for port 9891] INFO ipc.Server: Starting Socket Reader #1 for port 9891
recon_1      | 2021-06-25 13:39:15,802 [Listener at 0.0.0.0/9891] INFO pipeline.PipelineStateManager: No pipeline exists in current db
recon_1      | 2021-06-25 13:39:15,962 [Listener at 0.0.0.0/9891] INFO recon.ReconServer: Recon server initialized successfully!
recon_1      | 2021-06-25 13:39:15,962 [Listener at 0.0.0.0/9891] INFO recon.ReconServer: Starting Recon server
recon_1      | 2021-06-25 13:39:16,148 [Listener at 0.0.0.0/9891] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
recon_1      | 2021-06-25 13:39:16,174 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
recon_1      | 2021-06-25 13:39:16,176 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Recon metrics system started
recon_1      | 2021-06-25 13:39:16,623 [Listener at 0.0.0.0/9891] INFO http.HttpServer2: Jetty bound to port 9888
recon_1      | 2021-06-25 13:39:16,624 [Listener at 0.0.0.0/9891] INFO server.Server: jetty-9.4.35.v20201120; built: 2020-11-20T21:17:03.964Z; git: bdc54f03a5e0a7e280fab27f55c3c75ee8da89fb; jvm 11.0.10+9-LTS
recon_1      | 2021-06-25 13:39:16,674 [Listener at 0.0.0.0/9891] INFO server.session: DefaultSessionIdManager workerName=node0
recon_1      | 2021-06-25 13:39:16,674 [Listener at 0.0.0.0/9891] INFO server.session: No SessionScavenger set, using defaults
recon_1      | 2021-06-25 13:39:16,676 [Listener at 0.0.0.0/9891] INFO server.session: node0 Scavenging every 600000ms
recon_1      | 2021-06-25 13:39:16,758 [Listener at 0.0.0.0/9891] INFO server.session: node0 Stopped scavenging
recon_1      | Problem starting http server
recon_1      | 2021-06-25 13:39:16,807 [shutdown-hook-0] INFO recon.ReconServer: SHUTDOWN_MSG: 
recon_1      | /************************************************************
recon_1      | SHUTDOWN_MSG: Shutting down ReconServer at recon/172.25.0.115
recon_1      | ************************************************************/
om2_1        | 2021-06-25 13:50:45,450 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:50:46,220 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:50:46,221 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38192
om2_1        | 2021-06-25 13:50:46,223 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:50:47,064 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:50:47,065 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38204
om2_1        | 2021-06-25 13:50:47,066 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:50:48,475 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:50:48,476 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38226
om2_1        | 2021-06-25 13:50:48,477 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:50:49,807 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:50:49,807 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38238
om2_1        | 2021-06-25 13:50:49,809 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:50:50,634 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:50:50,635 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38248
om2_1        | 2021-06-25 13:50:50,636 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:50:54,502 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:50:54,503 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38276
om2_1        | 2021-06-25 13:50:54,504 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:50:55,567 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:50:55,568 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38286
om2_1        | 2021-06-25 13:50:55,569 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:50:56,269 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:50:56,270 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38298
om2_1        | 2021-06-25 13:50:56,275 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:50:57,393 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:50:57,393 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38314
om2_1        | 2021-06-25 13:50:57,394 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:50:58,235 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:50:58,235 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38322
om2_1        | 2021-06-25 13:50:58,237 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:50:59,247 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:50:59,248 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38336
om2_1        | 2021-06-25 13:50:59,249 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:51:00,311 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:51:00,312 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38354
om2_1        | 2021-06-25 13:51:00,318 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:51:00,363 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload: /s3v/bucket-04686/30295/multipartKey2 Part number: 1 size 6  is less than minimum part size 5242880
om2_1        | 2021-06-25 13:51:00,363 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 30295/multipartKey2 in Volume/Bucket s3v/bucket-04686
om2_1        | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-04686 key: 30295/multipartKey2. Entity too small.
om1_1        | 2021-06-25 13:50:36,070 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:50:36,756 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:50:36,757 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39206
om1_1        | 2021-06-25 13:50:36,760 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:50:41,353 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:59324
om1_1        | 2021-06-25 13:50:41,372 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:50:44,726 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:50:44,727 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39246
om1_1        | 2021-06-25 13:50:44,742 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:50:45,441 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
s3g_1        | 2021-06-25 13:49:30,282 [qtp382627885-22] INFO impl.MetricsSinkAdapter: Sink prometheus started
s3g_1        | 2021-06-25 13:49:30,282 [qtp382627885-22] INFO impl.MetricsSystemImpl: Registered sink prometheus
s3g_1        | 2021-06-25 13:49:30,882 [qtp382627885-22] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
s3g_1        | 2021-06-25 13:49:30,882 [qtp382627885-22] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-5E761CEF5A17->d7f71981-d306-415b-992d-ee4808a385fa
s3g_1        | 2021-06-25 13:49:30,883 [qtp382627885-22] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-25 13:49:32,950 [qtp382627885-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
datanode3_1  | 2021-06-25 13:47:02,570 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:47:05,646 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:47:11,791 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:47:14,862 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:47:17,930 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:47:21,002 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:47:24,074 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:47:27,146 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:47:30,218 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:47:33,291 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:47:36,362 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:47:39,434 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:47:42,506 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:47:45,578 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:47:48,650 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:47:51,722 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:47:54,795 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:48:00,938 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:48:04,011 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:48:07,083 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:48:10,154 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:48:13,231 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:48:16,298 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:48:19,374 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:48:22,442 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:48:25,518 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:48:28,590 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:464)
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:184)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om2_1        | 2021-06-25 13:51:01,374 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:51:01,375 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38382
om2_1        | 2021-06-25 13:51:01,386 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:51:02,130 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:51:02,130 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38392
om2_1        | 2021-06-25 13:51:02,135 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:51:02,183 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-04686/54205/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 1
om2_1        | partName: "etag1"
om2_1        | , partNumber: 2
om2_1        | partName: "etag2"
om2_1        | ]
om2_1        | 2021-06-25 13:51:02,185 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 54205/multipartKey3 in Volume/Bucket s3v/bucket-04686
om2_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-04686 key: 54205/multipartKey3
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:174)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om2_1        | 2021-06-25 13:51:02,850 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:51:02,851 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38402
om2_1        | 2021-06-25 13:51:02,857 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:51:02,906 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-04686/54205/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 2
om2_1        | partName: "etag1"
om2_1        | , partNumber: 1
om2_1        | partName: "etag2"
om2_1        | ]
om2_1        | 2021-06-25 13:51:02,910 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 54205/multipartKey3 in Volume/Bucket s3v/bucket-04686
om2_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-04686 key: 54205/multipartKey3
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:174)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om2_1        | 2021-06-25 13:51:03,674 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:51:03,675 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38412
om2_1        | 2021-06-25 13:51:03,678 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:51:05,137 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
datanode3_1  | 2021-06-25 13:48:31,662 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:48:34,730 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:48:37,802 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:48:40,874 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:48:43,946 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:48:50,091 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:48:53,166 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:48:56,234 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:48:59,306 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:49:02,378 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:49:05,450 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:49:08,522 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:49:11,595 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:49:14,666 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:49:17,738 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:49:20,810 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:49:23,882 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:49:26,954 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:49:30,027 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:49:33,102 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:49:39,242 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:49:42,315 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:49:45,386 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:49:48,458 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:49:51,532 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:49:54,602 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:49:57,674 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:50:00,747 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:50:03,818 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:50:06,890 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:50:09,962 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:50:13,036 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:50:16,106 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:50:19,178 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:50:22,250 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:50:28,394 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:50:31,466 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:50:34,548 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:50:37,611 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:50:40,682 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:50:43,755 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:50:46,827 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:50:49,902 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:50:52,970 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:50:56,042 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:50:59,114 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:51:02,187 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:51:05,259 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:51:08,330 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:51:11,402 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:51:17,546 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:51:20,618 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:51:23,709 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:51:26,763 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:51:29,834 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:51:32,907 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:51:35,978 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:51:39,054 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:51:42,122 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:51:45,194 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:51:48,266 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:51:51,340 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:51:54,410 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:51:57,486 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:52:00,554 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:52:06,698 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:52:09,770 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:52:12,842 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:52:15,914 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:52:18,986 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:52:22,058 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:52:25,130 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:52:28,202 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:52:31,274 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:52:34,346 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:52:37,418 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:52:40,490 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:52:43,562 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:52:46,634 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:52:49,706 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:52:55,852 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:52:58,922 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-06-25 13:51:05,137 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38424
om2_1        | 2021-06-25 13:51:05,138 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:51:06,871 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:51:06,872 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38446
datanode1_1  | 2021-06-25 13:47:26,730 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:47:29,806 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:47:32,875 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:47:35,946 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:47:39,019 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:47:42,091 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:47:45,166 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:47:48,236 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:47:51,306 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:47:54,378 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:48:00,522 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:48:03,594 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:48:06,666 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:48:09,738 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:48:12,811 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:48:15,882 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:48:18,958 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:48:22,027 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:48:25,098 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:48:28,170 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:48:31,242 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:48:34,315 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:48:37,386 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:48:40,458 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:48:43,531 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:48:49,674 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:48:52,746 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:48:55,822 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-06-25 13:50:45,441 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39256
om1_1        | 2021-06-25 13:50:45,444 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:50:46,208 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:50:46,208 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39264
om1_1        | 2021-06-25 13:50:46,211 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:50:47,057 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:50:47,058 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39276
om1_1        | 2021-06-25 13:50:47,059 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:50:48,467 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:50:48,468 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39298
om1_1        | 2021-06-25 13:50:48,471 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:50:49,795 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:50:49,796 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39310
om1_1        | 2021-06-25 13:50:49,797 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:50:50,628 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:50:50,628 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39320
om1_1        | 2021-06-25 13:50:50,630 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:50:54,489 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:50:54,489 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39348
om1_1        | 2021-06-25 13:50:54,494 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:50:55,557 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:50:55,558 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39358
om1_1        | 2021-06-25 13:50:55,561 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:50:56,261 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:50:56,262 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39370
om1_1        | 2021-06-25 13:50:56,264 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:50:57,386 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:50:57,386 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39386
om1_1        | 2021-06-25 13:50:57,388 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:50:58,219 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:50:58,220 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39394
om1_1        | 2021-06-25 13:50:58,224 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:50:59,241 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:50:59,241 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39408
om1_1        | 2021-06-25 13:50:59,243 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:51:00,294 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:51:00,295 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39426
om1_1        | 2021-06-25 13:51:00,306 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:51:00,351 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload: /s3v/bucket-04686/30295/multipartKey2 Part number: 1 size 6  is less than minimum part size 5242880
om1_1        | 2021-06-25 13:51:00,355 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 30295/multipartKey2 in Volume/Bucket s3v/bucket-04686
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:49:33,023 [qtp382627885-24] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-F69140399C2E->ee31bb40-6981-4b57-b8d7-3be03fa0c81d
s3g_1        | 2021-06-25 13:49:33,024 [qtp382627885-24] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-25 13:49:33,831 [qtp382627885-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:49:34,602 [qtp382627885-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:49:35,254 [qtp382627885-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
om1_1        | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-04686 key: 30295/multipartKey2. Entity too small.
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:464)
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:184)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1        | 2021-06-25 13:51:01,360 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:51:01,361 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39454
om1_1        | 2021-06-25 13:51:01,362 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:51:02,118 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:51:02,119 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39464
om1_1        | 2021-06-25 13:51:02,125 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:51:02,185 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-04686/54205/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 1
om1_1        | partName: "etag1"
om1_1        | , partNumber: 2
om1_1        | partName: "etag2"
om1_1        | ]
om1_1        | 2021-06-25 13:51:02,189 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 54205/multipartKey3 in Volume/Bucket s3v/bucket-04686
om1_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-04686 key: 54205/multipartKey3
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:174)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1        | 2021-06-25 13:51:02,836 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:51:02,837 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39474
om1_1        | 2021-06-25 13:51:02,843 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:51:02,912 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-04686/54205/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 2
om1_1        | partName: "etag1"
om1_1        | , partNumber: 1
om1_1        | partName: "etag2"
om1_1        | ]
om1_1        | 2021-06-25 13:51:02,917 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 54205/multipartKey3 in Volume/Bucket s3v/bucket-04686
om1_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-04686 key: 54205/multipartKey3
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:174)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1        | 2021-06-25 13:51:03,667 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:51:03,667 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39484
om1_1        | 2021-06-25 13:51:03,669 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:51:05,127 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:51:05,128 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39496
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
om3_1        | 2021-06-25 13:44:43,025 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54868
om3_1        | 2021-06-25 13:44:43,055 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:44:48,026 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54894
om3_1        | 2021-06-25 13:44:48,030 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:44:53,059 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54920
om3_1        | 2021-06-25 13:44:53,067 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:44:58,254 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54948
om3_1        | 2021-06-25 13:44:58,262 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:45:03,317 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54966
om3_1        | 2021-06-25 13:45:03,322 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:45:07,723 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55008
om3_1        | 2021-06-25 13:45:07,731 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:45:12,858 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55034
om3_1        | 2021-06-25 13:45:12,861 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:45:18,365 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55062
om3_1        | 2021-06-25 13:45:18,372 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:45:23,971 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55088
om3_1        | 2021-06-25 13:45:23,978 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:45:29,417 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55118
om3_1        | 2021-06-25 13:45:29,431 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:45:35,085 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55172
om3_1        | 2021-06-25 13:45:35,096 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:45:40,314 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55198
om3_1        | 2021-06-25 13:45:40,323 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:45:48,418 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55232
om3_1        | 2021-06-25 13:45:48,430 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:45:56,627 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55272
om3_1        | 2021-06-25 13:45:56,630 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:46:05,894 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55336
om3_1        | 2021-06-25 13:46:05,896 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:46:13,250 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55370
om3_1        | 2021-06-25 13:46:13,255 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:46:18,593 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55400
om3_1        | 2021-06-25 13:46:18,599 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:46:23,965 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55422
om3_1        | 2021-06-25 13:46:23,971 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:46:29,193 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55450
om3_1        | 2021-06-25 13:46:29,198 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:46:34,776 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55506
om3_1        | 2021-06-25 13:46:34,778 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:46:40,216 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55524
om3_1        | 2021-06-25 13:46:40,223 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:46:45,601 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55552
om3_1        | 2021-06-25 13:46:45,604 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:46:50,772 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55580
om3_1        | 2021-06-25 13:46:50,774 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:46:55,825 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55606
om3_1        | 2021-06-25 13:46:55,827 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:47:01,406 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55652
om3_1        | 2021-06-25 13:47:01,411 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:47:06,627 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55678
om3_1        | 2021-06-25 13:47:06,634 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:47:11,383 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55702
om3_1        | 2021-06-25 13:47:11,385 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:47:16,136 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55720
om3_1        | 2021-06-25 13:47:16,143 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:47:21,215 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55748
datanode2_1  | 2021-06-25 13:45:56,298 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:45:59,370 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:46:02,442 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:46:05,514 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:46:08,586 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:46:11,663 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:46:14,730 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:46:17,802 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:46:23,946 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:46:27,018 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:46:30,090 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:46:33,163 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:46:36,234 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:46:39,306 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:46:42,382 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:46:45,450 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:46:48,526 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:46:51,594 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:46:54,670 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:46:57,738 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:47:00,810 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:47:03,882 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:47:06,954 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:47:13,098 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:47:16,170 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:47:19,242 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:47:22,314 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:47:25,386 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:47:28,458 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:47:31,530 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:47:34,602 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:47:37,674 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:47:40,747 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:47:43,822 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:47:46,890 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:47:49,962 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:47:53,034 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:47:56,106 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:48:02,250 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:48:05,322 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:48:08,395 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:48:11,467 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:48:14,538 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:48:17,614 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:48:20,682 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:48:23,754 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:48:26,826 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:48:29,898 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:48:32,970 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:48:36,046 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:48:39,114 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:48:42,189 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:48:45,258 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:48:51,402 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:48:54,474 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-06-25 13:51:06,873 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:51:07,843 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:51:07,844 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38456
om2_1        | 2021-06-25 13:51:07,850 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:51:07,886 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 54205/multipartKey3 in Volume/Bucket s3v/bucket-04686
om2_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-04686 key: 54205/multipartKey3. Provided Part info is { etag1, 1}, whereas OM has partName /s3v/bucket-04686/54205/multipartKey3106471690318512161
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:446)
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:184)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om2_1        | 2021-06-25 13:51:08,539 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:51:08,540 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38468
om2_1        | 2021-06-25 13:51:08,540 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:51:08,577 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 54205/multipartKey3 in Volume/Bucket s3v/bucket-04686
om2_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-04686 key: 54205/multipartKey3. Provided Part info is { etag2, 2}, whereas OM has partName /s3v/bucket-04686/54205/multipartKey3106471690413867042
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:446)
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:184)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om2_1        | 2021-06-25 13:51:09,187 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:51:09,188 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38476
om2_1        | 2021-06-25 13:51:09,189 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:51:09,223 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: PartNumber at index 1 is 2, and its previous partNumber at index 0 is 4 for ozonekey is /s3v/bucket-04686/54205/multipartKey3
om2_1        | 2021-06-25 13:51:09,223 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 54205/multipartKey3 in Volume/Bucket s3v/bucket-04686
om2_1        | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-04686 key: 54205/multipartKey3 because parts are in Invalid order.
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getPartsListSize(S3MultipartUploadCompleteRequest.java:412)
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:180)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om2_1        | 2021-06-25 13:51:09,839 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:51:09,839 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38486
om2_1        | 2021-06-25 13:51:09,842 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:51:10,543 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:51:10,545 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38494
om2_1        | 2021-06-25 13:51:10,552 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:51:05,133 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:51:06,863 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:51:06,863 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39518
datanode1_1  | 2021-06-25 13:48:58,897 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:49:01,962 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:49:05,035 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:49:08,106 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:49:11,178 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:49:14,250 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:49:17,322 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:49:20,394 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:49:23,466 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:49:26,539 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:49:29,610 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:49:32,682 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:49:38,826 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:49:41,899 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:49:44,989 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:49:48,042 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:49:51,119 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:49:53,987 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$323/0x0000000840576840@2266476b] WARN util.JvmPauseMonitor: JvmPauseMonitor-ee31bb40-6981-4b57-b8d7-3be03fa0c81d: Detected pause in JVM or host machine (eg GC): pause of approximately 129665041ns.
datanode1_1  | GC pool 'ParNew' had collection(s): count=1 time=146ms
datanode1_1  | 2021-06-25 13:49:54,187 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:49:57,258 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:50:00,334 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:50:03,402 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:50:06,475 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:50:09,546 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:50:12,619 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:50:15,690 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:50:18,762 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:48:57,546 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:49:00,618 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:49:03,690 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:49:06,762 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:49:09,835 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:49:12,906 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:49:15,978 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:49:19,050 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:49:22,122 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:49:25,197 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:49:28,266 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:49:31,338 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:49:34,410 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:49:40,554 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:49:43,628 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:49:46,698 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:49:49,770 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:49:52,842 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:49:55,914 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:49:58,986 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:50:02,058 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:50:05,134 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:50:08,206 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:50:11,274 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:50:14,350 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:50:17,418 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:50:20,490 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:50:23,562 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:49:42,744 [qtp382627885-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:49:42,772 [qtp382627885-24] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-80447, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2021-06-25 13:49:42,788 [qtp382627885-24] INFO endpoint.BucketEndpoint: Location is /bucket-80447
s3g_1        | 2021-06-25 13:49:43,549 [qtp382627885-22] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:49:43,578 [qtp382627885-22] INFO rpc.RpcClient: Creating Bucket: s3v/boto-bucket999, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2021-06-25 13:49:43,594 [qtp382627885-22] INFO endpoint.BucketEndpoint: Location is /boto-bucket999
s3g_1        | 2021-06-25 13:49:43,657 [qtp382627885-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
datanode2_1  | 2021-06-25 13:50:29,706 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:50:32,778 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:50:35,850 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:50:38,923 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:50:41,994 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:50:45,066 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:50:48,138 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:50:51,212 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:50:54,282 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:50:57,358 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:51:00,426 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:51:03,498 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:51:06,570 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:51:09,642 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:51:12,715 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:51:18,858 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:51:21,939 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:51:25,003 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:51:28,134 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:51:31,150 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:51:34,224 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:51:37,294 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:51:40,362 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:51:43,441 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:51:46,506 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:51:49,578 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:51:52,650 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-06-25 13:47:21,221 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:47:21,912 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:link2 in volume:05944-target
om3_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om3_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:198)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om3_1        | 2021-06-25 13:47:26,252 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55772
om3_1        | 2021-06-25 13:47:26,259 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:47:31,494 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55826
om3_1        | 2021-06-25 13:47:31,499 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:47:32,304 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket3 in volume:05944-target
om3_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om3_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:198)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om3_1        | 2021-06-25 13:47:36,733 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55854
om3_1        | 2021-06-25 13:47:36,740 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:47:42,073 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55878
om3_1        | 2021-06-25 13:47:42,081 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:47:42,655 [IPC Server handler 24 on default port 9862] WARN om.OzoneManager: User testuser2/scm@EXAMPLE.COM doesn't have READ permission to access bucket /05944-target/unreadable-link/null
om3_1        | 2021-06-25 13:47:46,933 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55906
om3_1        | 2021-06-25 13:47:46,944 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:47:52,141 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55924
om3_1        | 2021-06-25 13:47:52,150 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:47:52,795 [IPC Server handler 20 on default port 9862] WARN om.OzoneManager: User testuser2/scm@EXAMPLE.COM doesn't have LIST permission to access bucket /05944-source/unreadable-bucket/
om3_1        | 2021-06-25 13:47:57,029 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55954
om3_1        | 2021-06-25 13:47:57,043 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:48:02,427 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55996
om3_1        | 2021-06-25 13:48:02,441 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:48:07,441 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:56022
om3_1        | 2021-06-25 13:48:07,447 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:48:12,742 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:56046
om3_1        | 2021-06-25 13:48:12,746 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:48:16,924 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:56064
om3_1        | 2021-06-25 13:48:16,928 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:48:22,108 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:56090
om3_1        | 2021-06-25 13:48:22,111 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode1_1  | 2021-06-25 13:50:21,834 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:50:27,978 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:50:31,054 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:50:34,126 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:50:37,194 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:50:40,266 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:50:43,339 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:50:46,410 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:50:49,482 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:50:52,554 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:50:55,630 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:50:58,698 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:51:01,770 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:51:04,842 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:51:07,915 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:51:10,986 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:51:17,130 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:51:20,202 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:51:23,407 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:51:26,351 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:51:29,425 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:51:32,490 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:51:35,562 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:51:38,636 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:51:41,706 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:51:44,778 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:51:47,850 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:51:55,722 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:51:58,794 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:52:01,866 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:52:08,014 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:52:11,082 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:52:14,154 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:52:17,226 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:52:20,298 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:52:23,370 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:52:26,442 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:52:29,518 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:52:32,590 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:52:35,658 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:52:38,734 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:52:41,803 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:52:44,874 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:52:47,946 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:52:51,018 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:52:57,162 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:53:00,234 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:53:03,306 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:53:06,382 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:53:09,450 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:53:12,523 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:53:15,594 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:53:18,666 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:53:21,738 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:53:24,810 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-06-25 13:48:30,460 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:56144
om3_1        | 2021-06-25 13:48:30,463 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:48:39,198 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:56200
om3_1        | 2021-06-25 13:48:39,207 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:48:44,365 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:56226
om3_1        | 2021-06-25 13:48:44,371 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:48:49,982 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:56252
om3_1        | 2021-06-25 13:48:49,990 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:49:15,838 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:56496
om3_1        | 2021-06-25 13:49:15,846 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:49:20,170 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om3_1        | 2021-06-25 13:49:20,175 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:56450
om3_1        | 2021-06-25 13:49:20,180 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:49:25,118 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:56546
om3_1        | 2021-06-25 13:49:25,120 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:49:28,383 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om3_1        | 2021-06-25 13:49:28,384 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:56492
om3_1        | 2021-06-25 13:49:28,391 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:49:29,180 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om3_1        | 2021-06-25 13:49:29,180 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:56500
om3_1        | 2021-06-25 13:49:29,187 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:49:32,957 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om3_1        | 2021-06-25 13:49:32,959 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:56554
om3_1        | 2021-06-25 13:49:32,963 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:49:33,836 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om3_1        | 2021-06-25 13:49:33,837 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:56566
om3_1        | 2021-06-25 13:49:33,845 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:49:34,606 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om3_1        | 2021-06-25 13:49:34,607 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:56576
om3_1        | 2021-06-25 13:49:34,621 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:49:35,259 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om3_1        | 2021-06-25 13:49:35,260 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:56588
om3_1        | 2021-06-25 13:49:35,262 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:49:39,519 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:56680
om3_1        | 2021-06-25 13:49:39,536 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:49:42,749 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om3_1        | 2021-06-25 13:49:42,750 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:56632
om3_1        | 2021-06-25 13:49:42,765 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:49:43,560 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
datanode2_1  | 2021-06-25 13:53:27,886 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:53:30,954 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:53:34,026 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:53:37,099 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:53:40,174 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:53:46,315 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:53:49,386 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:53:52,458 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:53:55,530 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:53:58,602 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:54:01,674 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:54:04,746 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:54:07,818 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:54:10,890 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:54:13,962 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:54:17,034 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:54:20,106 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:54:23,178 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:54:26,250 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:54:29,322 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:54:31,640 [pool-36-thread-6] INFO keyvalue.KeyValueContainer: Container 1 is synced with bcsId 124.
datanode2_1  | 2021-06-25 13:54:31,678 [pool-36-thread-6] INFO keyvalue.KeyValueContainer: Container 1 is synced with bcsId 124.
datanode2_1  | 2021-06-25 13:54:31,745 [pool-36-thread-6] INFO keyvalue.KeyValueContainer: Container 1 is closed with bcsId 124.
datanode2_1  | 2021-06-25 13:54:31,748 [Datanode State Machine Thread - 0] WARN statemachine.StateContext: No available thread in pool for past 30 seconds.
datanode2_1  | 2021-06-25 13:54:35,466 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:54:38,538 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:54:41,610 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:54:44,683 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:54:47,754 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:49:43,757 [qtp382627885-24] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-671B2519FCB6->ee31bb40-6981-4b57-b8d7-3be03fa0c81d
om3_1        | 2021-06-25 13:49:43,561 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:56640
om3_1        | 2021-06-25 13:49:43,567 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:49:43,661 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om3_1        | 2021-06-25 13:49:43,662 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:56648
om3_1        | 2021-06-25 13:49:43,667 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:49:44,118 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om3_1        | 2021-06-25 13:49:44,119 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:56660
om3_1        | 2021-06-25 13:49:44,122 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:49:44,431 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om3_1        | 2021-06-25 13:49:44,432 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:56668
om3_1        | 2021-06-25 13:49:44,443 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:49:44,712 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om3_1        | 2021-06-25 13:49:44,713 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:56676
om3_1        | 2021-06-25 13:49:44,719 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:49:44,946 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om3_1        | 2021-06-25 13:49:44,947 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:56682
om3_1        | 2021-06-25 13:49:44,950 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:49:45,057 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om3_1        | 2021-06-25 13:49:45,058 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:56692
om3_1        | 2021-06-25 13:49:45,066 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:49:49,297 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om3_1        | 2021-06-25 13:49:49,298 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:56718
om3_1        | 2021-06-25 13:49:49,302 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:49:49,617 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om3_1        | 2021-06-25 13:49:49,618 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:56724
om3_1        | 2021-06-25 13:49:49,623 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:49:49,805 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om3_1        | 2021-06-25 13:49:49,807 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:56734
om3_1        | 2021-06-25 13:49:49,819 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:49:49,907 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om3_1        | 2021-06-25 13:49:49,908 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:56740
om3_1        | 2021-06-25 13:49:49,917 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:49:51,335 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om3_1        | 2021-06-25 13:49:51,335 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:56752
om3_1        | 2021-06-25 13:49:51,340 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:49:51,477 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om3_1        | 2021-06-25 13:49:51,479 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:56760
om3_1        | 2021-06-25 13:49:51,486 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:49:51,590 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om3_1        | 2021-06-25 13:49:51,590 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:56768
om3_1        | 2021-06-25 13:49:51,595 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode2_1  | 2021-06-25 13:54:50,826 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:54:53,898 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:54:56,970 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:55:00,043 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:55:03,114 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:55:06,190 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:55:09,258 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:55:12,330 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:55:15,402 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:55:18,474 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:55:24,618 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:55:27,690 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:55:30,762 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:55:33,834 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:55:36,906 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:55:39,982 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:55:43,050 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:55:46,122 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:55:49,194 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:55:52,266 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:55:55,338 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:55:58,410 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:56:01,482 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:56:04,554 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:56:07,630 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:56:13,771 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:56:16,842 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:56:19,914 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm1.org_1   | Sleeping for 5 seconds
scm1.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm1.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm1.org_1   | 2021-06-25 13:39:05,862 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm1.org_1   | /************************************************************
scm1.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm1.org_1   | STARTUP_MSG:   host = scm1.org/172.25.0.116
scm1.org_1   | STARTUP_MSG:   args = [--init]
scm1.org_1   | STARTUP_MSG:   version = 1.2.0-SNAPSHOT
om3_1        | 2021-06-25 13:49:51,680 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om3_1        | 2021-06-25 13:49:51,681 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:56774
om3_1        | 2021-06-25 13:49:51,681 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:49:51,732 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om3_1        | 2021-06-25 13:49:51,733 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:56780
om3_1        | 2021-06-25 13:49:51,734 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:49:51,830 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om3_1        | 2021-06-25 13:49:51,831 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:56786
om3_1        | 2021-06-25 13:49:51,833 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:49:52,061 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om3_1        | 2021-06-25 13:49:52,062 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:56794
om3_1        | 2021-06-25 13:49:52,065 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:49:52,219 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om3_1        | 2021-06-25 13:49:52,220 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:56802
om3_1        | 2021-06-25 13:49:52,222 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:49:52,295 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om3_1        | 2021-06-25 13:49:52,295 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:56808
om3_1        | 2021-06-25 13:49:52,297 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:49:52,591 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om3_1        | 2021-06-25 13:49:52,592 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:56816
om3_1        | 2021-06-25 13:49:52,594 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:49:52,760 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om3_1        | 2021-06-25 13:49:52,761 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:56822
om3_1        | 2021-06-25 13:49:52,767 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:49:52,849 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om3_1        | 2021-06-25 13:49:52,850 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:56830
om3_1        | 2021-06-25 13:49:52,851 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:49:52,938 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om3_1        | 2021-06-25 13:49:52,939 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:56836
om3_1        | 2021-06-25 13:49:52,941 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:49:57,027 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om3_1        | 2021-06-25 13:49:57,028 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:56864
om3_1        | 2021-06-25 13:49:57,030 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:49:58,703 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om3_1        | 2021-06-25 13:49:58,704 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:56878
om3_1        | 2021-06-25 13:49:58,711 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:50:04,623 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:56994
om3_1        | 2021-06-25 13:50:04,627 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:50:07,610 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om3_1        | 2021-06-25 13:50:07,611 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:56946
datanode1_1  | 2021-06-25 13:51:50,922 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:51:53,994 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:51:57,066 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:52:00,142 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:52:06,282 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:52:09,354 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:52:12,426 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:52:15,498 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:52:18,570 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:52:21,642 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:52:24,715 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:52:27,786 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:52:30,864 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:52:33,930 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:52:37,002 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:52:40,075 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:52:43,155 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:52:46,218 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:52:49,290 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:52:55,434 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:52:58,506 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:53:01,578 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:53:04,650 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:53:07,722 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:53:10,795 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:53:13,866 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:53:16,942 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:53:20,010 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:56:22,990 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:56:26,058 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:56:29,130 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:56:32,203 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:56:35,274 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:56:38,346 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:56:41,422 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:56:44,490 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:56:47,562 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:56:50,634 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:56:53,706 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:56:56,778 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:57:02,922 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:57:05,994 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:57:09,067 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:57:12,138 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:57:15,210 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:57:18,282 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:57:21,354 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:57:24,426 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:57:27,502 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:57:30,570 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:57:33,642 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:57:36,714 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:57:39,786 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:57:42,858 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:57:45,930 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-06-25 13:51:06,865 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:51:07,832 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:51:07,832 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39528
om1_1        | 2021-06-25 13:51:07,838 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:51:07,880 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 54205/multipartKey3 in Volume/Bucket s3v/bucket-04686
om1_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-04686 key: 54205/multipartKey3. Provided Part info is { etag1, 1}, whereas OM has partName /s3v/bucket-04686/54205/multipartKey3106471690318512161
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:446)
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:184)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1        | 2021-06-25 13:51:08,528 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:51:08,529 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39540
om1_1        | 2021-06-25 13:51:08,534 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:51:08,573 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 54205/multipartKey3 in Volume/Bucket s3v/bucket-04686
om1_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-04686 key: 54205/multipartKey3. Provided Part info is { etag2, 2}, whereas OM has partName /s3v/bucket-04686/54205/multipartKey3106471690413867042
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:446)
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:184)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1        | 2021-06-25 13:51:09,178 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:51:09,179 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39548
om1_1        | 2021-06-25 13:51:09,182 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:51:09,220 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: PartNumber at index 1 is 2, and its previous partNumber at index 0 is 4 for ozonekey is /s3v/bucket-04686/54205/multipartKey3
om1_1        | 2021-06-25 13:51:09,221 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 54205/multipartKey3 in Volume/Bucket s3v/bucket-04686
om1_1        | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-04686 key: 54205/multipartKey3 because parts are in Invalid order.
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getPartsListSize(S3MultipartUploadCompleteRequest.java:412)
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:180)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1        | 2021-06-25 13:51:09,830 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:51:09,831 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39558
om1_1        | 2021-06-25 13:51:09,833 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:51:10,530 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:51:10,531 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39566
scm1.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/javax.activation-api-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.2.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0-a398b19-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.2.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.2.0-SNAPSHOT.jar
scm1.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/450c3750335593082ae39a2d17d4a2a58090f75f ; compiled by 'runner' on 2021-06-25T12:44Z
scm1.org_1   | STARTUP_MSG:   java = 11.0.10
scm1.org_1   | ************************************************************/
scm1.org_1   | 2021-06-25 13:39:05,914 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm1.org_1   | 2021-06-25 13:39:06,423 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2021-06-25 13:39:06,544 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm1.org_1   | 2021-06-25 13:39:06,545 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm1.org_1   | 2021-06-25 13:39:06,746 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm1, RPC Address: scm1.org:9894 and Ratis port: 9894
scm1.org_1   | 2021-06-25 13:39:06,752 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm1: scm1.org
scm1.org_1   | 2021-06-25 13:39:06,780 [main] INFO ha.HASecurityUtils: Initializing secure StorageContainerManager.
scm1.org_1   | 2021-06-25 13:39:08,976 [main] ERROR client.SCMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
scm1.org_1   | 2021-06-25 13:39:08,977 [main] INFO client.SCMCertificateClient: Certificate client init case: 0
scm1.org_1   | 2021-06-25 13:39:08,979 [main] INFO client.SCMCertificateClient: Creating keypair for client as keypair and certificate not found.
scm1.org_1   | 2021-06-25 13:39:10,813 [main] INFO ha.HASecurityUtils: Init response: GETCERT
scm1.org_1   | 2021-06-25 13:39:12,857 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.116,host:scm1.org
scm1.org_1   | 2021-06-25 13:39:12,858 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm1.org_1   | 2021-06-25 13:39:13,478 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.116,host:scm1.org
scm1.org_1   | 2021-06-25 13:39:13,482 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm1.org_1   | 2021-06-25 13:39:13,491 [main] INFO ha.HASecurityUtils: Creating csr for SCM->hostName:scm1.org,scmId:76093931-f232-4415-806f-239960e589cb,clusterId:CID-8e5d7696-3ffc-40b4-8848-61155fd5a026,subject:scm-sub@scm1.org
scm1.org_1   | 2021-06-25 13:39:13,859 [main] INFO ha.HASecurityUtils: Successfully stored SCM signed certificate.
scm1.org_1   | 2021-06-25 13:39:14,499 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
scm1.org_1   | 2021-06-25 13:39:14,976 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
scm1.org_1   | 2021-06-25 13:39:14,980 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2021-06-25 13:39:14,982 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
scm1.org_1   | 2021-06-25 13:39:14,983 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2021-06-25 13:39:14,984 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2021-06-25 13:39:14,998 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
scm1.org_1   | 2021-06-25 13:39:15,000 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2021-06-25 13:39:15,009 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm1.org_1   | 2021-06-25 13:39:15,010 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm1.org_1   | 2021-06-25 13:39:15,987 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
scm1.org_1   | 2021-06-25 13:39:16,014 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm1.org_1   | 2021-06-25 13:39:16,020 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm1.org_1   | 2021-06-25 13:39:16,076 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm1.org_1   | 2021-06-25 13:39:16,114 [main] INFO server.RaftServer: 76093931-f232-4415-806f-239960e589cb: addNew group-61155FD5A026:[76093931-f232-4415-806f-239960e589cb|rpc:scm1.org:9894|priority:0] returns group-61155FD5A026:java.util.concurrent.CompletableFuture@268cbb86[Not completed]
scm1.org_1   | 2021-06-25 13:39:16,211 [pool-2-thread-1] INFO server.RaftServer$Division: 76093931-f232-4415-806f-239960e589cb: new RaftServerImpl for group-61155FD5A026:[76093931-f232-4415-806f-239960e589cb|rpc:scm1.org:9894|priority:0] with SCMStateMachine:uninitialized
scm1.org_1   | 2021-06-25 13:39:16,214 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm1.org_1   | 2021-06-25 13:39:16,223 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm1.org_1   | 2021-06-25 13:39:16,224 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm1.org_1   | 2021-06-25 13:39:16,224 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm1.org_1   | 2021-06-25 13:39:16,224 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm1.org_1   | 2021-06-25 13:39:16,224 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
scm1.org_1   | 2021-06-25 13:39:16,225 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm1.org_1   | 2021-06-25 13:39:16,230 [pool-2-thread-1] INFO server.RaftServer$Division: 76093931-f232-4415-806f-239960e589cb@group-61155FD5A026: ConfigurationManager, init=-1: [76093931-f232-4415-806f-239960e589cb|rpc:scm1.org:9894|priority:0], old=null, confs=<EMPTY_MAP>
scm1.org_1   | 2021-06-25 13:39:16,241 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm1.org_1   | 2021-06-25 13:39:16,246 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm1.org_1   | 2021-06-25 13:39:16,267 [pool-2-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/8e5d7696-3ffc-40b4-8848-61155fd5a026 does not exist. Creating ...
scm1.org_1   | 2021-06-25 13:39:16,355 [pool-2-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/8e5d7696-3ffc-40b4-8848-61155fd5a026/in_use.lock acquired by nodename 86@scm1.org
scm1.org_1   | 2021-06-25 13:39:16,398 [pool-2-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/8e5d7696-3ffc-40b4-8848-61155fd5a026 has been successfully formatted.
scm1.org_1   | 2021-06-25 13:39:16,422 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm1.org_1   | 2021-06-25 13:39:16,433 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om1_1        | 2021-06-25 13:51:10,540 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:51:11,649 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:51:11,650 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39584
om1_1        | 2021-06-25 13:51:11,655 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:51:12,388 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:51:12,389 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39600
om1_1        | 2021-06-25 13:51:12,390 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:51:13,115 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:51:13,116 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39612
om1_1        | 2021-06-25 13:51:13,117 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:51:13,172 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadAbortRequest: Abort Multipart request is failed for KeyName 82586/multipartKey5 in VolumeName/Bucket s3v/bucket-04686
om1_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: s3vbucket: bucket-04686key: 82586/multipartKey5
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:148)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1        | 2021-06-25 13:51:13,787 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:51:13,788 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39622
om1_1        | 2021-06-25 13:51:13,795 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:51:13,842 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyCreateRequest: Key creation failed. Volume:s3v, Bucket:bucket-04686, Key31669/multipartKey. Exception:{}
om1_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartFileInfo(OMKeyRequest.java:708)
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareFileInfo(OMKeyRequest.java:600)
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:577)
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyCreateRequest.validateAndUpdateCache(OMKeyCreateRequest.java:278)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1        | 2021-06-25 13:51:14,454 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:51:14,458 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39630
om1_1        | 2021-06-25 13:51:14,459 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:51:15,314 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:51:15,314 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39640
om1_1        | 2021-06-25 13:51:15,317 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:51:16,619 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:51:16,620 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39650
om1_1        | 2021-06-25 13:51:16,621 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:51:17,537 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:51:17,537 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39662
om1_1        | 2021-06-25 13:51:17,546 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:51:18,356 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:51:11,660 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:51:11,661 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38512
om2_1        | 2021-06-25 13:51:11,665 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:51:12,395 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:51:12,396 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38528
om2_1        | 2021-06-25 13:51:12,404 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:51:13,122 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:51:13,123 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38540
om2_1        | 2021-06-25 13:51:13,126 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:51:13,166 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadAbortRequest: Abort Multipart request is failed for KeyName 82586/multipartKey5 in VolumeName/Bucket s3v/bucket-04686
om2_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: s3vbucket: bucket-04686key: 82586/multipartKey5
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:148)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om2_1        | 2021-06-25 13:51:13,799 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:51:13,800 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38550
om2_1        | 2021-06-25 13:51:13,805 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:51:13,847 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyCreateRequest: Key creation failed. Volume:s3v, Bucket:bucket-04686, Key31669/multipartKey. Exception:{}
om2_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartFileInfo(OMKeyRequest.java:708)
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareFileInfo(OMKeyRequest.java:600)
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:577)
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyCreateRequest.validateAndUpdateCache(OMKeyCreateRequest.java:278)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om2_1        | 2021-06-25 13:51:14,463 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:51:14,464 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38558
om2_1        | 2021-06-25 13:51:14,471 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:51:15,323 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:51:15,323 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38568
om2_1        | 2021-06-25 13:51:15,326 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:51:16,625 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:51:16,626 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38578
om2_1        | 2021-06-25 13:51:16,626 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:51:17,552 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:51:17,552 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38590
om2_1        | 2021-06-25 13:51:17,557 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:51:18,364 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:51:18,364 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38608
om2_1        | 2021-06-25 13:51:18,365 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:51:19,149 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:51:19,150 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38618
om2_1        | 2021-06-25 13:51:19,152 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:51:19,861 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:51:19,862 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38626
om2_1        | 2021-06-25 13:51:19,869 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:51:20,828 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:51:20,828 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38638
om2_1        | 2021-06-25 13:51:20,831 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:51:21,032 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:51:18,357 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39680
om1_1        | 2021-06-25 13:51:18,358 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:51:19,142 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:51:19,143 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39690
om1_1        | 2021-06-25 13:51:19,145 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:51:19,846 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:51:19,847 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39698
om1_1        | 2021-06-25 13:51:19,855 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:51:20,821 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:51:20,821 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39710
om1_1        | 2021-06-25 13:51:20,823 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:51:21,007 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:51:21,007 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39716
om1_1        | 2021-06-25 13:51:21,022 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:51:21,186 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:51:21,187 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39728
om1_1        | 2021-06-25 13:51:21,190 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:51:21,196 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:51:21,196 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39726
om1_1        | 2021-06-25 13:51:21,205 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:51:22,915 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:51:22,916 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39746
om1_1        | 2021-06-25 13:51:22,926 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:51:23,500 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:51:23,502 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39756
om1_1        | 2021-06-25 13:51:23,507 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:51:23,658 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:51:23,659 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39770
om1_1        | 2021-06-25 13:51:23,660 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:51:23,661 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39772
om1_1        | 2021-06-25 13:51:23,662 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:51:23,665 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:51:23,665 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39774
om1_1        | 2021-06-25 13:51:23,670 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:51:23,676 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:51:24,896 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:51:24,897 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39806
om1_1        | 2021-06-25 13:51:24,898 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:51:25,768 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:51:25,770 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39816
om1_1        | 2021-06-25 13:51:25,771 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode2_1  | 2021-06-25 13:57:52,074 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:57:55,146 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:57:58,219 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:58:01,290 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:58:02,806 [pool-37-thread-5] INFO keyvalue.KeyValueContainer: Container 2 is synced with bcsId 122.
datanode2_1  | 2021-06-25 13:58:02,843 [pool-37-thread-5] INFO keyvalue.KeyValueContainer: Container 2 is synced with bcsId 122.
datanode2_1  | 2021-06-25 13:58:02,886 [pool-37-thread-5] INFO keyvalue.KeyValueContainer: Container 2 is closed with bcsId 122.
datanode2_1  | 2021-06-25 13:58:02,895 [Datanode State Machine Thread - 0] WARN statemachine.StateContext: No available thread in pool for past 30 seconds.
datanode2_1  | 2021-06-25 13:58:04,362 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:58:07,434 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:58:10,506 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:58:13,579 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:58:16,650 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:58:19,727 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:58:22,794 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:58:25,866 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:58:28,938 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:58:32,010 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:58:35,087 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:58:41,226 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:58:44,299 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:58:47,370 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:58:50,443 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:58:53,514 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:58:56,591 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:58:59,662 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:59:02,730 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:59:05,802 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:59:08,878 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:59:11,946 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:59:15,019 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:59:18,090 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:59:21,163 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:59:24,234 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:59:30,378 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:59:33,455 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:59:36,522 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:59:39,594 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:59:42,666 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:59:45,742 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:59:48,814 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:59:51,882 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:59:54,954 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 13:59:58,026 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 14:00:01,098 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 14:00:04,170 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 14:00:07,242 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 14:00:10,314 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 14:00:13,386 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-25 14:00:19,530 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-06-25 13:51:27,043 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:51:27,043 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39830
om1_1        | 2021-06-25 13:51:27,045 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:51:27,773 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:51:27,773 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39838
om1_1        | 2021-06-25 13:51:27,779 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:51:29,300 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:51:29,300 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39852
om1_1        | 2021-06-25 13:51:29,307 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:51:29,967 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:51:29,968 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39864
om1_1        | 2021-06-25 13:51:29,974 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:51:31,248 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:51:31,249 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39914
om1_1        | 2021-06-25 13:51:31,250 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:51:32,823 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:51:32,824 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39926
om1_1        | 2021-06-25 13:51:32,826 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:51:33,558 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:51:33,559 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39936
om1_1        | 2021-06-25 13:51:33,570 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:51:35,156 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:51:35,157 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39952
om1_1        | 2021-06-25 13:51:35,166 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:51:36,170 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:51:36,171 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39968
om1_1        | 2021-06-25 13:51:36,173 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:51:36,912 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:51:36,913 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39984
om1_1        | 2021-06-25 13:51:36,918 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:51:38,391 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:51:38,391 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39998
om1_1        | 2021-06-25 13:51:38,403 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:51:39,752 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:51:39,753 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40012
om1_1        | 2021-06-25 13:51:39,766 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:51:40,505 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:51:40,506 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40022
om1_1        | 2021-06-25 13:51:40,508 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:51:41,282 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:51:41,283 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40030
om2_1        | 2021-06-25 13:51:21,033 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38644
om2_1        | 2021-06-25 13:51:21,046 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:51:21,199 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:51:21,200 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38656
om2_1        | 2021-06-25 13:51:21,227 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:51:21,229 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38658
om2_1        | 2021-06-25 13:51:21,247 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:51:21,247 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:51:22,933 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:51:22,934 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38674
om2_1        | 2021-06-25 13:51:22,935 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:51:23,511 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:51:23,511 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38684
om2_1        | 2021-06-25 13:51:23,514 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:51:23,667 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:51:23,667 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38702
om2_1        | 2021-06-25 13:51:23,672 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:51:23,673 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38704
om2_1        | 2021-06-25 13:51:23,675 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:51:23,681 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:51:23,682 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38708
om2_1        | 2021-06-25 13:51:23,689 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:51:23,689 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:51:24,900 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:51:24,901 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38734
om2_1        | 2021-06-25 13:51:24,901 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:51:25,776 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:51:25,777 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38744
om2_1        | 2021-06-25 13:51:25,778 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:51:27,049 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
s3g_1        | 2021-06-25 13:49:43,761 [qtp382627885-24] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-25 13:49:44,110 [qtp382627885-22] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:49:44,178 [qtp382627885-22] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-E7B5E98F8C82->ee31bb40-6981-4b57-b8d7-3be03fa0c81d
s3g_1        | 2021-06-25 13:49:44,179 [qtp382627885-22] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-25 13:49:44,427 [qtp382627885-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:49:44,518 [qtp382627885-24] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-42F11884F68F->d7f71981-d306-415b-992d-ee4808a385fa
s3g_1        | 2021-06-25 13:49:44,518 [qtp382627885-24] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-25 13:49:44,708 [qtp382627885-22] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1        | 2021-06-25 13:51:41,294 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:51:42,008 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:51:42,008 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40040
om1_1        | 2021-06-25 13:51:42,010 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:51:43,895 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:51:43,895 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40064
om1_1        | 2021-06-25 13:51:43,901 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:51:45,000 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:51:45,001 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40078
om1_1        | 2021-06-25 13:51:45,005 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:51:45,664 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:51:45,665 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40088
om1_1        | 2021-06-25 13:51:45,677 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:51:46,666 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:51:46,667 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40100
om1_1        | 2021-06-25 13:51:46,668 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:51:47,386 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:51:47,386 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40108
om1_1        | 2021-06-25 13:51:47,391 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:51:48,154 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:51:48,155 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40118
om1_1        | 2021-06-25 13:51:48,156 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:51:52,658 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:60242
om1_1        | 2021-06-25 13:51:52,670 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:51:55,793 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:51:55,793 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40168
om1_1        | 2021-06-25 13:51:55,797 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:51:56,439 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:51:56,439 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40176
om1_1        | 2021-06-25 13:51:56,440 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:51:57,121 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:51:57,122 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40186
om1_1        | 2021-06-25 13:51:57,123 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:51:58,072 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:51:58,073 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40198
om1_1        | 2021-06-25 13:51:58,076 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:51:58,704 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:51:58,705 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40206
om1_1        | 2021-06-25 13:51:58,707 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:51:59,595 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
datanode1_1  | 2021-06-25 13:53:23,087 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:53:26,154 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:53:29,230 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:53:32,298 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:53:35,374 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:53:38,442 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:53:44,586 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:53:47,658 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:53:50,730 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:53:53,806 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:53:56,875 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:53:59,946 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:54:03,018 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:54:06,094 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:54:09,162 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:54:12,235 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:54:15,310 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:54:18,378 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:54:21,450 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:54:24,522 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:54:27,594 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:54:31,701 [pool-35-thread-5] INFO keyvalue.KeyValueContainer: Container 1 is synced with bcsId 124.
datanode1_1  | 2021-06-25 13:54:31,705 [pool-35-thread-5] INFO keyvalue.KeyValueContainer: Container 1 is synced with bcsId 124.
datanode1_1  | 2021-06-25 13:54:31,738 [pool-35-thread-5] INFO keyvalue.KeyValueContainer: Container 1 is closed with bcsId 124.
datanode1_1  | 2021-06-25 13:54:33,738 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:54:36,810 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:54:39,882 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:54:42,954 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:54:46,026 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:54:49,098 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:54:52,170 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:54:55,242 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:54:58,314 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:55:01,386 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:55:04,458 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:55:07,530 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:55:10,602 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:55:13,675 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:55:16,746 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:55:22,890 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:55:25,962 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:55:29,038 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:55:32,106 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:55:35,178 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:49:44,939 [qtp382627885-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
om3_1        | 2021-06-25 13:50:07,612 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:50:08,286 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om3_1        | 2021-06-25 13:50:08,286 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:56956
om3_1        | 2021-06-25 13:50:08,294 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:50:08,995 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om3_1        | 2021-06-25 13:50:08,996 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:56964
om3_1        | 2021-06-25 13:50:08,998 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:50:09,022 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket-25047 in volume:s3v
om3_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om3_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:198)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om3_1        | 2021-06-25 13:50:09,672 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om3_1        | 2021-06-25 13:50:09,673 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:56974
om3_1        | 2021-06-25 13:50:09,678 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:50:14,428 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:57070
om3_1        | 2021-06-25 13:50:14,430 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:50:17,617 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om3_1        | 2021-06-25 13:50:17,618 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:57014
om3_1        | 2021-06-25 13:50:17,623 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:50:18,275 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om3_1        | 2021-06-25 13:50:18,275 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:57030
om3_1        | 2021-06-25 13:50:18,276 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:50:18,968 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om3_1        | 2021-06-25 13:50:18,970 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:57040
om3_1        | 2021-06-25 13:50:18,978 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:50:19,510 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om3_1        | 2021-06-25 13:50:19,511 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:57050
om3_1        | 2021-06-25 13:50:19,514 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:50:19,531 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketDeleteRequest: Delete bucket failed for bucket:nosuchbucket in volume:s3v
om3_1        | BUCKET_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Bucket not exists
om3_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketDeleteRequest.validateAndUpdateCache(OMBucketDeleteRequest.java:119)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om3_1        | 2021-06-25 13:50:23,436 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:57134
om3_1        | 2021-06-25 13:50:23,442 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:50:26,584 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om3_1        | 2021-06-25 13:50:26,585 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:57088
om3_1        | 2021-06-25 13:50:26,587 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:49:45,047 [qtp382627885-22] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:49:45,243 [qtp382627885-24] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-A2D2DBDE24D6->d7f71981-d306-415b-992d-ee4808a385fa
om2_1        | 2021-06-25 13:51:27,050 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38758
om2_1        | 2021-06-25 13:51:27,057 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:51:27,783 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:51:27,784 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38766
om2_1        | 2021-06-25 13:51:27,785 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:51:29,311 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:51:29,312 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38780
om2_1        | 2021-06-25 13:51:29,319 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:51:29,978 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:51:29,979 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38792
om2_1        | 2021-06-25 13:51:29,982 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:51:31,257 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:51:31,257 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38842
om2_1        | 2021-06-25 13:51:31,258 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:51:32,832 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:51:32,834 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38854
om2_1        | 2021-06-25 13:51:32,842 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:51:33,574 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:51:33,575 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38864
om2_1        | 2021-06-25 13:51:33,580 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:51:35,174 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:51:35,175 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38880
om2_1        | 2021-06-25 13:51:35,181 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:51:36,179 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:51:36,182 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38896
om2_1        | 2021-06-25 13:51:36,189 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:51:36,925 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:51:36,925 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38912
om2_1        | 2021-06-25 13:51:36,930 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:51:38,408 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:51:38,408 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38926
om2_1        | 2021-06-25 13:51:38,412 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:51:39,772 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:51:39,777 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38940
om2_1        | 2021-06-25 13:51:39,779 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:51:40,512 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:51:40,513 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38950
om2_1        | 2021-06-25 13:51:40,517 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:51:41,298 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:51:41,299 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38958
datanode1_1  | 2021-06-25 13:55:38,250 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:55:41,322 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:55:44,394 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:55:47,466 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:55:50,538 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:55:53,610 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:55:56,682 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:55:59,754 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:56:02,826 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:56:05,898 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:56:12,042 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:56:15,114 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm1.org_1   | 2021-06-25 13:39:16,481 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm1.org_1   | 2021-06-25 13:39:16,481 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2021-06-25 13:39:16,547 [pool-2-thread-1] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm1.org_1   | 2021-06-25 13:39:16,548 [pool-2-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.76093931-f232-4415-806f-239960e589cb@group-61155FD5A026
scm1.org_1   | 2021-06-25 13:39:16,549 [pool-2-thread-1] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm1.org_1   | 2021-06-25 13:39:16,555 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 16384 (custom)
scm1.org_1   | 2021-06-25 13:39:16,595 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm1.org_1   | 2021-06-25 13:39:16,596 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
scm1.org_1   | 2021-06-25 13:39:16,633 [pool-2-thread-1] INFO segmented.SegmentedRaftLogWorker: new 76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/8e5d7696-3ffc-40b4-8848-61155fd5a026
scm1.org_1   | 2021-06-25 13:39:16,633 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
scm1.org_1   | 2021-06-25 13:39:16,633 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm1.org_1   | 2021-06-25 13:39:16,640 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 16384 (custom)
scm1.org_1   | 2021-06-25 13:39:16,640 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
scm1.org_1   | 2021-06-25 13:39:16,641 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm1.org_1   | 2021-06-25 13:39:16,682 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm1.org_1   | 2021-06-25 13:39:16,683 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm1.org_1   | 2021-06-25 13:39:16,683 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm1.org_1   | 2021-06-25 13:39:16,703 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
scm1.org_1   | 2021-06-25 13:39:16,712 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
scm1.org_1   | 2021-06-25 13:39:16,738 [pool-2-thread-1] INFO segmented.SegmentedRaftLogWorker: 76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm1.org_1   | 2021-06-25 13:39:16,738 [pool-2-thread-1] INFO segmented.SegmentedRaftLogWorker: 76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm1.org_1   | 2021-06-25 13:39:16,751 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm1.org_1   | 2021-06-25 13:39:16,752 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
scm1.org_1   | 2021-06-25 13:39:16,755 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
scm1.org_1   | 2021-06-25 13:39:16,756 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode3_1  | 2021-06-25 13:53:01,994 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm1.org_1   | 2021-06-25 13:39:16,768 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
om1_1        | 2021-06-25 13:51:59,595 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40222
om2_1        | 2021-06-25 13:51:41,307 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:51:42,014 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om3_1        | 2021-06-25 13:50:27,271 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm2.org_1   | Sleeping for 5 seconds
scm2.org_1   | Waiting for the service scm1.org:9894
om1_1        | 2021-06-25 13:51:59,596 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:52:00,238 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
s3g_1        | 2021-06-25 13:49:45,247 [qtp382627885-24] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
datanode3_1  | 2021-06-25 13:53:05,066 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:56:18,186 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-06-25 13:50:27,271 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:57096
scm2.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm1.org_1   | 2021-06-25 13:39:16,773 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm3.org_1   | Sleeping for 5 seconds
om1_1        | 2021-06-25 13:52:00,239 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40232
om2_1        | 2021-06-25 13:51:42,015 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38968
s3g_1        | 2021-06-25 13:49:45,327 [qtp382627885-22] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-D5A1D2A34DE6->ee31bb40-6981-4b57-b8d7-3be03fa0c81d
datanode3_1  | 2021-06-25 13:53:08,138 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:56:21,258 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:56:24,330 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm2.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm1.org_1   | 2021-06-25 13:39:16,895 [pool-2-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.76093931-f232-4415-806f-239960e589cb@group-61155FD5A026
scm3.org_1   | Waiting for the service scm2.org:9894
om1_1        | 2021-06-25 13:52:00,242 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:51:42,016 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 2021-06-25 13:49:45,346 [qtp382627885-22] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
datanode3_1  | 2021-06-25 13:53:11,210 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:56:27,402 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-06-25 13:50:27,272 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-25 13:39:20,586 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm1.org_1   | 2021-06-25 13:39:16,898 [pool-2-thread-1] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm3.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om1_1        | 2021-06-25 13:52:01,692 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:51:43,912 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
s3g_1        | 2021-06-25 13:49:49,291 [qtp382627885-22] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
datanode3_1  | 2021-06-25 13:53:14,282 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:56:30,474 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-06-25 13:50:27,908 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm2.org_1   | /************************************************************
scm1.org_1   | 2021-06-25 13:39:16,902 [pool-2-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.76093931-f232-4415-806f-239960e589cb@group-61155FD5A026
scm3.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om1_1        | 2021-06-25 13:52:01,693 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40276
om2_1        | 2021-06-25 13:51:43,913 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38992
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
datanode3_1  | 2021-06-25 13:53:17,354 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:56:33,546 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-06-25 13:50:27,908 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:57104
scm2.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm1.org_1   | 2021-06-25 13:39:16,906 [pool-2-thread-1] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm3.org_1   | 2021-06-25 13:39:59,346 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
om1_1        | 2021-06-25 13:52:01,694 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:51:43,921 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
datanode3_1  | 2021-06-25 13:53:20,426 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:56:36,618 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-06-25 13:50:27,914 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | STARTUP_MSG:   host = scm2.org/172.25.0.117
scm1.org_1   | 2021-06-25 13:39:16,925 [main] INFO server.RaftServer$Division: 76093931-f232-4415-806f-239960e589cb@group-61155FD5A026: start as a follower, conf=-1: [76093931-f232-4415-806f-239960e589cb|rpc:scm1.org:9894|priority:0], old=null
scm3.org_1   | /************************************************************
om1_1        | 2021-06-25 13:52:02,322 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:51:45,009 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
datanode3_1  | 2021-06-25 13:53:23,498 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:56:39,690 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-06-25 13:50:32,831 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:57230
scm2.org_1   | STARTUP_MSG:   args = [--bootstrap]
scm1.org_1   | 2021-06-25 13:39:16,927 [main] INFO server.RaftServer$Division: 76093931-f232-4415-806f-239960e589cb@group-61155FD5A026: changes role from      null to FOLLOWER at term 0 for startAsFollower
scm3.org_1   | STARTUP_MSG: Starting StorageContainerManager
om1_1        | 2021-06-25 13:52:02,323 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40288
om2_1        | 2021-06-25 13:51:45,010 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39006
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
datanode3_1  | 2021-06-25 13:53:26,570 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:56:42,763 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-06-25 13:50:32,833 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | STARTUP_MSG:   version = 1.2.0-SNAPSHOT
scm1.org_1   | 2021-06-25 13:39:16,929 [main] INFO impl.RoleInfo: 76093931-f232-4415-806f-239960e589cb: start 76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-FollowerState
scm3.org_1   | STARTUP_MSG:   host = scm3.org/172.25.0.118
om1_1        | 2021-06-25 13:52:02,326 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:51:45,012 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
datanode3_1  | 2021-06-25 13:53:29,646 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:56:45,834 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-06-25 13:50:36,099 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm2.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/javax.activation-api-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.2.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0-a398b19-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.2.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.2.0-SNAPSHOT.jar
scm1.org_1   | 2021-06-25 13:39:17,158 [main] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-61155FD5A026,id=76093931-f232-4415-806f-239960e589cb
scm3.org_1   | STARTUP_MSG:   args = [--bootstrap]
om1_1        | 2021-06-25 13:52:02,946 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:51:45,680 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:51:45,681 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39016
datanode3_1  | 2021-06-25 13:53:32,714 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:56:48,906 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-06-25 13:50:36,099 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:57182
scm2.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/450c3750335593082ae39a2d17d4a2a58090f75f ; compiled by 'runner' on 2021-06-25T12:44Z
scm1.org_1   | 2021-06-25 13:39:17,166 [main] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.76093931-f232-4415-806f-239960e589cb@group-61155FD5A026
scm3.org_1   | STARTUP_MSG:   version = 1.2.0-SNAPSHOT
om1_1        | 2021-06-25 13:52:02,946 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40298
om2_1        | 2021-06-25 13:51:45,688 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
datanode3_1  | 2021-06-25 13:53:35,786 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:56:51,978 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-06-25 13:50:36,101 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | STARTUP_MSG:   java = 11.0.10
scm1.org_1   | 2021-06-25 13:39:17,167 [main] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
om1_1        | 2021-06-25 13:52:02,948 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/javax.activation-api-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.2.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0-a398b19-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.2.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.2.0-SNAPSHOT.jar
om2_1        | 2021-06-25 13:51:46,673 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
datanode3_1  | 2021-06-25 13:53:38,858 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:56:55,050 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-06-25 13:50:36,771 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm2.org_1   | ************************************************************/
scm1.org_1   | 2021-06-25 13:39:17,176 [main] INFO server.RaftServer: 76093931-f232-4415-806f-239960e589cb: start RPC server
om1_1        | 2021-06-25 13:52:03,604 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm3.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/450c3750335593082ae39a2d17d4a2a58090f75f ; compiled by 'runner' on 2021-06-25T12:44Z
om2_1        | 2021-06-25 13:51:46,673 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39028
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
datanode3_1  | 2021-06-25 13:53:45,002 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:57:01,194 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-06-25 13:50:36,772 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:57190
scm2.org_1   | 2021-06-25 13:39:20,599 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm1.org_1   | 2021-06-25 13:39:17,340 [main] INFO server.GrpcService: 76093931-f232-4415-806f-239960e589cb: GrpcService started, listening on 9894
om1_1        | 2021-06-25 13:52:03,605 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40306
scm3.org_1   | STARTUP_MSG:   java = 11.0.10
om2_1        | 2021-06-25 13:51:46,674 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
datanode3_1  | 2021-06-25 13:53:48,078 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:57:04,270 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-06-25 13:50:36,778 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-25 13:39:20,725 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm1.org_1   | 2021-06-25 13:39:17,387 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$329/0x00000008402fc840@462e1e64] INFO util.JvmPauseMonitor: JvmPauseMonitor-76093931-f232-4415-806f-239960e589cb: Started
om1_1        | 2021-06-25 13:52:03,608 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | ************************************************************/
om2_1        | 2021-06-25 13:51:47,395 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
datanode3_1  | 2021-06-25 13:53:51,146 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:57:07,338 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-06-25 13:50:41,472 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:57278
scm2.org_1   | 2021-06-25 13:39:20,726 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm1.org_1   | 2021-06-25 13:39:21,997 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-FollowerState] INFO impl.FollowerState: 76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5069047735ns, electionTimeout:5053ms
om1_1        | 2021-06-25 13:52:04,251 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm3.org_1   | 2021-06-25 13:39:59,384 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om2_1        | 2021-06-25 13:51:47,396 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39036
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
datanode3_1  | 2021-06-25 13:53:54,218 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:57:10,410 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-06-25 13:50:41,476 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-25 13:39:20,783 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm2, RPC Address: scm2.org:9894 and Ratis port: 9894
scm1.org_1   | 2021-06-25 13:39:21,998 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-FollowerState] INFO impl.RoleInfo: 76093931-f232-4415-806f-239960e589cb: shutdown 76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-FollowerState
om1_1        | 2021-06-25 13:52:04,252 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40316
scm3.org_1   | 2021-06-25 13:39:59,896 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
om2_1        | 2021-06-25 13:51:47,396 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:51:48,160 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
datanode3_1  | 2021-06-25 13:53:57,290 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:57:13,483 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-06-25 13:50:44,765 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm2.org_1   | 2021-06-25 13:39:20,786 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm2: scm2.org
scm1.org_1   | 2021-06-25 13:39:21,999 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-FollowerState] INFO server.RaftServer$Division: 76093931-f232-4415-806f-239960e589cb@group-61155FD5A026: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
om1_1        | 2021-06-25 13:52:04,261 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-25 13:39:59,897 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om2_1        | 2021-06-25 13:51:48,161 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39046
datanode3_1  | 2021-06-25 13:54:00,362 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:57:16,554 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-06-25 13:50:44,766 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:57230
scm2.org_1   | 2021-06-25 13:39:20,802 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2021-06-25 13:39:22,003 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om1_1        | 2021-06-25 13:52:08,676 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:60438
scm3.org_1   | 2021-06-25 13:40:00,056 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm3, RPC Address: scm3.org:9894 and Ratis port: 9894
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om2_1        | 2021-06-25 13:51:48,178 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode3_1  | 2021-06-25 13:54:03,438 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:57:19,626 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-06-25 13:50:44,769 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-25 13:39:21,095 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file /etc/security/keytabs/scm.keytab
scm1.org_1   | 2021-06-25 13:39:22,003 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-FollowerState] INFO impl.RoleInfo: 76093931-f232-4415-806f-239960e589cb: start 76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-LeaderElection1
om1_1        | 2021-06-25 13:52:08,695 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:52:12,049 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
om2_1        | 2021-06-25 13:51:52,717 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:57934
datanode3_1  | 2021-06-25 13:54:06,506 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:57:22,698 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-06-25 13:50:45,455 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm2.org_1   | 2021-06-25 13:39:21,095 [main] INFO server.StorageContainerManager: SCM login successful.
om1_1        | 2021-06-25 13:52:12,050 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40352
scm3.org_1   | 2021-06-25 13:40:00,066 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm3: scm3.org
scm1.org_1   | 2021-06-25 13:39:22,011 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-LeaderElection1] INFO impl.LeaderElection: 76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [76093931-f232-4415-806f-239960e589cb|rpc:scm1.org:9894|priority:0], old=null
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
om2_1        | 2021-06-25 13:51:52,720 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode3_1  | 2021-06-25 13:54:09,578 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:57:25,770 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-06-25 13:50:45,456 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:57240
scm2.org_1   | 2021-06-25 13:39:23,364 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm2.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863 after 1 failover attempts. Trying to failover after sleeping for 2000ms.
om1_1        | 2021-06-25 13:52:12,052 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-25 13:40:00,130 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2021-06-25 13:39:22,012 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-LeaderElection1] INFO impl.LeaderElection: 76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-LeaderElection1 ELECTION round 0: result PASSED (term=1)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
om2_1        | 2021-06-25 13:51:55,801 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
datanode3_1  | 2021-06-25 13:54:12,651 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:57:28,842 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-06-25 13:50:45,466 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-25 13:39:25,367 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
om1_1        | 2021-06-25 13:52:12,764 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm3.org_1   | 2021-06-25 13:40:00,842 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file /etc/security/keytabs/scm.keytab
scm1.org_1   | 2021-06-25 13:39:22,012 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-LeaderElection1] INFO impl.RoleInfo: 76093931-f232-4415-806f-239960e589cb: shutdown 76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-LeaderElection1
s3g_1        | 2021-06-25 13:49:49,610 [qtp382627885-22] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
om2_1        | 2021-06-25 13:51:55,806 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39096
datanode3_1  | 2021-06-25 13:54:15,722 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:57:31,914 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:57:34,986 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm2.org_1   | 2021-06-25 13:39:27,368 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm1.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863 after 3 failover attempts. Trying to failover after sleeping for 2000ms.
om1_1        | 2021-06-25 13:52:12,765 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40370
scm3.org_1   | 2021-06-25 13:40:00,842 [main] INFO server.StorageContainerManager: SCM login successful.
scm1.org_1   | 2021-06-25 13:39:22,013 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-LeaderElection1] INFO server.RaftServer$Division: 76093931-f232-4415-806f-239960e589cb@group-61155FD5A026: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
om2_1        | 2021-06-25 13:51:55,808 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode3_1  | 2021-06-25 13:54:18,794 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:57:38,058 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-06-25 13:50:46,231 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm2.org_1   | 2021-06-25 13:39:29,370 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm2.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863 after 4 failover attempts. Trying to failover after sleeping for 2000ms.
om1_1        | 2021-06-25 13:52:12,767 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-25 13:40:02,365 [main] INFO ha.HASecurityUtils: Initializing secure StorageContainerManager.
scm1.org_1   | 2021-06-25 13:39:22,013 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-LeaderElection1] INFO server.RaftServer$Division: 76093931-f232-4415-806f-239960e589cb@group-61155FD5A026: change Leader from null to 76093931-f232-4415-806f-239960e589cb at term 1 for becomeLeader, leader elected after 5591ms
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
om2_1        | 2021-06-25 13:51:56,444 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
datanode3_1  | 2021-06-25 13:54:21,866 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:57:41,130 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-06-25 13:50:46,232 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:57248
scm2.org_1   | 2021-06-25 13:39:31,375 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
om1_1        | 2021-06-25 13:52:13,593 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm3.org_1   | 2021-06-25 13:40:03,546 [main] ERROR client.SCMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
scm1.org_1   | 2021-06-25 13:39:22,018 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om2_1        | 2021-06-25 13:51:56,445 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39104
datanode3_1  | 2021-06-25 13:54:24,942 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:57:44,202 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-06-25 13:50:46,232 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-25 13:39:33,578 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:76093931-f232-4415-806f-239960e589cb is not the leader. Could not determine the leader node.
om1_1        | 2021-06-25 13:52:13,593 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40384
scm3.org_1   | 2021-06-25 13:40:03,547 [main] INFO client.SCMCertificateClient: Certificate client init case: 0
scm1.org_1   | 2021-06-25 13:39:22,020 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.76093931-f232-4415-806f-239960e589cb@group-61155FD5A026
om2_1        | 2021-06-25 13:51:56,446 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
datanode3_1  | 2021-06-25 13:54:28,010 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-06-25 13:50:47,073 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
datanode1_1  | 2021-06-25 13:57:50,346 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm2.org_1   | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
om1_1        | 2021-06-25 13:52:13,595 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-25 13:40:03,549 [main] INFO client.SCMCertificateClient: Creating keypair for client as keypair and certificate not found.
scm1.org_1   | 2021-06-25 13:39:22,021 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-LeaderElection1] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
om2_1        | 2021-06-25 13:51:57,127 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
datanode3_1  | 2021-06-25 13:54:31,617 [pool-35-thread-5] INFO keyvalue.KeyValueContainer: Container 1 is synced with bcsId 124.
om3_1        | 2021-06-25 13:50:47,074 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:57260
datanode1_1  | 2021-06-25 13:57:53,419 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm2.org_1   | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:196)
om1_1        | 2021-06-25 13:52:14,265 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm3.org_1   | 2021-06-25 13:40:04,657 [main] INFO ha.HASecurityUtils: Init response: GETCERT
scm1.org_1   | 2021-06-25 13:39:22,023 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm1.org_1   | 2021-06-25 13:39:22,023 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
datanode3_1  | 2021-06-25 13:54:31,617 [pool-35-thread-5] INFO keyvalue.KeyValueContainer: Container 1 is synced with bcsId 124.
om3_1        | 2021-06-25 13:50:47,075 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode1_1  | 2021-06-25 13:57:56,490 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm2.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:108)
om1_1        | 2021-06-25 13:52:14,266 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40394
scm3.org_1   | 2021-06-25 13:40:04,795 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.118,host:scm3.org
scm1.org_1   | 2021-06-25 13:39:22,028 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
om2_1        | 2021-06-25 13:51:57,128 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39114
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
datanode3_1  | 2021-06-25 13:54:31,639 [pool-35-thread-5] INFO keyvalue.KeyValueContainer: Container 1 is closed with bcsId 124.
om3_1        | 2021-06-25 13:50:48,482 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
datanode1_1  | 2021-06-25 13:57:59,562 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm2.org_1   | 	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13937)
om1_1        | 2021-06-25 13:52:14,268 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-25 13:40:04,795 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm1.org_1   | 2021-06-25 13:39:22,028 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
om2_1        | 2021-06-25 13:51:57,129 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
datanode3_1  | 2021-06-25 13:54:34,154 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-06-25 13:50:48,482 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:57282
datanode1_1  | 2021-06-25 13:58:02,634 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm2.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1        | 2021-06-25 13:52:14,933 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm3.org_1   | 2021-06-25 13:40:04,804 [main] INFO ha.HASecurityUtils: Creating csr for SCM->hostName:scm3.org,scmId:084c6adf-4c09-417d-ac5b-6ae661ceeb47,clusterId:CID-8e5d7696-3ffc-40b4-8848-61155fd5a026,subject:scm-sub@scm3.org
scm1.org_1   | 2021-06-25 13:39:22,029 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
om2_1        | 2021-06-25 13:51:58,080 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
datanode3_1  | 2021-06-25 13:54:37,226 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-06-25 13:50:48,484 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode1_1  | 2021-06-25 13:58:02,786 [pool-36-thread-5] INFO keyvalue.KeyValueContainer: Container 2 is synced with bcsId 122.
scm2.org_1   | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
om1_1        | 2021-06-25 13:52:14,933 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40404
scm3.org_1   | 2021-06-25 13:40:05,827 [main] INFO ha.HASecurityUtils: Successfully stored SCM signed certificate.
om2_1        | 2021-06-25 13:51:58,081 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39126
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
datanode3_1  | 2021-06-25 13:54:40,298 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-06-25 13:50:49,815 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
datanode1_1  | 2021-06-25 13:58:02,787 [pool-36-thread-5] INFO keyvalue.KeyValueContainer: Container 2 is synced with bcsId 122.
scm2.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
om1_1        | 2021-06-25 13:52:14,934 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-25 13:40:05,839 [main] INFO server.StorageContainerManager: SCM BootStrap  is successful for ClusterID CID-8e5d7696-3ffc-40b4-8848-61155fd5a026, SCMID 084c6adf-4c09-417d-ac5b-6ae661ceeb47
scm1.org_1   | 2021-06-25 13:39:22,040 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-LeaderElection1] INFO impl.RoleInfo: 76093931-f232-4415-806f-239960e589cb: start 76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-LeaderStateImpl
om2_1        | 2021-06-25 13:51:58,081 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
datanode3_1  | 2021-06-25 13:54:43,371 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-06-25 13:50:49,815 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:57294
datanode1_1  | 2021-06-25 13:58:02,797 [pool-36-thread-5] INFO keyvalue.KeyValueContainer: Container 2 is closed with bcsId 122.
scm2.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
om1_1        | 2021-06-25 13:52:15,574 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm3.org_1   | 2021-06-25 13:40:05,839 [main] INFO server.StorageContainerManager: Primary SCM Node ID 76093931-f232-4415-806f-239960e589cb
scm1.org_1   | 2021-06-25 13:39:22,094 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-SegmentedRaftLogWorker: Starting segment from index:0
om2_1        | 2021-06-25 13:51:58,713 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
datanode3_1  | 2021-06-25 13:54:46,442 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-06-25 13:50:49,816 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode1_1  | 2021-06-25 13:58:05,706 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:58:08,778 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-06-25 13:52:15,574 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40414
scm3.org_1   | 2021-06-25 13:40:05,858 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm1.org_1   | 2021-06-25 13:39:22,152 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-LeaderElection1] INFO server.RaftServer$Division: 76093931-f232-4415-806f-239960e589cb@group-61155FD5A026: set configuration 0: [76093931-f232-4415-806f-239960e589cb|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
om2_1        | 2021-06-25 13:51:58,714 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39134
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
datanode3_1  | 2021-06-25 13:54:49,514 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-06-25 13:50:50,646 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
datanode1_1  | 2021-06-25 13:58:11,850 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm2.org_1   | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1        | 2021-06-25 13:52:15,579 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | /************************************************************
scm1.org_1   | 2021-06-25 13:39:22,162 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/8e5d7696-3ffc-40b4-8848-61155fd5a026/current/log_inprogress_0
om2_1        | 2021-06-25 13:51:58,725 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
datanode3_1  | 2021-06-25 13:54:52,586 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-06-25 13:50:50,647 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:57304
datanode1_1  | 2021-06-25 13:58:14,923 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm2.org_1   | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1        | 2021-06-25 13:52:16,205 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm3.org_1   | SHUTDOWN_MSG: Shutting down StorageContainerManager at scm3.org/172.25.0.118
scm3.org_1   | ************************************************************/
om2_1        | 2021-06-25 13:51:59,600 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
datanode3_1  | 2021-06-25 13:54:55,658 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-06-25 13:50:50,649 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode1_1  | 2021-06-25 13:58:17,994 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm2.org_1   | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
scm3.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm1.org_1   | 2021-06-25 13:39:23,389 [main] INFO server.RaftServer: 76093931-f232-4415-806f-239960e589cb: close
om1_1        | 2021-06-25 13:52:16,206 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40424
om2_1        | 2021-06-25 13:51:59,601 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39150
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:49:49,791 [qtp382627885-19] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
om3_1        | 2021-06-25 13:50:54,509 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
datanode1_1  | 2021-06-25 13:58:21,066 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm2.org_1   | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
scm3.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm1.org_1   | 2021-06-25 13:39:23,391 [main] INFO server.RaftServer$Division: 76093931-f232-4415-806f-239960e589cb@group-61155FD5A026: shutdown
om1_1        | 2021-06-25 13:52:16,210 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
datanode3_1  | 2021-06-25 13:54:58,730 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-06-25 13:51:59,602 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:50:54,510 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:57332
datanode1_1  | 2021-06-25 13:58:24,138 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm2.org_1   | , while invoking $Proxy15.send over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863 after 6 failover attempts. Trying to failover after sleeping for 2000ms.
scm3.org_1   | 2021-06-25 13:40:07,549 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm1.org_1   | 2021-06-25 13:39:23,391 [main] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-61155FD5A026,id=76093931-f232-4415-806f-239960e589cb
om1_1        | 2021-06-25 13:52:16,820 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
datanode3_1  | 2021-06-25 13:55:01,802 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-06-25 13:52:00,254 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om3_1        | 2021-06-25 13:50:54,512 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode1_1  | 2021-06-25 13:58:27,210 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm2.org_1   | 2021-06-25 13:39:35,579 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm2.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863 after 7 failover attempts. Trying to failover after sleeping for 2000ms.
scm3.org_1   | /************************************************************
scm1.org_1   | 2021-06-25 13:39:23,391 [main] INFO impl.RoleInfo: 76093931-f232-4415-806f-239960e589cb: shutdown 76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-LeaderStateImpl
om1_1        | 2021-06-25 13:52:16,821 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40432
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
datanode3_1  | 2021-06-25 13:55:04,874 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-06-25 13:52:00,255 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39160
datanode1_1  | 2021-06-25 13:58:30,282 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-06-25 13:50:55,575 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om3_1        | 2021-06-25 13:50:55,576 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:57342
om3_1        | 2021-06-25 13:50:55,577 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-25 13:39:23,398 [main] INFO impl.PendingRequests: 76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-PendingRequests: sendNotLeaderResponses
om1_1        | 2021-06-25 13:52:16,823 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
datanode3_1  | 2021-06-25 13:55:07,946 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-06-25 13:52:00,256 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:50:56,281 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm2.org_1   | 2021-06-25 13:39:37,582 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 8 failover attempts. Trying to failover after sleeping for 2000ms.
datanode1_1  | 2021-06-25 13:58:33,354 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm3.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm1.org_1   | 2021-06-25 13:39:23,399 [main] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.log_appender.76093931-f232-4415-806f-239960e589cb@group-61155FD5A026
om1_1        | 2021-06-25 13:52:17,469 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
datanode3_1  | 2021-06-25 13:55:11,018 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-06-25 13:52:01,698 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om3_1        | 2021-06-25 13:50:56,281 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:57354
scm2.org_1   | 2021-06-25 13:39:39,692 [main] INFO ha.HASecurityUtils: Initializing secure StorageContainerManager.
datanode1_1  | 2021-06-25 13:58:39,498 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm3.org_1   | STARTUP_MSG:   host = scm3.org/172.25.0.118
scm1.org_1   | 2021-06-25 13:39:23,400 [main] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.server.76093931-f232-4415-806f-239960e589cb@group-61155FD5A026
om1_1        | 2021-06-25 13:52:17,469 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40442
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
datanode3_1  | 2021-06-25 13:55:14,090 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-06-25 13:52:01,699 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39204
om3_1        | 2021-06-25 13:50:56,282 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-25 13:39:40,370 [main] ERROR client.SCMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode1_1  | 2021-06-25 13:58:42,570 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm3.org_1   | STARTUP_MSG:   args = []
scm1.org_1   | 2021-06-25 13:39:23,401 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-StateMachineUpdater] INFO impl.StateMachineUpdater: 76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-StateMachineUpdater: Took a snapshot at index 0
om1_1        | 2021-06-25 13:52:17,472 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
datanode3_1  | 2021-06-25 13:55:17,162 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-06-25 13:52:01,700 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:50:57,398 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm2.org_1   | 2021-06-25 13:39:40,370 [main] INFO client.SCMCertificateClient: Certificate client init case: 0
datanode1_1  | 2021-06-25 13:58:45,643 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm3.org_1   | STARTUP_MSG:   version = 1.2.0-SNAPSHOT
scm1.org_1   | 2021-06-25 13:39:23,401 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-StateMachineUpdater] INFO impl.StateMachineUpdater: 76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
scm1.org_1   | 2021-06-25 13:39:23,402 [main] INFO impl.StateMachineUpdater: 76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-StateMachineUpdater: set stopIndex = 0
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
datanode3_1  | 2021-06-25 13:55:23,310 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-06-25 13:52:02,331 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om3_1        | 2021-06-25 13:50:57,399 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:57370
scm2.org_1   | 2021-06-25 13:39:40,372 [main] INFO client.SCMCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode1_1  | 2021-06-25 13:58:48,714 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm1.org_1   | 2021-06-25 13:39:23,418 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-StateMachineUpdater] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.state_machine.76093931-f232-4415-806f-239960e589cb@group-61155FD5A026
om1_1        | 2021-06-25 13:52:18,317 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm3.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/javax.activation-api-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.2.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0-a398b19-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.2.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.2.0-SNAPSHOT.jar
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
datanode3_1  | 2021-06-25 13:55:26,382 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-06-25 13:52:02,332 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39216
om3_1        | 2021-06-25 13:50:57,400 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode1_1  | 2021-06-25 13:58:51,786 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm2.org_1   | 2021-06-25 13:39:41,099 [main] INFO ha.HASecurityUtils: Init response: GETCERT
scm1.org_1   | 2021-06-25 13:39:23,419 [main] INFO server.RaftServer$Division: 76093931-f232-4415-806f-239960e589cb@group-61155FD5A026: closes. applyIndex: 0
om1_1        | 2021-06-25 13:52:18,317 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40452
scm3.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/450c3750335593082ae39a2d17d4a2a58090f75f ; compiled by 'runner' on 2021-06-25T12:44Z
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
datanode3_1  | 2021-06-25 13:55:29,450 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-06-25 13:52:02,334 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:50:58,241 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
datanode1_1  | 2021-06-25 13:58:54,858 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm2.org_1   | 2021-06-25 13:39:41,183 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.117,host:scm2.org
scm1.org_1   | 2021-06-25 13:39:23,421 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
om1_1        | 2021-06-25 13:52:18,324 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | STARTUP_MSG:   java = 11.0.10
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
datanode3_1  | 2021-06-25 13:55:32,522 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-06-25 13:52:02,953 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om3_1        | 2021-06-25 13:50:58,242 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:57378
datanode1_1  | 2021-06-25 13:58:57,930 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm2.org_1   | 2021-06-25 13:39:41,184 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm1.org_1   | 2021-06-25 13:39:23,421 [main] INFO segmented.SegmentedRaftLogWorker: 76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-SegmentedRaftLogWorker close()
om1_1        | 2021-06-25 13:52:18,956 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm3.org_1   | ************************************************************/
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
datanode3_1  | 2021-06-25 13:55:35,594 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-06-25 13:52:02,953 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39226
om3_1        | 2021-06-25 13:50:58,243 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode1_1  | 2021-06-25 13:59:01,002 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm2.org_1   | 2021-06-25 13:39:41,190 [main] INFO ha.HASecurityUtils: Creating csr for SCM->hostName:scm2.org,scmId:76cadbf9-8202-4493-b276-7e4d9594dfab,clusterId:CID-8e5d7696-3ffc-40b4-8848-61155fd5a026,subject:scm-sub@scm2.org
scm1.org_1   | 2021-06-25 13:39:23,423 [main] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.log_worker.76093931-f232-4415-806f-239960e589cb@group-61155FD5A026
om1_1        | 2021-06-25 13:52:18,956 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40470
scm3.org_1   | 2021-06-25 13:40:07,587 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
datanode3_1  | 2021-06-25 13:55:38,670 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-06-25 13:52:02,954 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:50:59,253 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
datanode1_1  | 2021-06-25 13:59:04,074 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm2.org_1   | 2021-06-25 13:39:44,107 [main] INFO ha.HASecurityUtils: Successfully stored SCM signed certificate.
scm1.org_1   | 2021-06-25 13:39:23,423 [main] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.leader_election.76093931-f232-4415-806f-239960e589cb@group-61155FD5A026
om1_1        | 2021-06-25 13:52:18,965 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-25 13:40:07,804 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
datanode3_1  | 2021-06-25 13:55:41,739 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-06-25 13:52:03,612 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om3_1        | 2021-06-25 13:50:59,254 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:57392
datanode1_1  | 2021-06-25 13:59:07,146 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm2.org_1   | 2021-06-25 13:39:44,129 [main] INFO server.StorageContainerManager: SCM BootStrap  is successful for ClusterID CID-8e5d7696-3ffc-40b4-8848-61155fd5a026, SCMID 76cadbf9-8202-4493-b276-7e4d9594dfab
scm2.org_1   | 2021-06-25 13:39:44,129 [main] INFO server.StorageContainerManager: Primary SCM Node ID 76093931-f232-4415-806f-239960e589cb
om1_1        | 2021-06-25 13:52:19,604 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm3.org_1   | 2021-06-25 13:40:07,804 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
datanode3_1  | 2021-06-25 13:55:44,811 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-06-25 13:52:03,613 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39234
om3_1        | 2021-06-25 13:50:59,255 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode1_1  | 2021-06-25 13:59:10,218 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm2.org_1   | 2021-06-25 13:39:44,174 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm2.org_1   | /************************************************************
om1_1        | 2021-06-25 13:52:19,605 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40480
scm3.org_1   | 2021-06-25 13:40:07,993 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm3, RPC Address: scm3.org:9894 and Ratis port: 9894
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
datanode3_1  | 2021-06-25 13:55:47,886 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-06-25 13:52:03,616 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:51:00,324 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm2.org_1   | SHUTDOWN_MSG: Shutting down StorageContainerManager at scm2.org/172.25.0.117
scm1.org_1   | 2021-06-25 13:39:23,423 [main] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.server.76093931-f232-4415-806f-239960e589cb@group-61155FD5A026
datanode1_1  | 2021-06-25 13:59:13,294 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-06-25 13:52:19,606 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-25 13:40:07,993 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm3: scm3.org
s3g_1        | 2021-06-25 13:49:49,879 [qtp382627885-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
datanode3_1  | 2021-06-25 13:55:50,954 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-06-25 13:52:04,266 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om3_1        | 2021-06-25 13:51:00,325 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:57410
scm2.org_1   | ************************************************************/
scm1.org_1   | 2021-06-25 13:39:23,424 [main] INFO server.GrpcService: 76093931-f232-4415-806f-239960e589cb: shutdown server with port 9894 now
datanode1_1  | 2021-06-25 13:59:16,362 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:59:19,438 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm3.org_1   | 2021-06-25 13:40:08,134 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
datanode3_1  | 2021-06-25 13:55:54,030 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-06-25 13:52:04,266 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39244
om3_1        | 2021-06-25 13:51:00,329 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm1.org_1   | 2021-06-25 13:39:23,428 [main] INFO server.GrpcService: 76093931-f232-4415-806f-239960e589cb: shutdown server with port 9894 successfully
datanode1_1  | 2021-06-25 13:59:22,506 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-06-25 13:52:20,247 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm3.org_1   | 2021-06-25 13:40:09,305 [main] INFO client.SCMCertificateClient: Loading certificate from location:/data/metadata/scm/sub-ca/certs.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
om2_1        | 2021-06-25 13:52:04,270 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode3_1  | 2021-06-25 13:55:57,098 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-06-25 13:51:00,349 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload: /s3v/bucket-04686/30295/multipartKey2 Part number: 1 size 6  is less than minimum part size 5242880
scm2.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm1.org_1   | 2021-06-25 13:39:23,428 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$329/0x00000008402fc840@462e1e64] INFO util.JvmPauseMonitor: JvmPauseMonitor-76093931-f232-4415-806f-239960e589cb: Stopped
datanode1_1  | 2021-06-25 13:59:28,650 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:59:31,722 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm3.org_1   | 2021-06-25 13:40:09,582 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/certificate.crt.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om2_1        | 2021-06-25 13:52:08,733 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:58128
datanode3_1  | 2021-06-25 13:56:00,170 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-06-25 13:51:00,353 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 30295/multipartKey2 in Volume/Bucket s3v/bucket-04686
scm2.org_1   | 2021-06-25 13:39:47,497 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
datanode1_1  | 2021-06-25 13:59:34,794 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-06-25 13:52:20,249 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40488
scm1.org_1   | 2021-06-25 13:39:23,428 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm3.org_1   | 2021-06-25 13:40:09,590 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/2935539918726.crt.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om2_1        | 2021-06-25 13:52:08,746 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode3_1  | 2021-06-25 13:56:03,242 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-04686 key: 30295/multipartKey2. Entity too small.
scm2.org_1   | /************************************************************
datanode1_1  | 2021-06-25 13:59:37,866 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-06-25 13:52:20,256 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-25 13:39:23,431 [main] INFO server.StorageContainerManager: SCM initialization succeeded. Current cluster id for sd=/data/metadata/scm; cid=CID-8e5d7696-3ffc-40b4-8848-61155fd5a026; layoutVersion=0; scmId=76093931-f232-4415-806f-239960e589cb
scm3.org_1   | 2021-06-25 13:40:09,634 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/CA-1.crt.
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om2_1        | 2021-06-25 13:52:12,059 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
datanode3_1  | 2021-06-25 13:56:06,314 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:464)
scm2.org_1   | STARTUP_MSG: Starting StorageContainerManager
datanode1_1  | 2021-06-25 13:59:40,938 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-06-25 13:52:20,896 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm1.org_1   | 2021-06-25 13:39:23,440 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm3.org_1   | 2021-06-25 13:40:10,157 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file /etc/security/keytabs/scm.keytab
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
datanode3_1  | 2021-06-25 13:56:12,458 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:184)
scm2.org_1   | STARTUP_MSG:   host = scm2.org/172.25.0.117
datanode1_1  | 2021-06-25 13:59:44,010 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-06-25 13:52:20,896 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40498
scm1.org_1   | /************************************************************
scm3.org_1   | 2021-06-25 13:40:10,157 [main] INFO server.StorageContainerManager: SCM login successful.
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om2_1        | 2021-06-25 13:52:12,059 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39280
datanode3_1  | 2021-06-25 13:56:15,534 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
scm2.org_1   | STARTUP_MSG:   args = []
datanode1_1  | 2021-06-25 13:59:47,082 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-06-25 13:52:20,897 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | SHUTDOWN_MSG: Shutting down StorageContainerManager at scm1.org/172.25.0.116
scm3.org_1   | 2021-06-25 13:40:10,250 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
om2_1        | 2021-06-25 13:52:12,063 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode3_1  | 2021-06-25 13:56:18,606 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
scm2.org_1   | STARTUP_MSG:   version = 1.2.0-SNAPSHOT
datanode1_1  | 2021-06-25 13:59:50,154 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-25 13:59:53,226 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm1.org_1   | ************************************************************/
scm3.org_1   | 2021-06-25 13:40:10,601 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
om2_1        | 2021-06-25 13:52:12,771 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
datanode3_1  | 2021-06-25 13:56:21,674 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
datanode1_1  | 2021-06-25 13:59:56,302 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-06-25 13:52:21,693 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm2.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/javax.activation-api-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.2.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0-a398b19-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.2.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.2.0-SNAPSHOT.jar
scm1.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm3.org_1   | 2021-06-25 13:40:10,988 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar!/network-topology-default.xml]
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
om2_1        | 2021-06-25 13:52:12,772 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39298
datanode3_1  | 2021-06-25 13:56:24,746 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode1_1  | 2021-06-25 13:59:59,370 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-06-25 13:52:21,694 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40510
scm2.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/450c3750335593082ae39a2d17d4a2a58090f75f ; compiled by 'runner' on 2021-06-25T12:44Z
scm1.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm3.org_1   | 2021-06-25 13:40:10,989 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om2_1        | 2021-06-25 13:52:12,774 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode3_1  | 2021-06-25 13:56:27,818 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode1_1  | 2021-06-25 14:00:02,442 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-06-25 13:52:21,695 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | STARTUP_MSG:   java = 11.0.10
scm1.org_1   | 2021-06-25 13:39:25,312 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm3.org_1   | 2021-06-25 13:40:11,168 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:084c6adf-4c09-417d-ac5b-6ae661ceeb47
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om2_1        | 2021-06-25 13:52:13,599 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
datanode3_1  | 2021-06-25 13:56:30,890 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode1_1  | 2021-06-25 14:00:05,514 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-06-25 13:52:22,341 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm2.org_1   | ************************************************************/
scm1.org_1   | /************************************************************
scm3.org_1   | 2021-06-25 13:40:11,387 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
om2_1        | 2021-06-25 13:52:13,600 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39312
datanode3_1  | 2021-06-25 13:56:33,966 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode1_1  | 2021-06-25 14:00:08,586 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-06-25 13:52:22,342 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40520
scm2.org_1   | 2021-06-25 13:39:47,518 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm1.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm3.org_1   | 2021-06-25 13:40:11,602 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
om2_1        | 2021-06-25 13:52:13,600 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode3_1  | 2021-06-25 13:56:37,034 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-06-25 13:51:01,391 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
datanode1_1  | 2021-06-25 14:00:11,658 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-06-25 13:52:22,344 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-25 13:39:47,758 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm1.org_1   | STARTUP_MSG:   host = scm1.org/172.25.0.116
scm3.org_1   | 2021-06-25 13:40:11,605 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
om2_1        | 2021-06-25 13:52:14,272 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
datanode3_1  | 2021-06-25 13:56:40,110 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-06-25 13:51:01,392 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:57438
datanode1_1  | 2021-06-25 14:00:17,802 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-06-25 13:52:23,004 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm2.org_1   | 2021-06-25 13:39:47,759 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm1.org_1   | STARTUP_MSG:   args = []
scm3.org_1   | 2021-06-25 13:40:11,611 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
s3g_1        | 2021-06-25 13:49:49,928 [qtp382627885-19] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-527D211E85BE->d7f71981-d306-415b-992d-ee4808a385fa
om2_1        | 2021-06-25 13:52:14,273 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39322
datanode3_1  | 2021-06-25 13:56:43,179 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-06-25 13:51:01,396 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode1_1  | 2021-06-25 14:00:20,874 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-06-25 13:52:23,005 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40528
scm2.org_1   | 2021-06-25 13:39:47,859 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm2, RPC Address: scm2.org:9894 and Ratis port: 9894
scm1.org_1   | STARTUP_MSG:   version = 1.2.0-SNAPSHOT
s3g_1        | 2021-06-25 13:49:49,934 [qtp382627885-19] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm3.org_1   | 2021-06-25 13:40:11,611 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
om2_1        | 2021-06-25 13:52:14,274 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode3_1  | 2021-06-25 13:56:46,250 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-06-25 13:51:02,140 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:52:23,014 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-25 13:39:47,860 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm2: scm2.org
s3g_1        | 2021-06-25 13:49:50,124 [qtp382627885-24] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-84358E29E3BD->d7f71981-d306-415b-992d-ee4808a385fa
scm1.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/javax.activation-api-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.2.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0-a398b19-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.2.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.2.0-SNAPSHOT.jar
scm3.org_1   | 2021-06-25 13:40:11,612 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
om2_1        | 2021-06-25 13:52:14,938 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
datanode3_1  | 2021-06-25 13:56:49,322 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-06-25 13:51:02,141 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:57448
om1_1        | 2021-06-25 13:52:23,650 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm2.org_1   | 2021-06-25 13:39:47,948 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
s3g_1        | 2021-06-25 13:49:50,133 [qtp382627885-24] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm3.org_1   | 2021-06-25 13:40:11,613 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
om2_1        | 2021-06-25 13:52:14,939 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39332
datanode3_1  | 2021-06-25 13:56:52,394 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-06-25 13:51:02,148 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:52:23,650 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40538
scm2.org_1   | 2021-06-25 13:39:48,817 [main] INFO client.SCMCertificateClient: Loading certificate from location:/data/metadata/scm/sub-ca/certs.
s3g_1        | 2021-06-25 13:49:51,330 [qtp382627885-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
scm1.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/450c3750335593082ae39a2d17d4a2a58090f75f ; compiled by 'runner' on 2021-06-25T12:44Z
scm3.org_1   | 2021-06-25 13:40:11,616 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om2_1        | 2021-06-25 13:52:14,946 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode3_1  | 2021-06-25 13:56:55,466 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:57:01,610 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-06-25 13:52:23,653 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-25 13:39:49,048 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/certificate.crt.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
scm1.org_1   | STARTUP_MSG:   java = 11.0.10
scm3.org_1   | 2021-06-25 13:40:11,620 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om2_1        | 2021-06-25 13:52:15,582 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
datanode3_1  | 2021-06-25 13:57:04,682 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-06-25 13:51:02,184 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-04686/54205/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 1
om1_1        | 2021-06-25 13:52:24,291 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm2.org_1   | 2021-06-25 13:39:49,054 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/2912775987470.crt.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
scm1.org_1   | ************************************************************/
scm3.org_1   | 2021-06-25 13:40:11,621 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
om2_1        | 2021-06-25 13:52:15,583 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39342
datanode3_1  | 2021-06-25 13:57:07,754 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | partName: "etag1"
om1_1        | 2021-06-25 13:52:24,292 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40546
scm2.org_1   | 2021-06-25 13:39:49,058 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/CA-1.crt.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
scm1.org_1   | 2021-06-25 13:39:25,328 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm3.org_1   | 2021-06-25 13:40:12,930 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om2_1        | 2021-06-25 13:52:15,587 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode3_1  | 2021-06-25 13:57:10,826 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | , partNumber: 2
om1_1        | 2021-06-25 13:52:24,293 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-25 13:39:49,332 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file /etc/security/keytabs/scm.keytab
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
scm1.org_1   | 2021-06-25 13:39:25,438 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm3.org_1   | 2021-06-25 13:40:12,934 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
om2_1        | 2021-06-25 13:52:16,214 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
datanode3_1  | 2021-06-25 13:57:13,898 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | partName: "etag2"
om1_1        | 2021-06-25 13:52:27,958 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:60668
scm2.org_1   | 2021-06-25 13:39:49,332 [main] INFO server.StorageContainerManager: SCM login successful.
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
scm1.org_1   | 2021-06-25 13:39:25,438 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm3.org_1   | 2021-06-25 13:40:12,935 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om2_1        | 2021-06-25 13:52:16,214 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39352
datanode3_1  | 2021-06-25 13:57:16,970 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | ]
om1_1        | 2021-06-25 13:52:27,977 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-25 13:39:49,414 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2021-06-25 13:39:49,716 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2021-06-25 13:39:50,091 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar!/network-topology-default.xml]
scm2.org_1   | 2021-06-25 13:39:50,092 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm2.org_1   | 2021-06-25 13:39:50,177 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:76cadbf9-8202-4493-b276-7e4d9594dfab
om2_1        | 2021-06-25 13:52:16,217 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:51:02,186 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 54205/multipartKey3 in Volume/Bucket s3v/bucket-04686
scm1.org_1   | 2021-06-25 13:39:25,505 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm1, RPC Address: scm1.org:9894 and Ratis port: 9894
scm2.org_1   | 2021-06-25 13:39:50,272 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode3_1  | 2021-06-25 13:57:20,042 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
scm3.org_1   | 2021-06-25 13:40:12,950 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm3.org_1   | 2021-06-25 13:40:12,962 [main] INFO server.RaftServer: 084c6adf-4c09-417d-ac5b-6ae661ceeb47: addNew group-61155FD5A026:[] returns group-61155FD5A026:java.util.concurrent.CompletableFuture@322e49ee[Not completed]
scm3.org_1   | 2021-06-25 13:40:13,051 [pool-13-thread-1] INFO server.RaftServer$Division: 084c6adf-4c09-417d-ac5b-6ae661ceeb47: new RaftServerImpl for group-61155FD5A026:[] with SCMStateMachine:uninitialized
scm2.org_1   | 2021-06-25 13:39:50,329 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
scm1.org_1   | 2021-06-25 13:39:25,506 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm1: scm1.org
datanode3_1  | 2021-06-25 13:57:23,114 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-06-25 13:52:30,803 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm3.org_1   | 2021-06-25 13:40:13,059 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm2.org_1   | 2021-06-25 13:39:50,330 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
om3_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-04686 key: 54205/multipartKey3
om2_1        | 2021-06-25 13:52:16,827 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm1.org_1   | 2021-06-25 13:39:25,580 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
datanode3_1  | 2021-06-25 13:57:26,186 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-06-25 13:52:30,803 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40618
om1_1        | 2021-06-25 13:52:30,805 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-25 13:39:50,330 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:174)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
scm1.org_1   | 2021-06-25 13:39:26,260 [main] INFO client.SCMCertificateClient: Loading certificate from location:/data/metadata/scm/sub-ca/certs.
om1_1        | 2021-06-25 13:52:31,518 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm3.org_1   | 2021-06-25 13:40:13,060 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode3_1  | 2021-06-25 13:57:29,262 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm2.org_1   | 2021-06-25 13:39:50,331 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
om2_1        | 2021-06-25 13:52:16,828 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39360
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
scm1.org_1   | 2021-06-25 13:39:26,358 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/2884006640668.crt.
scm1.org_1   | 2021-06-25 13:39:26,361 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/certificate.crt.
scm3.org_1   | 2021-06-25 13:40:13,060 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode3_1  | 2021-06-25 13:57:32,330 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm2.org_1   | 2021-06-25 13:39:50,331 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm1.org_1   | 2021-06-25 13:39:26,369 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/CA-1.crt.
scm1.org_1   | 2021-06-25 13:39:26,628 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file /etc/security/keytabs/scm.keytab
scm2.org_1   | 2021-06-25 13:39:50,332 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
om2_1        | 2021-06-25 13:52:16,829 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-25 13:40:13,061 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
om1_1        | 2021-06-25 13:52:31,519 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40630
scm1.org_1   | 2021-06-25 13:39:26,632 [main] INFO server.StorageContainerManager: SCM login successful.
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
datanode3_1  | 2021-06-25 13:57:35,402 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm2.org_1   | 2021-06-25 13:39:50,334 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm2.org_1   | 2021-06-25 13:39:50,334 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm3.org_1   | 2021-06-25 13:40:13,061 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om1_1        | 2021-06-25 13:52:31,520 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-25 13:39:26,680 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode3_1  | 2021-06-25 13:57:38,474 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-06-25 13:52:17,477 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm2.org_1   | 2021-06-25 13:39:50,335 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm3.org_1   | 2021-06-25 13:40:13,062 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om1_1        | 2021-06-25 13:52:32,322 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm1.org_1   | 2021-06-25 13:39:26,868 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
datanode3_1  | 2021-06-25 13:57:41,546 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-06-25 13:52:17,477 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39370
scm2.org_1   | 2021-06-25 13:39:50,975 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
scm3.org_1   | 2021-06-25 13:40:13,063 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om1_1        | 2021-06-25 13:52:32,323 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40642
scm1.org_1   | 2021-06-25 13:39:27,166 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar!/network-topology-default.xml]
om3_1        | 2021-06-25 13:51:02,864 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
datanode3_1  | 2021-06-25 13:57:44,618 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-06-25 13:52:17,479 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-25 13:39:50,977 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm3.org_1   | 2021-06-25 13:40:13,072 [pool-13-thread-1] INFO server.RaftServer$Division: 084c6adf-4c09-417d-ac5b-6ae661ceeb47@group-61155FD5A026: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
om1_1        | 2021-06-25 13:52:32,325 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-25 13:39:27,166 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
om3_1        | 2021-06-25 13:51:02,865 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:57458
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
datanode3_1  | 2021-06-25 13:57:50,766 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-06-25 13:52:18,328 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm2.org_1   | 2021-06-25 13:39:50,978 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm3.org_1   | 2021-06-25 13:40:13,073 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
om1_1        | 2021-06-25 13:52:33,059 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm1.org_1   | 2021-06-25 13:39:27,274 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:76093931-f232-4415-806f-239960e589cb
om3_1        | 2021-06-25 13:51:02,879 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
datanode3_1  | 2021-06-25 13:57:53,834 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-06-25 13:52:18,329 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39380
scm2.org_1   | 2021-06-25 13:39:50,991 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm3.org_1   | 2021-06-25 13:40:13,085 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om1_1        | 2021-06-25 13:52:33,060 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40654
scm1.org_1   | 2021-06-25 13:39:27,436 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
om3_1        | 2021-06-25 13:51:02,896 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-04686/54205/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 2
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
datanode3_1  | 2021-06-25 13:57:56,906 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-06-25 13:52:18,330 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-25 13:39:51,000 [main] INFO server.RaftServer: 76cadbf9-8202-4493-b276-7e4d9594dfab: addNew group-61155FD5A026:[] returns group-61155FD5A026:java.util.concurrent.CompletableFuture@322e49ee[Not completed]
scm3.org_1   | 2021-06-25 13:40:13,087 [pool-13-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/8e5d7696-3ffc-40b4-8848-61155fd5a026 does not exist. Creating ...
om1_1        | 2021-06-25 13:52:33,061 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-25 13:39:27,511 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
om3_1        | partName: "etag1"
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
datanode3_1  | 2021-06-25 13:57:59,978 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-06-25 13:52:18,969 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm2.org_1   | 2021-06-25 13:39:51,048 [pool-13-thread-1] INFO server.RaftServer$Division: 76cadbf9-8202-4493-b276-7e4d9594dfab: new RaftServerImpl for group-61155FD5A026:[] with SCMStateMachine:uninitialized
scm3.org_1   | 2021-06-25 13:40:13,133 [pool-13-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/8e5d7696-3ffc-40b4-8848-61155fd5a026/in_use.lock acquired by nodename 8@scm3.org
om1_1        | 2021-06-25 13:52:33,819 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm1.org_1   | 2021-06-25 13:39:27,512 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
om3_1        | , partNumber: 1
s3g_1        | 2021-06-25 13:49:51,472 [qtp382627885-19] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
datanode3_1  | 2021-06-25 13:58:02,789 [pool-37-thread-4] INFO keyvalue.KeyValueContainer: Container 2 is synced with bcsId 122.
om2_1        | 2021-06-25 13:52:18,970 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39398
scm2.org_1   | 2021-06-25 13:39:51,051 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
om1_1        | 2021-06-25 13:52:33,819 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40664
scm1.org_1   | 2021-06-25 13:39:27,512 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
om3_1        | partName: "etag2"
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
datanode3_1  | 2021-06-25 13:58:02,793 [pool-37-thread-4] INFO keyvalue.KeyValueContainer: Container 2 is synced with bcsId 122.
om2_1        | 2021-06-25 13:52:18,974 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-25 13:39:51,052 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm3.org_1   | 2021-06-25 13:40:13,163 [pool-13-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/8e5d7696-3ffc-40b4-8848-61155fd5a026 has been successfully formatted.
om1_1        | 2021-06-25 13:52:33,820 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-25 13:39:27,512 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
om3_1        | ]
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
datanode3_1  | 2021-06-25 13:58:02,802 [pool-37-thread-4] INFO keyvalue.KeyValueContainer: Container 2 is closed with bcsId 122.
om2_1        | 2021-06-25 13:52:19,619 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm2.org_1   | 2021-06-25 13:39:51,052 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm3.org_1   | 2021-06-25 13:40:13,166 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
om1_1        | 2021-06-25 13:52:34,461 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm1.org_1   | 2021-06-25 13:39:27,513 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
om3_1        | 2021-06-25 13:51:02,897 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 54205/multipartKey3 in Volume/Bucket s3v/bucket-04686
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
datanode3_1  | 2021-06-25 13:58:03,050 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-06-25 13:52:19,620 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39408
scm2.org_1   | 2021-06-25 13:39:51,053 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm3.org_1   | 2021-06-25 13:40:13,170 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om1_1        | 2021-06-25 13:52:34,461 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40676
scm1.org_1   | 2021-06-25 13:39:27,514 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
om3_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-04686 key: 54205/multipartKey3
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
datanode3_1  | 2021-06-25 13:58:06,122 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-06-25 13:52:19,621 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-25 13:39:51,053 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm3.org_1   | 2021-06-25 13:40:13,196 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om1_1        | 2021-06-25 13:52:34,463 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-25 13:39:27,519 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:174)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
datanode3_1  | 2021-06-25 13:58:09,194 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-06-25 13:52:20,259 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm2.org_1   | 2021-06-25 13:39:51,053 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
scm3.org_1   | 2021-06-25 13:40:13,196 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om1_1        | 2021-06-25 13:52:34,533 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:s3v, Bucket:bucket-96700, Key:29528/multidelete/f4.
scm1.org_1   | 2021-06-25 13:39:27,520 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
datanode3_1  | 2021-06-25 13:58:12,270 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-06-25 13:52:20,260 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39416
scm2.org_1   | 2021-06-25 13:39:51,054 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm3.org_1   | 2021-06-25 13:40:13,214 [pool-13-thread-1] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om1_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
scm1.org_1   | 2021-06-25 13:39:27,520 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
datanode3_1  | 2021-06-25 13:58:15,338 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-06-25 13:52:20,261 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-25 13:39:51,060 [pool-13-thread-1] INFO server.RaftServer$Division: 76cadbf9-8202-4493-b276-7e4d9594dfab@group-61155FD5A026: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
scm3.org_1   | 2021-06-25 13:40:13,221 [pool-13-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.084c6adf-4c09-417d-ac5b-6ae661ceeb47@group-61155FD5A026
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:133)
scm1.org_1   | 2021-06-25 13:39:28,175 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
datanode3_1  | 2021-06-25 13:58:18,411 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-06-25 13:52:20,901 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm3.org_1   | 2021-06-25 13:40:13,223 [pool-13-thread-1] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm2.org_1   | 2021-06-25 13:39:51,061 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
scm1.org_1   | 2021-06-25 13:39:28,177 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
datanode3_1  | 2021-06-25 13:58:21,482 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-06-25 13:52:20,901 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39426
scm3.org_1   | 2021-06-25 13:40:13,227 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 16384 (custom)
scm2.org_1   | 2021-06-25 13:39:51,090 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
scm1.org_1   | 2021-06-25 13:39:28,178 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
datanode3_1  | 2021-06-25 13:58:24,554 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-06-25 13:52:20,902 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-25 13:40:13,238 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm2.org_1   | 2021-06-25 13:39:51,092 [pool-13-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/8e5d7696-3ffc-40b4-8848-61155fd5a026 does not exist. Creating ...
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
scm1.org_1   | 2021-06-25 13:39:28,189 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
datanode3_1  | 2021-06-25 13:58:27,627 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-06-25 13:52:21,699 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm3.org_1   | 2021-06-25 13:40:13,243 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
scm3.org_1   | 2021-06-25 13:40:13,255 [pool-13-thread-1] INFO segmented.SegmentedRaftLogWorker: new 084c6adf-4c09-417d-ac5b-6ae661ceeb47@group-61155FD5A026-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/8e5d7696-3ffc-40b4-8848-61155fd5a026
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm1.org_1   | 2021-06-25 13:39:28,192 [main] INFO server.RaftServer: 76093931-f232-4415-806f-239960e589cb: found a subdirectory /data/metadata/scm-ha/8e5d7696-3ffc-40b4-8848-61155fd5a026
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
datanode3_1  | 2021-06-25 13:58:30,698 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-06-25 13:52:21,700 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39438
scm3.org_1   | 2021-06-25 13:40:13,255 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
scm2.org_1   | 2021-06-25 13:39:51,110 [pool-13-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/8e5d7696-3ffc-40b4-8848-61155fd5a026/in_use.lock acquired by nodename 9@scm2.org
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm1.org_1   | 2021-06-25 13:39:28,196 [main] INFO server.RaftServer: 76093931-f232-4415-806f-239960e589cb: addNew group-61155FD5A026:[] returns group-61155FD5A026:java.util.concurrent.CompletableFuture@648c5fb3[Not completed]
om3_1        | 2021-06-25 13:51:03,687 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
datanode3_1  | 2021-06-25 13:58:33,770 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-06-25 13:52:21,700 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-25 13:40:13,261 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm2.org_1   | 2021-06-25 13:39:51,135 [pool-13-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/8e5d7696-3ffc-40b4-8848-61155fd5a026 has been successfully formatted.
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm1.org_1   | 2021-06-25 13:39:28,238 [pool-13-thread-1] INFO server.RaftServer$Division: 76093931-f232-4415-806f-239960e589cb: new RaftServerImpl for group-61155FD5A026:[] with SCMStateMachine:uninitialized
om3_1        | 2021-06-25 13:51:03,688 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:57468
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
datanode3_1  | 2021-06-25 13:58:39,914 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-06-25 13:52:22,357 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm3.org_1   | 2021-06-25 13:40:13,262 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 16384 (custom)
scm2.org_1   | 2021-06-25 13:39:51,139 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm1.org_1   | 2021-06-25 13:39:28,240 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
om3_1        | 2021-06-25 13:51:03,690 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
om2_1        | 2021-06-25 13:52:22,357 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39448
om2_1        | 2021-06-25 13:52:22,358 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-25 13:39:51,142 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om1_1        | 2021-06-25 13:52:35,162 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm1.org_1   | 2021-06-25 13:39:28,241 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om3_1        | 2021-06-25 13:51:05,144 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
s3g_1        | 2021-06-25 13:49:51,499 [qtp382627885-19] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-pycndgwpra, with Versioning false and Storage Type set to DISK and Encryption set to false 
datanode3_1  | 2021-06-25 13:58:42,986 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-06-25 13:52:23,019 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm3.org_1   | 2021-06-25 13:40:13,265 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
scm2.org_1   | 2021-06-25 13:39:51,150 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om1_1        | 2021-06-25 13:52:35,163 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40686
scm1.org_1   | 2021-06-25 13:39:28,241 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om3_1        | 2021-06-25 13:51:05,145 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:57480
s3g_1        | 2021-06-25 13:49:51,522 [qtp382627885-19] INFO endpoint.BucketEndpoint: Location is /bucket-pycndgwpra
datanode3_1  | 2021-06-25 13:58:46,062 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-06-25 13:52:23,019 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39456
scm3.org_1   | 2021-06-25 13:40:13,282 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm2.org_1   | 2021-06-25 13:39:51,151 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om1_1        | 2021-06-25 13:52:35,166 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-25 13:39:28,242 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
om3_1        | 2021-06-25 13:51:05,146 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 2021-06-25 13:49:51,586 [qtp382627885-19] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
datanode3_1  | 2021-06-25 13:58:49,130 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-06-25 13:52:23,028 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-25 13:40:13,286 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm2.org_1   | 2021-06-25 13:39:51,160 [pool-13-thread-1] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om1_1        | 2021-06-25 13:52:39,479 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:60810
scm1.org_1   | 2021-06-25 13:39:28,242 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om3_1        | 2021-06-25 13:51:06,879 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
datanode3_1  | 2021-06-25 13:58:52,202 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-06-25 13:52:23,658 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:52:23,658 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39466
scm2.org_1   | 2021-06-25 13:39:51,161 [pool-13-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.76cadbf9-8202-4493-b276-7e4d9594dfab@group-61155FD5A026
om1_1        | 2021-06-25 13:52:39,518 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-25 13:39:28,242 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om3_1        | 2021-06-25 13:51:06,879 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:57502
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
om2_1        | 2021-06-25 13:52:23,659 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-25 13:40:13,286 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode3_1  | 2021-06-25 13:58:55,274 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm2.org_1   | 2021-06-25 13:39:51,163 [pool-13-thread-1] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm2.org_1   | 2021-06-25 13:39:51,165 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 16384 (custom)
scm1.org_1   | 2021-06-25 13:39:28,243 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om3_1        | 2021-06-25 13:51:06,880 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om2_1        | 2021-06-25 13:52:24,297 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm3.org_1   | 2021-06-25 13:40:13,287 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode3_1  | 2021-06-25 13:58:58,346 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm2.org_1   | 2021-06-25 13:39:51,171 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om1_1        | 2021-06-25 13:52:42,515 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm1.org_1   | 2021-06-25 13:39:28,248 [pool-13-thread-1] INFO server.RaftServer$Division: 76093931-f232-4415-806f-239960e589cb@group-61155FD5A026: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
om3_1        | 2021-06-25 13:51:07,855 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om2_1        | 2021-06-25 13:52:24,298 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39474
scm3.org_1   | 2021-06-25 13:40:13,310 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
datanode3_1  | 2021-06-25 13:59:01,418 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm2.org_1   | 2021-06-25 13:39:51,172 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om1_1        | 2021-06-25 13:52:42,516 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40724
scm1.org_1   | 2021-06-25 13:39:28,248 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
om3_1        | 2021-06-25 13:51:07,855 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:57512
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om2_1        | 2021-06-25 13:52:24,300 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-25 13:40:13,312 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
datanode3_1  | 2021-06-25 13:59:04,490 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm2.org_1   | 2021-06-25 13:39:51,178 [pool-13-thread-1] INFO segmented.SegmentedRaftLogWorker: new 76cadbf9-8202-4493-b276-7e4d9594dfab@group-61155FD5A026-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/8e5d7696-3ffc-40b4-8848-61155fd5a026
om1_1        | 2021-06-25 13:52:42,517 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-25 13:39:28,251 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om3_1        | 2021-06-25 13:51:07,856 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:51:07,873 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 54205/multipartKey3 in Volume/Bucket s3v/bucket-04686
om2_1        | 2021-06-25 13:52:28,027 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:58360
scm3.org_1   | 2021-06-25 13:40:13,334 [pool-13-thread-1] INFO segmented.SegmentedRaftLogWorker: 084c6adf-4c09-417d-ac5b-6ae661ceeb47@group-61155FD5A026-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode3_1  | 2021-06-25 13:59:07,562 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm2.org_1   | 2021-06-25 13:39:51,178 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om1_1        | 2021-06-25 13:52:43,190 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:52:43,190 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40742
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
scm1.org_1   | 2021-06-25 13:39:28,269 [pool-13-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/8e5d7696-3ffc-40b4-8848-61155fd5a026/in_use.lock acquired by nodename 7@scm1.org
om2_1        | 2021-06-25 13:52:28,040 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-25 13:40:13,334 [pool-13-thread-1] INFO segmented.SegmentedRaftLogWorker: 084c6adf-4c09-417d-ac5b-6ae661ceeb47@group-61155FD5A026-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode3_1  | 2021-06-25 13:59:10,634 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm2.org_1   | 2021-06-25 13:39:51,179 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om1_1        | 2021-06-25 13:52:43,195 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-04686 key: 54205/multipartKey3. Provided Part info is { etag1, 1}, whereas OM has partName /s3v/bucket-04686/54205/multipartKey3106471690318512161
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
scm1.org_1   | 2021-06-25 13:39:28,278 [pool-13-thread-1] INFO storage.RaftStorage: Read RaftStorageMetadata{term=1, votedFor=76093931-f232-4415-806f-239960e589cb} from /data/metadata/scm-ha/8e5d7696-3ffc-40b4-8848-61155fd5a026/current/raft-meta
om2_1        | 2021-06-25 13:52:30,817 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm3.org_1   | 2021-06-25 13:40:13,340 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om1_1        | 2021-06-25 13:52:43,998 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
datanode3_1  | 2021-06-25 13:59:13,706 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
scm2.org_1   | 2021-06-25 13:39:51,180 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 16384 (custom)
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:446)
scm1.org_1   | 2021-06-25 13:39:28,308 [pool-13-thread-1] INFO server.RaftServer$Division: 76093931-f232-4415-806f-239960e589cb@group-61155FD5A026: set configuration 0: [76093931-f232-4415-806f-239960e589cb|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2021-06-25 13:40:13,355 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
om1_1        | 2021-06-25 13:52:43,999 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40756
datanode3_1  | 2021-06-25 13:59:16,778 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-06-25 13:52:30,817 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39546
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
scm2.org_1   | 2021-06-25 13:39:51,181 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:184)
scm1.org_1   | 2021-06-25 13:39:28,309 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm3.org_1   | 2021-06-25 13:40:13,358 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om1_1        | 2021-06-25 13:52:44,000 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode3_1  | 2021-06-25 13:59:19,850 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-06-25 13:52:30,827 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
scm2.org_1   | 2021-06-25 13:39:51,182 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
scm1.org_1   | 2021-06-25 13:39:28,311 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm3.org_1   | 2021-06-25 13:40:13,359 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
om1_1        | 2021-06-25 13:52:44,616 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:52:44,617 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40764
om1_1        | 2021-06-25 13:52:44,618 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:52:45,316 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:52:45,317 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40774
om1_1        | 2021-06-25 13:52:45,318 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:52:45,962 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:52:31,525 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:52:45,962 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40782
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
datanode3_1  | 2021-06-25 13:59:22,922 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm1.org_1   | 2021-06-25 13:39:28,319 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
om2_1        | 2021-06-25 13:52:31,525 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39558
scm3.org_1   | 2021-06-25 13:40:13,361 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
om1_1        | 2021-06-25 13:52:45,964 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
datanode3_1  | 2021-06-25 13:59:29,067 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm1.org_1   | 2021-06-25 13:39:28,320 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm2.org_1   | 2021-06-25 13:39:51,183 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm2.org_1   | 2021-06-25 13:39:51,184 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm2.org_1   | 2021-06-25 13:39:51,184 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm2.org_1   | 2021-06-25 13:39:51,194 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
scm2.org_1   | 2021-06-25 13:39:51,195 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
scm2.org_1   | 2021-06-25 13:39:51,203 [pool-13-thread-1] INFO segmented.SegmentedRaftLogWorker: 76cadbf9-8202-4493-b276-7e4d9594dfab@group-61155FD5A026-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm2.org_1   | 2021-06-25 13:39:51,203 [pool-13-thread-1] INFO segmented.SegmentedRaftLogWorker: 76cadbf9-8202-4493-b276-7e4d9594dfab@group-61155FD5A026-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm2.org_1   | 2021-06-25 13:39:51,211 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm2.org_1   | 2021-06-25 13:39:51,213 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
scm2.org_1   | 2021-06-25 13:39:51,214 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
scm2.org_1   | 2021-06-25 13:39:51,215 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm2.org_1   | 2021-06-25 13:39:51,217 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
scm2.org_1   | 2021-06-25 13:39:51,217 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm2.org_1   | 2021-06-25 13:39:51,242 [pool-13-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.76cadbf9-8202-4493-b276-7e4d9594dfab@group-61155FD5A026
scm2.org_1   | 2021-06-25 13:39:51,243 [pool-13-thread-1] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm2.org_1   | 2021-06-25 13:39:51,246 [pool-13-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.76cadbf9-8202-4493-b276-7e4d9594dfab@group-61155FD5A026
scm2.org_1   | 2021-06-25 13:39:51,247 [pool-13-thread-1] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm2.org_1   | 2021-06-25 13:39:51,258 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
scm2.org_1   | 2021-06-25 13:39:51,259 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
scm2.org_1   | 2021-06-25 13:39:51,260 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
scm2.org_1   | 2021-06-25 13:39:51,610 [main] INFO ha.SequenceIdGenerator: upgrade localId to 107544261427200000
scm2.org_1   | 2021-06-25 13:39:51,610 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
scm2.org_1   | 2021-06-25 13:39:51,615 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
scm2.org_1   | 2021-06-25 13:39:51,618 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
scm2.org_1   | 2021-06-25 13:39:51,699 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm2.org_1   | 2021-06-25 13:39:51,837 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm2.org_1   | 2021-06-25 13:39:51,853 [main] INFO pipeline.PipelineStateManager: No pipeline exists in current db
scm2.org_1   | 2021-06-25 13:39:51,900 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
scm2.org_1   | 2021-06-25 13:39:51,918 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
scm2.org_1   | 2021-06-25 13:39:51,918 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
scm2.org_1   | 2021-06-25 13:39:51,968 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
scm2.org_1   | 2021-06-25 13:39:51,998 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
scm2.org_1   | 2021-06-25 13:39:52,046 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
scm2.org_1   | 2021-06-25 13:39:52,052 [main] INFO container.ReplicationManager: Starting Replication Monitor Thread.
scm2.org_1   | 2021-06-25 13:39:52,065 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 0 containers.
scm2.org_1   | 2021-06-25 13:39:52,069 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
om1_1        | 2021-06-25 13:52:46,652 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:52:46,653 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40798
om1_1        | 2021-06-25 13:52:46,655 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:52:47,357 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
datanode3_1  | 2021-06-25 13:59:32,138 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-25 13:59:35,210 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
om2_1        | 2021-06-25 13:52:31,526 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:52:47,357 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40808
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm1.org_1   | 2021-06-25 13:39:28,333 [pool-13-thread-1] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm3.org_1   | 2021-06-25 13:40:13,363 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om2_1        | 2021-06-25 13:52:32,330 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
datanode3_1  | 2021-06-25 13:59:38,282 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm2.org_1   | 2021-06-25 13:39:52,143 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
om1_1        | 2021-06-25 13:52:47,358 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:52:48,078 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm1.org_1   | 2021-06-25 13:39:28,339 [pool-13-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.76093931-f232-4415-806f-239960e589cb@group-61155FD5A026
scm3.org_1   | 2021-06-25 13:40:13,411 [pool-13-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.084c6adf-4c09-417d-ac5b-6ae661ceeb47@group-61155FD5A026
om2_1        | 2021-06-25 13:52:32,330 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39570
datanode3_1  | 2021-06-25 13:59:41,354 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm2.org_1   | 2021-06-25 13:39:52,155 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
om1_1        | 2021-06-25 13:52:48,079 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40820
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
scm1.org_1   | 2021-06-25 13:39:28,342 [pool-13-thread-1] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
om2_1        | 2021-06-25 13:52:32,331 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode3_1  | 2021-06-25 13:59:44,426 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm2.org_1   | 2021-06-25 13:39:52,244 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
om1_1        | 2021-06-25 13:52:48,080 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 2021-06-25 13:49:51,677 [qtp382627885-19] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm3.org_1   | 2021-06-25 13:40:13,418 [pool-13-thread-1] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm1.org_1   | 2021-06-25 13:39:28,345 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 16384 (custom)
om2_1        | 2021-06-25 13:52:33,064 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
datanode3_1  | 2021-06-25 13:59:47,498 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm2.org_1   | 2021-06-25 13:39:52,305 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om1_1        | 2021-06-25 13:52:49,036 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm3.org_1   | 2021-06-25 13:40:13,427 [pool-13-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.084c6adf-4c09-417d-ac5b-6ae661ceeb47@group-61155FD5A026
scm1.org_1   | 2021-06-25 13:39:28,351 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om2_1        | 2021-06-25 13:52:33,065 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39582
datanode3_1  | 2021-06-25 13:59:50,574 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm2.org_1   | 2021-06-25 13:39:52,367 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
om1_1        | 2021-06-25 13:52:49,037 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40838
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
om3_1        | 2021-06-25 13:51:08,546 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm3.org_1   | 2021-06-25 13:40:13,428 [pool-13-thread-1] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm1.org_1   | 2021-06-25 13:39:28,352 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om2_1        | 2021-06-25 13:52:33,065 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode3_1  | 2021-06-25 13:59:53,646 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm2.org_1   | 2021-06-25 13:39:53,932 [Listener at 0.0.0.0/9961] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om1_1        | 2021-06-25 13:52:49,038 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om3_1        | 2021-06-25 13:51:08,547 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:57524
scm3.org_1   | 2021-06-25 13:40:13,463 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
scm1.org_1   | 2021-06-25 13:39:28,359 [pool-13-thread-1] INFO segmented.SegmentedRaftLogWorker: new 76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/8e5d7696-3ffc-40b4-8848-61155fd5a026
om2_1        | 2021-06-25 13:52:33,824 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
datanode3_1  | 2021-06-25 13:59:56,714 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm2.org_1   | 2021-06-25 13:39:53,958 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om1_1        | 2021-06-25 13:52:49,616 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om3_1        | 2021-06-25 13:51:08,548 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-25 13:40:13,468 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
scm1.org_1   | 2021-06-25 13:39:28,360 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
datanode3_1  | 2021-06-25 13:59:59,786 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm2.org_1   | 2021-06-25 13:39:53,940 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
om1_1        | 2021-06-25 13:52:49,616 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40848
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om3_1        | 2021-06-25 13:51:08,578 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 54205/multipartKey3 in Volume/Bucket s3v/bucket-04686
scm3.org_1   | 2021-06-25 13:40:13,478 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
scm1.org_1   | 2021-06-25 13:39:28,361 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om2_1        | 2021-06-25 13:52:33,825 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39592
datanode3_1  | 2021-06-25 14:00:02,887 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm2.org_1   | 2021-06-25 13:39:53,959 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
om1_1        | 2021-06-25 13:52:49,617 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om3_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-04686 key: 54205/multipartKey3. Provided Part info is { etag2, 2}, whereas OM has partName /s3v/bucket-04686/54205/multipartKey3106471690413867042
scm3.org_1   | 2021-06-25 13:40:14,146 [main] INFO ha.SequenceIdGenerator: upgrade localId to 107544261427200000
scm1.org_1   | 2021-06-25 13:39:28,363 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 16384 (custom)
om2_1        | 2021-06-25 13:52:33,825 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode3_1  | 2021-06-25 14:00:05,930 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm2.org_1   | 2021-06-25 13:39:54,019 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om1_1        | 2021-06-25 13:52:50,320 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:446)
scm3.org_1   | 2021-06-25 13:40:14,147 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
scm1.org_1   | 2021-06-25 13:39:28,364 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
om2_1        | 2021-06-25 13:52:34,467 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
datanode3_1  | 2021-06-25 14:00:09,002 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm2.org_1   | 2021-06-25 13:39:54,022 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
om1_1        | 2021-06-25 13:52:50,320 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40860
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:184)
scm3.org_1   | 2021-06-25 13:40:14,159 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
scm1.org_1   | 2021-06-25 13:39:28,364 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om2_1        | 2021-06-25 13:52:34,467 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39604
datanode3_1  | 2021-06-25 14:00:12,074 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm2.org_1   | 2021-06-25 13:39:54,250 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: 
om1_1        | 2021-06-25 13:52:50,322 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
scm3.org_1   | 2021-06-25 13:40:14,170 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
scm1.org_1   | 2021-06-25 13:39:28,366 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om2_1        | 2021-06-25 13:52:34,468 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode3_1  | 2021-06-25 14:00:18,218 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm2.org_1   | Container Balancer status:
om1_1        | 2021-06-25 13:52:51,002 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
scm3.org_1   | 2021-06-25 13:40:14,306 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm1.org_1   | 2021-06-25 13:39:28,366 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om2_1        | 2021-06-25 13:52:34,530 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:s3v, Bucket:bucket-96700, Key:29528/multidelete/f4.
datanode3_1  | 2021-06-25 14:00:21,294 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm2.org_1   | Key                            Value
om1_1        | 2021-06-25 13:52:51,002 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40870
om1_1        | 2021-06-25 13:52:51,003 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-25 13:40:14,548 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
scm1.org_1   | 2021-06-25 13:39:28,367 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om2_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
scm2.org_1   | Running                        true
scm2.org_1   | Container Balancer Configuration values:
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
scm3.org_1   | 2021-06-25 13:40:14,595 [main] INFO pipeline.PipelineStateManager: No pipeline exists in current db
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm1.org_1   | 2021-06-25 13:39:28,375 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:133)
om1_1        | 2021-06-25 13:52:51,672 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm2.org_1   | Key                            Value
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm3.org_1   | 2021-06-25 13:40:14,683 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm1.org_1   | 2021-06-25 13:39:28,376 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
om1_1        | 2021-06-25 13:52:51,673 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40884
scm2.org_1   | Threshold                      0.1
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm3.org_1   | 2021-06-25 13:40:14,706 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm1.org_1   | 2021-06-25 13:39:28,400 [pool-13-thread-1] INFO server.RaftServer$Division: 76093931-f232-4415-806f-239960e589cb@group-61155FD5A026: set configuration 0: [76093931-f232-4415-806f-239960e589cb|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
om1_1        | 2021-06-25 13:52:51,674 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | Max Datanodes to Balance       5
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
scm3.org_1   | 2021-06-25 13:40:14,706 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm1.org_1   | 2021-06-25 13:39:28,401 [pool-13-thread-1] INFO segmented.LogSegment: Successfully read 1 entries from segment file /data/metadata/scm-ha/8e5d7696-3ffc-40b4-8848-61155fd5a026/current/log_inprogress_0
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
om1_1        | 2021-06-25 13:52:52,412 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm2.org_1   | Max Size to Move               10737418240B
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
scm3.org_1   | 2021-06-25 13:40:14,785 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
om3_1        | 2021-06-25 13:51:09,194 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm1.org_1   | 2021-06-25 13:39:28,404 [pool-13-thread-1] INFO segmented.SegmentedRaftLogWorker: 76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 0
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 2021-06-25 13:52:52,413 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40896
scm2.org_1   | 
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
scm3.org_1   | 2021-06-25 13:40:14,877 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
scm3.org_1   | 2021-06-25 13:40:14,916 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
scm1.org_1   | 2021-06-25 13:39:28,404 [pool-13-thread-1] INFO segmented.SegmentedRaftLogWorker: 76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 2021-06-25 13:52:52,414 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-25 13:39:54,250 [Listener at 0.0.0.0/9860] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm3.org_1   | 2021-06-25 13:40:14,930 [main] INFO container.ReplicationManager: Starting Replication Monitor Thread.
om3_1        | 2021-06-25 13:51:09,195 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:57532
s3g_1        | 2021-06-25 13:49:51,727 [qtp382627885-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
scm1.org_1   | 2021-06-25 13:39:28,468 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 2021-06-25 13:52:53,191 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm2.org_1   | 2021-06-25 13:39:54,251 [Listener at 0.0.0.0/9860] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
scm3.org_1   | 2021-06-25 13:40:14,943 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 2 milliseconds for processing 0 containers.
om3_1        | 2021-06-25 13:51:09,195 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
scm1.org_1   | 2021-06-25 13:39:28,469 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1        | 2021-06-25 13:52:53,192 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40908
scm2.org_1   | 2021-06-25 13:39:54,260 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm3.org_1   | 2021-06-25 13:40:14,955 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
om3_1        | 2021-06-25 13:51:09,215 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: PartNumber at index 1 is 2, and its previous partNumber at index 0 is 4 for ozonekey is /s3v/bucket-04686/54205/multipartKey3
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
scm1.org_1   | 2021-06-25 13:39:28,469 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om2_1        | 2021-06-25 13:52:35,171 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:52:53,200 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-25 13:39:54,264 [Listener at 0.0.0.0/9860] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
scm3.org_1   | 2021-06-25 13:40:14,970 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
om3_1        | 2021-06-25 13:51:09,220 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 54205/multipartKey3 in Volume/Bucket s3v/bucket-04686
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
scm1.org_1   | 2021-06-25 13:39:28,470 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
om2_1        | 2021-06-25 13:52:35,171 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39614
om1_1        | 2021-06-25 13:52:53,888 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm2.org_1   | 2021-06-25 13:39:54,275 [Listener at 0.0.0.0/9860] INFO server.RaftServer$Division: 76cadbf9-8202-4493-b276-7e4d9594dfab@group-61155FD5A026: start with initializing state, conf=-1: [], old=null
scm3.org_1   | 2021-06-25 13:40:14,981 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
om3_1        | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-04686 key: 54205/multipartKey3 because parts are in Invalid order.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
scm1.org_1   | 2021-06-25 13:39:28,471 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
om2_1        | 2021-06-25 13:52:35,173 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:52:39,582 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:58500
scm2.org_1   | 2021-06-25 13:39:54,280 [Listener at 0.0.0.0/9860] INFO server.RaftServer$Division: 76cadbf9-8202-4493-b276-7e4d9594dfab@group-61155FD5A026: changes role from      null to FOLLOWER at term 0 for startInitializing
scm3.org_1   | 2021-06-25 13:40:15,087 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getPartsListSize(S3MultipartUploadCompleteRequest.java:412)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om2_1        | 2021-06-25 13:52:39,597 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:52:53,888 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40918
scm1.org_1   | 2021-06-25 13:39:28,471 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm1.org_1   | 2021-06-25 13:39:28,492 [pool-13-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.76093931-f232-4415-806f-239960e589cb@group-61155FD5A026
scm3.org_1   | 2021-06-25 13:40:15,163 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:180)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om2_1        | 2021-06-25 13:52:42,521 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:52:53,895 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-25 13:39:28,492 [pool-13-thread-1] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm2.org_1   | 2021-06-25 13:39:54,281 [Listener at 0.0.0.0/9860] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-61155FD5A026,id=76cadbf9-8202-4493-b276-7e4d9594dfab
scm3.org_1   | 2021-06-25 13:40:15,218 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om2_1        | 2021-06-25 13:52:42,521 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39652
om1_1        | 2021-06-25 13:52:54,579 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm1.org_1   | 2021-06-25 13:39:28,497 [pool-13-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.76093931-f232-4415-806f-239960e589cb@group-61155FD5A026
scm2.org_1   | 2021-06-25 13:39:54,282 [Listener at 0.0.0.0/9860] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.76cadbf9-8202-4493-b276-7e4d9594dfab@group-61155FD5A026
scm3.org_1   | 2021-06-25 13:40:17,120 [Listener at 0.0.0.0/9961] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om2_1        | 2021-06-25 13:52:42,522 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:52:54,581 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40928
scm1.org_1   | 2021-06-25 13:39:28,497 [pool-13-thread-1] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm2.org_1   | 2021-06-25 13:39:54,283 [Listener at 0.0.0.0/9860] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm3.org_1   | 2021-06-25 13:40:17,126 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
om2_1        | 2021-06-25 13:52:43,199 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:52:54,584 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-25 13:39:28,519 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
scm2.org_1   | 2021-06-25 13:39:54,302 [Listener at 0.0.0.0/9860] INFO server.RaftServer: 76cadbf9-8202-4493-b276-7e4d9594dfab: start RPC server
scm3.org_1   | 2021-06-25 13:40:17,173 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
om2_1        | 2021-06-25 13:52:43,199 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39670
om1_1        | 2021-06-25 13:52:55,299 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm1.org_1   | 2021-06-25 13:39:28,519 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
scm2.org_1   | 2021-06-25 13:39:54,369 [Listener at 0.0.0.0/9860] INFO server.GrpcService: 76cadbf9-8202-4493-b276-7e4d9594dfab: GrpcService started, listening on 9894
scm3.org_1   | 2021-06-25 13:40:17,174 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
om2_1        | 2021-06-25 13:52:43,201 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:52:55,300 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40948
scm1.org_1   | 2021-06-25 13:39:28,520 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
scm2.org_1   | 2021-06-25 13:39:54,382 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
scm3.org_1   | 2021-06-25 13:40:17,230 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om2_1        | 2021-06-25 13:52:44,004 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:52:55,302 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-25 13:39:28,809 [main] INFO ha.SequenceIdGenerator: upgrade localId to 107544261427200000
scm2.org_1   | 2021-06-25 13:39:54,383 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$390/0x00000008404d7c40@2c9aeec6] INFO util.JvmPauseMonitor: JvmPauseMonitor-76cadbf9-8202-4493-b276-7e4d9594dfab: Started
scm3.org_1   | 2021-06-25 13:40:17,248 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om2_1        | 2021-06-25 13:52:44,004 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39684
om1_1        | 2021-06-25 13:52:55,941 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm1.org_1   | 2021-06-25 13:39:28,809 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
scm2.org_1   | 2021-06-25 13:39:54,382 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
scm3.org_1   | 2021-06-25 13:40:17,334 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: 
om3_1        | 2021-06-25 13:51:09,847 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
om2_1        | 2021-06-25 13:52:44,005 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:52:55,942 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40960
scm1.org_1   | 2021-06-25 13:39:28,814 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
scm1.org_1   | 2021-06-25 13:39:28,816 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
scm2.org_1   | 2021-06-25 13:39:54,393 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
om3_1        | 2021-06-25 13:51:09,848 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:57542
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
om2_1        | 2021-06-25 13:52:44,622 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:52:55,943 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-25 13:39:28,878 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm3.org_1   | Container Balancer status:
scm2.org_1   | 2021-06-25 13:39:57,575 [grpc-default-executor-0] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server_message_metrics.76cadbf9-8202-4493-b276-7e4d9594dfab
om3_1        | 2021-06-25 13:51:09,849 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
om2_1        | 2021-06-25 13:52:44,622 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39692
om1_1        | 2021-06-25 13:52:56,593 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm1.org_1   | 2021-06-25 13:39:28,967 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm3.org_1   | Key                            Value
scm2.org_1   | 2021-06-25 13:39:57,578 [grpc-default-executor-0] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
om3_1        | 2021-06-25 13:51:10,557 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
s3g_1        | 2021-06-25 13:49:51,826 [qtp382627885-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
om2_1        | 2021-06-25 13:52:44,624 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:52:56,594 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40968
scm1.org_1   | 2021-06-25 13:39:28,986 [main] INFO pipeline.PipelineStateManager: No pipeline exists in current db
scm3.org_1   | Running                        true
scm2.org_1   | 2021-06-25 13:39:57,730 [grpc-default-executor-0] INFO ha.SCMStateMachine: leader changed, yet current SCM is still follower.
om3_1        | 2021-06-25 13:51:10,558 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:57550
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
om2_1        | 2021-06-25 13:52:45,322 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:52:56,595 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-25 13:53:01,241 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:32878
scm3.org_1   | Container Balancer Configuration values:
scm2.org_1   | 2021-06-25 13:39:57,730 [grpc-default-executor-0] INFO server.RaftServer$Division: 76cadbf9-8202-4493-b276-7e4d9594dfab@group-61155FD5A026: change Leader from null to 76093931-f232-4415-806f-239960e589cb at term 2 for appendEntries, leader elected after 6591ms
om3_1        | 2021-06-25 13:51:10,565 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
om1_1        | 2021-06-25 13:53:01,259 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-25 13:39:29,047 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
om2_1        | 2021-06-25 13:52:45,323 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39702
om2_1        | 2021-06-25 13:52:45,323 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:52:45,968 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm2.org_1   | 2021-06-25 13:39:57,738 [grpc-default-executor-0] INFO impl.RoleInfo: 76cadbf9-8202-4493-b276-7e4d9594dfab: start 76cadbf9-8202-4493-b276-7e4d9594dfab@group-61155FD5A026-FollowerState
om3_1        | 2021-06-25 13:51:11,670 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1        | 2021-06-25 13:53:04,338 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:52:45,969 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39710
scm3.org_1   | Key                            Value
scm1.org_1   | 2021-06-25 13:39:29,067 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
scm2.org_1   | 2021-06-25 13:39:57,961 [grpc-default-executor-0] INFO server.RaftServer$Division: 76cadbf9-8202-4493-b276-7e4d9594dfab@group-61155FD5A026: set configuration 0: [76093931-f232-4415-806f-239960e589cb|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
om3_1        | 2021-06-25 13:51:11,671 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:57568
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1        | 2021-06-25 13:53:04,339 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41024
om2_1        | 2021-06-25 13:52:45,970 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | Threshold                      0.1
scm1.org_1   | 2021-06-25 13:39:29,067 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
scm2.org_1   | 2021-06-25 13:39:57,974 [grpc-default-executor-0] INFO server.RaftServer$Division: 76cadbf9-8202-4493-b276-7e4d9594dfab@group-61155FD5A026: set configuration 1: [76093931-f232-4415-806f-239960e589cb|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
om3_1        | 2021-06-25 13:51:11,672 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:51:12,410 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om1_1        | 2021-06-25 13:53:04,351 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:52:46,658 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm3.org_1   | Max Datanodes to Balance       5
scm1.org_1   | 2021-06-25 13:39:29,157 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
scm1.org_1   | 2021-06-25 13:39:29,200 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
scm2.org_1   | 2021-06-25 13:39:57,983 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 76cadbf9-8202-4493-b276-7e4d9594dfab@group-61155FD5A026-SegmentedRaftLogWorker: Starting segment from index:0
om1_1        | 2021-06-25 13:53:21,224 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:32964
om2_1        | 2021-06-25 13:52:46,659 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39726
scm3.org_1   | Max Size to Move               10737418240B
scm1.org_1   | 2021-06-25 13:39:29,212 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
om3_1        | 2021-06-25 13:51:12,410 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:57584
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
scm2.org_1   | 2021-06-25 13:39:58,032 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 76cadbf9-8202-4493-b276-7e4d9594dfab@group-61155FD5A026-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
om1_1        | 2021-06-25 13:53:21,241 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:52:46,661 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 
scm1.org_1   | 2021-06-25 13:39:29,218 [main] INFO container.ReplicationManager: Starting Replication Monitor Thread.
scm1.org_1   | 2021-06-25 13:39:29,228 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 0 containers.
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
scm2.org_1   | 2021-06-25 13:39:58,450 [76cadbf9-8202-4493-b276-7e4d9594dfab@group-61155FD5A026-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 76cadbf9-8202-4493-b276-7e4d9594dfab@group-61155FD5A026-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/8e5d7696-3ffc-40b4-8848-61155fd5a026/current/log_inprogress_0
om1_1        | 2021-06-25 13:57:05,771 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:34422
om2_1        | 2021-06-25 13:52:47,362 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm3.org_1   | 2021-06-25 13:40:17,334 [Listener at 0.0.0.0/9860] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm1.org_1   | 2021-06-25 13:39:29,237 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
om3_1        | 2021-06-25 13:51:12,412 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
scm2.org_1   | 2021-06-25 13:39:58,467 [76cadbf9-8202-4493-b276-7e4d9594dfab@group-61155FD5A026-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 76cadbf9-8202-4493-b276-7e4d9594dfab@group-61155FD5A026-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/8e5d7696-3ffc-40b4-8848-61155fd5a026/current/log_inprogress_0 to /data/metadata/scm-ha/8e5d7696-3ffc-40b4-8848-61155fd5a026/current/log_0-0
om1_1        | 2021-06-25 13:57:05,788 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:52:47,362 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39736
scm3.org_1   | 2021-06-25 13:40:17,334 [Listener at 0.0.0.0/9860] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
scm1.org_1   | 2021-06-25 13:39:29,244 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
om3_1        | 2021-06-25 13:51:13,132 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
scm2.org_1   | 2021-06-25 13:39:58,495 [76cadbf9-8202-4493-b276-7e4d9594dfab@group-61155FD5A026-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 76cadbf9-8202-4493-b276-7e4d9594dfab@group-61155FD5A026-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/8e5d7696-3ffc-40b4-8848-61155fd5a026/current/log_inprogress_1
om2_1        | 2021-06-25 13:52:47,363 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-25 13:40:17,338 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm2.org_1   | 2021-06-25 13:39:58,566 [76cadbf9-8202-4493-b276-7e4d9594dfab@group-61155FD5A026-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2021-06-25 13:39:29,247 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
om3_1        | 2021-06-25 13:51:13,133 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:57596
om2_1        | 2021-06-25 13:52:48,084 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
scm3.org_1   | 2021-06-25 13:40:17,341 [Listener at 0.0.0.0/9860] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
scm2.org_1   | 2021-06-25 13:39:58,569 [76cadbf9-8202-4493-b276-7e4d9594dfab@group-61155FD5A026-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
scm1.org_1   | 2021-06-25 13:39:29,287 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
om3_1        | 2021-06-25 13:51:13,134 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:52:48,085 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39748
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
scm3.org_1   | 2021-06-25 13:40:17,342 [Listener at 0.0.0.0/9860] INFO server.RaftServer$Division: 084c6adf-4c09-417d-ac5b-6ae661ceeb47@group-61155FD5A026: start with initializing state, conf=-1: [], old=null
scm2.org_1   | 2021-06-25 13:39:58,574 [76cadbf9-8202-4493-b276-7e4d9594dfab@group-61155FD5A026-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm1.org_1   | 2021-06-25 13:39:29,299 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
om3_1        | 2021-06-25 13:51:13,163 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadAbortRequest: Abort Multipart request is failed for KeyName 82586/multipartKey5 in VolumeName/Bucket s3v/bucket-04686
om2_1        | 2021-06-25 13:52:48,085 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm3.org_1   | 2021-06-25 13:40:17,344 [Listener at 0.0.0.0/9860] INFO server.RaftServer$Division: 084c6adf-4c09-417d-ac5b-6ae661ceeb47@group-61155FD5A026: changes role from      null to FOLLOWER at term 0 for startInitializing
scm2.org_1   | 2021-06-25 13:39:58,577 [76cadbf9-8202-4493-b276-7e4d9594dfab@group-61155FD5A026-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: RPC server for DataNodes is listening at /0.0.0.0:9861
scm1.org_1   | 2021-06-25 13:39:29,300 [main] INFO server.StorageContainerManager: Storing sub-ca certificate serialId 2884006640668 on primary SCM
om3_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: s3vbucket: bucket-04686key: 82586/multipartKey5
om2_1        | 2021-06-25 13:52:49,043 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm3.org_1   | 2021-06-25 13:40:17,347 [Listener at 0.0.0.0/9860] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-61155FD5A026,id=084c6adf-4c09-417d-ac5b-6ae661ceeb47
scm2.org_1   | 2021-06-25 13:39:58,601 [grpc-default-executor-0] INFO server.RaftServer$Division: 76cadbf9-8202-4493-b276-7e4d9594dfab@group-61155FD5A026: set configuration 5: [76cadbf9-8202-4493-b276-7e4d9594dfab|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, 76093931-f232-4415-806f-239960e589cb|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=[76093931-f232-4415-806f-239960e589cb|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm1.org_1   | 2021-06-25 13:39:29,310 [main] INFO server.StorageContainerManager: Storing root certificate serialId 1
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:148)
om2_1        | 2021-06-25 13:52:49,043 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39766
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
scm3.org_1   | 2021-06-25 13:40:17,353 [Listener at 0.0.0.0/9860] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.084c6adf-4c09-417d-ac5b-6ae661ceeb47@group-61155FD5A026
scm2.org_1   | 2021-06-25 13:39:58,606 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm1.org_1   | 2021-06-25 13:39:29,354 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
om2_1        | 2021-06-25 13:52:49,044 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
scm3.org_1   | 2021-06-25 13:40:17,354 [Listener at 0.0.0.0/9860] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm2.org_1   | 2021-06-25 13:39:58,872 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm1.org_1   | 2021-06-25 13:39:29,380 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
om2_1        | 2021-06-25 13:52:49,622 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
scm2.org_1   | 2021-06-25 13:39:58,960 [grpc-default-executor-0] INFO server.RaftServer$Division: 76cadbf9-8202-4493-b276-7e4d9594dfab@group-61155FD5A026: set configuration 7: [76cadbf9-8202-4493-b276-7e4d9594dfab|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, 76093931-f232-4415-806f-239960e589cb|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2021-06-25 13:40:17,362 [Listener at 0.0.0.0/9860] INFO server.RaftServer: 084c6adf-4c09-417d-ac5b-6ae661ceeb47: start RPC server
scm1.org_1   | 2021-06-25 13:39:30,319 [Listener at 0.0.0.0/9961] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
om2_1        | 2021-06-25 13:52:49,623 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39776
s3g_1        | 2021-06-25 13:49:51,887 [qtp382627885-17] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-3F5080514A69->d7f71981-d306-415b-992d-ee4808a385fa
scm2.org_1   | 2021-06-25 13:39:59,114 [76cadbf9-8202-4493-b276-7e4d9594dfab@group-61155FD5A026-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2021-06-25 13:40:17,506 [Listener at 0.0.0.0/9860] INFO server.GrpcService: 084c6adf-4c09-417d-ac5b-6ae661ceeb47: GrpcService started, listening on 9894
scm1.org_1   | 2021-06-25 13:39:30,325 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 2021-06-25 13:52:49,623 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 2021-06-25 13:49:51,887 [qtp382627885-17] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm2.org_1   | 2021-06-25 13:39:59,124 [76cadbf9-8202-4493-b276-7e4d9594dfab@group-61155FD5A026-StateMachineUpdater] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm3.org_1   | 2021-06-25 13:40:17,521 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$393/0x00000008404d7c40@7ef7faa9] INFO util.JvmPauseMonitor: JvmPauseMonitor-084c6adf-4c09-417d-ac5b-6ae661ceeb47: Started
scm1.org_1   | 2021-06-25 13:39:30,348 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 2021-06-25 13:52:50,326 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
s3g_1        | 2021-06-25 13:49:52,057 [qtp382627885-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
scm3.org_1   | 2021-06-25 13:40:17,531 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
scm1.org_1   | 2021-06-25 13:39:30,355 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 2021-06-25 13:52:50,326 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39788
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
scm2.org_1   | 2021-06-25 13:39:59,130 [76cadbf9-8202-4493-b276-7e4d9594dfab@group-61155FD5A026-StateMachineUpdater] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm3.org_1   | 2021-06-25 13:40:17,532 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
scm1.org_1   | 2021-06-25 13:39:30,385 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om2_1        | 2021-06-25 13:52:50,329 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
scm2.org_1   | 2021-06-25 13:39:59,207 [Listener at 0.0.0.0/9860] INFO ha.SCMHAManagerImpl: Successfully added SCM scm2 to group group-61155FD5A026:[76cadbf9-8202-4493-b276-7e4d9594dfab|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, 76093931-f232-4415-806f-239960e589cb|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm3.org_1   | 2021-06-25 13:40:17,532 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
scm1.org_1   | 2021-06-25 13:39:30,386 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
om3_1        | 2021-06-25 13:51:13,813 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:52:51,009 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
scm2.org_1   | 2021-06-25 13:39:59,230 [Listener at 0.0.0.0/9860] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
scm3.org_1   | 2021-06-25 13:40:20,750 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$393/0x00000008404d7c40@7ef7faa9] WARN util.JvmPauseMonitor: JvmPauseMonitor-084c6adf-4c09-417d-ac5b-6ae661ceeb47: Detected pause in JVM or host machine (eg GC): pause of approximately 201557744ns.
scm1.org_1   | 2021-06-25 13:39:30,527 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: 
om3_1        | 2021-06-25 13:51:13,813 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:57606
om2_1        | 2021-06-25 13:52:51,009 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39798
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
scm2.org_1   | 2021-06-25 13:39:59,233 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Starting token manager
scm3.org_1   | GC pool 'ParNew' had collection(s): count=1 time=218ms
scm1.org_1   | Container Balancer status:
om3_1        | 2021-06-25 13:51:13,816 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:51:13,834 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyCreateRequest: Key creation failed. Volume:s3v, Bucket:bucket-04686, Key31669/multipartKey. Exception:{}
om2_1        | 2021-06-25 13:52:51,010 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-25 13:40:24,618 [grpc-default-executor-0] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server_message_metrics.084c6adf-4c09-417d-ac5b-6ae661ceeb47
scm2.org_1   | 2021-06-25 13:39:59,233 [Listener at 0.0.0.0/9860] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
scm1.org_1   | Key                            Value
om3_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
om2_1        | 2021-06-25 13:52:51,678 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm3.org_1   | 2021-06-25 13:40:24,628 [grpc-default-executor-0] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm2.org_1   | 2021-06-25 13:39:59,455 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
scm1.org_1   | Running                        true
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartFileInfo(OMKeyRequest.java:708)
om2_1        | 2021-06-25 13:52:51,678 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39812
scm3.org_1   | 2021-06-25 13:40:24,852 [grpc-default-executor-0] INFO ha.SCMStateMachine: leader changed, yet current SCM is still follower.
scm2.org_1   | 2021-06-25 13:39:59,521 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
scm1.org_1   | Container Balancer Configuration values:
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareFileInfo(OMKeyRequest.java:600)
om2_1        | 2021-06-25 13:52:51,679 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-25 13:40:24,853 [grpc-default-executor-0] INFO server.RaftServer$Division: 084c6adf-4c09-417d-ac5b-6ae661ceeb47@group-61155FD5A026: change Leader from null to 76093931-f232-4415-806f-239960e589cb at term 2 for appendEntries, leader elected after 11686ms
scm2.org_1   | 2021-06-25 13:39:59,521 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
scm1.org_1   | Key                            Value
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:577)
om2_1        | 2021-06-25 13:52:52,419 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm3.org_1   | 2021-06-25 13:40:24,858 [grpc-default-executor-0] INFO impl.RoleInfo: 084c6adf-4c09-417d-ac5b-6ae661ceeb47: start 084c6adf-4c09-417d-ac5b-6ae661ceeb47@group-61155FD5A026-FollowerState
scm2.org_1   | 2021-06-25 13:40:00,266 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
scm1.org_1   | Threshold                      0.1
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyCreateRequest.validateAndUpdateCache(OMKeyCreateRequest.java:278)
om2_1        | 2021-06-25 13:52:52,420 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39824
scm3.org_1   | 2021-06-25 13:40:25,418 [grpc-default-executor-0] INFO server.RaftServer$Division: 084c6adf-4c09-417d-ac5b-6ae661ceeb47@group-61155FD5A026: set configuration 0: [76093931-f232-4415-806f-239960e589cb|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2021-06-25 13:40:00,340 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
scm1.org_1   | Max Datanodes to Balance       5
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
om2_1        | 2021-06-25 13:52:52,421 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-25 13:40:25,419 [grpc-default-executor-0] INFO server.RaftServer$Division: 084c6adf-4c09-417d-ac5b-6ae661ceeb47@group-61155FD5A026: set configuration 1: [76093931-f232-4415-806f-239960e589cb|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2021-06-25 13:40:00,346 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm1.org_1   | Max Size to Move               10737418240B
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
om2_1        | 2021-06-25 13:52:53,204 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm3.org_1   | 2021-06-25 13:40:25,420 [grpc-default-executor-0] INFO server.RaftServer$Division: 084c6adf-4c09-417d-ac5b-6ae661ceeb47@group-61155FD5A026: set configuration 5: [76cadbf9-8202-4493-b276-7e4d9594dfab|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, 76093931-f232-4415-806f-239960e589cb|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=[76093931-f232-4415-806f-239960e589cb|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm2.org_1   | 2021-06-25 13:40:00,463 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm1.org_1   | 
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
om2_1        | 2021-06-25 13:52:53,205 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39836
scm3.org_1   | 2021-06-25 13:40:25,423 [grpc-default-executor-0] INFO server.RaftServer$Division: 084c6adf-4c09-417d-ac5b-6ae661ceeb47@group-61155FD5A026: set configuration 7: [76cadbf9-8202-4493-b276-7e4d9594dfab|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, 76093931-f232-4415-806f-239960e589cb|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2021-06-25 13:40:00,464 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
scm1.org_1   | 2021-06-25 13:39:30,527 [Listener at 0.0.0.0/9860] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 2021-06-25 13:52:53,208 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-25 13:40:25,446 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 084c6adf-4c09-417d-ac5b-6ae661ceeb47@group-61155FD5A026-SegmentedRaftLogWorker: Starting segment from index:0
scm2.org_1   | 2021-06-25 13:40:00,464 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
scm1.org_1   | 2021-06-25 13:39:30,530 [Listener at 0.0.0.0/9860] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 2021-06-25 13:52:53,899 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm3.org_1   | 2021-06-25 13:40:25,610 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 084c6adf-4c09-417d-ac5b-6ae661ceeb47@group-61155FD5A026-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
scm2.org_1   | 2021-06-25 13:40:00,464 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
scm1.org_1   | 2021-06-25 13:39:30,561 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 2021-06-25 13:52:53,901 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39846
scm3.org_1   | 2021-06-25 13:40:26,217 [084c6adf-4c09-417d-ac5b-6ae661ceeb47@group-61155FD5A026-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 084c6adf-4c09-417d-ac5b-6ae661ceeb47@group-61155FD5A026-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/8e5d7696-3ffc-40b4-8848-61155fd5a026/current/log_inprogress_0
scm2.org_1   | 2021-06-25 13:40:00,526 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmDatanodeProtocl RPC server is listening at /0.0.0.0:9861
s3g_1        | 2021-06-25 13:49:52,215 [qtp382627885-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
scm1.org_1   | 2021-06-25 13:39:30,562 [Listener at 0.0.0.0/9860] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om2_1        | 2021-06-25 13:52:53,901 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-25 13:40:26,227 [084c6adf-4c09-417d-ac5b-6ae661ceeb47@group-61155FD5A026-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 084c6adf-4c09-417d-ac5b-6ae661ceeb47@group-61155FD5A026-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/8e5d7696-3ffc-40b4-8848-61155fd5a026/current/log_inprogress_0 to /data/metadata/scm-ha/8e5d7696-3ffc-40b4-8848-61155fd5a026/current/log_0-0
scm2.org_1   | 2021-06-25 13:40:00,527 [Listener at 0.0.0.0/9860] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
scm1.org_1   | 2021-06-25 13:39:30,563 [Listener at 0.0.0.0/9860] INFO server.RaftServer$Division: 76093931-f232-4415-806f-239960e589cb@group-61155FD5A026: start as a follower, conf=0: [76093931-f232-4415-806f-239960e589cb|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
om3_1        | 2021-06-25 13:51:14,477 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:52:54,592 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm3.org_1   | 2021-06-25 13:40:26,269 [084c6adf-4c09-417d-ac5b-6ae661ceeb47@group-61155FD5A026-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 084c6adf-4c09-417d-ac5b-6ae661ceeb47@group-61155FD5A026-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/8e5d7696-3ffc-40b4-8848-61155fd5a026/current/log_inprogress_1
scm2.org_1   | 2021-06-25 13:40:00,528 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
scm1.org_1   | 2021-06-25 13:39:30,564 [Listener at 0.0.0.0/9860] INFO server.RaftServer$Division: 76093931-f232-4415-806f-239960e589cb@group-61155FD5A026: changes role from      null to FOLLOWER at term 1 for startAsFollower
om3_1        | 2021-06-25 13:51:14,479 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:57614
om2_1        | 2021-06-25 13:52:54,596 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39856
scm3.org_1   | 2021-06-25 13:40:26,342 [084c6adf-4c09-417d-ac5b-6ae661ceeb47@group-61155FD5A026-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2021-06-25 13:40:26,356 [084c6adf-4c09-417d-ac5b-6ae661ceeb47@group-61155FD5A026-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
scm2.org_1   | 2021-06-25 13:40:00,532 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
scm1.org_1   | 2021-06-25 13:39:30,566 [Listener at 0.0.0.0/9860] INFO impl.RoleInfo: 76093931-f232-4415-806f-239960e589cb: start 76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-FollowerState
om3_1        | 2021-06-25 13:51:14,486 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-25 13:40:26,356 [084c6adf-4c09-417d-ac5b-6ae661ceeb47@group-61155FD5A026-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
om2_1        | 2021-06-25 13:52:54,597 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
scm2.org_1   | 2021-06-25 13:40:00,532 [Listener at 0.0.0.0/9860] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService starting
scm1.org_1   | 2021-06-25 13:39:30,583 [Listener at 0.0.0.0/9860] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-61155FD5A026,id=76093931-f232-4415-806f-239960e589cb
om3_1        | 2021-06-25 13:51:15,330 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm3.org_1   | 2021-06-25 13:40:26,356 [084c6adf-4c09-417d-ac5b-6ae661ceeb47@group-61155FD5A026-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: RPC server for DataNodes is listening at /0.0.0.0:9861
om2_1        | 2021-06-25 13:52:55,309 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
scm2.org_1   | 2021-06-25 13:40:00,640 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
scm1.org_1   | 2021-06-25 13:39:30,584 [Listener at 0.0.0.0/9860] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.76093931-f232-4415-806f-239960e589cb@group-61155FD5A026
om3_1        | 2021-06-25 13:51:15,331 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:57624
scm3.org_1   | 2021-06-25 13:40:26,377 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
om2_1        | 2021-06-25 13:52:55,309 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39876
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
scm2.org_1   | 2021-06-25 13:40:00,654 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
scm2.org_1   | 2021-06-25 13:40:00,654 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
om3_1        | 2021-06-25 13:51:15,332 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-25 13:40:26,486 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om2_1        | 2021-06-25 13:52:55,310 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-25 13:40:01,088 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Persist certificate serialId 1 on Scm Bootstrap Node 76cadbf9-8202-4493-b276-7e4d9594dfab
scm1.org_1   | 2021-06-25 13:39:30,585 [Listener at 0.0.0.0/9860] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om3_1        | 2021-06-25 13:51:16,631 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm3.org_1   | 2021-06-25 13:40:26,617 [grpc-default-executor-0] INFO server.RaftServer$Division: 084c6adf-4c09-417d-ac5b-6ae661ceeb47@group-61155FD5A026: set configuration 11: [084c6adf-4c09-417d-ac5b-6ae661ceeb47|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0, 76cadbf9-8202-4493-b276-7e4d9594dfab|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, 76093931-f232-4415-806f-239960e589cb|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=[76cadbf9-8202-4493-b276-7e4d9594dfab|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, 76093931-f232-4415-806f-239960e589cb|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
om2_1        | 2021-06-25 13:52:55,947 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm2.org_1   | 2021-06-25 13:40:01,103 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Persist certificate serialId 2884006640668 on Scm Bootstrap Node 76cadbf9-8202-4493-b276-7e4d9594dfab
scm1.org_1   | 2021-06-25 13:39:30,590 [Listener at 0.0.0.0/9860] INFO server.RaftServer: 76093931-f232-4415-806f-239960e589cb: start RPC server
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om3_1        | 2021-06-25 13:51:16,631 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:57634
scm3.org_1   | 2021-06-25 13:40:26,730 [grpc-default-executor-0] INFO server.RaftServer$Division: 084c6adf-4c09-417d-ac5b-6ae661ceeb47@group-61155FD5A026: set configuration 13: [084c6adf-4c09-417d-ac5b-6ae661ceeb47|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0, 76cadbf9-8202-4493-b276-7e4d9594dfab|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, 76093931-f232-4415-806f-239960e589cb|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
om2_1        | 2021-06-25 13:52:55,947 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39888
scm2.org_1   | 2021-06-25 13:40:01,215 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@24710e61] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm1.org_1   | 2021-06-25 13:39:30,656 [Listener at 0.0.0.0/9860] INFO server.GrpcService: 76093931-f232-4415-806f-239960e589cb: GrpcService started, listening on 9894
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om3_1        | 2021-06-25 13:51:16,632 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-25 13:40:27,252 [084c6adf-4c09-417d-ac5b-6ae661ceeb47@group-61155FD5A026-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om2_1        | 2021-06-25 13:52:55,955 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:52:56,599 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm1.org_1   | 2021-06-25 13:39:30,660 [Listener at 0.0.0.0/9860] INFO ha.SCMHAManagerImpl:  scm role is FOLLOWER peers [76093931-f232-4415-806f-239960e589cb|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
om3_1        | 2021-06-25 13:51:17,562 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:52:56,600 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39896
scm2.org_1   | 2021-06-25 13:40:01,304 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm3.org_1   | 2021-06-25 13:40:27,260 [084c6adf-4c09-417d-ac5b-6ae661ceeb47@group-61155FD5A026-StateMachineUpdater] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm1.org_1   | 2021-06-25 13:39:30,660 [Listener at 0.0.0.0/9860] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
om3_1        | 2021-06-25 13:51:17,563 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:57646
om2_1        | 2021-06-25 13:52:56,605 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-25 13:40:01,305 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
scm3.org_1   | 2021-06-25 13:40:27,260 [084c6adf-4c09-417d-ac5b-6ae661ceeb47@group-61155FD5A026-StateMachineUpdater] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm1.org_1   | 2021-06-25 13:39:30,661 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$409/0x00000008404ef040@367fbb28] INFO util.JvmPauseMonitor: JvmPauseMonitor-76093931-f232-4415-806f-239960e589cb: Started
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
om3_1        | 2021-06-25 13:51:17,564 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:53:01,295 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:58800
scm2.org_1   | 2021-06-25 13:40:01,307 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
scm3.org_1   | 2021-06-25 13:40:27,280 [Listener at 0.0.0.0/9860] INFO ha.SCMHAManagerImpl: Successfully added SCM scm3 to group group-61155FD5A026:[084c6adf-4c09-417d-ac5b-6ae661ceeb47|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0, 76cadbf9-8202-4493-b276-7e4d9594dfab|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, 76093931-f232-4415-806f-239960e589cb|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm1.org_1   | 2021-06-25 13:39:30,663 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Starting token manager
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om3_1        | 2021-06-25 13:51:18,369 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:53:01,303 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-25 13:40:01,397 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @16754ms to org.eclipse.jetty.util.log.Slf4jLog
scm3.org_1   | 2021-06-25 13:40:27,318 [Listener at 0.0.0.0/9860] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
scm3.org_1   | 2021-06-25 13:40:27,328 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Starting token manager
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om3_1        | 2021-06-25 13:51:18,370 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:57664
om2_1        | 2021-06-25 13:53:04,355 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm2.org_1   | 2021-06-25 13:40:01,861 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm3.org_1   | 2021-06-25 13:40:27,338 [Listener at 0.0.0.0/9860] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
scm1.org_1   | 2021-06-25 13:39:30,664 [Listener at 0.0.0.0/9860] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
om3_1        | 2021-06-25 13:51:18,371 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:53:04,355 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39952
scm2.org_1   | 2021-06-25 13:40:01,887 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm3.org_1   | 2021-06-25 13:40:27,539 [084c6adf-4c09-417d-ac5b-6ae661ceeb47@group-61155FD5A026-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2021-06-25 13:39:30,810 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
om3_1        | 2021-06-25 13:51:19,160 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om2_1        | 2021-06-25 13:53:04,356 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-25 13:40:01,899 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
scm3.org_1   | 2021-06-25 13:40:28,247 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm1.org_1   | 2021-06-25 13:39:30,829 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:49:52,289 [qtp382627885-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
om2_1        | 2021-06-25 13:53:21,276 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:58886
om2_1        | 2021-06-25 13:53:21,282 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-25 13:40:28,391 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm1.org_1   | 2021-06-25 13:39:30,829 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
om3_1        | 2021-06-25 13:51:19,160 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:57674
om2_1        | 2021-06-25 13:57:05,830 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:58512
scm2.org_1   | 2021-06-25 13:40:01,906 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
scm3.org_1   | 2021-06-25 13:40:28,391 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm1.org_1   | 2021-06-25 13:39:31,134 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
om3_1        | 2021-06-25 13:51:19,162 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-25 13:57:05,839 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-25 13:40:01,906 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
scm3.org_1   | 2021-06-25 13:40:31,214 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm1.org_1   | 2021-06-25 13:39:31,135 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om3_1        | 2021-06-25 13:51:19,874 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm2.org_1   | 2021-06-25 13:40:01,910 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
scm3.org_1   | 2021-06-25 13:40:31,242 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm1.org_1   | 2021-06-25 13:39:31,136 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om3_1        | 2021-06-25 13:51:19,875 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:57682
scm2.org_1   | 2021-06-25 13:40:02,056 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
scm3.org_1   | 2021-06-25 13:40:31,242 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm1.org_1   | 2021-06-25 13:39:31,171 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om3_1        | 2021-06-25 13:51:19,878 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-25 13:40:02,067 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.35.v20201120; built: 2020-11-20T21:17:03.964Z; git: bdc54f03a5e0a7e280fab27f55c3c75ee8da89fb; jvm 11.0.10+9-LTS
scm3.org_1   | 2021-06-25 13:40:32,211 [084c6adf-4c09-417d-ac5b-6ae661ceeb47@group-61155FD5A026-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om3_1        | 2021-06-25 13:51:20,837 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm1.org_1   | 2021-06-25 13:39:31,175 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm2.org_1   | 2021-06-25 13:40:02,216 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm3.org_1   | 2021-06-25 13:40:32,276 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om3_1        | 2021-06-25 13:51:20,837 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:57694
scm1.org_1   | 2021-06-25 13:39:31,182 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm2.org_1   | 2021-06-25 13:40:02,216 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm3.org_1   | 2021-06-25 13:40:32,284 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om3_1        | 2021-06-25 13:51:20,838 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-25 13:39:31,186 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm2.org_1   | 2021-06-25 13:40:02,219 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 600000ms
scm3.org_1   | 2021-06-25 13:40:32,402 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
om3_1        | 2021-06-25 13:51:21,063 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm1.org_1   | 2021-06-25 13:39:31,272 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmDatanodeProtocl RPC server is listening at /0.0.0.0:9861
scm2.org_1   | 2021-06-25 13:40:02,325 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm3.org_1   | 2021-06-25 13:40:32,404 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
om3_1        | 2021-06-25 13:51:21,072 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:57700
scm1.org_1   | 2021-06-25 13:39:31,273 [Listener at 0.0.0.0/9860] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
scm2.org_1   | 2021-06-25 13:40:02,329 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@16cc5e51{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm3.org_1   | 2021-06-25 13:40:32,968 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$393/0x00000008404d7c40@7ef7faa9] WARN util.JvmPauseMonitor: JvmPauseMonitor-084c6adf-4c09-417d-ac5b-6ae661ceeb47: Detected pause in JVM or host machine (eg GC): pause of approximately 650679535ns. No GCs detected.
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
om3_1        | 2021-06-25 13:51:21,074 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-25 13:39:31,274 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm2.org_1   | 2021-06-25 13:40:02,342 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@3503e68e{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.2.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm3.org_1   | 2021-06-25 13:40:33,043 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmDatanodeProtocl RPC server is listening at /0.0.0.0:9861
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om3_1        | 2021-06-25 13:51:21,259 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm1.org_1   | 2021-06-25 13:39:31,275 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
scm2.org_1   | 2021-06-25 13:40:02,746 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm3.org_1   | 2021-06-25 13:40:33,059 [Listener at 0.0.0.0/9860] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om3_1        | 2021-06-25 13:51:21,259 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:57714
scm1.org_1   | 2021-06-25 13:39:31,275 [Listener at 0.0.0.0/9860] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService starting
scm2.org_1   | 2021-06-25 13:40:02,807 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@1427827f{scm,/,file:///tmp/jetty-0_0_0_0-9876-hdds-server-scm-1_2_0-SNAPSHOT_jar-_-any-14132112700462197477/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.2.0-SNAPSHOT.jar!/webapps/scm}
scm3.org_1   | 2021-06-25 13:40:33,102 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
om3_1        | 2021-06-25 13:51:21,264 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm1.org_1   | 2021-06-25 13:39:31,365 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@309b8144] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm2.org_1   | 2021-06-25 13:40:02,833 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@1a819769{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
scm3.org_1   | 2021-06-25 13:40:33,139 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
om3_1        | 2021-06-25 13:51:21,265 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:57716
scm1.org_1   | 2021-06-25 13:39:31,385 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm2.org_1   | 2021-06-25 13:40:02,834 [Listener at 0.0.0.0/9860] INFO server.Server: Started @18190ms
scm3.org_1   | 2021-06-25 13:40:33,140 [Listener at 0.0.0.0/9860] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService starting
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
om3_1        | 2021-06-25 13:51:21,273 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-25 13:39:31,385 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
scm2.org_1   | 2021-06-25 13:40:02,849 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm3.org_1   | 2021-06-25 13:40:33,627 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
s3g_1        | 2021-06-25 13:49:52,586 [qtp382627885-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
om3_1        | 2021-06-25 13:51:21,283 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-25 13:39:31,387 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
scm2.org_1   | 2021-06-25 13:40:02,849 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm3.org_1   | 2021-06-25 13:40:33,633 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
om3_1        | 2021-06-25 13:51:22,938 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm1.org_1   | 2021-06-25 13:39:31,419 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @7434ms to org.eclipse.jetty.util.log.Slf4jLog
scm1.org_1   | 2021-06-25 13:39:31,567 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm3.org_1   | 2021-06-25 13:40:33,635 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
om3_1        | 2021-06-25 13:51:22,939 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:57730
scm2.org_1   | 2021-06-25 13:40:02,851 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm1.org_1   | 2021-06-25 13:39:31,573 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm3.org_1   | 2021-06-25 13:40:35,020 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Persist certificate serialId 1 on Scm Bootstrap Node 084c6adf-4c09-417d-ac5b-6ae661ceeb47
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om3_1        | 2021-06-25 13:51:22,943 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-25 13:40:05,765 [76cadbf9-8202-4493-b276-7e4d9594dfab@group-61155FD5A026-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2021-06-25 13:39:31,575 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
scm3.org_1   | 2021-06-25 13:40:35,039 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Persist certificate serialId 2884006640668 on Scm Bootstrap Node 084c6adf-4c09-417d-ac5b-6ae661ceeb47
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om3_1        | 2021-06-25 13:51:23,518 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm2.org_1   | 2021-06-25 13:40:26,534 [grpc-default-executor-0] INFO server.RaftServer$Division: 76cadbf9-8202-4493-b276-7e4d9594dfab@group-61155FD5A026: set configuration 11: [084c6adf-4c09-417d-ac5b-6ae661ceeb47|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0, 76cadbf9-8202-4493-b276-7e4d9594dfab|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, 76093931-f232-4415-806f-239960e589cb|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=[76cadbf9-8202-4493-b276-7e4d9594dfab|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, 76093931-f232-4415-806f-239960e589cb|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm1.org_1   | 2021-06-25 13:39:31,575 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
scm3.org_1   | 2021-06-25 13:40:35,183 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@24710e61] INFO util.JvmPauseMonitor: Starting JVM pause monitor
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om3_1        | 2021-06-25 13:51:23,518 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:57740
scm2.org_1   | 2021-06-25 13:40:26,677 [grpc-default-executor-0] INFO server.RaftServer$Division: 76cadbf9-8202-4493-b276-7e4d9594dfab@group-61155FD5A026: set configuration 13: [084c6adf-4c09-417d-ac5b-6ae661ceeb47|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0, 76cadbf9-8202-4493-b276-7e4d9594dfab|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, 76093931-f232-4415-806f-239960e589cb|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2021-06-25 13:39:31,575 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
scm3.org_1   | 2021-06-25 13:40:35,284 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om3_1        | 2021-06-25 13:51:23,519 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-25 13:40:31,600 [76cadbf9-8202-4493-b276-7e4d9594dfab@group-61155FD5A026-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2021-06-25 13:39:31,578 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
scm3.org_1   | 2021-06-25 13:40:35,286 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om3_1        | 2021-06-25 13:51:23,679 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm2.org_1   | 2021-06-25 13:40:51,996 [76cadbf9-8202-4493-b276-7e4d9594dfab@group-61155FD5A026-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2021-06-25 13:39:31,616 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
scm3.org_1   | 2021-06-25 13:40:35,287 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om3_1        | 2021-06-25 13:51:23,679 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:57760
scm2.org_1   | 2021-06-25 13:40:52,760 [76cadbf9-8202-4493-b276-7e4d9594dfab@group-61155FD5A026-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2021-06-25 13:39:31,617 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.35.v20201120; built: 2020-11-20T21:17:03.964Z; git: bdc54f03a5e0a7e280fab27f55c3c75ee8da89fb; jvm 11.0.10+9-LTS
scm3.org_1   | 2021-06-25 13:40:35,517 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @29417ms to org.eclipse.jetty.util.log.Slf4jLog
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
scm2.org_1   | 2021-06-25 13:40:53,285 [76cadbf9-8202-4493-b276-7e4d9594dfab@group-61155FD5A026-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2021-06-25 13:39:31,682 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm3.org_1   | 2021-06-25 13:40:36,691 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
om3_1        | 2021-06-25 13:51:23,695 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-25 13:41:02,224 [76cadbf9-8202-4493-b276-7e4d9594dfab@group-61155FD5A026-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2021-06-25 13:39:31,682 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm3.org_1   | 2021-06-25 13:40:36,723 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om3_1        | 2021-06-25 13:51:23,704 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm2.org_1   | 2021-06-25 13:41:02,503 [76cadbf9-8202-4493-b276-7e4d9594dfab@group-61155FD5A026-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2021-06-25 13:39:31,684 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 600000ms
scm3.org_1   | 2021-06-25 13:40:36,744 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om3_1        | 2021-06-25 13:51:23,704 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:57764
scm2.org_1   | 2021-06-25 13:41:04,112 [76cadbf9-8202-4493-b276-7e4d9594dfab@group-61155FD5A026-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2021-06-25 13:39:31,701 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm3.org_1   | 2021-06-25 13:40:36,764 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
om3_1        | 2021-06-25 13:51:23,705 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm2.org_1   | 2021-06-25 13:41:23,550 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36302
scm1.org_1   | 2021-06-25 13:39:31,710 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@383a5260{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm3.org_1   | 2021-06-25 13:40:36,765 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
om3_1        | 2021-06-25 13:51:23,705 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:57766
scm2.org_1   | 2021-06-25 13:41:23,595 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:39:31,711 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@751526a7{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.2.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm3.org_1   | 2021-06-25 13:40:36,786 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
om3_1        | 2021-06-25 13:51:23,710 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-25 13:41:23,886 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:60456
scm1.org_1   | 2021-06-25 13:39:31,825 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm1.org_1   | 2021-06-25 13:39:31,839 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@57657b96{scm,/,file:///tmp/jetty-0_0_0_0-9876-hdds-server-scm-1_2_0-SNAPSHOT_jar-_-any-15914862850525390419/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.2.0-SNAPSHOT.jar!/webapps/scm}
s3g_1        | 2021-06-25 13:49:52,752 [qtp382627885-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
om3_1        | 2021-06-25 13:51:23,723 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-25 13:39:31,857 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@360d0c7a{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
scm3.org_1   | 2021-06-25 13:40:37,423 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
scm2.org_1   | 2021-06-25 13:41:23,951 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
om3_1        | 2021-06-25 13:51:24,905 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm1.org_1   | 2021-06-25 13:39:31,858 [Listener at 0.0.0.0/9860] INFO server.Server: Started @7873ms
scm3.org_1   | 2021-06-25 13:40:37,432 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.35.v20201120; built: 2020-11-20T21:17:03.964Z; git: bdc54f03a5e0a7e280fab27f55c3c75ee8da89fb; jvm 11.0.10+9-LTS
scm2.org_1   | 2021-06-25 13:41:25,158 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:60176
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
om3_1        | 2021-06-25 13:51:24,906 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:57790
scm1.org_1   | 2021-06-25 13:39:31,860 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm3.org_1   | 2021-06-25 13:40:37,779 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm2.org_1   | 2021-06-25 13:41:25,249 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om3_1        | 2021-06-25 13:51:24,906 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-25 13:39:31,860 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm3.org_1   | 2021-06-25 13:40:37,789 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm2.org_1   | 2021-06-25 13:41:27,291 [IPC Server handler 52 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/8dca9ea8-5191-4cce-a34e-3d546f33f7b1
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om3_1        | 2021-06-25 13:51:25,783 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm1.org_1   | 2021-06-25 13:39:31,862 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm3.org_1   | 2021-06-25 13:40:37,793 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 660000ms
scm2.org_1   | 2021-06-25 13:41:27,306 [IPC Server handler 52 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 8dca9ea8-5191-4cce-a34e-3d546f33f7b1{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 2982768810642, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om3_1        | 2021-06-25 13:51:25,784 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:57800
scm1.org_1   | 2021-06-25 13:39:32,379 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46286
scm3.org_1   | 2021-06-25 13:40:37,995 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm2.org_1   | 2021-06-25 13:41:27,336 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om3_1        | 2021-06-25 13:51:25,785 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-25 13:39:32,399 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm3.org_1   | 2021-06-25 13:40:38,023 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@16cc5e51{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm2.org_1   | 2021-06-25 13:41:27,634 [IPC Server handler 28 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/ee31bb40-6981-4b57-b8d7-3be03fa0c81d
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om3_1        | 2021-06-25 13:51:27,066 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm1.org_1   | 2021-06-25 13:39:33,500 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:40042
scm2.org_1   | 2021-06-25 13:41:27,716 [IPC Server handler 28 on default port 9861] INFO node.SCMNodeManager: Registered Data node : ee31bb40-6981-4b57-b8d7-3be03fa0c81d{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 2981987122066, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
scm3.org_1   | 2021-06-25 13:40:38,041 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@3503e68e{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.2.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om3_1        | 2021-06-25 13:51:27,070 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:57814
scm1.org_1   | 2021-06-25 13:39:33,511 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm2.org_1   | 2021-06-25 13:41:27,716 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
scm3.org_1   | 2021-06-25 13:40:38,943 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
om3_1        | 2021-06-25 13:51:27,071 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-25 13:39:35,668 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-FollowerState] INFO impl.FollowerState: 76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5102522256ns, electionTimeout:5083ms
scm2.org_1   | 2021-06-25 13:41:27,782 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
scm3.org_1   | 2021-06-25 13:40:39,079 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@1427827f{scm,/,file:///tmp/jetty-0_0_0_0-9876-hdds-server-scm-1_2_0-SNAPSHOT_jar-_-any-8426088587671069726/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.2.0-SNAPSHOT.jar!/webapps/scm}
om3_1        | 2021-06-25 13:51:27,792 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm1.org_1   | 2021-06-25 13:39:35,669 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-FollowerState] INFO impl.RoleInfo: 76093931-f232-4415-806f-239960e589cb: shutdown 76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-FollowerState
scm2.org_1   | 2021-06-25 13:41:27,835 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
scm3.org_1   | 2021-06-25 13:40:39,205 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@1a819769{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
om3_1        | 2021-06-25 13:51:27,792 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:57822
scm1.org_1   | 2021-06-25 13:39:35,669 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-FollowerState] INFO server.RaftServer$Division: 76093931-f232-4415-806f-239960e589cb@group-61155FD5A026: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
scm2.org_1   | 2021-06-25 13:41:27,982 [IPC Server handler 98 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/d7f71981-d306-415b-992d-ee4808a385fa
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm3.org_1   | 2021-06-25 13:40:39,205 [Listener at 0.0.0.0/9860] INFO server.Server: Started @33106ms
om3_1        | 2021-06-25 13:51:27,796 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-25 13:39:35,672 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
scm2.org_1   | 2021-06-25 13:41:27,982 [IPC Server handler 98 on default port 9861] INFO node.SCMNodeManager: Registered Data node : d7f71981-d306-415b-992d-ee4808a385fa{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 2983272084503, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm3.org_1   | 2021-06-25 13:40:39,245 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
om3_1        | 2021-06-25 13:51:29,323 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm1.org_1   | 2021-06-25 13:39:35,673 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-FollowerState] INFO impl.RoleInfo: 76093931-f232-4415-806f-239960e589cb: start 76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-LeaderElection1
scm2.org_1   | 2021-06-25 13:41:27,982 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
scm3.org_1   | 2021-06-25 13:40:39,245 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
om3_1        | 2021-06-25 13:51:29,325 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:57836
scm1.org_1   | 2021-06-25 13:39:35,689 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-LeaderElection1] INFO impl.LeaderElection: 76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-LeaderElection1 ELECTION round 0: submit vote requests at term 2 for 0: [76093931-f232-4415-806f-239960e589cb|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2021-06-25 13:41:28,048 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
scm3.org_1   | 2021-06-25 13:40:39,267 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
om3_1        | 2021-06-25 13:51:29,327 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-25 13:41:28,072 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm1.org_1   | 2021-06-25 13:39:35,690 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-LeaderElection1] INFO impl.LeaderElection: 76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-LeaderElection1 ELECTION round 0: result PASSED (term=2)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
scm3.org_1   | 2021-06-25 13:40:51,990 [084c6adf-4c09-417d-ac5b-6ae661ceeb47@group-61155FD5A026-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2021-06-25 13:40:52,762 [084c6adf-4c09-417d-ac5b-6ae661ceeb47@group-61155FD5A026-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2021-06-25 13:41:28,072 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm1.org_1   | 2021-06-25 13:39:35,691 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-LeaderElection1] INFO impl.RoleInfo: 76093931-f232-4415-806f-239960e589cb: shutdown 76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-LeaderElection1
scm3.org_1   | 2021-06-25 13:40:53,283 [084c6adf-4c09-417d-ac5b-6ae661ceeb47@group-61155FD5A026-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om3_1        | 2021-06-25 13:51:29,986 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
s3g_1        | 2021-06-25 13:49:52,845 [qtp382627885-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
scm2.org_1   | 2021-06-25 13:41:28,073 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm1.org_1   | 2021-06-25 13:39:35,691 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-LeaderElection1] INFO server.RaftServer$Division: 76093931-f232-4415-806f-239960e589cb@group-61155FD5A026: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
scm3.org_1   | 2021-06-25 13:41:02,221 [084c6adf-4c09-417d-ac5b-6ae661ceeb47@group-61155FD5A026-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om3_1        | 2021-06-25 13:51:29,987 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:57848
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
scm2.org_1   | 2021-06-25 13:41:28,126 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
scm1.org_1   | 2021-06-25 13:39:35,692 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-LeaderElection1] INFO ha.SCMStateMachine: current SCM becomes leader of term 2.
scm3.org_1   | 2021-06-25 13:41:02,489 [084c6adf-4c09-417d-ac5b-6ae661ceeb47@group-61155FD5A026-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om3_1        | 2021-06-25 13:51:29,990 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
scm2.org_1   | 2021-06-25 13:41:28,128 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm1.org_1   | 2021-06-25 13:39:35,692 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-LeaderElection1] INFO ha.SCMContext: update <isLeader,term> from <false,0> to <true,2>
scm3.org_1   | 2021-06-25 13:41:04,157 [084c6adf-4c09-417d-ac5b-6ae661ceeb47@group-61155FD5A026-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om3_1        | 2021-06-25 13:51:31,264 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
scm2.org_1   | 2021-06-25 13:41:29,228 [76cadbf9-8202-4493-b276-7e4d9594dfab@group-61155FD5A026-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 33fecaa5-f059-4c14-a3bf-a0d73e1f71d5, Nodes: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2021-06-25T13:41:27.529Z].
scm1.org_1   | 2021-06-25 13:39:35,694 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-LeaderElection1] INFO server.RaftServer$Division: 76093931-f232-4415-806f-239960e589cb@group-61155FD5A026: change Leader from null to 76093931-f232-4415-806f-239960e589cb at term 2 for becomeLeader, leader elected after 7383ms
scm3.org_1   | 2021-06-25 13:41:23,625 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:54562
om3_1        | 2021-06-25 13:51:31,265 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:57898
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
scm2.org_1   | 2021-06-25 13:41:29,286 [76cadbf9-8202-4493-b276-7e4d9594dfab@group-61155FD5A026-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2021-06-25 13:39:35,701 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
scm3.org_1   | 2021-06-25 13:41:23,680 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 2021-06-25 13:51:31,266 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
scm2.org_1   | 2021-06-25 13:41:29,292 [76cadbf9-8202-4493-b276-7e4d9594dfab@group-61155FD5A026-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 3175bb45-44a8-4478-8980-bfea630f7f68, Nodes: ee31bb40-6981-4b57-b8d7-3be03fa0c81d{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}8dca9ea8-5191-4cce-a34e-3d546f33f7b1{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}d7f71981-d306-415b-992d-ee4808a385fa{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2021-06-25T13:41:28.879Z].
scm1.org_1   | 2021-06-25 13:39:35,703 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.76093931-f232-4415-806f-239960e589cb@group-61155FD5A026
scm1.org_1   | 2021-06-25 13:39:35,703 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-LeaderElection1] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
om3_1        | 2021-06-25 13:51:32,846 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
scm2.org_1   | 2021-06-25 13:41:29,304 [76cadbf9-8202-4493-b276-7e4d9594dfab@group-61155FD5A026-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2021-06-25 13:39:35,706 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm3.org_1   | 2021-06-25 13:41:23,875 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:54882
om3_1        | 2021-06-25 13:51:32,847 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:57910
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
scm2.org_1   | 2021-06-25 13:41:29,313 [76cadbf9-8202-4493-b276-7e4d9594dfab@group-61155FD5A026-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 8a55befb-80cf-4326-9d11-6eb5e5add68d, Nodes: d7f71981-d306-415b-992d-ee4808a385fa{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2021-06-25T13:41:29.088Z].
scm1.org_1   | 2021-06-25 13:39:35,707 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
scm3.org_1   | 2021-06-25 13:41:23,951 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 2021-06-25 13:51:32,851 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
scm2.org_1   | 2021-06-25 13:41:29,327 [76cadbf9-8202-4493-b276-7e4d9594dfab@group-61155FD5A026-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2021-06-25 13:39:35,712 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
scm3.org_1   | 2021-06-25 13:41:25,286 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48492
om3_1        | 2021-06-25 13:51:33,584 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
scm2.org_1   | 2021-06-25 13:41:29,770 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 76cadbf9-8202-4493-b276-7e4d9594dfab@group-61155FD5A026-SegmentedRaftLogWorker: Rolling segment log-1_34 to index:34
scm1.org_1   | 2021-06-25 13:39:35,712 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
scm1.org_1   | 2021-06-25 13:39:35,713 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
om3_1        | 2021-06-25 13:51:33,585 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:57920
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
scm3.org_1   | 2021-06-25 13:41:25,382 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:39:35,722 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-LeaderElection1] INFO impl.RoleInfo: 76093931-f232-4415-806f-239960e589cb: start 76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-LeaderStateImpl
scm2.org_1   | 2021-06-25 13:41:29,807 [76cadbf9-8202-4493-b276-7e4d9594dfab@group-61155FD5A026-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 76cadbf9-8202-4493-b276-7e4d9594dfab@group-61155FD5A026-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/8e5d7696-3ffc-40b4-8848-61155fd5a026/current/log_inprogress_1 to /data/metadata/scm-ha/8e5d7696-3ffc-40b4-8848-61155fd5a026/current/log_1-34
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
om3_1        | 2021-06-25 13:51:33,588 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-25 13:41:27,457 [IPC Server handler 9 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/8dca9ea8-5191-4cce-a34e-3d546f33f7b1
scm1.org_1   | 2021-06-25 13:39:35,772 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
scm2.org_1   | 2021-06-25 13:41:29,822 [76cadbf9-8202-4493-b276-7e4d9594dfab@group-61155FD5A026-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 76cadbf9-8202-4493-b276-7e4d9594dfab@group-61155FD5A026-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/8e5d7696-3ffc-40b4-8848-61155fd5a026/current/log_inprogress_35
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om3_1        | 2021-06-25 13:51:35,186 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm3.org_1   | 2021-06-25 13:41:27,474 [IPC Server handler 9 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 8dca9ea8-5191-4cce-a34e-3d546f33f7b1{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 2982768810642, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm1.org_1   | 2021-06-25 13:39:35,779 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/8e5d7696-3ffc-40b4-8848-61155fd5a026/current/log_inprogress_0 to /data/metadata/scm-ha/8e5d7696-3ffc-40b4-8848-61155fd5a026/current/log_0-0
scm2.org_1   | 2021-06-25 13:41:29,879 [76cadbf9-8202-4493-b276-7e4d9594dfab@group-61155FD5A026-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 949dd475-00f3-4295-9774-5191be84cab1, Nodes: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}ee31bb40-6981-4b57-b8d7-3be03fa0c81d{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}d7f71981-d306-415b-992d-ee4808a385fa{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2021-06-25T13:41:29.318Z].
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om3_1        | 2021-06-25 13:51:35,186 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:57936
scm3.org_1   | 2021-06-25 13:41:27,600 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm1.org_1   | 2021-06-25 13:39:35,800 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/8e5d7696-3ffc-40b4-8848-61155fd5a026/current/log_inprogress_1
scm2.org_1   | 2021-06-25 13:41:29,880 [76cadbf9-8202-4493-b276-7e4d9594dfab@group-61155FD5A026-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
om3_1        | 2021-06-25 13:51:35,187 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-25 13:41:27,627 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
scm1.org_1   | 2021-06-25 13:39:35,812 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-LeaderElection1] INFO server.RaftServer$Division: 76093931-f232-4415-806f-239960e589cb@group-61155FD5A026: set configuration 1: [76093931-f232-4415-806f-239960e589cb|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2021-06-25 13:41:30,119 [76cadbf9-8202-4493-b276-7e4d9594dfab@group-61155FD5A026-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 145b110b-f1b2-4a24-b4ba-bf6d91d43fa5, Nodes: ee31bb40-6981-4b57-b8d7-3be03fa0c81d{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2021-06-25T13:41:29.947Z].
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
om3_1        | 2021-06-25 13:51:36,206 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm3.org_1   | 2021-06-25 13:41:27,813 [IPC Server handler 43 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/ee31bb40-6981-4b57-b8d7-3be03fa0c81d
scm1.org_1   | 2021-06-25 13:39:35,819 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-StateMachineUpdater] INFO ha.SCMContext: update <isLeaderReady> from <false> to <true>
scm2.org_1   | 2021-06-25 13:41:30,126 [76cadbf9-8202-4493-b276-7e4d9594dfab@group-61155FD5A026-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
om3_1        | 2021-06-25 13:51:36,207 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:57952
scm3.org_1   | 2021-06-25 13:41:27,855 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm1.org_1   | 2021-06-25 13:39:35,820 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-StateMachineUpdater] INFO pipeline.BackgroundPipelineCreator: Service BackgroundPipelineCreator transitions to RUNNING.
scm2.org_1   | 2021-06-25 13:41:31,400 [76cadbf9-8202-4493-b276-7e4d9594dfab@group-61155FD5A026-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
s3g_1        | 2021-06-25 13:49:52,932 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
om3_1        | 2021-06-25 13:51:36,216 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-25 13:41:27,855 [IPC Server handler 43 on default port 9861] INFO node.SCMNodeManager: Registered Data node : ee31bb40-6981-4b57-b8d7-3be03fa0c81d{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 2981987122066, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm1.org_1   | 2021-06-25 13:39:35,822 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2021-06-25 13:41:59,030 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:60340
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
om3_1        | 2021-06-25 13:51:36,935 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm3.org_1   | 2021-06-25 13:41:27,914 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
scm1.org_1   | 2021-06-25 13:39:35,823 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
scm2.org_1   | 2021-06-25 13:41:59,043 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
om3_1        | 2021-06-25 13:51:36,935 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:57968
scm3.org_1   | 2021-06-25 13:41:27,958 [IPC Server handler 20 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/d7f71981-d306-415b-992d-ee4808a385fa
scm1.org_1   | 2021-06-25 13:39:35,823 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm2.org_1   | 2021-06-25 13:41:59,140 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36492
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om3_1        | 2021-06-25 13:51:36,938 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-25 13:41:27,959 [IPC Server handler 20 on default port 9861] INFO node.SCMNodeManager: Registered Data node : d7f71981-d306-415b-992d-ee4808a385fa{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 2983272084503, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm1.org_1   | 2021-06-25 13:39:35,824 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: RPC server for DataNodes is listening at /0.0.0.0:9861
scm2.org_1   | 2021-06-25 13:41:59,174 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om3_1        | 2021-06-25 13:51:38,417 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm3.org_1   | 2021-06-25 13:41:27,960 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm1.org_1   | 2021-06-25 13:39:35,835 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm2.org_1   | 2021-06-25 13:41:59,604 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:60644
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om3_1        | 2021-06-25 13:51:38,418 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:57982
scm3.org_1   | 2021-06-25 13:41:28,058 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
scm1.org_1   | 2021-06-25 13:39:35,858 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm2.org_1   | 2021-06-25 13:41:59,624 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om3_1        | 2021-06-25 13:51:38,419 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-25 13:41:28,058 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm1.org_1   | 2021-06-25 13:39:41,704 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:33780
scm2.org_1   | 2021-06-25 13:42:00,661 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerV2Impl: Pipeline Pipeline[ Id: 33fecaa5-f059-4c14-a3bf-a0d73e1f71d5, Nodes: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:8dca9ea8-5191-4cce-a34e-3d546f33f7b1, CreationTimestamp2021-06-25T13:41:27.529Z] moved to OPEN state
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om3_1        | 2021-06-25 13:51:39,784 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm3.org_1   | 2021-06-25 13:41:28,314 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm1.org_1   | 2021-06-25 13:39:41,721 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm2.org_1   | 2021-06-25 13:42:00,811 [76cadbf9-8202-4493-b276-7e4d9594dfab@group-61155FD5A026-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om3_1        | 2021-06-25 13:51:39,785 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:57996
scm3.org_1   | 2021-06-25 13:41:28,362 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm1.org_1   | 2021-06-25 13:39:42,139 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for scm scm2.org, nodeId: 76cadbf9-8202-4493-b276-7e4d9594dfab
scm2.org_1   | 2021-06-25 13:42:00,848 [EventQueue-PipelineReportForPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@547c76b5, cost 125754.223us
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
om3_1        | 2021-06-25 13:51:39,790 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-25 13:41:28,379 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
scm1.org_1   | 2021-06-25 13:39:42,809 [IPC Server handler 0 on default port 9961] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-F32A2895CC4D->76093931-f232-4415-806f-239960e589cb
scm2.org_1   | 2021-06-25 13:42:01,841 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
om3_1        | 2021-06-25 13:51:40,521 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm3.org_1   | 2021-06-25 13:41:28,403 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm1.org_1   | 2021-06-25 13:39:42,809 [IPC Server handler 0 on default port 9961] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm1.org_1   | 2021-06-25 13:39:43,792 [grpc-default-executor-0] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server_message_metrics.76093931-f232-4415-806f-239960e589cb
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
om3_1        | 2021-06-25 13:51:40,522 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:58006
scm1.org_1   | 2021-06-25 13:39:43,792 [grpc-default-executor-0] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm2.org_1   | 2021-06-25 13:42:04,964 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerV2Impl: Pipeline Pipeline[ Id: 8a55befb-80cf-4326-9d11-6eb5e5add68d, Nodes: d7f71981-d306-415b-992d-ee4808a385fa{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:d7f71981-d306-415b-992d-ee4808a385fa, CreationTimestamp2021-06-25T13:41:29.088Z] moved to OPEN state
scm3.org_1   | 2021-06-25 13:41:29,308 [084c6adf-4c09-417d-ac5b-6ae661ceeb47@group-61155FD5A026-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 33fecaa5-f059-4c14-a3bf-a0d73e1f71d5, Nodes: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2021-06-25T13:41:27.529Z].
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om3_1        | 2021-06-25 13:51:40,523 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-25 13:39:43,961 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2021-06-25 13:42:04,969 [EventQueue-PipelineReportForPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@547c76b5, cost 1150.408us
scm3.org_1   | 2021-06-25 13:41:29,367 [084c6adf-4c09-417d-ac5b-6ae661ceeb47@group-61155FD5A026-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om3_1        | 2021-06-25 13:51:41,312 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm1.org_1   | 2021-06-25 13:39:43,962 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-StateMachineUpdater] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm2.org_1   | 2021-06-25 13:42:05,006 [76cadbf9-8202-4493-b276-7e4d9594dfab@group-61155FD5A026-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2021-06-25 13:41:29,422 [084c6adf-4c09-417d-ac5b-6ae661ceeb47@group-61155FD5A026-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 3175bb45-44a8-4478-8980-bfea630f7f68, Nodes: ee31bb40-6981-4b57-b8d7-3be03fa0c81d{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}8dca9ea8-5191-4cce-a34e-3d546f33f7b1{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}d7f71981-d306-415b-992d-ee4808a385fa{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2021-06-25T13:41:28.879Z].
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
scm1.org_1   | 2021-06-25 13:39:43,962 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-StateMachineUpdater] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm2.org_1   | 2021-06-25 13:42:05,107 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm3.org_1   | 2021-06-25 13:41:29,426 [084c6adf-4c09-417d-ac5b-6ae661ceeb47@group-61155FD5A026-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
om3_1        | 2021-06-25 13:51:41,312 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:58014
scm1.org_1   | 2021-06-25 13:39:43,979 [IPC Server handler 0 on default port 9961] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.security.x509.certificate.authority.CertificateStore.storeValidCertificate(java.math.BigInteger,java.security.cert.X509Certificate,org.apache.hadoop.hdds.protocol.proto.HddsProtos$NodeType) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1f7870bc, cost 1345836.571us
scm2.org_1   | 2021-06-25 13:42:05,484 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm3.org_1   | 2021-06-25 13:41:29,469 [084c6adf-4c09-417d-ac5b-6ae661ceeb47@group-61155FD5A026-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 8a55befb-80cf-4326-9d11-6eb5e5add68d, Nodes: d7f71981-d306-415b-992d-ee4808a385fa{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2021-06-25T13:41:29.088Z].
scm3.org_1   | 2021-06-25 13:41:29,484 [084c6adf-4c09-417d-ac5b-6ae661ceeb47@group-61155FD5A026-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
s3g_1        | 2021-06-25 13:49:53,257 [qtp382627885-21] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-A93456570072->ee31bb40-6981-4b57-b8d7-3be03fa0c81d
om3_1        | 2021-06-25 13:51:41,315 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-25 13:39:49,446 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46558
scm3.org_1   | 2021-06-25 13:41:29,766 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 084c6adf-4c09-417d-ac5b-6ae661ceeb47@group-61155FD5A026-SegmentedRaftLogWorker: Rolling segment log-1_34 to index:34
scm2.org_1   | 2021-06-25 13:42:06,359 [76cadbf9-8202-4493-b276-7e4d9594dfab@group-61155FD5A026-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
s3g_1        | 2021-06-25 13:49:53,257 [qtp382627885-21] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
om3_1        | 2021-06-25 13:51:42,021 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm1.org_1   | 2021-06-25 13:39:49,468 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm3.org_1   | 2021-06-25 13:41:29,777 [084c6adf-4c09-417d-ac5b-6ae661ceeb47@group-61155FD5A026-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 084c6adf-4c09-417d-ac5b-6ae661ceeb47@group-61155FD5A026-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/8e5d7696-3ffc-40b4-8848-61155fd5a026/current/log_inprogress_1 to /data/metadata/scm-ha/8e5d7696-3ffc-40b4-8848-61155fd5a026/current/log_1-34
scm2.org_1   | 2021-06-25 13:42:06,360 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
s3g_1        | 2021-06-25 13:49:57,023 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
om3_1        | 2021-06-25 13:51:42,021 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:58024
scm1.org_1   | 2021-06-25 13:39:54,978 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:40384
scm3.org_1   | 2021-06-25 13:41:29,794 [084c6adf-4c09-417d-ac5b-6ae661ceeb47@group-61155FD5A026-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 084c6adf-4c09-417d-ac5b-6ae661ceeb47@group-61155FD5A026-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/8e5d7696-3ffc-40b4-8848-61155fd5a026/current/log_inprogress_35
scm2.org_1   | 2021-06-25 13:42:29,082 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:60508
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
om3_1        | 2021-06-25 13:51:42,022 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-25 13:39:55,022 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm3.org_1   | 2021-06-25 13:41:29,932 [084c6adf-4c09-417d-ac5b-6ae661ceeb47@group-61155FD5A026-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 949dd475-00f3-4295-9774-5191be84cab1, Nodes: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}ee31bb40-6981-4b57-b8d7-3be03fa0c81d{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}d7f71981-d306-415b-992d-ee4808a385fa{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2021-06-25T13:41:29.318Z].
scm2.org_1   | 2021-06-25 13:42:29,093 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
om3_1        | 2021-06-25 13:51:43,928 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm1.org_1   | 2021-06-25 13:39:55,025 [IPC Server handler 4 on default port 9863] INFO ha.SCMRatisServerImpl: 76093931-f232-4415-806f-239960e589cb: Submitting SetConfiguration request to Ratis server with new SCM peers list: [76093931-f232-4415-806f-239960e589cb|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 76cadbf9-8202-4493-b276-7e4d9594dfab|rpc:scm2.org:9894|priority:0]
scm3.org_1   | 2021-06-25 13:41:29,960 [084c6adf-4c09-417d-ac5b-6ae661ceeb47@group-61155FD5A026-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2021-06-25 13:42:29,107 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om3_1        | 2021-06-25 13:51:43,928 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:58048
scm1.org_1   | 2021-06-25 13:39:55,035 [IPC Server handler 4 on default port 9863] INFO server.RaftServer$Division: 76093931-f232-4415-806f-239960e589cb@group-61155FD5A026: receive setConfiguration SetConfigurationRequest:client-6F1937D9801B->76093931-f232-4415-806f-239960e589cb@group-61155FD5A026, cid=0, seq=0, RW, null, peers:[76093931-f232-4415-806f-239960e589cb|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 76cadbf9-8202-4493-b276-7e4d9594dfab|rpc:scm2.org:9894|priority:0]
scm3.org_1   | 2021-06-25 13:41:30,167 [084c6adf-4c09-417d-ac5b-6ae661ceeb47@group-61155FD5A026-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 145b110b-f1b2-4a24-b4ba-bf6d91d43fa5, Nodes: ee31bb40-6981-4b57-b8d7-3be03fa0c81d{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2021-06-25T13:41:29.947Z].
scm2.org_1   | 2021-06-25 13:42:29,245 [76cadbf9-8202-4493-b276-7e4d9594dfab@group-61155FD5A026-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om3_1        | 2021-06-25 13:51:43,930 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-25 13:39:55,035 [IPC Server handler 4 on default port 9863] INFO server.RaftServer$Division: 76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-LeaderStateImpl: startSetConfiguration SetConfigurationRequest:client-6F1937D9801B->76093931-f232-4415-806f-239960e589cb@group-61155FD5A026, cid=0, seq=0, RW, null, peers:[76093931-f232-4415-806f-239960e589cb|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 76cadbf9-8202-4493-b276-7e4d9594dfab|rpc:scm2.org:9894|priority:0]
scm3.org_1   | 2021-06-25 13:41:30,175 [084c6adf-4c09-417d-ac5b-6ae661ceeb47@group-61155FD5A026-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2021-06-25 13:42:29,301 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36660
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om3_1        | 2021-06-25 13:51:45,018 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm1.org_1   | 2021-06-25 13:39:55,049 [IPC Server handler 4 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
scm3.org_1   | 2021-06-25 13:41:31,417 [084c6adf-4c09-417d-ac5b-6ae661ceeb47@group-61155FD5A026-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2021-06-25 13:42:29,318 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om3_1        | 2021-06-25 13:51:45,018 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:58062
scm1.org_1   | 2021-06-25 13:39:55,064 [IPC Server handler 4 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm3.org_1   | 2021-06-25 13:41:59,002 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48656
scm2.org_1   | 2021-06-25 13:42:29,322 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om3_1        | 2021-06-25 13:51:45,019 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-25 13:39:55,064 [IPC Server handler 4 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 33554432 (custom)
scm3.org_1   | 2021-06-25 13:41:59,022 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-25 13:42:29,322 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om3_1        | 2021-06-25 13:51:45,692 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm1.org_1   | 2021-06-25 13:39:56,150 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$409/0x00000008404ef040@367fbb28] WARN util.JvmPauseMonitor: JvmPauseMonitor-76093931-f232-4415-806f-239960e589cb: Detected pause in JVM or host machine (eg GC): pause of approximately 942024167ns.
scm3.org_1   | 2021-06-25 13:41:59,159 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:54744
scm2.org_1   | 2021-06-25 13:42:29,323 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
om3_1        | 2021-06-25 13:51:45,693 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:58072
scm1.org_1   | GC pool 'ParNew' had collection(s): count=1 time=59ms
scm3.org_1   | 2021-06-25 13:41:59,183 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-25 13:42:29,323 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
om3_1        | 2021-06-25 13:51:45,694 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=987ms
scm3.org_1   | 2021-06-25 13:41:59,700 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:55070
scm2.org_1   | 2021-06-25 13:42:29,323 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
om3_1        | 2021-06-25 13:51:46,678 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm1.org_1   | 2021-06-25 13:39:56,308 [IPC Server handler 4 on default port 9863] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
scm2.org_1   | 2021-06-25 13:42:29,323 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm3.org_1   | 2021-06-25 13:41:59,721 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om3_1        | 2021-06-25 13:51:46,679 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:58084
scm1.org_1   | 2021-06-25 13:39:56,309 [IPC Server handler 4 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm2.org_1   | 2021-06-25 13:42:29,323 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
scm3.org_1   | 2021-06-25 13:42:00,508 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerV2Impl: Pipeline Pipeline[ Id: 33fecaa5-f059-4c14-a3bf-a0d73e1f71d5, Nodes: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:8dca9ea8-5191-4cce-a34e-3d546f33f7b1, CreationTimestamp2021-06-25T13:41:27.529Z] moved to OPEN state
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om3_1        | 2021-06-25 13:51:46,679 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-25 13:39:56,310 [IPC Server handler 4 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm2.org_1   | 2021-06-25 13:42:29,780 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:60812
scm3.org_1   | 2021-06-25 13:42:00,892 [084c6adf-4c09-417d-ac5b-6ae661ceeb47@group-61155FD5A026-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
om3_1        | 2021-06-25 13:51:47,401 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm1.org_1   | 2021-06-25 13:39:56,326 [IPC Server handler 4 on default port 9863] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis_grpc.log_appender.76093931-f232-4415-806f-239960e589cb@group-61155FD5A026
scm2.org_1   | 2021-06-25 13:42:29,799 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-25 13:42:45,463 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36744
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
om3_1        | 2021-06-25 13:51:47,401 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:58092
scm1.org_1   | 2021-06-25 13:39:56,326 [IPC Server handler 4 on default port 9863] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm2.org_1   | 2021-06-25 13:42:45,485 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-25 13:42:00,956 [EventQueue-PipelineReportForPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@167f3300, cost 424562.379us
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
om3_1        | 2021-06-25 13:51:47,410 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-25 13:39:58,588 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-LeaderStateImpl] INFO server.RaftServer$Division: 76093931-f232-4415-806f-239960e589cb@group-61155FD5A026: set configuration 5: [76cadbf9-8202-4493-b276-7e4d9594dfab|rpc:scm2.org:9894|priority:0, 76093931-f232-4415-806f-239960e589cb|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=[76093931-f232-4415-806f-239960e589cb|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm2.org_1   | 2021-06-25 13:42:59,447 [76cadbf9-8202-4493-b276-7e4d9594dfab@group-61155FD5A026-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 107544261427200000.
scm3.org_1   | 2021-06-25 13:42:01,810 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
s3g_1        | 2021-06-25 13:49:57,387 [qtp382627885-21] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-3A186A1CB1C5->ee31bb40-6981-4b57-b8d7-3be03fa0c81d
om3_1        | 2021-06-25 13:51:48,183 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm1.org_1   | 2021-06-25 13:39:58,947 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-LeaderStateImpl] INFO server.RaftServer$Division: 76093931-f232-4415-806f-239960e589cb@group-61155FD5A026: set configuration 7: [76cadbf9-8202-4493-b276-7e4d9594dfab|rpc:scm2.org:9894|priority:0, 76093931-f232-4415-806f-239960e589cb|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2021-06-25 13:43:03,498 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:60976
scm3.org_1   | 2021-06-25 13:42:04,953 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerV2Impl: Pipeline Pipeline[ Id: 8a55befb-80cf-4326-9d11-6eb5e5add68d, Nodes: d7f71981-d306-415b-992d-ee4808a385fa{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:d7f71981-d306-415b-992d-ee4808a385fa, CreationTimestamp2021-06-25T13:41:29.088Z] moved to OPEN state
s3g_1        | 2021-06-25 13:49:57,388 [qtp382627885-21] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm1.org_1   | 2021-06-25 13:39:58,997 [IPC Server handler 4 on default port 9863] INFO ha.SCMRatisServerImpl: Successfully added new SCM: 76cadbf9-8202-4493-b276-7e4d9594dfab.
om3_1        | 2021-06-25 13:51:48,183 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:58102
scm2.org_1   | 2021-06-25 13:43:03,539 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-25 13:42:04,956 [EventQueue-PipelineReportForPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@167f3300, cost 1937.612us
s3g_1        | 2021-06-25 13:49:58,697 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
scm1.org_1   | 2021-06-25 13:40:00,950 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:34080
scm1.org_1   | 2021-06-25 13:40:00,974 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm2.org_1   | 2021-06-25 13:43:03,913 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36838
scm3.org_1   | 2021-06-25 13:42:05,008 [084c6adf-4c09-417d-ac5b-6ae661ceeb47@group-61155FD5A026-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
scm1.org_1   | 2021-06-25 13:40:02,098 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.118:50594
om3_1        | 2021-06-25 13:51:48,184 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-25 13:43:03,984 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-25 13:42:05,093 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
scm1.org_1   | 2021-06-25 13:40:02,172 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om3_1        | 2021-06-25 13:51:52,748 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:58198
scm2.org_1   | 2021-06-25 13:43:04,048 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:60698
scm3.org_1   | 2021-06-25 13:42:05,445 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
scm1.org_1   | 2021-06-25 13:40:04,580 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46782
om3_1        | 2021-06-25 13:51:52,755 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-25 13:43:04,117 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-25 13:42:06,329 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerV2Impl: Pipeline Pipeline[ Id: 145b110b-f1b2-4a24-b4ba-bf6d91d43fa5, Nodes: ee31bb40-6981-4b57-b8d7-3be03fa0c81d{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:ee31bb40-6981-4b57-b8d7-3be03fa0c81d, CreationTimestamp2021-06-25T13:41:29.947Z] moved to OPEN state
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
scm1.org_1   | 2021-06-25 13:40:04,613 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
om3_1        | 2021-06-25 13:51:55,811 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm2.org_1   | 2021-06-25 13:43:33,375 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:32918
scm3.org_1   | 2021-06-25 13:42:06,339 [EventQueue-PipelineReportForPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@167f3300, cost 2426.716us
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
scm1.org_1   | 2021-06-25 13:40:05,256 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.118:50152
om3_1        | 2021-06-25 13:51:55,811 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:58152
scm2.org_1   | 2021-06-25 13:43:33,416 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-25 13:42:06,362 [084c6adf-4c09-417d-ac5b-6ae661ceeb47@group-61155FD5A026-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
scm1.org_1   | 2021-06-25 13:40:05,261 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
om3_1        | 2021-06-25 13:51:55,812 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-25 13:43:33,883 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37016
scm3.org_1   | 2021-06-25 13:42:29,022 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48824
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
scm1.org_1   | 2021-06-25 13:40:05,261 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for scm scm3.org, nodeId: 084c6adf-4c09-417d-ac5b-6ae661ceeb47
om3_1        | 2021-06-25 13:51:56,450 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm2.org_1   | 2021-06-25 13:43:33,894 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-25 13:42:29,035 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
scm1.org_1   | 2021-06-25 13:40:05,330 [IPC Server handler 0 on default port 9961] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-6D9E80F0BC45->76cadbf9-8202-4493-b276-7e4d9594dfab
om3_1        | 2021-06-25 13:51:56,450 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:58160
scm2.org_1   | 2021-06-25 13:43:34,001 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:60876
scm3.org_1   | 2021-06-25 13:42:29,039 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
om3_1        | 2021-06-25 13:51:56,454 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-25 13:40:05,330 [IPC Server handler 0 on default port 9961] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm2.org_1   | 2021-06-25 13:43:34,019 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-25 13:42:29,226 [084c6adf-4c09-417d-ac5b-6ae661ceeb47@group-61155FD5A026-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
om3_1        | 2021-06-25 13:51:57,135 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm1.org_1   | 2021-06-25 13:40:05,580 [java.util.concurrent.ThreadPoolExecutor$Worker@5472252c[State = -1, empty queue]] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-6D9E80F0BC45->76093931-f232-4415-806f-239960e589cb
scm2.org_1   | 2021-06-25 13:44:03,359 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33068
scm3.org_1   | 2021-06-25 13:42:29,257 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:54914
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
om3_1        | 2021-06-25 13:51:57,135 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:58170
scm1.org_1   | 2021-06-25 13:40:05,580 [java.util.concurrent.ThreadPoolExecutor$Worker@5472252c[State = -1, empty queue]] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm2.org_1   | 2021-06-25 13:44:03,439 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-25 13:42:29,272 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om3_1        | 2021-06-25 13:51:57,138 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-25 13:40:05,757 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2021-06-25 13:44:03,867 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37168
scm3.org_1   | 2021-06-25 13:42:29,274 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om3_1        | 2021-06-25 13:51:58,086 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm1.org_1   | 2021-06-25 13:40:05,771 [IPC Server handler 0 on default port 9961] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.security.x509.certificate.authority.CertificateStore.storeValidCertificate(java.math.BigInteger,java.security.cert.X509Certificate,org.apache.hadoop.hdds.protocol.proto.HddsProtos$NodeType) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1f7870bc, cost 446266.982us
scm2.org_1   | 2021-06-25 13:44:03,893 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-25 13:42:29,275 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
om3_1        | 2021-06-25 13:51:58,086 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:58182
scm1.org_1   | 2021-06-25 13:40:16,420 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46952
scm2.org_1   | 2021-06-25 13:44:04,023 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:32798
scm3.org_1   | 2021-06-25 13:42:29,275 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
om3_1        | 2021-06-25 13:51:58,087 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-25 13:40:16,463 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm2.org_1   | 2021-06-25 13:44:04,041 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-25 13:42:29,275 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm3.org_1   | 2021-06-25 13:42:29,275 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
om3_1        | 2021-06-25 13:51:58,733 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm1.org_1   | 2021-06-25 13:40:21,175 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.118:50828
scm3.org_1   | 2021-06-25 13:42:29,275 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
scm2.org_1   | 2021-06-25 13:44:33,331 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33236
om3_1        | 2021-06-25 13:51:58,733 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:58190
scm1.org_1   | 2021-06-25 13:40:21,350 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm3.org_1   | 2021-06-25 13:42:29,275 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
s3g_1        | 2021-06-25 13:50:07,606 [qtp382627885-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
scm2.org_1   | 2021-06-25 13:44:33,359 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 2021-06-25 13:51:58,734 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-25 13:40:21,353 [IPC Server handler 4 on default port 9863] INFO ha.SCMRatisServerImpl: 76093931-f232-4415-806f-239960e589cb: Submitting SetConfiguration request to Ratis server with new SCM peers list: [76cadbf9-8202-4493-b276-7e4d9594dfab|rpc:scm2.org:9894|priority:0, 76093931-f232-4415-806f-239960e589cb|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 084c6adf-4c09-417d-ac5b-6ae661ceeb47|rpc:scm3.org:9894|priority:0]
scm3.org_1   | 2021-06-25 13:42:29,731 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:55238
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
scm2.org_1   | 2021-06-25 13:44:33,826 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37338
om3_1        | 2021-06-25 13:51:59,613 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm1.org_1   | 2021-06-25 13:40:21,358 [IPC Server handler 4 on default port 9863] INFO server.RaftServer$Division: 76093931-f232-4415-806f-239960e589cb@group-61155FD5A026: receive setConfiguration SetConfigurationRequest:client-6F1937D9801B->76093931-f232-4415-806f-239960e589cb@group-61155FD5A026, cid=1, seq=0, RW, null, peers:[76cadbf9-8202-4493-b276-7e4d9594dfab|rpc:scm2.org:9894|priority:0, 76093931-f232-4415-806f-239960e589cb|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 084c6adf-4c09-417d-ac5b-6ae661ceeb47|rpc:scm3.org:9894|priority:0]
scm3.org_1   | 2021-06-25 13:42:29,746 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
scm2.org_1   | 2021-06-25 13:44:33,838 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 2021-06-25 13:51:59,614 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:58206
scm1.org_1   | 2021-06-25 13:40:21,366 [IPC Server handler 4 on default port 9863] INFO server.RaftServer$Division: 76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-LeaderStateImpl: startSetConfiguration SetConfigurationRequest:client-6F1937D9801B->76093931-f232-4415-806f-239960e589cb@group-61155FD5A026, cid=1, seq=0, RW, null, peers:[76cadbf9-8202-4493-b276-7e4d9594dfab|rpc:scm2.org:9894|priority:0, 76093931-f232-4415-806f-239960e589cb|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 084c6adf-4c09-417d-ac5b-6ae661ceeb47|rpc:scm3.org:9894|priority:0]
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
scm3.org_1   | 2021-06-25 13:42:45,511 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55002
scm2.org_1   | 2021-06-25 13:44:33,992 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:32968
om3_1        | 2021-06-25 13:51:59,615 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-25 13:40:21,366 [IPC Server handler 4 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
scm3.org_1   | 2021-06-25 13:42:45,532 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-25 13:44:34,031 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 2021-06-25 13:52:00,260 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm1.org_1   | 2021-06-25 13:40:21,368 [IPC Server handler 4 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
scm3.org_1   | 2021-06-25 13:42:59,448 [084c6adf-4c09-417d-ac5b-6ae661ceeb47@group-61155FD5A026-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 107544261427200000.
scm2.org_1   | 2021-06-25 13:44:52,066 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 2 containers.
om3_1        | 2021-06-25 13:52:00,261 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:58216
om3_1        | 2021-06-25 13:52:00,262 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
scm3.org_1   | 2021-06-25 13:43:03,404 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:55402
scm3.org_1   | 2021-06-25 13:43:03,453 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:40:21,368 [IPC Server handler 4 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 33554432 (custom)
om3_1        | 2021-06-25 13:52:01,704 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
scm3.org_1   | 2021-06-25 13:43:03,953 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55096
scm2.org_1   | 2021-06-25 13:45:03,336 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33404
scm1.org_1   | 2021-06-25 13:40:21,878 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$409/0x00000008404ef040@367fbb28] WARN util.JvmPauseMonitor: JvmPauseMonitor-76093931-f232-4415-806f-239960e589cb: Detected pause in JVM or host machine (eg GC): pause of approximately 101047332ns. No GCs detected.
om3_1        | 2021-06-25 13:52:01,705 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:58260
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
scm3.org_1   | 2021-06-25 13:43:04,012 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-25 13:45:03,372 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:40:21,927 [IPC Server handler 4 on default port 9863] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
om3_1        | 2021-06-25 13:52:01,705 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
scm3.org_1   | 2021-06-25 13:43:04,066 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49020
scm2.org_1   | 2021-06-25 13:45:03,840 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37506
scm1.org_1   | 2021-06-25 13:40:21,938 [IPC Server handler 4 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
om3_1        | 2021-06-25 13:52:02,339 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
scm3.org_1   | 2021-06-25 13:43:04,131 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-25 13:45:03,849 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:40:21,938 [IPC Server handler 4 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om3_1        | 2021-06-25 13:52:02,339 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:58272
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
scm3.org_1   | 2021-06-25 13:43:33,387 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:55582
scm2.org_1   | 2021-06-25 13:45:04,122 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:33134
scm1.org_1   | 2021-06-25 13:40:26,530 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-LeaderStateImpl] INFO server.RaftServer$Division: 76093931-f232-4415-806f-239960e589cb@group-61155FD5A026: set configuration 11: [084c6adf-4c09-417d-ac5b-6ae661ceeb47|rpc:scm3.org:9894|priority:0, 76cadbf9-8202-4493-b276-7e4d9594dfab|rpc:scm2.org:9894|priority:0, 76093931-f232-4415-806f-239960e589cb|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=[76cadbf9-8202-4493-b276-7e4d9594dfab|rpc:scm2.org:9894|priority:0, 76093931-f232-4415-806f-239960e589cb|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
om3_1        | 2021-06-25 13:52:02,341 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm3.org_1   | 2021-06-25 13:43:33,420 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-25 13:45:04,146 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:40:26,670 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-LeaderStateImpl] INFO server.RaftServer$Division: 76093931-f232-4415-806f-239960e589cb@group-61155FD5A026: set configuration 13: [084c6adf-4c09-417d-ac5b-6ae661ceeb47|rpc:scm3.org:9894|priority:0, 76cadbf9-8202-4493-b276-7e4d9594dfab|rpc:scm2.org:9894|priority:0, 76093931-f232-4415-806f-239960e589cb|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
om3_1        | 2021-06-25 13:52:02,958 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm3.org_1   | 2021-06-25 13:43:33,839 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55270
scm2.org_1   | 2021-06-25 13:45:33,335 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33576
scm1.org_1   | 2021-06-25 13:40:26,723 [IPC Server handler 4 on default port 9863] INFO ha.SCMRatisServerImpl: Successfully added new SCM: 084c6adf-4c09-417d-ac5b-6ae661ceeb47.
om3_1        | 2021-06-25 13:52:02,961 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:58282
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
scm3.org_1   | 2021-06-25 13:43:33,854 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-25 13:45:33,372 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:40:29,107 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$409/0x00000008404ef040@367fbb28] WARN util.JvmPauseMonitor: JvmPauseMonitor-76093931-f232-4415-806f-239960e589cb: Detected pause in JVM or host machine (eg GC): pause of approximately 151158359ns. No GCs detected.
om3_1        | 2021-06-25 13:52:02,962 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
scm3.org_1   | 2021-06-25 13:43:34,028 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49196
scm2.org_1   | 2021-06-25 13:45:33,837 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37670
scm1.org_1   | 2021-06-25 13:40:31,570 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om3_1        | 2021-06-25 13:52:03,620 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
scm3.org_1   | 2021-06-25 13:43:34,055 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-25 13:45:33,902 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:40:31,589 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1f7870bc, cost 205794.737us
om3_1        | 2021-06-25 13:52:03,621 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:58290
s3g_1        | 2021-06-25 13:50:07,618 [qtp382627885-24] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-25047, with Versioning false and Storage Type set to DISK and Encryption set to false 
scm3.org_1   | 2021-06-25 13:44:03,365 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:55726
scm2.org_1   | 2021-06-25 13:45:34,019 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:33306
scm1.org_1   | 2021-06-25 13:40:34,843 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.118:50388
om3_1        | 2021-06-25 13:52:03,624 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 2021-06-25 13:50:07,629 [qtp382627885-24] INFO endpoint.BucketEndpoint: Location is /bucket-25047
scm3.org_1   | 2021-06-25 13:44:03,440 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-25 13:45:34,090 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:40:34,869 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
om3_1        | 2021-06-25 13:52:04,276 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
s3g_1        | 2021-06-25 13:50:08,281 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
scm3.org_1   | 2021-06-25 13:44:03,829 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55422
scm2.org_1   | 2021-06-25 13:46:00,593 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33730
scm1.org_1   | 2021-06-25 13:40:48,533 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:43636
om3_1        | 2021-06-25 13:52:04,277 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:58300
om3_1        | 2021-06-25 13:52:04,278 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-25 13:44:03,851 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-25 13:46:00,639 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 2021-06-25 13:52:08,773 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:58392
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
scm3.org_1   | 2021-06-25 13:44:04,069 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49346
scm2.org_1   | 2021-06-25 13:46:00,672 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:33442
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
scm1.org_1   | 2021-06-25 13:40:48,579 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:53404
om3_1        | 2021-06-25 13:52:08,779 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-25 13:44:04,087 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-25 13:46:00,696 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
scm1.org_1   | 2021-06-25 13:40:48,617 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om3_1        | 2021-06-25 13:52:12,068 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm3.org_1   | 2021-06-25 13:44:33,346 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:55894
scm2.org_1   | 2021-06-25 13:46:00,804 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37826
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
scm1.org_1   | 2021-06-25 13:40:48,698 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om3_1        | 2021-06-25 13:52:12,068 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:58336
scm3.org_1   | 2021-06-25 13:44:33,360 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-25 13:46:00,838 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
scm1.org_1   | 2021-06-25 13:40:49,226 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:58510
om3_1        | 2021-06-25 13:52:12,072 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-25 13:44:33,829 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55596
scm2.org_1   | 2021-06-25 13:46:30,568 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33900
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
scm1.org_1   | 2021-06-25 13:40:49,366 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om3_1        | 2021-06-25 13:52:12,778 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm3.org_1   | 2021-06-25 13:44:33,863 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-25 13:46:30,590 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
scm1.org_1   | 2021-06-25 13:40:51,466 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38746
om3_1        | 2021-06-25 13:52:12,780 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:58354
scm3.org_1   | 2021-06-25 13:44:33,995 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49520
scm2.org_1   | 2021-06-25 13:46:30,624 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:33616
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
scm1.org_1   | 2021-06-25 13:40:51,656 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
om3_1        | 2021-06-25 13:52:12,781 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-25 13:44:34,031 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-25 13:46:30,661 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
scm1.org_1   | 2021-06-25 13:40:51,660 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn 9d41ca97b170, UUID: ee31bb40-6981-4b57-b8d7-3be03fa0c81d
om3_1        | 2021-06-25 13:52:13,605 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm3.org_1   | 2021-06-25 13:45:03,342 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56062
scm2.org_1   | 2021-06-25 13:46:30,769 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37998
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
scm1.org_1   | 2021-06-25 13:40:51,977 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om3_1        | 2021-06-25 13:52:13,606 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:58368
scm3.org_1   | 2021-06-25 13:45:03,372 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-25 13:46:30,793 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm1.org_1   | 2021-06-25 13:40:52,030 [IPC Server handler 0 on default port 9961] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.security.x509.certificate.authority.CertificateStore.storeValidCertificate(java.math.BigInteger,java.security.cert.X509Certificate,org.apache.hadoop.hdds.protocol.proto.HddsProtos$NodeType) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1f7870bc, cost 166575.846us
om3_1        | 2021-06-25 13:52:13,607 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-25 13:45:03,842 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55760
scm2.org_1   | 2021-06-25 13:47:00,543 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34064
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm1.org_1   | 2021-06-25 13:40:52,366 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47848
om3_1        | 2021-06-25 13:52:14,278 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm3.org_1   | 2021-06-25 13:45:03,878 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-25 13:47:00,551 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
scm1.org_1   | 2021-06-25 13:40:52,435 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
om3_1        | 2021-06-25 13:52:14,278 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:58378
scm3.org_1   | 2021-06-25 13:45:04,073 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49686
scm2.org_1   | 2021-06-25 13:47:00,655 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:33782
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
scm1.org_1   | 2021-06-25 13:40:52,440 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn 2c32953938b8, UUID: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1
om3_1        | 2021-06-25 13:52:14,279 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-25 13:45:04,119 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-25 13:47:00,675 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
scm1.org_1   | 2021-06-25 13:40:52,751 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2021-06-25 13:40:52,776 [IPC Server handler 0 on default port 9961] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.security.x509.certificate.authority.CertificateStore.storeValidCertificate(java.math.BigInteger,java.security.cert.X509Certificate,org.apache.hadoop.hdds.protocol.proto.HddsProtos$NodeType) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1f7870bc, cost 131689.205us
scm3.org_1   | 2021-06-25 13:45:14,947 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 2 containers.
scm2.org_1   | 2021-06-25 13:47:00,761 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38162
s3g_1        | 2021-06-25 13:50:08,303 [qtp382627885-21] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-66065, with Versioning false and Storage Type set to DISK and Encryption set to false 
scm1.org_1   | 2021-06-25 13:40:52,853 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46672
om3_1        | 2021-06-25 13:52:14,950 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm3.org_1   | 2021-06-25 13:45:33,382 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56234
scm2.org_1   | 2021-06-25 13:47:00,796 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 2021-06-25 13:50:08,324 [qtp382627885-21] INFO endpoint.BucketEndpoint: Location is /bucket-66065
scm1.org_1   | 2021-06-25 13:40:52,956 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
om3_1        | 2021-06-25 13:52:14,951 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:58388
scm3.org_1   | 2021-06-25 13:45:33,400 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-25 13:47:30,554 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34242
s3g_1        | 2021-06-25 13:50:08,991 [qtp382627885-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
scm1.org_1   | 2021-06-25 13:40:52,962 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn 7b9eb44ecf31, UUID: d7f71981-d306-415b-992d-ee4808a385fa
om3_1        | 2021-06-25 13:52:14,951 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-25 13:45:33,857 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55924
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
scm2.org_1   | 2021-06-25 13:47:30,600 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:33956
scm1.org_1   | 2021-06-25 13:40:53,260 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om3_1        | 2021-06-25 13:52:15,592 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm3.org_1   | 2021-06-25 13:45:33,913 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
scm1.org_1   | 2021-06-25 13:40:53,310 [IPC Server handler 1 on default port 9961] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.security.x509.certificate.authority.CertificateStore.storeValidCertificate(java.math.BigInteger,java.security.cert.X509Certificate,org.apache.hadoop.hdds.protocol.proto.HddsProtos$NodeType) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1f7870bc, cost 135755.332us
om3_1        | 2021-06-25 13:52:15,592 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:58398
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
scm2.org_1   | 2021-06-25 13:47:30,602 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-25 13:45:34,030 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49858
scm1.org_1   | 2021-06-25 13:40:57,243 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47072
om3_1        | 2021-06-25 13:52:15,610 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
scm2.org_1   | 2021-06-25 13:47:30,642 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-25 13:45:34,090 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:40:57,418 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
om3_1        | 2021-06-25 13:52:16,227 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
scm2.org_1   | 2021-06-25 13:47:30,744 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38340
scm3.org_1   | 2021-06-25 13:46:00,626 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56388
scm1.org_1   | 2021-06-25 13:41:01,883 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:35476
om3_1        | 2021-06-25 13:52:16,228 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:58408
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
scm2.org_1   | 2021-06-25 13:47:30,752 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-25 13:46:00,644 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49994
scm1.org_1   | 2021-06-25 13:41:01,899 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:34814
om3_1        | 2021-06-25 13:52:16,229 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-25 13:48:00,541 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34404
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
scm3.org_1   | 2021-06-25 13:46:00,650 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:41:01,924 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
om3_1        | 2021-06-25 13:52:16,833 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm2.org_1   | 2021-06-25 13:48:00,569 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
scm3.org_1   | 2021-06-25 13:46:00,682 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:41:01,950 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for om om1, UUID: 6706fc84-93a7-4d90-b1ad-31f9c4de0cf0
om3_1        | 2021-06-25 13:52:16,833 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:58416
scm2.org_1   | 2021-06-25 13:48:00,605 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:34124
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
scm3.org_1   | 2021-06-25 13:46:00,761 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56084
scm1.org_1   | 2021-06-25 13:41:01,977 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
om3_1        | 2021-06-25 13:52:16,845 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-25 13:48:00,625 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
scm3.org_1   | 2021-06-25 13:46:00,800 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:41:01,998 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for om om3, UUID: dda8dce1-05ff-417a-9c39-a2e98eb1f5cb
om3_1        | 2021-06-25 13:52:17,484 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm2.org_1   | 2021-06-25 13:48:00,758 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38504
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm3.org_1   | 2021-06-25 13:46:30,658 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56562
scm1.org_1   | 2021-06-25 13:41:02,197 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om3_1        | 2021-06-25 13:52:17,485 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:58426
scm2.org_1   | 2021-06-25 13:48:00,792 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm3.org_1   | 2021-06-25 13:46:30,672 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:41:02,270 [IPC Server handler 1 on default port 9961] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.security.x509.certificate.authority.CertificateStore.storeValidCertificate(java.math.BigInteger,java.security.cert.X509Certificate,org.apache.hadoop.hdds.protocol.proto.HddsProtos$NodeType) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1f7870bc, cost 128223.975us
om3_1        | 2021-06-25 13:52:17,486 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-25 13:48:30,557 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34582
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
scm3.org_1   | 2021-06-25 13:46:30,741 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50164
scm1.org_1   | 2021-06-25 13:41:02,481 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om3_1        | 2021-06-25 13:52:18,335 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm2.org_1   | 2021-06-25 13:48:30,600 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
scm3.org_1   | 2021-06-25 13:46:30,772 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:41:02,499 [IPC Server handler 0 on default port 9961] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.security.x509.certificate.authority.CertificateStore.storeValidCertificate(java.math.BigInteger,java.security.cert.X509Certificate,org.apache.hadoop.hdds.protocol.proto.HddsProtos$NodeType) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1f7870bc, cost 122563.936us
om3_1        | 2021-06-25 13:52:18,335 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:58436
scm2.org_1   | 2021-06-25 13:48:30,629 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:34300
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
scm3.org_1   | 2021-06-25 13:46:30,798 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56256
scm1.org_1   | 2021-06-25 13:41:03,110 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38774
om3_1        | 2021-06-25 13:52:18,336 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-25 13:48:30,669 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 2021-06-25 13:50:09,009 [qtp382627885-24] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-25047, with Versioning false and Storage Type set to DISK and Encryption set to false 
scm3.org_1   | 2021-06-25 13:46:30,808 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-25 13:47:00,623 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50328
om3_1        | 2021-06-25 13:52:18,978 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm2.org_1   | 2021-06-25 13:48:30,763 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38682
s3g_1        | 2021-06-25 13:50:09,050 [qtp382627885-24] INFO endpoint.BucketEndpoint: Location is /bucket-25047
scm3.org_1   | 2021-06-25 13:47:00,627 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56722
scm1.org_1   | 2021-06-25 13:41:03,156 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
om3_1        | 2021-06-25 13:52:18,979 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:58454
scm2.org_1   | 2021-06-25 13:48:30,792 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 2021-06-25 13:50:09,670 [qtp382627885-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
scm3.org_1   | 2021-06-25 13:47:00,654 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:41:03,633 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:46568
om3_1        | 2021-06-25 13:52:18,984 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-25 13:49:00,662 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34730
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
scm3.org_1   | 2021-06-25 13:47:00,690 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:41:03,691 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
om3_1        | 2021-06-25 13:52:19,627 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm2.org_1   | 2021-06-25 13:49:00,676 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:34446
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
scm3.org_1   | 2021-06-25 13:47:00,784 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56416
om3_1        | 2021-06-25 13:52:19,627 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:58464
scm2.org_1   | 2021-06-25 13:49:00,689 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
scm3.org_1   | 2021-06-25 13:47:00,804 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:41:03,692 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for om om2, UUID: 5419ac9d-dea6-4894-8589-f30e9d8c9d30
om3_1        | 2021-06-25 13:52:19,628 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-25 13:49:00,721 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
scm3.org_1   | 2021-06-25 13:47:30,554 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56900
scm1.org_1   | 2021-06-25 13:41:04,049 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om3_1        | 2021-06-25 13:52:20,265 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm2.org_1   | 2021-06-25 13:49:00,795 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38828
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
scm3.org_1   | 2021-06-25 13:47:30,599 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-25 13:47:30,615 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50508
om3_1        | 2021-06-25 13:52:20,265 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:58472
scm2.org_1   | 2021-06-25 13:49:00,803 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
scm3.org_1   | 2021-06-25 13:47:30,628 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:41:04,130 [IPC Server handler 1 on default port 9961] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.security.x509.certificate.authority.CertificateStore.storeValidCertificate(java.math.BigInteger,java.security.cert.X509Certificate,org.apache.hadoop.hdds.protocol.proto.HddsProtos$NodeType) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1f7870bc, cost 236165.31us
om3_1        | 2021-06-25 13:52:20,267 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-25 13:49:30,607 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35030
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
scm3.org_1   | 2021-06-25 13:47:30,759 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56594
scm1.org_1   | 2021-06-25 13:41:05,118 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47878
om3_1        | 2021-06-25 13:52:20,906 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm2.org_1   | 2021-06-25 13:49:30,616 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:34746
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
scm3.org_1   | 2021-06-25 13:47:30,772 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:41:05,174 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
om3_1        | 2021-06-25 13:52:20,906 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:58482
scm2.org_1   | 2021-06-25 13:49:30,638 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
scm3.org_1   | 2021-06-25 13:48:00,605 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50672
scm1.org_1   | 2021-06-25 13:41:05,906 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46702
om3_1        | 2021-06-25 13:52:20,910 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-25 13:49:30,645 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
scm3.org_1   | 2021-06-25 13:48:00,624 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:57066
scm1.org_1   | 2021-06-25 13:41:05,954 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
om3_1        | 2021-06-25 13:52:21,704 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm2.org_1   | 2021-06-25 13:49:30,762 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:39130
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
scm3.org_1   | 2021-06-25 13:48:00,630 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:41:23,671 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38892
om3_1        | 2021-06-25 13:52:21,705 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:58494
scm2.org_1   | 2021-06-25 13:49:30,794 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm3.org_1   | 2021-06-25 13:48:00,635 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:41:23,734 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 2021-06-25 13:52:21,705 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-25 13:49:52,067 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 2 containers.
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm3.org_1   | 2021-06-25 13:48:00,757 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56758
scm1.org_1   | 2021-06-25 13:41:24,027 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:54740
scm1.org_1   | 2021-06-25 13:41:24,062 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:41:25,446 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:42600
scm1.org_1   | 2021-06-25 13:41:25,474 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:41:27,479 [IPC Server handler 95 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/8dca9ea8-5191-4cce-a34e-3d546f33f7b1
scm1.org_1   | 2021-06-25 13:41:27,506 [IPC Server handler 95 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 8dca9ea8-5191-4cce-a34e-3d546f33f7b1{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 2982768810642, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm1.org_1   | 2021-06-25 13:41:27,514 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm1.org_1   | 2021-06-25 13:41:27,578 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=33fecaa5-f059-4c14-a3bf-a0d73e1f71d5 to datanode:8dca9ea8-5191-4cce-a34e-3d546f33f7b1
scm1.org_1   | 2021-06-25 13:41:27,605 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
om3_1        | 2021-06-25 13:52:22,365 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om3_1        | 2021-06-25 13:52:22,366 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:58504
om3_1        | 2021-06-25 13:52:22,369 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:52:23,033 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om3_1        | 2021-06-25 13:52:23,035 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:58512
scm2.org_1   | 2021-06-25 13:50:00,589 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35400
scm2.org_1   | 2021-06-25 13:50:00,630 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:35114
scm2.org_1   | 2021-06-25 13:50:00,651 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-25 13:50:00,662 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-25 13:50:00,755 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:39498
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:50:09,682 [qtp382627885-24] ERROR endpoint.BucketEndpoint: Error in Create Bucket Request for bucket: bucket_1
om3_1        | 2021-06-25 13:52:23,036 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:52:23,663 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om3_1        | 2021-06-25 13:52:23,664 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:58522
om3_1        | 2021-06-25 13:52:23,666 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-25 13:52:24,304 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om3_1        | 2021-06-25 13:52:24,304 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:58530
scm2.org_1   | 2021-06-25 13:50:00,790 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-25 13:50:30,656 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:35352
scm2.org_1   | 2021-06-25 13:50:30,700 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35638
s3g_1        | INVALID_BUCKET_NAME org.apache.hadoop.ozone.om.exceptions.OMException: Bucket or Volume name has an unsupported character : _
s3g_1        | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.verifyBucketName(RpcClient.java:519)
s3g_1        | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.createBucket(RpcClient.java:463)
s3g_1        | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.createBucket(RpcClient.java:454)
s3g_1        | 	at org.apache.hadoop.ozone.client.OzoneVolume.createBucket(OzoneVolume.java:385)
s3g_1        | 	at org.apache.hadoop.ozone.client.ObjectStore.createS3Bucket(ObjectStore.java:118)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.EndpointBase.createS3Bucket(EndpointBase.java:94)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:239)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
scm3.org_1   | 2021-06-25 13:48:00,787 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
scm1.org_1   | 2021-06-25 13:41:27,816 [IPC Server handler 62 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/ee31bb40-6981-4b57-b8d7-3be03fa0c81d
scm2.org_1   | 2021-06-25 13:50:30,714 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 2021-06-25 13:52:24,305 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-25 13:48:30,601 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:57244
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
scm1.org_1   | 2021-06-25 13:41:27,923 [IPC Server handler 62 on default port 9861] INFO node.SCMNodeManager: Registered Data node : ee31bb40-6981-4b57-b8d7-3be03fa0c81d{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 2981987122066, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm2.org_1   | 2021-06-25 13:50:30,732 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 2021-06-25 13:52:28,090 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:58624
scm3.org_1   | 2021-06-25 13:48:30,632 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50846
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
scm1.org_1   | 2021-06-25 13:41:27,924 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm2.org_1   | 2021-06-25 13:50:30,826 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:39736
om3_1        | 2021-06-25 13:52:28,097 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-25 13:48:30,652 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
scm1.org_1   | 2021-06-25 13:41:28,023 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
scm2.org_1   | 2021-06-25 13:50:30,849 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 2021-06-25 13:52:30,835 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
om3_1        | 2021-06-25 13:52:30,841 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:58602
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
scm1.org_1   | 2021-06-25 13:41:28,112 [IPC Server handler 56 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/d7f71981-d306-415b-992d-ee4808a385fa
scm2.org_1   | 2021-06-25 13:51:00,586 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35918
om3_1        | 2021-06-25 13:52:30,846 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-25 13:48:30,666 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
scm1.org_1   | 2021-06-25 13:41:28,144 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm2.org_1   | 2021-06-25 13:51:00,613 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:35636
om3_1        | 2021-06-25 13:52:31,530 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm3.org_1   | 2021-06-25 13:48:30,755 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56936
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
scm1.org_1   | 2021-06-25 13:41:28,144 [IPC Server handler 56 on default port 9861] INFO node.SCMNodeManager: Registered Data node : d7f71981-d306-415b-992d-ee4808a385fa{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 2983272084503, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm2.org_1   | 2021-06-25 13:51:00,641 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 2021-06-25 13:52:31,530 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:58614
scm3.org_1   | 2021-06-25 13:48:30,772 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
scm1.org_1   | 2021-06-25 13:41:28,374 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
scm2.org_1   | 2021-06-25 13:51:00,692 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 2021-06-25 13:52:31,531 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
scm3.org_1   | 2021-06-25 13:49:00,647 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:57388
scm1.org_1   | 2021-06-25 13:41:28,374 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm1.org_1   | 2021-06-25 13:41:28,374 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
om3_1        | 2021-06-25 13:52:32,335 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
scm3.org_1   | 2021-06-25 13:49:00,669 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50994
scm1.org_1   | 2021-06-25 13:41:28,375 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm2.org_1   | 2021-06-25 13:51:00,766 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:40020
om3_1        | 2021-06-25 13:52:32,335 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:58626
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
scm3.org_1   | 2021-06-25 13:49:00,694 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:41:28,375 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
scm2.org_1   | 2021-06-25 13:51:00,815 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 2021-06-25 13:52:32,336 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
scm3.org_1   | 2021-06-25 13:49:00,722 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:41:28,375 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm2.org_1   | 2021-06-25 13:51:30,585 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:36380
om3_1        | 2021-06-25 13:52:33,069 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
scm3.org_1   | 2021-06-25 13:49:00,766 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:57086
scm2.org_1   | 2021-06-25 13:51:30,615 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36096
scm1.org_1   | 2021-06-25 13:41:28,391 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$409/0x00000008404ef040@367fbb28] WARN util.JvmPauseMonitor: JvmPauseMonitor-76093931-f232-4415-806f-239960e589cb: Detected pause in JVM or host machine (eg GC): pause of approximately 140450190ns. No GCs detected.
om3_1        | 2021-06-25 13:52:33,070 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:58638
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
scm3.org_1   | 2021-06-25 13:49:00,781 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-25 13:51:30,638 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:41:28,702 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 33fecaa5-f059-4c14-a3bf-a0d73e1f71d5, Nodes: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2021-06-25T13:41:27.529Z].
om3_1        | 2021-06-25 13:52:33,070 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
scm3.org_1   | 2021-06-25 13:49:30,606 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51298
scm2.org_1   | 2021-06-25 13:51:30,639 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:41:28,735 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om3_1        | 2021-06-25 13:52:33,829 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
scm3.org_1   | 2021-06-25 13:49:30,609 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:57692
scm2.org_1   | 2021-06-25 13:51:30,761 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:40476
scm1.org_1   | 2021-06-25 13:41:28,736 [RatisPipelineUtilsThread - 0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.addPipeline(org.apache.hadoop.hdds.protocol.proto.HddsProtos$Pipeline) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1f7870bc, cost 205778.078us
om3_1        | 2021-06-25 13:52:33,830 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:58648
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
scm3.org_1   | 2021-06-25 13:49:30,626 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-25 13:51:30,791 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:41:28,879 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=3175bb45-44a8-4478-8980-bfea630f7f68 to datanode:ee31bb40-6981-4b57-b8d7-3be03fa0c81d
om3_1        | 2021-06-25 13:52:33,830 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
scm3.org_1   | 2021-06-25 13:49:30,645 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-25 13:52:00,639 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:36750
scm1.org_1   | 2021-06-25 13:41:28,880 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=3175bb45-44a8-4478-8980-bfea630f7f68 to datanode:8dca9ea8-5191-4cce-a34e-3d546f33f7b1
om3_1        | 2021-06-25 13:52:34,471 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
scm3.org_1   | 2021-06-25 13:49:30,747 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:57384
scm2.org_1   | 2021-06-25 13:52:00,673 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36458
scm1.org_1   | 2021-06-25 13:41:28,882 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=3175bb45-44a8-4478-8980-bfea630f7f68 to datanode:d7f71981-d306-415b-992d-ee4808a385fa
om3_1        | 2021-06-25 13:52:34,472 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:58660
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
scm3.org_1   | 2021-06-25 13:49:30,760 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-25 13:52:00,681 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:41:28,955 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 3175bb45-44a8-4478-8980-bfea630f7f68, Nodes: ee31bb40-6981-4b57-b8d7-3be03fa0c81d{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}8dca9ea8-5191-4cce-a34e-3d546f33f7b1{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}d7f71981-d306-415b-992d-ee4808a385fa{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2021-06-25T13:41:28.879Z].
om3_1        | 2021-06-25 13:52:34,472 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
scm2.org_1   | 2021-06-25 13:52:00,787 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:40840
scm1.org_1   | 2021-06-25 13:41:28,986 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om3_1        | 2021-06-25 13:52:34,525 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:s3v, Bucket:bucket-96700, Key:29528/multidelete/f4.
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
scm3.org_1   | 2021-06-25 13:50:00,607 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:58056
scm2.org_1   | 2021-06-25 13:52:00,810 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:41:29,028 [RatisPipelineUtilsThread - 0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.addPipeline(org.apache.hadoop.hdds.protocol.proto.HddsProtos$Pipeline) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1f7870bc, cost 144962.571us
om3_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
scm3.org_1   | 2021-06-25 13:50:00,627 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51662
scm2.org_1   | 2021-06-25 13:52:00,838 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:41:29,088 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=8a55befb-80cf-4326-9d11-6eb5e5add68d to datanode:d7f71981-d306-415b-992d-ee4808a385fa
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:133)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
scm3.org_1   | 2021-06-25 13:50:00,655 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-25 13:52:30,602 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:37076
scm1.org_1   | 2021-06-25 13:41:29,172 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 8a55befb-80cf-4326-9d11-6eb5e5add68d, Nodes: d7f71981-d306-415b-992d-ee4808a385fa{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2021-06-25T13:41:29.088Z].
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
scm3.org_1   | 2021-06-25 13:50:00,667 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-25 13:52:30,612 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:41:29,195 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
scm3.org_1   | 2021-06-25 13:50:00,754 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:57752
scm2.org_1   | 2021-06-25 13:52:30,619 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36792
scm1.org_1   | 2021-06-25 13:41:29,207 [RatisPipelineUtilsThread - 0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.addPipeline(org.apache.hadoop.hdds.protocol.proto.HddsProtos$Pipeline) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1f7870bc, cost 110269.138us
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
scm3.org_1   | 2021-06-25 13:50:00,787 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-25 13:52:30,633 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:41:29,318 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=949dd475-00f3-4295-9774-5191be84cab1 to datanode:8dca9ea8-5191-4cce-a34e-3d546f33f7b1
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm3.org_1   | 2021-06-25 13:50:14,948 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 2 containers.
scm3.org_1   | 2021-06-25 13:50:30,653 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51906
scm1.org_1   | 2021-06-25 13:41:29,330 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=949dd475-00f3-4295-9774-5191be84cab1 to datanode:ee31bb40-6981-4b57-b8d7-3be03fa0c81d
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
scm3.org_1   | 2021-06-25 13:50:30,721 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-25 13:52:30,766 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41182
scm1.org_1   | 2021-06-25 13:41:29,338 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=949dd475-00f3-4295-9774-5191be84cab1 to datanode:d7f71981-d306-415b-992d-ee4808a385fa
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
scm1.org_1   | 2021-06-25 13:41:29,707 [RatisPipelineUtilsThread - 0] INFO segmented.SegmentedRaftLogWorker: 76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-SegmentedRaftLogWorker: Rolling segment log-1_34 to index:34
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm2.org_1   | 2021-06-25 13:52:30,797 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-25 13:50:30,762 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:58300
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
scm1.org_1   | 2021-06-25 13:41:29,738 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/8e5d7696-3ffc-40b4-8848-61155fd5a026/current/log_inprogress_1 to /data/metadata/scm-ha/8e5d7696-3ffc-40b4-8848-61155fd5a026/current/log_1-34
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm2.org_1   | 2021-06-25 13:53:00,618 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:37472
scm3.org_1   | 2021-06-25 13:50:30,765 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:57994
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
scm1.org_1   | 2021-06-25 13:41:29,758 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/8e5d7696-3ffc-40b4-8848-61155fd5a026/current/log_inprogress_35
om3_1        | 2021-06-25 13:52:35,178 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm2.org_1   | 2021-06-25 13:53:00,650 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37186
scm3.org_1   | 2021-06-25 13:50:30,777 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
om3_1        | 2021-06-25 13:52:35,179 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:58670
scm2.org_1   | 2021-06-25 13:53:00,671 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:41:29,857 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 949dd475-00f3-4295-9774-5191be84cab1, Nodes: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}ee31bb40-6981-4b57-b8d7-3be03fa0c81d{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}d7f71981-d306-415b-992d-ee4808a385fa{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2021-06-25T13:41:29.318Z].
scm3.org_1   | 2021-06-25 13:50:30,797 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
om3_1        | 2021-06-25 13:52:35,182 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-25 13:53:00,700 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:41:29,887 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2021-06-25 13:51:00,581 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:58580
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
om3_1        | 2021-06-25 13:52:39,629 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:58764
scm2.org_1   | 2021-06-25 13:53:00,753 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41570
scm1.org_1   | 2021-06-25 13:41:29,895 [RatisPipelineUtilsThread - 0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.addPipeline(org.apache.hadoop.hdds.protocol.proto.HddsProtos$Pipeline) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1f7870bc, cost 550408.083us
scm3.org_1   | 2021-06-25 13:51:00,610 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52188
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
om3_1        | 2021-06-25 13:52:39,642 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-25 13:53:00,793 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:41:29,946 [RatisPipelineUtilsThread - 0] INFO pipeline.PipelineManagerV2Impl: Pipeline: PipelineID=949dd475-00f3-4295-9774-5191be84cab1 contains same datanodes as previous pipelines: PipelineID=3175bb45-44a8-4478-8980-bfea630f7f68 nodeIds: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1, ee31bb40-6981-4b57-b8d7-3be03fa0c81d, d7f71981-d306-415b-992d-ee4808a385fa
scm3.org_1   | 2021-06-25 13:51:00,635 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
om3_1        | 2021-06-25 13:52:42,529 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm2.org_1   | 2021-06-25 13:53:30,495 [76cadbf9-8202-4493-b276-7e4d9594dfab@group-61155FD5A026-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: e166831c-4ec6-45e5-8ea8-b63dd27aa2c5, Nodes: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:OPEN, leaderId:, CreationTimestamp2021-06-25T13:53:30.441Z].
scm1.org_1   | 2021-06-25 13:41:29,947 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=145b110b-f1b2-4a24-b4ba-bf6d91d43fa5 to datanode:ee31bb40-6981-4b57-b8d7-3be03fa0c81d
scm3.org_1   | 2021-06-25 13:51:00,686 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
om3_1        | 2021-06-25 13:52:42,529 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:58708
scm2.org_1   | 2021-06-25 13:53:30,572 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:37636
scm1.org_1   | 2021-06-25 13:41:30,091 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 145b110b-f1b2-4a24-b4ba-bf6d91d43fa5, Nodes: ee31bb40-6981-4b57-b8d7-3be03fa0c81d{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2021-06-25T13:41:29.947Z].
scm1.org_1   | 2021-06-25 13:41:30,104 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
om3_1        | 2021-06-25 13:52:42,530 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-25 13:51:00,770 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58274
scm1.org_1   | 2021-06-25 13:41:30,115 [RatisPipelineUtilsThread - 0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.addPipeline(org.apache.hadoop.hdds.protocol.proto.HddsProtos$Pipeline) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1f7870bc, cost 162678.188us
scm2.org_1   | 2021-06-25 13:53:30,600 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
om3_1        | 2021-06-25 13:52:43,206 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm3.org_1   | 2021-06-25 13:51:00,814 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:41:31,384 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2021-06-25 13:53:30,606 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37352
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
om3_1        | 2021-06-25 13:52:43,207 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:58726
scm3.org_1   | 2021-06-25 13:51:30,552 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:59038
scm1.org_1   | 2021-06-25 13:41:31,388 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1f7870bc, cost 29992.2us
scm2.org_1   | 2021-06-25 13:53:30,627 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
om3_1        | 2021-06-25 13:52:43,208 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-25 13:51:30,616 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52642
scm1.org_1   | 2021-06-25 13:41:32,654 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:43774
scm2.org_1   | 2021-06-25 13:53:30,750 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41732
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
om3_1        | 2021-06-25 13:52:44,009 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm3.org_1   | 2021-06-25 13:51:30,628 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:41:32,736 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm2.org_1   | 2021-06-25 13:53:30,768 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
om3_1        | 2021-06-25 13:52:44,009 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:58740
scm3.org_1   | 2021-06-25 13:51:30,640 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-25 13:51:30,768 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58730
scm2.org_1   | 2021-06-25 13:54:00,547 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:37778
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
om3_1        | 2021-06-25 13:52:44,010 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-25 13:51:30,806 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:41:33,137 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:58654
scm2.org_1   | 2021-06-25 13:54:00,550 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
om3_1        | 2021-06-25 13:52:44,628 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm3.org_1   | 2021-06-25 13:52:00,636 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:59400
scm1.org_1   | 2021-06-25 13:41:33,236 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm2.org_1   | 2021-06-25 13:54:00,745 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41870
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
om3_1        | 2021-06-25 13:52:44,628 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:58748
scm3.org_1   | 2021-06-25 13:52:00,656 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53006
scm1.org_1   | 2021-06-25 13:41:33,906 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:53552
scm2.org_1   | 2021-06-25 13:54:00,755 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
scm3.org_1   | 2021-06-25 13:52:00,743 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:41:33,960 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm2.org_1   | 2021-06-25 13:54:02,955 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37514
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
om3_1        | 2021-06-25 13:52:44,629 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-25 13:52:00,817 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:41:35,686 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47208
scm2.org_1   | 2021-06-25 13:54:02,984 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
om3_1        | 2021-06-25 13:52:45,327 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm3.org_1   | 2021-06-25 13:52:00,826 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:59094
scm1.org_1   | 2021-06-25 13:41:35,757 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm2.org_1   | 2021-06-25 13:54:30,553 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:37916
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
om3_1        | 2021-06-25 13:52:45,328 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:58758
scm3.org_1   | 2021-06-25 13:52:00,849 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:41:40,711 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:34960
scm2.org_1   | 2021-06-25 13:54:30,559 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
om3_1        | 2021-06-25 13:52:45,328 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-25 13:52:30,642 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:59738
scm1.org_1   | 2021-06-25 13:41:40,735 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm2.org_1   | 2021-06-25 13:54:30,755 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:42014
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
om3_1        | 2021-06-25 13:52:45,974 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm3.org_1   | 2021-06-25 13:52:30,643 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53344
scm2.org_1   | 2021-06-25 13:54:30,788 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
om3_1        | 2021-06-25 13:52:45,974 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:58766
scm1.org_1   | 2021-06-25 13:41:40,913 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:35626
scm3.org_1   | 2021-06-25 13:52:30,652 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-25 13:54:31,674 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37656
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
om3_1        | 2021-06-25 13:52:45,975 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-25 13:41:40,927 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm3.org_1   | 2021-06-25 13:52:30,669 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-25 13:54:31,676 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] INFO container.IncrementalContainerReportHandler: Moving container #1 to CLOSED state, datanode d7f71981-d306-415b-992d-ee4808a385fa{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
om3_1        | 2021-06-25 13:52:46,665 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm1.org_1   | 2021-06-25 13:41:41,424 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:46708
scm3.org_1   | 2021-06-25 13:52:30,771 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:59440
scm2.org_1   | 2021-06-25 13:54:31,690 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.container.ContainerStateManagerV2.updateContainerState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$ContainerID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$LifeCycleEvent) throws java.io.IOException,org.apache.hadoop.ozone.common.statemachine.InvalidStateTransitionException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@547c76b5, cost 1315.706us
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
om3_1        | 2021-06-25 13:52:46,665 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:58782
scm1.org_1   | 2021-06-25 13:41:41,444 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm3.org_1   | 2021-06-25 13:52:30,809 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-25 13:54:31,702 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] ERROR container.IncrementalContainerReportHandler: Exception while processing ICR for container 1
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
om3_1        | 2021-06-25 13:52:46,666 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-25 13:41:52,400 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47278
scm3.org_1   | 2021-06-25 13:53:00,638 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53738
scm2.org_1   | org.apache.ratis.protocol.exceptions.NotLeaderException: Server 76cadbf9-8202-4493-b276-7e4d9594dfab@group-61155FD5A026 is not the leader 76093931-f232-4415-806f-239960e589cb|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
om3_1        | 2021-06-25 13:52:47,367 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm1.org_1   | 2021-06-25 13:41:52,427 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm3.org_1   | 2021-06-25 13:53:00,642 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:60128
scm2.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.generateNotLeaderException(RaftServerImpl.java:661)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
om3_1        | 2021-06-25 13:52:47,368 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:58792
scm1.org_1   | 2021-06-25 13:41:59,014 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:42770
scm3.org_1   | 2021-06-25 13:53:00,674 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.checkLeaderState(RaftServerImpl.java:626)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
om3_1        | 2021-06-25 13:52:47,370 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-25 13:41:59,038 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-25 13:53:00,675 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.submitClientRequestAsync(RaftServerImpl.java:754)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
om3_1        | 2021-06-25 13:52:48,095 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm1.org_1   | 2021-06-25 13:41:59,158 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:39078
scm3.org_1   | 2021-06-25 13:53:00,754 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:59824
scm2.org_1   | 	at org.apache.ratis.server.impl.RaftServerProxy.lambda$submitClientRequestAsync$9(RaftServerProxy.java:417)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
om3_1        | 2021-06-25 13:52:48,096 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:58804
scm1.org_1   | 2021-06-25 13:41:59,191 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-25 13:53:00,796 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 	at org.apache.ratis.server.impl.RaftServerProxy.lambda$null$7(RaftServerProxy.java:412)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
om3_1        | 2021-06-25 13:52:48,103 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-25 13:41:59,627 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:54920
scm3.org_1   | 2021-06-25 13:53:30,520 [084c6adf-4c09-417d-ac5b-6ae661ceeb47@group-61155FD5A026-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: e166831c-4ec6-45e5-8ea8-b63dd27aa2c5, Nodes: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:OPEN, leaderId:, CreationTimestamp2021-06-25T13:53:30.441Z].
scm3.org_1   | 2021-06-25 13:53:30,552 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:60294
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
om3_1        | 2021-06-25 13:52:49,049 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm3.org_1   | 2021-06-25 13:53:30,562 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 	at org.apache.ratis.util.JavaUtils.callAsUnchecked(JavaUtils.java:115)
scm1.org_1   | 2021-06-25 13:41:59,702 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om3_1        | 2021-06-25 13:52:49,049 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:58822
scm3.org_1   | 2021-06-25 13:53:30,591 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53900
scm2.org_1   | 	at org.apache.ratis.server.impl.RaftServerProxy.lambda$submitRequest$8(RaftServerProxy.java:412)
scm1.org_1   | 2021-06-25 13:42:00,557 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerV2Impl: Pipeline Pipeline[ Id: 33fecaa5-f059-4c14-a3bf-a0d73e1f71d5, Nodes: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:8dca9ea8-5191-4cce-a34e-3d546f33f7b1, CreationTimestamp2021-06-25T13:41:27.529Z] moved to OPEN state
s3g_1        | 2021-06-25 13:50:10,055 [qtp382627885-24] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
om3_1        | 2021-06-25 13:52:49,050 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-25 13:53:30,603 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 	at java.base/java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:1106)
scm1.org_1   | 2021-06-25 13:42:00,667 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
s3g_1        | <Error>
om3_1        | 2021-06-25 13:52:49,627 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm3.org_1   | 2021-06-25 13:53:30,751 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:59990
scm2.org_1   | 	at java.base/java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2235)
scm1.org_1   | 2021-06-25 13:42:00,686 [EventQueue-PipelineReportForPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1f7870bc, cost 117333.668us
s3g_1        |   <Code>InvalidBucketName</Code>
om3_1        | 2021-06-25 13:52:49,628 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:58832
scm3.org_1   | 2021-06-25 13:53:30,769 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-25 13:54:00,568 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:60440
scm1.org_1   | 2021-06-25 13:42:00,742 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
s3g_1        |   <Message>The specified bucket is not valid.</Message>
scm3.org_1   | 2021-06-25 13:54:00,592 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 	at org.apache.ratis.server.impl.RaftServerProxy.submitRequest(RaftServerProxy.java:411)
scm2.org_1   | 	at org.apache.ratis.server.impl.RaftServerProxy.submitClientRequestAsync(RaftServerProxy.java:417)
scm1.org_1   | 2021-06-25 13:42:01,789 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
s3g_1        |   <Resource>bucket_1</Resource>
scm3.org_1   | 2021-06-25 13:54:00,760 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:60128
scm2.org_1   | 	at org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl.submitRequest(SCMRatisServerImpl.java:212)
om3_1        | 2021-06-25 13:52:49,630 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-25 13:42:04,964 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerV2Impl: Pipeline Pipeline[ Id: 8a55befb-80cf-4326-9d11-6eb5e5add68d, Nodes: d7f71981-d306-415b-992d-ee4808a385fa{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:d7f71981-d306-415b-992d-ee4808a385fa, CreationTimestamp2021-06-25T13:41:29.088Z] moved to OPEN state
s3g_1        |   <RequestId/>
scm3.org_1   | 2021-06-25 13:54:00,768 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invokeRatis(SCMHAInvocationHandler.java:110)
om3_1        | 2021-06-25 13:52:50,333 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm1.org_1   | 2021-06-25 13:42:04,996 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
s3g_1        | </Error>
scm3.org_1   | 2021-06-25 13:54:02,967 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54066
scm2.org_1   | 	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invoke(SCMHAInvocationHandler.java:67)
om3_1        | 2021-06-25 13:52:50,333 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:58844
scm1.org_1   | 2021-06-25 13:42:05,021 [EventQueue-PipelineReportForPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1f7870bc, cost 51213.834us
s3g_1        | 
scm3.org_1   | 2021-06-25 13:54:02,994 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 	at com.sun.proxy.$Proxy16.updateContainerState(Unknown Source)
om3_1        | 2021-06-25 13:52:50,334 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-25 13:42:05,023 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
scm3.org_1   | 2021-06-25 13:54:30,568 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:60574
scm2.org_1   | 	at org.apache.hadoop.hdds.scm.container.ContainerManagerImpl.updateContainerState(ContainerManagerImpl.java:242)
om3_1        | 2021-06-25 13:52:51,017 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm1.org_1   | 2021-06-25 13:42:05,068 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:88)
scm3.org_1   | 2021-06-25 13:54:30,581 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 	at org.apache.hadoop.hdds.scm.container.AbstractContainerReportHandler.updateContainerState(AbstractContainerReportHandler.java:227)
om3_1        | 2021-06-25 13:52:51,017 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:58854
scm1.org_1   | 2021-06-25 13:42:05,395 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
scm3.org_1   | 2021-06-25 13:54:30,758 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:60272
scm2.org_1   | 	at org.apache.hadoop.hdds.scm.container.AbstractContainerReportHandler.processContainerReplica(AbstractContainerReportHandler.java:96)
om3_1        | 2021-06-25 13:52:51,018 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-25 13:42:05,680 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47362
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
scm3.org_1   | 2021-06-25 13:54:30,781 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 	at org.apache.hadoop.hdds.scm.container.IncrementalContainerReportHandler.onMessage(IncrementalContainerReportHandler.java:88)
om3_1        | 2021-06-25 13:52:51,688 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm1.org_1   | 2021-06-25 13:42:05,743 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
scm2.org_1   | 	at org.apache.hadoop.hdds.scm.container.IncrementalContainerReportHandler.onMessage(IncrementalContainerReportHandler.java:40)
scm3.org_1   | 2021-06-25 13:54:31,685 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] INFO container.IncrementalContainerReportHandler: Moving container #1 to CLOSED state, datanode d7f71981-d306-415b-992d-ee4808a385fa{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
om3_1        | 2021-06-25 13:52:51,689 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:58868
scm1.org_1   | 2021-06-25 13:42:06,310 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerV2Impl: Pipeline Pipeline[ Id: 145b110b-f1b2-4a24-b4ba-bf6d91d43fa5, Nodes: ee31bb40-6981-4b57-b8d7-3be03fa0c81d{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:ee31bb40-6981-4b57-b8d7-3be03fa0c81d, CreationTimestamp2021-06-25T13:41:29.947Z] moved to OPEN state
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
scm2.org_1   | 	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.lambda$onMessage$1(SingleThreadExecutor.java:85)
scm3.org_1   | 2021-06-25 13:54:31,713 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54204
om3_1        | 2021-06-25 13:52:51,690 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-25 13:42:06,331 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
scm2.org_1   | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm3.org_1   | 2021-06-25 13:54:31,715 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.container.ContainerStateManagerV2.updateContainerState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$ContainerID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$LifeCycleEvent) throws java.io.IOException,org.apache.hadoop.ozone.common.statemachine.InvalidStateTransitionException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@167f3300, cost 2172.81us
om3_1        | 2021-06-25 13:52:52,425 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm1.org_1   | 2021-06-25 13:42:06,347 [EventQueue-PipelineReportForPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1f7870bc, cost 34259.723us
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
scm2.org_1   | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm3.org_1   | 2021-06-25 13:54:31,739 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] ERROR container.IncrementalContainerReportHandler: Exception while processing ICR for container 1
om3_1        | 2021-06-25 13:52:52,426 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:58880
scm1.org_1   | 2021-06-25 13:42:06,352 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
scm2.org_1   | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm3.org_1   | org.apache.ratis.protocol.exceptions.NotLeaderException: Server 084c6adf-4c09-417d-ac5b-6ae661ceeb47@group-61155FD5A026 is not the leader 76093931-f232-4415-806f-239960e589cb|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0
om3_1        | 2021-06-25 13:52:52,430 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-25 13:42:14,803 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47424
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
scm2.org_1   | 2021-06-25 13:54:31,755 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.generateNotLeaderException(RaftServerImpl.java:661)
om3_1        | 2021-06-25 13:52:53,212 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm1.org_1   | 2021-06-25 13:42:14,830 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
scm2.org_1   | 2021-06-25 13:54:52,068 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 3 containers.
scm3.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.checkLeaderState(RaftServerImpl.java:626)
scm3.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.submitClientRequestAsync(RaftServerImpl.java:754)
scm3.org_1   | 	at org.apache.ratis.server.impl.RaftServerProxy.lambda$submitClientRequestAsync$9(RaftServerProxy.java:417)
scm3.org_1   | 	at org.apache.ratis.server.impl.RaftServerProxy.lambda$null$7(RaftServerProxy.java:412)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
om3_1        | 2021-06-25 13:52:53,213 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:58892
scm1.org_1   | 2021-06-25 13:42:22,963 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47458
om3_1        | 2021-06-25 13:52:53,215 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-25 13:55:01,704 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:38072
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
scm1.org_1   | 2021-06-25 13:42:22,979 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm3.org_1   | 	at org.apache.ratis.util.JavaUtils.callAsUnchecked(JavaUtils.java:115)
om3_1        | 2021-06-25 13:52:53,906 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm2.org_1   | 2021-06-25 13:55:01,716 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
scm1.org_1   | 2021-06-25 13:42:28,979 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:42932
scm3.org_1   | 	at org.apache.ratis.server.impl.RaftServerProxy.lambda$submitRequest$8(RaftServerProxy.java:412)
om3_1        | 2021-06-25 13:52:53,906 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:58902
scm2.org_1   | 2021-06-25 13:55:01,787 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37794
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
scm1.org_1   | 2021-06-25 13:42:28,985 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 	at java.base/java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:1106)
om3_1        | 2021-06-25 13:52:53,909 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-25 13:55:01,788 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:42166
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
scm1.org_1   | 2021-06-25 13:42:28,994 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm3.org_1   | 	at java.base/java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2235)
om3_1        | 2021-06-25 13:52:54,601 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm2.org_1   | 2021-06-25 13:55:01,821 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
scm1.org_1   | 2021-06-25 13:42:29,175 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:39242
scm3.org_1   | 	at org.apache.ratis.server.impl.RaftServerProxy.submitRequest(RaftServerProxy.java:411)
om3_1        | 2021-06-25 13:52:54,602 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:58912
scm2.org_1   | 2021-06-25 13:55:01,845 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
scm1.org_1   | 2021-06-25 13:42:29,183 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 	at org.apache.ratis.server.impl.RaftServerProxy.submitClientRequestAsync(RaftServerProxy.java:417)
scm3.org_1   | 	at org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl.submitRequest(SCMRatisServerImpl.java:212)
scm2.org_1   | 2021-06-25 13:55:21,024 [76cadbf9-8202-4493-b276-7e4d9594dfab@group-61155FD5A026-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: b33a7b3b-a75c-4d79-8ef2-49fbac2a5fe4, Nodes: d7f71981-d306-415b-992d-ee4808a385fa{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:OPEN, leaderId:, CreationTimestamp2021-06-25T13:55:21.004Z].
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
scm3.org_1   | 	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invokeRatis(SCMHAInvocationHandler.java:110)
om3_1        | 2021-06-25 13:52:54,610 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-25 13:42:29,188 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerV2Impl: Pipeline Pipeline[ Id: 949dd475-00f3-4295-9774-5191be84cab1, Nodes: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}ee31bb40-6981-4b57-b8d7-3be03fa0c81d{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}d7f71981-d306-415b-992d-ee4808a385fa{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:ee31bb40-6981-4b57-b8d7-3be03fa0c81d, CreationTimestamp2021-06-25T13:41:29.318Z] moved to OPEN state
scm2.org_1   | 2021-06-25 13:55:31,673 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:38216
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
scm3.org_1   | 	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invoke(SCMHAInvocationHandler.java:67)
om3_1        | 2021-06-25 13:52:55,314 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm1.org_1   | 2021-06-25 13:42:29,188 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm2.org_1   | 2021-06-25 13:55:31,704 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
scm3.org_1   | 	at com.sun.proxy.$Proxy16.updateContainerState(Unknown Source)
om3_1        | 2021-06-25 13:52:55,315 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:58932
scm1.org_1   | 2021-06-25 13:42:29,216 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
scm2.org_1   | 2021-06-25 13:55:31,776 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37940
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
scm3.org_1   | 	at org.apache.hadoop.hdds.scm.container.ContainerManagerImpl.updateContainerState(ContainerManagerImpl.java:242)
om3_1        | 2021-06-25 13:52:55,315 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-25 13:42:29,221 [EventQueue-PipelineReportForPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1f7870bc, cost 31238.4us
scm2.org_1   | 2021-06-25 13:55:31,805 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:42310
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
scm3.org_1   | 	at org.apache.hadoop.hdds.scm.container.AbstractContainerReportHandler.updateContainerState(AbstractContainerReportHandler.java:227)
om3_1        | 2021-06-25 13:52:55,959 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm1.org_1   | 2021-06-25 13:42:29,231 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
scm2.org_1   | 2021-06-25 13:55:31,820 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
scm3.org_1   | 	at org.apache.hadoop.hdds.scm.container.AbstractContainerReportHandler.processContainerReplica(AbstractContainerReportHandler.java:96)
om3_1        | 2021-06-25 13:52:55,960 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:58944
scm1.org_1   | 2021-06-25 13:42:29,233 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm2.org_1   | 2021-06-25 13:55:31,823 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
scm3.org_1   | 	at org.apache.hadoop.hdds.scm.container.IncrementalContainerReportHandler.onMessage(IncrementalContainerReportHandler.java:88)
om3_1        | 2021-06-25 13:52:55,961 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-25 13:42:29,233 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm2.org_1   | 2021-06-25 13:56:01,711 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:38362
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
scm3.org_1   | 	at org.apache.hadoop.hdds.scm.container.IncrementalContainerReportHandler.onMessage(IncrementalContainerReportHandler.java:40)
om3_1        | 2021-06-25 13:52:56,609 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm1.org_1   | 2021-06-25 13:42:29,233 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
scm2.org_1   | 2021-06-25 13:56:01,715 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
scm3.org_1   | 	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.lambda$onMessage$1(SingleThreadExecutor.java:85)
om3_1        | 2021-06-25 13:52:56,610 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:58952
scm1.org_1   | 2021-06-25 13:42:29,233 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm2.org_1   | 2021-06-25 13:56:01,812 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:42456
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
scm3.org_1   | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 2021-06-25 13:52:56,610 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-25 13:42:29,237 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
scm2.org_1   | 2021-06-25 13:56:01,812 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38086
scm2.org_1   | 2021-06-25 13:56:01,822 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 2021-06-25 13:53:01,328 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:59064
scm1.org_1   | 2021-06-25 13:42:29,238 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO container.ReplicationManager: Service ReplicationManager transitions to RUNNING.
scm2.org_1   | 2021-06-25 13:56:01,875 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
scm3.org_1   | 	at java.base/java.lang.Thread.run(Thread.java:834)
om3_1        | 2021-06-25 13:53:01,340 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-25 13:42:29,674 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:55088
scm2.org_1   | 2021-06-25 13:56:12,507 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50114
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
scm3.org_1   | 2021-06-25 13:54:31,762 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 2021-06-25 13:53:04,361 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 3d6bbc9d77fcd9af52a2da6ed06556509def66833b04b5e521eed2622b0a438e
scm1.org_1   | 2021-06-25 13:42:29,693 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-25 13:56:12,521 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
scm3.org_1   | 2021-06-25 13:55:01,687 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:60734
om3_1        | 2021-06-25 13:53:04,362 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:59008
scm1.org_1   | 2021-06-25 13:42:31,373 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1f7870bc, cost 14321.592us
scm2.org_1   | 2021-06-25 13:56:12,883 [IPC Server handler 44 on default port 9860] INFO container.ReplicationManager: Stopping Replication Monitor Thread.
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
scm3.org_1   | 2021-06-25 13:55:01,697 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 2021-06-25 13:53:04,370 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-25 13:42:31,776 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47514
scm2.org_1   | 2021-06-25 13:56:22,289 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50162
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
scm3.org_1   | 2021-06-25 13:55:01,790 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54346
om3_1        | 2021-06-25 13:53:21,305 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:59150
scm1.org_1   | 2021-06-25 13:42:31,805 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm2.org_1   | 2021-06-25 13:56:22,299 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
scm3.org_1   | 2021-06-25 13:55:01,797 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:60418
om3_1        | 2021-06-25 13:53:21,309 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-25 13:42:33,637 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerV2Impl: Pipeline Pipeline[ Id: 3175bb45-44a8-4478-8980-bfea630f7f68, Nodes: ee31bb40-6981-4b57-b8d7-3be03fa0c81d{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}8dca9ea8-5191-4cce-a34e-3d546f33f7b1{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}d7f71981-d306-415b-992d-ee4808a385fa{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:d7f71981-d306-415b-992d-ee4808a385fa, CreationTimestamp2021-06-25T13:41:28.879Z] moved to OPEN state
scm2.org_1   | 2021-06-25 13:56:22,302 [IPC Server handler 30 on default port 9860] INFO container.ReplicationManager: Starting Replication Monitor Thread.
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
scm3.org_1   | 2021-06-25 13:55:01,827 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 2021-06-25 13:57:05,865 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:50312
scm1.org_1   | 2021-06-25 13:42:33,679 [EventQueue-PipelineReportForPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1f7870bc, cost 41397.165us
scm2.org_1   | 2021-06-25 13:56:22,308 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 5 milliseconds for processing 3 containers.
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
scm3.org_1   | 2021-06-25 13:55:01,851 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 2021-06-25 13:57:05,870 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-25 13:42:45,490 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:39330
scm2.org_1   | 2021-06-25 13:56:31,686 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:38522
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
scm3.org_1   | 2021-06-25 13:55:14,948 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 3 containers.
scm1.org_1   | 2021-06-25 13:42:45,517 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-25 13:56:31,711 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
scm3.org_1   | 2021-06-25 13:55:21,026 [084c6adf-4c09-417d-ac5b-6ae661ceeb47@group-61155FD5A026-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: b33a7b3b-a75c-4d79-8ef2-49fbac2a5fe4, Nodes: d7f71981-d306-415b-992d-ee4808a385fa{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:OPEN, leaderId:, CreationTimestamp2021-06-25T13:55:21.004Z].
scm1.org_1   | 2021-06-25 13:42:59,121 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:44220
scm2.org_1   | 2021-06-25 13:56:31,789 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38244
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
scm3.org_1   | 2021-06-25 13:55:31,688 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:60874
scm1.org_1   | 2021-06-25 13:42:59,144 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm2.org_1   | 2021-06-25 13:56:31,805 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:42616
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
scm3.org_1   | 2021-06-25 13:55:31,731 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:42:59,244 [IPC Server handler 44 on default port 9863] INFO ha.SCMHAInvocationHandler: Invoking method public abstract java.lang.Boolean org.apache.hadoop.hdds.scm.ha.SequenceIdGenerator$StateManager.allocateBatch(java.lang.String,java.lang.Long,java.lang.Long) on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1f7870bc, cost 80916.709us
scm2.org_1   | 2021-06-25 13:56:31,816 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
scm1.org_1   | 2021-06-25 13:42:59,245 [IPC Server handler 44 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for containerId, change lastId from 0 to 1000.
scm2.org_1   | 2021-06-25 13:56:31,820 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
scm3.org_1   | 2021-06-25 13:55:31,764 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:60562
scm1.org_1   | 2021-06-25 13:42:59,327 [IPC Server handler 44 on default port 9863] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.container.ContainerStateManagerV2.addContainer(org.apache.hadoop.hdds.protocol.proto.HddsProtos$ContainerInfoProto) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1f7870bc, cost 64584.006us
scm2.org_1   | 2021-06-25 13:57:01,723 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:38662
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
scm3.org_1   | 2021-06-25 13:55:31,786 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:42:59,422 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 107544261427200000.
scm2.org_1   | 2021-06-25 13:57:01,764 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
scm3.org_1   | 2021-06-25 13:55:31,806 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54488
scm1.org_1   | 2021-06-25 13:42:59,436 [IPC Server handler 44 on default port 9863] INFO ha.SCMHAInvocationHandler: Invoking method public abstract java.lang.Boolean org.apache.hadoop.hdds.scm.ha.SequenceIdGenerator$StateManager.allocateBatch(java.lang.String,java.lang.Long,java.lang.Long) on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1f7870bc, cost 32007.601us
scm2.org_1   | 2021-06-25 13:57:01,850 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:42756
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
scm3.org_1   | 2021-06-25 13:55:31,818 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:42:59,477 [IPC Server handler 44 on default port 9863] INFO ha.SCMHAInvocationHandler: Invoking method public abstract java.lang.Boolean org.apache.hadoop.hdds.scm.ha.SequenceIdGenerator$StateManager.allocateBatch(java.lang.String,java.lang.Long,java.lang.Long) on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1f7870bc, cost 40022.952us
scm2.org_1   | 2021-06-25 13:57:01,853 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38384
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
scm3.org_1   | 2021-06-25 13:56:01,691 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:32792
scm1.org_1   | 2021-06-25 13:42:59,486 [IPC Server handler 44 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for localId, change lastId from 107544261427200000 to 107544261427201000.
scm1.org_1   | 2021-06-25 13:43:02,834 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47250
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
scm1.org_1   | 2021-06-25 13:43:02,847 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm2.org_1   | 2021-06-25 13:57:01,858 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-25 13:56:01,705 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
scm1.org_1   | 2021-06-25 13:43:03,121 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:39338
scm2.org_1   | 2021-06-25 13:57:01,861 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-25 13:56:01,790 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:60710
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
scm1.org_1   | 2021-06-25 13:43:03,133 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm2.org_1   | 2021-06-25 13:57:16,683 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38468
scm3.org_1   | 2021-06-25 13:56:01,797 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54634
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
scm1.org_1   | 2021-06-25 13:43:03,397 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48448
scm2.org_1   | 2021-06-25 13:57:16,714 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-25 13:56:01,811 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
scm1.org_1   | 2021-06-25 13:43:03,421 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm2.org_1   | 2021-06-25 13:57:31,680 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:38830
scm3.org_1   | 2021-06-25 13:56:01,866 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
scm1.org_1   | 2021-06-25 13:43:03,438 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:55258
scm2.org_1   | 2021-06-25 13:57:31,703 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-25 13:56:13,174 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50642
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
scm1.org_1   | 2021-06-25 13:43:03,533 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-25 13:57:31,782 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:42926
scm3.org_1   | 2021-06-25 13:56:13,181 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
scm1.org_1   | 2021-06-25 13:43:03,911 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:39424
scm2.org_1   | 2021-06-25 13:57:31,804 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-25 13:56:13,806 [IPC Server handler 5 on default port 9860] INFO container.ReplicationManager: Stopping Replication Monitor Thread.
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
scm1.org_1   | 2021-06-25 13:43:03,994 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:43128
scm2.org_1   | 2021-06-25 13:57:46,641 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38620
scm3.org_1   | 2021-06-25 13:56:22,548 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50688
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
scm1.org_1   | 2021-06-25 13:43:04,009 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-25 13:57:46,657 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-25 13:56:22,550 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:43:04,020 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-25 13:58:01,715 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:38976
scm3.org_1   | 2021-06-25 13:56:22,554 [IPC Server handler 89 on default port 9860] INFO container.ReplicationManager: Starting Replication Monitor Thread.
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
scm1.org_1   | 2021-06-25 13:43:11,365 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:44302
scm2.org_1   | 2021-06-25 13:58:01,724 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-25 13:56:22,557 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 3 containers.
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
scm1.org_1   | 2021-06-25 13:43:11,383 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm2.org_1   | 2021-06-25 13:58:01,787 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43068
scm3.org_1   | 2021-06-25 13:56:31,684 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:32952
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
scm1.org_1   | 2021-06-25 13:43:11,406 [IPC Server handler 97 on default port 9863] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.container.ContainerStateManagerV2.addContainer(org.apache.hadoop.hdds.protocol.proto.HddsProtos$ContainerInfoProto) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1f7870bc, cost 21943.237us
scm2.org_1   | 2021-06-25 13:58:01,811 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-25 13:56:31,697 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
scm1.org_1   | 2021-06-25 13:43:24,316 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:44368
scm2.org_1   | 2021-06-25 13:58:02,846 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38704
scm3.org_1   | 2021-06-25 13:56:31,778 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:60870
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
scm1.org_1   | 2021-06-25 13:43:24,321 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm2.org_1   | 2021-06-25 13:58:02,868 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] INFO container.IncrementalContainerReportHandler: Moving container #2 to CLOSED state, datanode ee31bb40-6981-4b57-b8d7-3be03fa0c81d{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
scm3.org_1   | 2021-06-25 13:56:31,788 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54796
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
scm1.org_1   | 2021-06-25 13:43:31,371 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1f7870bc, cost 12752.279us
scm2.org_1   | 2021-06-25 13:58:02,869 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.container.ContainerStateManagerV2.updateContainerState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$ContainerID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$LifeCycleEvent) throws java.io.IOException,org.apache.hadoop.ozone.common.statemachine.InvalidStateTransitionException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@547c76b5, cost 1000.205us
scm3.org_1   | 2021-06-25 13:56:31,797 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
scm1.org_1   | 2021-06-25 13:43:33,428 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:55428
scm2.org_1   | 2021-06-25 13:58:02,870 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] ERROR container.IncrementalContainerReportHandler: Exception while processing ICR for container 2
scm3.org_1   | 2021-06-25 13:56:31,802 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
scm1.org_1   | 2021-06-25 13:43:33,450 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | org.apache.ratis.protocol.exceptions.NotLeaderException: Server 76cadbf9-8202-4493-b276-7e4d9594dfab@group-61155FD5A026 is not the leader 76093931-f232-4415-806f-239960e589cb|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0
scm3.org_1   | 2021-06-25 13:57:01,736 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33092
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
scm1.org_1   | 2021-06-25 13:43:33,857 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:39600
scm2.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.generateNotLeaderException(RaftServerImpl.java:661)
scm3.org_1   | 2021-06-25 13:57:01,766 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
scm1.org_1   | 2021-06-25 13:43:33,878 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.checkLeaderState(RaftServerImpl.java:626)
scm3.org_1   | 2021-06-25 13:57:01,817 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:32776
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
scm1.org_1   | 2021-06-25 13:43:34,034 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:43302
scm2.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.submitClientRequestAsync(RaftServerImpl.java:754)
scm3.org_1   | 2021-06-25 13:57:01,825 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54936
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
scm1.org_1   | 2021-06-25 13:43:34,058 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 	at org.apache.ratis.server.impl.RaftServerProxy.lambda$submitClientRequestAsync$9(RaftServerProxy.java:417)
scm2.org_1   | 	at org.apache.ratis.server.impl.RaftServerProxy.lambda$null$7(RaftServerProxy.java:412)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
scm1.org_1   | 2021-06-25 13:43:48,064 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:44510
scm2.org_1   | 	at org.apache.ratis.util.JavaUtils.callAsUnchecked(JavaUtils.java:115)
scm3.org_1   | 2021-06-25 13:57:01,843 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
scm1.org_1   | 2021-06-25 13:43:48,077 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm2.org_1   | 	at org.apache.ratis.server.impl.RaftServerProxy.lambda$submitRequest$8(RaftServerProxy.java:412)
scm3.org_1   | 2021-06-25 13:57:01,856 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
scm1.org_1   | 2021-06-25 13:43:48,148 [IPC Server handler 4 on default port 9863] INFO ha.SCMHAInvocationHandler: Invoking method public abstract java.lang.Boolean org.apache.hadoop.hdds.scm.ha.SequenceIdGenerator$StateManager.allocateBatch(java.lang.String,java.lang.Long,java.lang.Long) on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1f7870bc, cost 30599.887us
scm2.org_1   | 	at java.base/java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:1106)
scm3.org_1   | 2021-06-25 13:57:16,655 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55016
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
scm1.org_1   | 2021-06-25 13:43:48,148 [IPC Server handler 4 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for delTxnId, change lastId from 0 to 1000.
scm2.org_1   | 	at java.base/java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2235)
scm2.org_1   | 	at org.apache.ratis.server.impl.RaftServerProxy.submitRequest(RaftServerProxy.java:411)
scm2.org_1   | 	at org.apache.ratis.server.impl.RaftServerProxy.submitClientRequestAsync(RaftServerProxy.java:417)
scm3.org_1   | 2021-06-25 13:57:16,702 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
scm2.org_1   | 	at org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl.submitRequest(SCMRatisServerImpl.java:212)
scm3.org_1   | 2021-06-25 13:57:31,679 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33260
scm1.org_1   | 2021-06-25 13:43:48,194 [IPC Server handler 4 on default port 9863] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.addTransactionsToDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1f7870bc, cost 40260.546us
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
scm2.org_1   | 	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invokeRatis(SCMHAInvocationHandler.java:110)
scm3.org_1   | 2021-06-25 13:57:31,704 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:43:52,287 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:46406
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
scm2.org_1   | 	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invoke(SCMHAInvocationHandler.java:67)
scm3.org_1   | 2021-06-25 13:57:31,765 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:32948
scm1.org_1   | 2021-06-25 13:43:52,291 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm2.org_1   | 	at com.sun.proxy.$Proxy16.updateContainerState(Unknown Source)
scm3.org_1   | 2021-06-25 13:57:31,782 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 2021-06-25 13:50:17,611 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
scm2.org_1   | 	at org.apache.hadoop.hdds.scm.container.ContainerManagerImpl.updateContainerState(ContainerManagerImpl.java:242)
scm1.org_1   | 2021-06-25 13:44:03,404 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:55576
scm3.org_1   | 2021-06-25 13:57:46,642 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55170
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
scm2.org_1   | 	at org.apache.hadoop.hdds.scm.container.AbstractContainerReportHandler.updateContainerState(AbstractContainerReportHandler.java:227)
scm1.org_1   | 2021-06-25 13:44:03,438 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-25 13:57:46,655 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
scm2.org_1   | 	at org.apache.hadoop.hdds.scm.container.AbstractContainerReportHandler.processContainerReplica(AbstractContainerReportHandler.java:96)
scm1.org_1   | 2021-06-25 13:44:03,853 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:39752
scm3.org_1   | 2021-06-25 13:58:01,727 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33402
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
scm2.org_1   | 	at org.apache.hadoop.hdds.scm.container.IncrementalContainerReportHandler.onMessage(IncrementalContainerReportHandler.java:88)
scm1.org_1   | 2021-06-25 13:44:03,892 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-25 13:58:01,741 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
scm2.org_1   | 	at org.apache.hadoop.hdds.scm.container.IncrementalContainerReportHandler.onMessage(IncrementalContainerReportHandler.java:40)
scm1.org_1   | 2021-06-25 13:44:04,024 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:43454
scm3.org_1   | 2021-06-25 13:58:01,786 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33088
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
scm2.org_1   | 	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.lambda$onMessage$1(SingleThreadExecutor.java:85)
scm1.org_1   | 2021-06-25 13:44:04,075 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-25 13:58:01,814 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm1.org_1   | 2021-06-25 13:44:24,900 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:44694
scm3.org_1   | 2021-06-25 13:58:02,818 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] INFO container.IncrementalContainerReportHandler: Moving container #2 to CLOSED state, datanode ee31bb40-6981-4b57-b8d7-3be03fa0c81d{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
scm2.org_1   | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm1.org_1   | 2021-06-25 13:44:24,912 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
scm3.org_1   | 2021-06-25 13:58:02,822 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.container.ContainerStateManagerV2.updateContainerState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$ContainerID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$LifeCycleEvent) throws java.io.IOException,org.apache.hadoop.ozone.common.statemachine.InvalidStateTransitionException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@167f3300, cost 1062.305us
scm2.org_1   | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm1.org_1   | 2021-06-25 13:44:29,229 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 2 containers.
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
scm3.org_1   | 2021-06-25 13:58:02,824 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] ERROR container.IncrementalContainerReportHandler: Exception while processing ICR for container 2
scm2.org_1   | 2021-06-25 13:58:02,871 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] INFO container.IncrementalContainerReportHandler: Moving container #2 to CLOSED state, datanode d7f71981-d306-415b-992d-ee4808a385fa{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
scm1.org_1   | 2021-06-25 13:44:31,379 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1f7870bc, cost 18576.011us
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
scm3.org_1   | org.apache.ratis.protocol.exceptions.NotLeaderException: Server 084c6adf-4c09-417d-ac5b-6ae661ceeb47@group-61155FD5A026 is not the leader 76093931-f232-4415-806f-239960e589cb|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0
scm2.org_1   | 2021-06-25 13:58:02,872 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.container.ContainerStateManagerV2.updateContainerState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$ContainerID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$LifeCycleEvent) throws java.io.IOException,org.apache.hadoop.ozone.common.statemachine.InvalidStateTransitionException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@547c76b5, cost 631.903us
scm1.org_1   | 2021-06-25 13:44:33,371 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:55750
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
scm3.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.generateNotLeaderException(RaftServerImpl.java:661)
scm2.org_1   | 2021-06-25 13:58:02,872 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] ERROR container.IncrementalContainerReportHandler: Exception while processing ICR for container 2
scm1.org_1   | 2021-06-25 13:44:33,392 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
scm3.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.checkLeaderState(RaftServerImpl.java:626)
scm2.org_1   | org.apache.ratis.protocol.exceptions.NotLeaderException: Server 76cadbf9-8202-4493-b276-7e4d9594dfab@group-61155FD5A026 is not the leader 76093931-f232-4415-806f-239960e589cb|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0
scm1.org_1   | 2021-06-25 13:44:33,826 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:39924
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm2.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.generateNotLeaderException(RaftServerImpl.java:661)
scm1.org_1   | 2021-06-25 13:44:33,862 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm3.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.submitClientRequestAsync(RaftServerImpl.java:754)
scm2.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.checkLeaderState(RaftServerImpl.java:626)
scm1.org_1   | 2021-06-25 13:44:34,005 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:43626
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
scm1.org_1   | 2021-06-25 13:44:34,031 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.submitClientRequestAsync(RaftServerImpl.java:754)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
scm3.org_1   | 	at org.apache.ratis.server.impl.RaftServerProxy.lambda$submitClientRequestAsync$9(RaftServerProxy.java:417)
scm1.org_1   | 2021-06-25 13:45:03,351 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:55918
scm2.org_1   | 	at org.apache.ratis.server.impl.RaftServerProxy.lambda$submitClientRequestAsync$9(RaftServerProxy.java:417)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
scm3.org_1   | 	at org.apache.ratis.server.impl.RaftServerProxy.lambda$null$7(RaftServerProxy.java:412)
scm1.org_1   | 2021-06-25 13:45:03,388 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 	at org.apache.ratis.server.impl.RaftServerProxy.lambda$null$7(RaftServerProxy.java:412)
s3g_1        | 2021-06-25 13:50:17,629 [qtp382627885-21] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-33237, with Versioning false and Storage Type set to DISK and Encryption set to false 
scm1.org_1   | 2021-06-25 13:45:03,883 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:40090
scm2.org_1   | 	at org.apache.ratis.util.JavaUtils.callAsUnchecked(JavaUtils.java:115)
s3g_1        | 2021-06-25 13:50:17,664 [qtp382627885-21] INFO endpoint.BucketEndpoint: Location is /bucket-33237
scm3.org_1   | 	at org.apache.ratis.util.JavaUtils.callAsUnchecked(JavaUtils.java:115)
scm1.org_1   | 2021-06-25 13:45:03,905 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 	at org.apache.ratis.server.impl.RaftServerProxy.lambda$submitRequest$8(RaftServerProxy.java:412)
s3g_1        | 2021-06-25 13:50:18,271 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
scm3.org_1   | 	at org.apache.ratis.server.impl.RaftServerProxy.lambda$submitRequest$8(RaftServerProxy.java:412)
scm1.org_1   | 2021-06-25 13:45:04,137 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:43792
scm2.org_1   | 	at java.base/java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:1106)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
scm3.org_1   | 	at java.base/java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:1106)
scm1.org_1   | 2021-06-25 13:45:04,158 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 	at java.base/java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2235)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
scm3.org_1   | 	at java.base/java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2235)
scm1.org_1   | 2021-06-25 13:45:31,379 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1f7870bc, cost 20126.616us
scm2.org_1   | 	at org.apache.ratis.server.impl.RaftServerProxy.submitRequest(RaftServerProxy.java:411)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
scm3.org_1   | 	at org.apache.ratis.server.impl.RaftServerProxy.submitRequest(RaftServerProxy.java:411)
scm1.org_1   | 2021-06-25 13:45:33,347 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56084
scm2.org_1   | 	at org.apache.ratis.server.impl.RaftServerProxy.submitClientRequestAsync(RaftServerProxy.java:417)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
scm3.org_1   | 	at org.apache.ratis.server.impl.RaftServerProxy.submitClientRequestAsync(RaftServerProxy.java:417)
scm1.org_1   | 2021-06-25 13:45:33,376 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 	at org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl.submitRequest(SCMRatisServerImpl.java:212)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
scm3.org_1   | 	at org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl.submitRequest(SCMRatisServerImpl.java:212)
scm1.org_1   | 2021-06-25 13:45:33,820 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:40254
scm2.org_1   | 	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invokeRatis(SCMHAInvocationHandler.java:110)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
scm3.org_1   | 	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invokeRatis(SCMHAInvocationHandler.java:110)
scm1.org_1   | 2021-06-25 13:45:33,835 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invoke(SCMHAInvocationHandler.java:67)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
scm3.org_1   | 	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invoke(SCMHAInvocationHandler.java:67)
scm1.org_1   | 2021-06-25 13:45:34,011 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:43964
scm2.org_1   | 	at com.sun.proxy.$Proxy16.updateContainerState(Unknown Source)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
scm3.org_1   | 	at com.sun.proxy.$Proxy16.updateContainerState(Unknown Source)
scm1.org_1   | 2021-06-25 13:45:34,078 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 	at org.apache.hadoop.hdds.scm.container.ContainerManagerImpl.updateContainerState(ContainerManagerImpl.java:242)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
scm3.org_1   | 	at org.apache.hadoop.hdds.scm.container.ContainerManagerImpl.updateContainerState(ContainerManagerImpl.java:242)
scm1.org_1   | 2021-06-25 13:45:40,899 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:45140
scm2.org_1   | 	at org.apache.hadoop.hdds.scm.container.AbstractContainerReportHandler.updateContainerState(AbstractContainerReportHandler.java:227)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
scm3.org_1   | 	at org.apache.hadoop.hdds.scm.container.AbstractContainerReportHandler.updateContainerState(AbstractContainerReportHandler.java:227)
scm1.org_1   | 2021-06-25 13:45:40,908 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm2.org_1   | 	at org.apache.hadoop.hdds.scm.container.AbstractContainerReportHandler.processContainerReplica(AbstractContainerReportHandler.java:96)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
scm3.org_1   | 	at org.apache.hadoop.hdds.scm.container.AbstractContainerReportHandler.processContainerReplica(AbstractContainerReportHandler.java:96)
scm1.org_1   | 2021-06-25 13:45:49,163 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:47046
scm2.org_1   | 	at org.apache.hadoop.hdds.scm.container.IncrementalContainerReportHandler.onMessage(IncrementalContainerReportHandler.java:88)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm3.org_1   | 	at org.apache.hadoop.hdds.scm.container.IncrementalContainerReportHandler.onMessage(IncrementalContainerReportHandler.java:88)
scm1.org_1   | 2021-06-25 13:45:49,166 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm2.org_1   | 	at org.apache.hadoop.hdds.scm.container.IncrementalContainerReportHandler.onMessage(IncrementalContainerReportHandler.java:40)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm1.org_1   | 2021-06-25 13:45:57,354 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:45214
scm2.org_1   | 	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.lambda$onMessage$1(SingleThreadExecutor.java:85)
scm2.org_1   | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
scm2.org_1   | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm3.org_1   | 	at org.apache.hadoop.hdds.scm.container.IncrementalContainerReportHandler.onMessage(IncrementalContainerReportHandler.java:40)
scm1.org_1   | 2021-06-25 13:45:57,360 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
scm2.org_1   | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm3.org_1   | 	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.lambda$onMessage$1(SingleThreadExecutor.java:85)
scm1.org_1   | 2021-06-25 13:46:00,596 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56238
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
scm2.org_1   | 2021-06-25 13:58:02,939 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm1.org_1   | 2021-06-25 13:46:00,601 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:44106
scm2.org_1   | 2021-06-25 13:58:32,843 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43212
s3g_1        | 2021-06-25 13:50:18,283 [qtp382627885-21] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-59860, with Versioning false and Storage Type set to DISK and Encryption set to false 
scm3.org_1   | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm1.org_1   | 2021-06-25 13:46:00,638 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm2.org_1   | 2021-06-25 13:58:32,885 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 2021-06-25 13:50:18,296 [qtp382627885-21] INFO endpoint.BucketEndpoint: Location is /bucket-59860
scm1.org_1   | 2021-06-25 13:46:00,659 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-25 13:58:02,850 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] INFO container.IncrementalContainerReportHandler: Moving container #2 to CLOSED state, datanode d7f71981-d306-415b-992d-ee4808a385fa{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
scm2.org_1   | 2021-06-25 13:58:32,928 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39132
s3g_1        | 2021-06-25 13:50:18,963 [qtp382627885-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
scm3.org_1   | 2021-06-25 13:58:02,851 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.container.ContainerStateManagerV2.updateContainerState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$ContainerID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$LifeCycleEvent) throws java.io.IOException,org.apache.hadoop.ozone.common.statemachine.InvalidStateTransitionException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@167f3300, cost 890.104us
scm2.org_1   | 2021-06-25 13:58:32,947 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
scm1.org_1   | 2021-06-25 13:46:00,765 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:40412
scm3.org_1   | 2021-06-25 13:58:02,852 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] ERROR container.IncrementalContainerReportHandler: Exception while processing ICR for container 2
scm2.org_1   | 2021-06-25 13:58:32,960 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38846
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
scm1.org_1   | 2021-06-25 13:46:00,820 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | org.apache.ratis.protocol.exceptions.NotLeaderException: Server 084c6adf-4c09-417d-ac5b-6ae661ceeb47@group-61155FD5A026 is not the leader 76093931-f232-4415-806f-239960e589cb|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0
scm2.org_1   | 2021-06-25 13:58:32,978 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
scm1.org_1   | 2021-06-25 13:46:06,609 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:47146
scm3.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.generateNotLeaderException(RaftServerImpl.java:661)
scm2.org_1   | 2021-06-25 13:58:49,375 [76cadbf9-8202-4493-b276-7e4d9594dfab@group-61155FD5A026-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 6433b88b-1781-489a-9e20-61b0f5e70d27, Nodes: d7f71981-d306-415b-992d-ee4808a385fa{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:OPEN, leaderId:, CreationTimestamp2021-06-25T13:58:49.321Z].
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
scm1.org_1   | 2021-06-25 13:46:06,614 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm3.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.checkLeaderState(RaftServerImpl.java:626)
scm2.org_1   | 2021-06-25 13:59:02,870 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43360
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
scm1.org_1   | 2021-06-25 13:46:30,575 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56410
scm3.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.submitClientRequestAsync(RaftServerImpl.java:754)
scm2.org_1   | 2021-06-25 13:59:02,871 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39276
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
scm1.org_1   | 2021-06-25 13:46:30,587 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 	at org.apache.ratis.server.impl.RaftServerProxy.lambda$submitClientRequestAsync$9(RaftServerProxy.java:417)
scm2.org_1   | 2021-06-25 13:59:02,885 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
scm1.org_1   | 2021-06-25 13:46:30,636 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:44278
scm3.org_1   | 	at org.apache.ratis.server.impl.RaftServerProxy.lambda$null$7(RaftServerProxy.java:412)
scm2.org_1   | 2021-06-25 13:59:02,938 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
scm1.org_1   | 2021-06-25 13:46:30,655 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 	at org.apache.ratis.util.JavaUtils.callAsUnchecked(JavaUtils.java:115)
scm2.org_1   | 2021-06-25 13:59:02,990 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38994
scm2.org_1   | 2021-06-25 13:59:03,009 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:46:30,748 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:40584
scm3.org_1   | 	at org.apache.ratis.server.impl.RaftServerProxy.lambda$submitRequest$8(RaftServerProxy.java:412)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
scm2.org_1   | 2021-06-25 13:59:32,852 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39428
scm1.org_1   | 2021-06-25 13:46:30,777 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 	at java.base/java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:1106)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm2.org_1   | 2021-06-25 13:59:32,874 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 	at java.base/java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2235)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm1.org_1   | 2021-06-25 13:46:31,390 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1f7870bc, cost 31515.976us
scm2.org_1   | 2021-06-25 13:59:32,897 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43516
scm3.org_1   | 	at org.apache.ratis.server.impl.RaftServerProxy.submitRequest(RaftServerProxy.java:411)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
scm1.org_1   | 2021-06-25 13:46:47,979 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:45508
scm2.org_1   | 2021-06-25 13:59:32,933 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 	at org.apache.ratis.server.impl.RaftServerProxy.submitClientRequestAsync(RaftServerProxy.java:417)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
scm1.org_1   | 2021-06-25 13:46:47,983 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm2.org_1   | 2021-06-25 13:59:32,951 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39148
scm3.org_1   | 	at org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl.submitRequest(SCMRatisServerImpl.java:212)
scm3.org_1   | 	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invokeRatis(SCMHAInvocationHandler.java:110)
scm1.org_1   | 2021-06-25 13:46:48,000 [IPC Server handler 4 on default port 9863] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.addTransactionsToDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1f7870bc, cost 16389.791us
scm3.org_1   | 	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invoke(SCMHAInvocationHandler.java:67)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
scm2.org_1   | 2021-06-25 13:59:32,966 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:47:00,654 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56578
scm3.org_1   | 	at com.sun.proxy.$Proxy16.updateContainerState(Unknown Source)
s3g_1        | 2021-06-25 13:50:19,507 [qtp382627885-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
scm2.org_1   | 2021-06-25 13:59:40,647 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:56856
scm1.org_1   | 2021-06-25 13:47:00,659 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:44440
scm3.org_1   | 	at org.apache.hadoop.hdds.scm.container.ContainerManagerImpl.updateContainerState(ContainerManagerImpl.java:242)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
scm2.org_1   | 2021-06-25 13:59:40,664 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:47:00,679 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 	at org.apache.hadoop.hdds.scm.container.AbstractContainerReportHandler.updateContainerState(AbstractContainerReportHandler.java:227)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
scm2.org_1   | 2021-06-25 13:59:40,675 [IPC Server handler 98 on default port 9860] INFO container.ReplicationManager: Stopping Replication Monitor Thread.
scm1.org_1   | 2021-06-25 13:47:00,694 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 	at org.apache.hadoop.hdds.scm.container.AbstractContainerReportHandler.processContainerReplica(AbstractContainerReportHandler.java:96)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
scm2.org_1   | 2021-06-25 13:59:48,810 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:56892
scm1.org_1   | 2021-06-25 13:47:00,773 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:40752
scm3.org_1   | 	at org.apache.hadoop.hdds.scm.container.IncrementalContainerReportHandler.onMessage(IncrementalContainerReportHandler.java:88)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
scm2.org_1   | 2021-06-25 13:59:48,820 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:47:00,802 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:47:30,652 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56750
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
scm2.org_1   | 2021-06-25 13:59:48,823 [IPC Server handler 77 on default port 9860] INFO container.ReplicationManager: Starting Replication Monitor Thread.
scm1.org_1   | 2021-06-25 13:47:30,661 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 	at org.apache.hadoop.hdds.scm.container.IncrementalContainerReportHandler.onMessage(IncrementalContainerReportHandler.java:40)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
scm2.org_1   | 2021-06-25 13:59:48,829 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 4 containers.
scm1.org_1   | 2021-06-25 13:47:30,665 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:44614
scm3.org_1   | 	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.lambda$onMessage$1(SingleThreadExecutor.java:85)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
scm2.org_1   | 2021-06-25 14:00:02,940 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43670
scm1.org_1   | 2021-06-25 13:47:30,670 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
scm2.org_1   | 2021-06-25 14:00:02,960 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39580
scm1.org_1   | 2021-06-25 13:47:30,780 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:40924
scm3.org_1   | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm3.org_1   | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm2.org_1   | 2021-06-25 14:00:02,964 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:47:30,791 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-25 13:58:02,896 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55252
scm3.org_1   | 2021-06-25 13:58:02,952 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-25 14:00:02,996 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39300
scm1.org_1   | 2021-06-25 13:47:31,375 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1f7870bc, cost 16218.088us
scm3.org_1   | 2021-06-25 13:58:32,841 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33234
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
scm2.org_1   | 2021-06-25 14:00:02,998 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-25 13:58:32,868 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33556
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
scm2.org_1   | 2021-06-25 14:00:03,002 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:48:00,583 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56914
scm3.org_1   | 2021-06-25 13:58:32,870 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
scm1.org_1   | 2021-06-25 13:48:00,607 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-25 13:58:32,914 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm1.org_1   | 2021-06-25 13:48:00,645 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:44780
scm3.org_1   | 2021-06-25 13:58:32,939 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55398
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm1.org_1   | 2021-06-25 13:48:00,659 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-25 13:58:32,964 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-25 13:58:49,336 [084c6adf-4c09-417d-ac5b-6ae661ceeb47@group-61155FD5A026-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 6433b88b-1781-489a-9e20-61b0f5e70d27, Nodes: d7f71981-d306-415b-992d-ee4808a385fa{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:OPEN, leaderId:, CreationTimestamp2021-06-25T13:58:49.321Z].
scm3.org_1   | 2021-06-25 13:59:02,850 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33388
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
scm1.org_1   | 2021-06-25 13:48:00,791 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41094
scm3.org_1   | 2021-06-25 13:59:02,858 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33700
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
scm1.org_1   | 2021-06-25 13:48:00,805 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-25 13:59:02,875 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
scm1.org_1   | 2021-06-25 13:48:22,888 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:46034
scm3.org_1   | 2021-06-25 13:59:02,937 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-25 13:59:02,946 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55542
scm3.org_1   | 2021-06-25 13:59:02,977 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-25 13:59:32,877 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33534
s3g_1        | 2021-06-25 13:50:19,538 [qtp382627885-24] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
scm1.org_1   | 2021-06-25 13:48:22,896 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm3.org_1   | 2021-06-25 13:59:32,879 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33854
scm1.org_1   | 2021-06-25 13:48:30,589 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:44958
s3g_1        | <Error>
scm3.org_1   | 2021-06-25 13:59:32,887 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:48:30,606 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        |   <Code>NoSuchBucket</Code>
scm1.org_1   | 2021-06-25 13:48:30,620 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:57092
s3g_1        |   <Message>The specified bucket does not exist</Message>
scm3.org_1   | 2021-06-25 13:59:32,892 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:48:30,678 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        |   <Resource>nosuchbucket</Resource>
scm3.org_1   | 2021-06-25 13:59:32,914 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55694
scm1.org_1   | 2021-06-25 13:48:30,814 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41266
s3g_1        |   <RequestId/>
scm3.org_1   | 2021-06-25 13:59:32,930 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:48:30,826 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | </Error>
scm3.org_1   | 2021-06-25 13:59:40,932 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:53636
scm1.org_1   | 2021-06-25 13:48:31,378 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1f7870bc, cost 18301.098us
s3g_1        | 
scm3.org_1   | 2021-06-25 13:59:40,939 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:48:31,439 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:47974
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
scm1.org_1   | 2021-06-25 13:48:31,442 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm3.org_1   | 2021-06-25 13:59:40,942 [IPC Server handler 13 on default port 9860] INFO container.ReplicationManager: Stopping Replication Monitor Thread.
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:51)
scm1.org_1   | 2021-06-25 13:49:00,691 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:45102
scm3.org_1   | 2021-06-25 13:59:48,983 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:53674
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
scm1.org_1   | 2021-06-25 13:49:00,705 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:57238
scm3.org_1   | 2021-06-25 13:59:48,986 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
scm1.org_1   | 2021-06-25 13:49:00,710 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-25 13:59:48,988 [IPC Server handler 45 on default port 9860] INFO container.ReplicationManager: Starting Replication Monitor Thread.
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
scm1.org_1   | 2021-06-25 13:49:00,742 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-25 13:59:48,994 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 5 milliseconds for processing 4 containers.
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
scm1.org_1   | 2021-06-25 13:49:00,789 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41414
scm3.org_1   | 2021-06-25 14:00:02,843 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34006
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
scm1.org_1   | 2021-06-25 13:49:00,800 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-25 14:00:02,851 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33696
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
scm1.org_1   | 2021-06-25 13:49:29,232 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 3 milliseconds for processing 2 containers.
scm3.org_1   | 2021-06-25 14:00:02,877 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
scm1.org_1   | 2021-06-25 13:49:29,367 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:46512
scm3.org_1   | 2021-06-25 14:00:02,888 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
scm1.org_1   | 2021-06-25 13:49:29,373 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm3.org_1   | 2021-06-25 14:00:02,927 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55854
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
scm1.org_1   | 2021-06-25 13:49:30,563 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:57546
scm3.org_1   | 2021-06-25 14:00:02,977 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
scm1.org_1   | 2021-06-25 13:49:30,608 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:45406
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
scm1.org_1   | 2021-06-25 13:49:30,631 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
scm1.org_1   | 2021-06-25 13:49:30,651 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
scm1.org_1   | 2021-06-25 13:49:30,769 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41714
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
scm1.org_1   | 2021-06-25 13:49:30,794 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:49:31,368 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1f7870bc, cost 8462.244us
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
scm1.org_1   | 2021-06-25 13:49:43,711 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:46660
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
scm1.org_1   | 2021-06-25 13:49:43,717 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
scm1.org_1   | 2021-06-25 13:49:52,145 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:48674
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
scm1.org_1   | 2021-06-25 13:49:52,150 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
scm1.org_1   | 2021-06-25 13:50:00,613 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:57910
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
scm1.org_1   | 2021-06-25 13:50:00,620 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:45776
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
scm1.org_1   | 2021-06-25 13:50:00,653 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
scm1.org_1   | 2021-06-25 13:50:00,653 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
scm1.org_1   | 2021-06-25 13:50:00,759 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:42082
scm1.org_1   | 2021-06-25 13:50:00,789 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:50:30,658 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:46014
scm1.org_1   | 2021-06-25 13:50:30,706 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:58148
scm1.org_1   | 2021-06-25 13:50:30,750 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:50:30,783 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:50:30,828 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:42322
scm1.org_1   | 2021-06-25 13:50:30,853 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:50:31,380 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1f7870bc, cost 20508.104us
scm1.org_1   | 2021-06-25 13:50:47,139 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:47272
scm1.org_1   | 2021-06-25 13:50:47,157 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2021-06-25 13:50:47,973 [IPC Server handler 26 on default port 9863] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.addTransactionsToDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1f7870bc, cost 15799.48us
scm1.org_1   | 2021-06-25 13:50:56,317 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:49234
scm1.org_1   | 2021-06-25 13:50:56,326 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:51:00,652 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:58434
scm1.org_1   | 2021-06-25 13:51:00,656 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:46294
scm1.org_1   | 2021-06-25 13:51:00,686 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:51:00,696 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:51:00,795 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:42604
scm1.org_1   | 2021-06-25 13:51:00,823 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:51:10,713 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:49430
scm1.org_1   | 2021-06-25 13:51:10,721 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:51:23,614 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:49620
scm1.org_1   | 2021-06-25 13:51:23,617 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:51:30,594 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:58888
scm1.org_1   | 2021-06-25 13:51:30,637 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:46754
scm1.org_1   | 2021-06-25 13:51:30,639 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:51:30,660 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:51:30,785 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43066
scm1.org_1   | 2021-06-25 13:51:30,808 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:51:31,370 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1f7870bc, cost 9954.35us
scm1.org_1   | 2021-06-25 13:51:47,981 [IPC Server handler 80 on default port 9863] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.addTransactionsToDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1f7870bc, cost 21777.109us
scm1.org_1   | 2021-06-25 13:51:58,760 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:50070
scm1.org_1   | 2021-06-25 13:51:58,768 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:52:00,385 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:58288
scm1.org_1   | 2021-06-25 13:52:00,405 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:44712
scm1.org_1   | 2021-06-25 13:52:00,427 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:52:00,432 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:52:00,623 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47114
scm1.org_1   | 2021-06-25 13:52:00,678 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:52:00,785 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43430
scm1.org_1   | 2021-06-25 13:52:00,809 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:59250
scm1.org_1   | 2021-06-25 13:52:00,856 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:52:00,865 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:52:12,803 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:48366
scm1.org_1   | 2021-06-25 13:52:12,806 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2021-06-25 13:52:14,306 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:50258
scm1.org_1   | 2021-06-25 13:52:14,308 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:52:30,596 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47450
scm1.org_1   | 2021-06-25 13:52:30,618 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:52:30,641 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:59586
scm1.org_1   | 2021-06-25 13:52:30,664 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:52:30,768 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43768
scm1.org_1   | 2021-06-25 13:52:30,809 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:52:31,377 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1f7870bc, cost 16595.482us
scm1.org_1   | 2021-06-25 13:52:31,549 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:48626
scm1.org_1   | 2021-06-25 13:52:31,550 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2021-06-25 13:52:43,236 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:48738
scm1.org_1   | 2021-06-25 13:52:43,247 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2021-06-25 13:52:46,003 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:50646
scm1.org_1   | 2021-06-25 13:52:46,005 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:52:47,979 [IPC Server handler 81 on default port 9863] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.addTransactionsToDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1f7870bc, cost 21350.905us
scm1.org_1   | 2021-06-25 13:53:00,644 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:59982
scm1.org_1   | 2021-06-25 13:53:00,662 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47844
scm1.org_1   | 2021-06-25 13:53:00,680 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:53:00,705 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:53:00,773 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44154
scm1.org_1   | 2021-06-25 13:53:00,799 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:53:21,981 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:49094
scm1.org_1   | 2021-06-25 13:53:21,984 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2021-06-25 13:53:30,017 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40836
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-06-25 13:50:26,570 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:50:26,597 [qtp382627885-21] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-79834, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2021-06-25 13:50:26,612 [qtp382627885-21] INFO endpoint.BucketEndpoint: Location is /bucket-79834
s3g_1        | 2021-06-25 13:50:27,267 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
scm1.org_1   | 2021-06-25 13:53:30,033 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2021-06-25 13:53:30,425 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:52540
scm1.org_1   | 2021-06-25 13:53:30,430 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:53:30,487 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: e166831c-4ec6-45e5-8ea8-b63dd27aa2c5, Nodes: 8dca9ea8-5191-4cce-a34e-3d546f33f7b1{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:OPEN, leaderId:, CreationTimestamp2021-06-25T13:53:30.441Z].
scm1.org_1   | 2021-06-25 13:53:30,499 [IPC Server handler 97 on default port 9860] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.addPipeline(org.apache.hadoop.hdds.protocol.proto.HddsProtos$Pipeline) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1f7870bc, cost 57666.678us
scm1.org_1   | 2021-06-25 13:53:30,514 [IPC Server handler 97 on default port 9860] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.container.ContainerStateManagerV2.addContainer(org.apache.hadoop.hdds.protocol.proto.HddsProtos$ContainerInfoProto) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1f7870bc, cost 14217.169us
scm1.org_1   | 2021-06-25 13:53:30,609 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:60144
scm1.org_1   | 2021-06-25 13:53:30,634 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:53:30,635 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48008
scm1.org_1   | 2021-06-25 13:53:30,649 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:53:30,773 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44318
scm1.org_1   | 2021-06-25 13:53:30,781 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:53:31,367 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1f7870bc, cost 6570.631us
scm1.org_1   | 2021-06-25 13:53:37,901 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:52604
scm1.org_1   | 2021-06-25 13:53:37,918 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:53:42,929 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:52620
scm1.org_1   | 2021-06-25 13:53:42,944 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:53:47,731 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:52638
scm1.org_1   | 2021-06-25 13:53:47,750 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:53:52,495 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:52660
scm1.org_1   | 2021-06-25 13:53:52,518 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:53:57,158 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:52684
scm1.org_1   | 2021-06-25 13:53:57,177 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:54:00,555 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:60288
scm1.org_1   | 2021-06-25 13:54:00,597 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:54:00,768 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44456
scm1.org_1   | 2021-06-25 13:54:00,776 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:54:01,592 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:52716
scm1.org_1   | 2021-06-25 13:54:01,603 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:54:02,983 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48172
scm1.org_1   | 2021-06-25 13:54:03,001 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:54:05,934 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:52734
scm1.org_1   | 2021-06-25 13:54:05,949 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:50:27,901 [qtp382627885-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:50:27,926 [qtp382627885-24] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>NoSuchBucket</Code>
s3g_1        |   <Message>The specified bucket does not exist</Message>
s3g_1        |   <Resource>ozonenosuchbucketqqweqwe</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:51)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
scm1.org_1   | 2021-06-25 13:54:06,180 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #1
scm1.org_1   | 2021-06-25 13:54:06,205 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.container.ContainerStateManagerV2.updateContainerState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$ContainerID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$LifeCycleEvent) throws java.io.IOException,org.apache.hadoop.ozone.common.statemachine.InvalidStateTransitionException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1f7870bc, cost 23708.013us
scm1.org_1   | 2021-06-25 13:54:10,400 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:52756
scm1.org_1   | 2021-06-25 13:54:10,421 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:54:14,626 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:52776
scm1.org_1   | 2021-06-25 13:54:14,646 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:54:29,072 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:52824
scm1.org_1   | 2021-06-25 13:54:29,086 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:54:29,235 [ReplicationMonitor] INFO container.ReplicationManager: Sending close container command for container #1 to datanode d7f71981-d306-415b-992d-ee4808a385fa{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
scm1.org_1   | 2021-06-25 13:54:29,243 [ReplicationMonitor] INFO container.ReplicationManager: Sending close container command for container #1 to datanode ee31bb40-6981-4b57-b8d7-3be03fa0c81d{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
scm1.org_1   | 2021-06-25 13:54:29,249 [ReplicationMonitor] INFO container.ReplicationManager: Sending close container command for container #1 to datanode 8dca9ea8-5191-4cce-a34e-3d546f33f7b1{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
scm1.org_1   | 2021-06-25 13:54:29,260 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 28 milliseconds for processing 3 containers.
scm1.org_1   | 2021-06-25 13:54:30,569 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:60424
scm1.org_1   | 2021-06-25 13:54:30,581 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:54:30,749 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44606
scm1.org_1   | 2021-06-25 13:54:30,781 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:54:31,371 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1f7870bc, cost 10481.35us
scm1.org_1   | 2021-06-25 13:54:31,667 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] INFO container.IncrementalContainerReportHandler: Moving container #1 to CLOSED state, datanode d7f71981-d306-415b-992d-ee4808a385fa{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
scm1.org_1   | 2021-06-25 13:54:31,675 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48318
scm1.org_1   | 2021-06-25 13:54:31,679 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.container.ContainerStateManagerV2.updateContainerState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$ContainerID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$LifeCycleEvent) throws java.io.IOException,org.apache.hadoop.ozone.common.statemachine.InvalidStateTransitionException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1f7870bc, cost 11677.756us
scm1.org_1   | 2021-06-25 13:54:31,759 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:54:43,547 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:52900
scm1.org_1   | 2021-06-25 13:54:43,571 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:54:50,937 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:52936
scm1.org_1   | 2021-06-25 13:54:50,951 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:54:50,953 [IPC Server handler 67 on default port 9860] INFO ipc.Server: IPC Server handler 67 on default port 9860, call Call#0 Retry#0 org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol.submitRequest from 172.25.0.116:52936
scm1.org_1   | org.apache.hadoop.security.AccessControlException: Access denied for user testuser2/scm@EXAMPLE.COM. Superuser privilege is required.
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.server.StorageContainerManager.checkAdminAccess(StorageContainerManager.java:1551)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.server.SCMClientProtocolServer.getContainer(SCMClientProtocolServer.java:212)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.getContainer(StorageContainerLocationProtocolServerSideTranslatorPB.java:403)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.processRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:183)
scm1.org_1   | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:162)
scm1.org_1   | 	at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:52594)
scm1.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
scm1.org_1   | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
scm1.org_1   | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm1.org_1   | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm1.org_1   | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
scm1.org_1   | 2021-06-25 13:54:55,265 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41246
scm1.org_1   | 2021-06-25 13:54:55,284 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2021-06-25 13:54:55,607 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:52962
scm1.org_1   | 2021-06-25 13:54:55,616 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:54:55,617 [IPC Server handler 4 on default port 9860] INFO ipc.Server: IPC Server handler 4 on default port 9860, call Call#1 Retry#0 org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol.submitRequest from 172.25.0.116:52962
scm1.org_1   | org.apache.hadoop.security.AccessControlException: Access denied for user testuser2/scm@EXAMPLE.COM. Superuser privilege is required.
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.server.StorageContainerManager.checkAdminAccess(StorageContainerManager.java:1551)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.server.SCMClientProtocolServer.allocateContainer(SCMClientProtocolServer.java:196)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.allocateContainer(StorageContainerLocationProtocolServerSideTranslatorPB.java:392)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.processRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:175)
scm1.org_1   | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:162)
scm1.org_1   | 	at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:52594)
scm1.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
scm1.org_1   | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
scm1.org_1   | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm1.org_1   | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm1.org_1   | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
scm1.org_1   | 2021-06-25 13:55:00,089 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:52974
scm1.org_1   | 2021-06-25 13:55:00,105 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:55:00,106 [IPC Server handler 31 on default port 9860] INFO ipc.Server: IPC Server handler 31 on default port 9860, call Call#0 Retry#0 org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol.submitRequest from 172.25.0.116:52974
scm1.org_1   | org.apache.hadoop.security.AccessControlException: Access denied for user testuser2/scm@EXAMPLE.COM. Superuser privilege is required.
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.server.StorageContainerManager.checkAdminAccess(StorageContainerManager.java:1551)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.server.SCMClientProtocolServer.getContainer(SCMClientProtocolServer.java:212)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.getContainer(StorageContainerLocationProtocolServerSideTranslatorPB.java:403)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.processRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:183)
scm1.org_1   | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:162)
scm1.org_1   | 	at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:52594)
scm1.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
scm1.org_1   | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
scm1.org_1   | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm1.org_1   | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-06-25 13:50:27,927 [qtp382627885-24] ERROR endpoint.BucketEndpoint: Exception occurred in headBucket
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.newError(S3ErrorTable.java:131)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.EndpointBase.getBucket(EndpointBase.java:68)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.head(BucketEndpoint.java:295)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
scm1.org_1   | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
scm1.org_1   | 2021-06-25 13:55:01,693 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:60582
scm1.org_1   | 2021-06-25 13:55:01,715 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:55:01,850 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44752
scm1.org_1   | 2021-06-25 13:55:01,855 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48452
scm1.org_1   | 2021-06-25 13:55:01,859 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:55:01,860 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:55:04,785 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53014
scm1.org_1   | 2021-06-25 13:55:04,804 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:55:09,543 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53036
scm1.org_1   | 2021-06-25 13:55:09,560 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:55:13,792 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53046
scm1.org_1   | 2021-06-25 13:55:13,803 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:55:20,989 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53086
scm1.org_1   | 2021-06-25 13:55:21,000 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:55:21,018 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: b33a7b3b-a75c-4d79-8ef2-49fbac2a5fe4, Nodes: d7f71981-d306-415b-992d-ee4808a385fa{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:OPEN, leaderId:, CreationTimestamp2021-06-25T13:55:21.004Z].
scm1.org_1   | 2021-06-25 13:55:21,027 [IPC Server handler 68 on default port 9860] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.addPipeline(org.apache.hadoop.hdds.protocol.proto.HddsProtos$Pipeline) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1f7870bc, cost 22550.007us
scm1.org_1   | 2021-06-25 13:55:25,203 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53096
scm1.org_1   | 2021-06-25 13:55:25,224 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:55:29,827 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53118
scm1.org_1   | 2021-06-25 13:55:29,844 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:55:31,378 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1f7870bc, cost 16899.179us
scm1.org_1   | 2021-06-25 13:55:31,698 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:60730
scm1.org_1   | 2021-06-25 13:55:31,721 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:55:31,806 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48596
scm1.org_1   | 2021-06-25 13:55:31,824 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44896
scm1.org_1   | 2021-06-25 13:55:31,831 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:55:31,833 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:55:34,458 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53166
scm1.org_1   | 2021-06-25 13:55:34,479 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:55:34,490 [IPC Server handler 97 on default port 9860] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1f7870bc, cost 10755.551us
scm1.org_1   | 2021-06-25 13:55:37,909 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53176
scm1.org_1   | 2021-06-25 13:55:37,930 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:55:41,983 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53196
scm1.org_1   | 2021-06-25 13:55:42,013 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:55:42,031 [IPC Server handler 95 on default port 9860] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1f7870bc, cost 17042.98us
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
scm1.org_1   | 2021-06-25 13:55:46,353 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53218
scm1.org_1   | 2021-06-25 13:55:46,378 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:55:50,954 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53238
scm1.org_1   | 2021-06-25 13:55:50,983 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:55:51,003 [IPC Server handler 35 on default port 9860] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1f7870bc, cost 17211.88us
scm1.org_1   | 2021-06-25 13:55:51,003 [IPC Server handler 35 on default port 9860] INFO pipeline.PipelineManagerV2Impl: Pipeline Pipeline[ Id: b33a7b3b-a75c-4d79-8ef2-49fbac2a5fe4, Nodes: d7f71981-d306-415b-992d-ee4808a385fa{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:OPEN, leaderId:, CreationTimestamp2021-06-25T13:55:21.004Z] moved to CLOSED state
scm1.org_1   | 2021-06-25 13:55:55,404 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53250
scm1.org_1   | 2021-06-25 13:55:55,422 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:56:01,670 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:60872
scm1.org_1   | 2021-06-25 13:56:01,682 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:56:01,817 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45040
scm1.org_1   | 2021-06-25 13:56:01,828 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48742
scm1.org_1   | 2021-06-25 13:56:01,838 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:56:01,877 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:56:03,262 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53308
scm1.org_1   | 2021-06-25 13:56:03,274 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:56:07,902 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53322
scm1.org_1   | 2021-06-25 13:56:07,918 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:56:13,134 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53346
scm1.org_1   | 2021-06-25 13:56:13,145 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:56:13,146 [IPC Server handler 54 on default port 9860] INFO container.ReplicationManager: Stopping Replication Monitor Thread.
scm1.org_1   | 2021-06-25 13:56:17,784 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53368
scm1.org_1   | 2021-06-25 13:56:17,807 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:56:22,498 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53392
scm1.org_1   | 2021-06-25 13:56:22,505 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:56:22,511 [IPC Server handler 97 on default port 9860] INFO container.ReplicationManager: Starting Replication Monitor Thread.
scm1.org_1   | 2021-06-25 13:56:22,529 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 8 milliseconds for processing 3 containers.
scm1.org_1   | 2021-06-25 13:56:26,668 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53414
scm1.org_1   | 2021-06-25 13:56:26,698 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:56:31,380 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1f7870bc, cost 16024.875us
scm1.org_1   | 2021-06-25 13:56:31,691 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:32800
scm1.org_1   | 2021-06-25 13:56:31,715 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:56:31,814 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45200
scm1.org_1   | 2021-06-25 13:56:31,823 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48902
scm1.org_1   | 2021-06-25 13:56:31,832 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:56:31,845 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:56:34,534 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53472
scm1.org_1   | 2021-06-25 13:56:34,560 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:56:38,961 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53494
scm1.org_1   | 2021-06-25 13:56:38,978 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:56:42,474 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53504
scm1.org_1   | 2021-06-25 13:56:42,493 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:56:49,721 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53534
scm1.org_1   | 2021-06-25 13:56:49,739 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:57:01,742 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:32940
scm1.org_1   | 2021-06-25 13:57:01,775 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:57:01,786 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45342
scm1.org_1   | 2021-06-25 13:57:01,788 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49042
scm1.org_1   | 2021-06-25 13:57:01,809 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:57:01,847 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:57:06,523 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:50208
scm1.org_1   | 2021-06-25 13:57:06,526 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2021-06-25 13:57:06,570 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:46690
scm1.org_1   | 2021-06-25 13:57:06,579 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:52080
scm1.org_1   | 2021-06-25 13:57:06,582 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:57:06,597 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:60272
scm1.org_1   | 2021-06-25 13:57:06,605 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:57:06,609 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:57:13,916 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:41002
scm1.org_1   | 2021-06-25 13:57:13,933 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2021-06-25 13:57:14,283 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:59474
scm1.org_1   | 2021-06-25 13:57:14,287 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:57:14,295 [IPC Server handler 86 on default port 9860] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.container.ContainerStateManagerV2.addContainer(org.apache.hadoop.hdds.protocol.proto.HddsProtos$ContainerInfoProto) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1f7870bc, cost 7092.633us
scm1.org_1   | 2021-06-25 13:57:16,653 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49130
scm1.org_1   | 2021-06-25 13:57:16,687 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:57:21,302 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:59514
scm1.org_1   | 2021-06-25 13:57:21,321 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:57:25,647 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:59526
scm1.org_1   | 2021-06-25 13:57:25,664 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:57:30,590 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:59548
scm1.org_1   | 2021-06-25 13:57:30,603 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:57:31,370 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1f7870bc, cost 9101.242us
scm1.org_1   | 2021-06-25 13:57:31,701 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33108
scm1.org_1   | 2021-06-25 13:57:31,711 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:57:31,766 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45510
scm1.org_1   | 2021-06-25 13:57:31,793 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:57:35,373 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:59592
scm1.org_1   | 2021-06-25 13:57:35,393 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:57:39,948 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:59612
scm1.org_1   | 2021-06-25 13:57:39,968 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:57:43,803 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:59624
scm1.org_1   | 2021-06-25 13:57:43,819 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:57:46,641 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49284
scm1.org_1   | 2021-06-25 13:57:46,657 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:57:47,977 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:59652
scm1.org_1   | 2021-06-25 13:57:48,000 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:57:48,251 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #2
scm1.org_1   | 2021-06-25 13:57:48,262 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.container.ContainerStateManagerV2.updateContainerState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$ContainerID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$LifeCycleEvent) throws java.io.IOException,org.apache.hadoop.ozone.common.statemachine.InvalidStateTransitionException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1f7870bc, cost 10637.648us
scm1.org_1   | 2021-06-25 13:57:52,552 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:59672
scm1.org_1   | 2021-06-25 13:57:52,575 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:57:57,223 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:59696
scm1.org_1   | 2021-06-25 13:57:57,247 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:58:01,728 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33252
scm1.org_1   | 2021-06-25 13:58:01,740 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:58:01,778 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45654
scm1.org_1   | 2021-06-25 13:58:01,794 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:58:02,855 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] INFO container.IncrementalContainerReportHandler: Moving container #2 to CLOSED state, datanode d7f71981-d306-415b-992d-ee4808a385fa{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-06-25 13:50:36,093 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:50:36,107 [qtp382627885-21] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-47678, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2021-06-25 13:50:36,122 [qtp382627885-21] INFO endpoint.BucketEndpoint: Location is /bucket-47678
s3g_1        | 2021-06-25 13:50:36,768 [qtp382627885-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
scm1.org_1   | 2021-06-25 13:58:02,915 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.container.ContainerStateManagerV2.updateContainerState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$ContainerID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$LifeCycleEvent) throws java.io.IOException,org.apache.hadoop.ozone.common.statemachine.InvalidStateTransitionException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1f7870bc, cost 55684.255us
scm1.org_1   | 2021-06-25 13:58:02,920 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49360
scm1.org_1   | 2021-06-25 13:58:02,952 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:58:12,142 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:59762
scm1.org_1   | 2021-06-25 13:58:12,163 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:58:20,103 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:59792
s3g_1        | 2021-06-25 13:50:44,755 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:50:44,783 [qtp382627885-21] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-04686, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2021-06-25 13:50:44,793 [qtp382627885-21] INFO endpoint.BucketEndpoint: Location is /bucket-04686
s3g_1        | 2021-06-25 13:50:45,451 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:50:46,224 [qtp382627885-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:50:47,069 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
scm1.org_1   | 2021-06-25 13:58:20,119 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:58:20,120 [IPC Server handler 31 on default port 9860] INFO ipc.Server: IPC Server handler 31 on default port 9860, call Call#0 Retry#0 org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol.submitRequest from 172.25.0.117:59792
scm1.org_1   | org.apache.hadoop.security.AccessControlException: Access denied for user testuser2/scm@EXAMPLE.COM. Superuser privilege is required.
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.server.StorageContainerManager.checkAdminAccess(StorageContainerManager.java:1551)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.server.SCMClientProtocolServer.getContainer(SCMClientProtocolServer.java:212)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.getContainer(StorageContainerLocationProtocolServerSideTranslatorPB.java:403)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.processRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:183)
scm1.org_1   | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:162)
scm1.org_1   | 	at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:52594)
scm1.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
scm1.org_1   | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
scm1.org_1   | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm1.org_1   | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm1.org_1   | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
scm1.org_1   | 2021-06-25 13:58:24,716 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:41344
scm1.org_1   | 2021-06-25 13:58:24,736 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2021-06-25 13:58:25,048 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:59816
scm1.org_1   | 2021-06-25 13:58:25,056 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:58:25,057 [IPC Server handler 95 on default port 9860] INFO ipc.Server: IPC Server handler 95 on default port 9860, call Call#1 Retry#0 org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol.submitRequest from 172.25.0.117:59816
scm1.org_1   | org.apache.hadoop.security.AccessControlException: Access denied for user testuser2/scm@EXAMPLE.COM. Superuser privilege is required.
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.server.StorageContainerManager.checkAdminAccess(StorageContainerManager.java:1551)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.server.SCMClientProtocolServer.allocateContainer(SCMClientProtocolServer.java:196)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.allocateContainer(StorageContainerLocationProtocolServerSideTranslatorPB.java:392)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.processRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:175)
scm1.org_1   | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:162)
scm1.org_1   | 	at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:52594)
scm1.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
scm1.org_1   | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
scm1.org_1   | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm1.org_1   | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm1.org_1   | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
scm1.org_1   | 2021-06-25 13:58:29,399 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:59836
scm1.org_1   | 2021-06-25 13:58:29,410 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:58:29,411 [IPC Server handler 76 on default port 9860] INFO ipc.Server: IPC Server handler 76 on default port 9860, call Call#0 Retry#0 org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol.submitRequest from 172.25.0.117:59836
scm1.org_1   | org.apache.hadoop.security.AccessControlException: Access denied for user testuser2/scm@EXAMPLE.COM. Superuser privilege is required.
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.server.StorageContainerManager.checkAdminAccess(StorageContainerManager.java:1551)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.server.SCMClientProtocolServer.getContainer(SCMClientProtocolServer.java:212)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.getContainer(StorageContainerLocationProtocolServerSideTranslatorPB.java:403)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.processRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:183)
scm1.org_1   | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:162)
scm1.org_1   | 	at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:52594)
scm1.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
scm1.org_1   | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
scm1.org_1   | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
scm1.org_1   | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm1.org_1   | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
scm1.org_1   | 2021-06-25 13:58:31,369 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1f7870bc, cost 8246.637us
scm1.org_1   | 2021-06-25 13:58:32,822 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45796
scm1.org_1   | 2021-06-25 13:58:32,867 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33410
scm1.org_1   | 2021-06-25 13:58:32,875 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:58:32,908 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:58:32,943 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49504
scm1.org_1   | 2021-06-25 13:58:32,979 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:58:33,808 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:59884
scm1.org_1   | 2021-06-25 13:58:33,822 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:58:38,493 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:59898
scm1.org_1   | 2021-06-25 13:58:38,506 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:58:43,080 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:59918
scm1.org_1   | 2021-06-25 13:58:43,093 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:58:49,299 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:59944
scm1.org_1   | 2021-06-25 13:58:49,320 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:58:49,330 [76093931-f232-4415-806f-239960e589cb@group-61155FD5A026-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 6433b88b-1781-489a-9e20-61b0f5e70d27, Nodes: d7f71981-d306-415b-992d-ee4808a385fa{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:OPEN, leaderId:, CreationTimestamp2021-06-25T13:58:49.321Z].
scm1.org_1   | 2021-06-25 13:58:49,331 [IPC Server handler 66 on default port 9860] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.addPipeline(org.apache.hadoop.hdds.protocol.proto.HddsProtos$Pipeline) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1f7870bc, cost 10298.247us
scm1.org_1   | 2021-06-25 13:58:53,489 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:59964
scm1.org_1   | 2021-06-25 13:58:53,505 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:58:57,907 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:59986
scm1.org_1   | 2021-06-25 13:58:57,918 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:59:02,420 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:60000
scm1.org_1   | 2021-06-25 13:59:02,440 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:59:02,449 [IPC Server handler 97 on default port 9860] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1f7870bc, cost 8996.141us
scm1.org_1   | 2021-06-25 13:59:02,821 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33550
scm1.org_1   | 2021-06-25 13:59:02,835 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45954
scm1.org_1   | 2021-06-25 13:59:02,842 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:59:02,924 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49656
scm1.org_1   | 2021-06-25 13:59:02,933 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:59:02,975 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:59:06,790 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:60038
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:50:47,229 [qtp382627885-21] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-62A16A7CAB2E->d7f71981-d306-415b-992d-ee4808a385fa
s3g_1        | 2021-06-25 13:50:47,231 [qtp382627885-21] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-25 13:50:48,479 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:50:48,615 [qtp382627885-21] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-B86DACCF8EAD->ee31bb40-6981-4b57-b8d7-3be03fa0c81d
s3g_1        | 2021-06-25 13:50:48,615 [qtp382627885-21] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-25 13:50:49,811 [qtp382627885-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:50:50,637 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
scm1.org_1   | 2021-06-25 13:59:06,808 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:59:11,403 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:60060
scm1.org_1   | 2021-06-25 13:59:11,417 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:59:11,429 [IPC Server handler 76 on default port 9860] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1f7870bc, cost 10941.549us
scm1.org_1   | 2021-06-25 13:59:16,257 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:60080
scm1.org_1   | 2021-06-25 13:59:16,275 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:59:20,764 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:60094
scm1.org_1   | 2021-06-25 13:59:20,780 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:59:20,790 [IPC Server handler 14 on default port 9860] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1f7870bc, cost 8617.639us
scm1.org_1   | 2021-06-25 13:59:20,790 [IPC Server handler 14 on default port 9860] INFO pipeline.PipelineManagerV2Impl: Pipeline Pipeline[ Id: 6433b88b-1781-489a-9e20-61b0f5e70d27, Nodes: d7f71981-d306-415b-992d-ee4808a385fa{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:OPEN, leaderId:, CreationTimestamp2021-06-25T13:58:49.321Z] moved to CLOSED state
scm1.org_1   | 2021-06-25 13:59:25,165 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:60116
scm1.org_1   | 2021-06-25 13:59:25,186 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:59:31,369 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1f7870bc, cost 7551.534us
scm1.org_1   | 2021-06-25 13:59:32,397 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:60154
scm1.org_1   | 2021-06-25 13:59:32,412 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:59:32,833 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33702
scm1.org_1   | 2021-06-25 13:59:32,840 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:59:32,879 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46106
scm1.org_1   | 2021-06-25 13:59:32,921 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49806
scm1.org_1   | 2021-06-25 13:59:32,931 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:59:32,933 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 13:59:36,581 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:60190
scm1.org_1   | 2021-06-25 13:59:36,592 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:59:40,896 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:60212
scm1.org_1   | 2021-06-25 13:59:40,902 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:59:40,904 [IPC Server handler 38 on default port 9860] INFO container.ReplicationManager: Stopping Replication Monitor Thread.
scm1.org_1   | 2021-06-25 13:59:44,855 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:60228
scm1.org_1   | 2021-06-25 13:59:44,876 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:59:48,962 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:60250
scm1.org_1   | 2021-06-25 13:59:48,966 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:59:48,968 [IPC Server handler 1 on default port 9860] INFO container.ReplicationManager: Starting Replication Monitor Thread.
scm1.org_1   | 2021-06-25 13:59:48,970 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 4 containers.
scm1.org_1   | 2021-06-25 13:59:52,402 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:60270
scm1.org_1   | 2021-06-25 13:59:52,421 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 13:59:59,759 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:60300
scm1.org_1   | 2021-06-25 13:59:59,780 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 14:00:02,845 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46256
scm1.org_1   | 2021-06-25 14:00:02,856 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33856
scm1.org_1   | 2021-06-25 14:00:02,868 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 14:00:02,894 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 14:00:02,925 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49962
scm1.org_1   | 2021-06-25 14:00:02,977 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-25 14:00:04,362 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:60338
scm1.org_1   | 2021-06-25 14:00:04,375 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 14:00:08,653 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:60350
scm1.org_1   | 2021-06-25 14:00:08,666 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-25 14:00:15,705 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:60382
scm1.org_1   | 2021-06-25 14:00:15,725 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:50:50,756 [qtp382627885-21] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-B596F04DD0A7->d7f71981-d306-415b-992d-ee4808a385fa
s3g_1        | 2021-06-25 13:50:50,756 [qtp382627885-21] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-25 13:50:54,506 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:50:54,609 [qtp382627885-21] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-A84CD8D3507E->d7f71981-d306-415b-992d-ee4808a385fa
s3g_1        | 2021-06-25 13:50:54,609 [qtp382627885-21] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-25 13:50:55,572 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:50:56,277 [qtp382627885-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:50:57,395 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:50:58,238 [qtp382627885-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:50:58,343 [qtp382627885-24] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-48E2AF2AE581->d7f71981-d306-415b-992d-ee4808a385fa
s3g_1        | 2021-06-25 13:50:58,348 [qtp382627885-24] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-25 13:50:59,250 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:50:59,314 [qtp382627885-21] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-BFCC99A0A429->ee31bb40-6981-4b57-b8d7-3be03fa0c81d
s3g_1        | 2021-06-25 13:50:59,315 [qtp382627885-21] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-25 13:51:00,320 [qtp382627885-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:51:00,362 [qtp382627885-24] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-04686, , key: 30295/multipartKey2
s3g_1        | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-04686 key: 30295/multipartKey2. Entity too small.
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:605)
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:977)
s3g_1        | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:1075)
s3g_1        | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:691)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:531)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-06-25 13:51:00,366 [qtp382627885-24] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>EntityTooSmall</Code>
s3g_1        |   <Message>Your proposed upload is smaller than the minimum allowed object size. Each part must be at least 5 MB in size, except the last part.</Message>
s3g_1        |   <Resource>30295/multipartKey2</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:102)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-06-25 13:51:01,388 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:51:02,137 [qtp382627885-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:51:02,191 [qtp382627885-24] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-04686, , key: 54205/multipartKey3
s3g_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-04686 key: 54205/multipartKey3
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:605)
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:977)
s3g_1        | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:1075)
s3g_1        | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:691)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:531)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-06-25 13:51:02,192 [qtp382627885-24] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>InvalidPart</Code>
s3g_1        |   <Message>One or more of the specified parts could not be found. The part might not have been uploaded, or the specified entity tag might not have matched the part's entity tag.</Message>
s3g_1        |   <Resource>54205/multipartKey3</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:92)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-06-25 13:51:02,858 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:51:02,907 [qtp382627885-21] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-04686, , key: 54205/multipartKey3
s3g_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-04686 key: 54205/multipartKey3
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:605)
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:977)
s3g_1        | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:1075)
s3g_1        | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:691)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:531)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-06-25 13:51:02,908 [qtp382627885-21] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>InvalidPart</Code>
s3g_1        |   <Message>One or more of the specified parts could not be found. The part might not have been uploaded, or the specified entity tag might not have matched the part's entity tag.</Message>
s3g_1        |   <Resource>54205/multipartKey3</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:92)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-06-25 13:51:03,683 [qtp382627885-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:51:03,779 [qtp382627885-24] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-92696E461737->ee31bb40-6981-4b57-b8d7-3be03fa0c81d
s3g_1        | 2021-06-25 13:51:03,779 [qtp382627885-24] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-25 13:51:05,140 [qtp382627885-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:51:05,239 [qtp382627885-24] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-98A550E399CC->ee31bb40-6981-4b57-b8d7-3be03fa0c81d
s3g_1        | 2021-06-25 13:51:05,239 [qtp382627885-24] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-25 13:51:06,875 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:51:06,949 [qtp382627885-21] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-A0BB01A5315D->d7f71981-d306-415b-992d-ee4808a385fa
s3g_1        | 2021-06-25 13:51:06,949 [qtp382627885-21] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-25 13:51:07,851 [qtp382627885-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:51:07,883 [qtp382627885-24] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-04686, , key: 54205/multipartKey3
s3g_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-04686 key: 54205/multipartKey3. Provided Part info is { etag1, 1}, whereas OM has partName /s3v/bucket-04686/54205/multipartKey3106471690318512161
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:605)
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:977)
s3g_1        | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:1075)
s3g_1        | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:691)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:531)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-06-25 13:51:07,885 [qtp382627885-24] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>InvalidPart</Code>
s3g_1        |   <Message>One or more of the specified parts could not be found. The part might not have been uploaded, or the specified entity tag might not have matched the part's entity tag.</Message>
s3g_1        |   <Resource>54205/multipartKey3</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:92)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-06-25 13:51:08,542 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:51:08,580 [qtp382627885-21] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-04686, , key: 54205/multipartKey3
s3g_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-04686 key: 54205/multipartKey3. Provided Part info is { etag2, 2}, whereas OM has partName /s3v/bucket-04686/54205/multipartKey3106471690413867042
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:605)
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:977)
s3g_1        | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:1075)
s3g_1        | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:691)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:531)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-06-25 13:51:08,581 [qtp382627885-21] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>InvalidPart</Code>
s3g_1        |   <Message>One or more of the specified parts could not be found. The part might not have been uploaded, or the specified entity tag might not have matched the part's entity tag.</Message>
s3g_1        |   <Resource>54205/multipartKey3</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:92)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-06-25 13:51:09,191 [qtp382627885-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:51:09,222 [qtp382627885-24] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-04686, , key: 54205/multipartKey3
s3g_1        | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-04686 key: 54205/multipartKey3 because parts are in Invalid order.
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:605)
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:977)
s3g_1        | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:1075)
s3g_1        | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:691)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:531)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-06-25 13:51:09,227 [qtp382627885-24] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>InvalidPartOrder</Code>
s3g_1        |   <Message>The list of parts was not in ascending order. The parts list must be specified in order by part number.</Message>
s3g_1        |   <Resource>54205/multipartKey3</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:97)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-06-25 13:51:09,843 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:51:10,554 [qtp382627885-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:51:11,667 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:51:12,407 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:51:13,127 [qtp382627885-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:51:13,167 [qtp382627885-24] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>NoSuchUpload</Code>
s3g_1        |   <Message>The specified multipart upload does not exist. The upload ID might be invalid, or the multipart upload might have been aborted or completed.</Message>
s3g_1        |   <Resource>random</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:83)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-06-25 13:51:13,807 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:51:13,837 [qtp382627885-21] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>NoSuchUpload</Code>
s3g_1        |   <Message>The specified multipart upload does not exist. The upload ID might be invalid, or the multipart upload might have been aborted or completed.</Message>
s3g_1        |   <Resource>random</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:83)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-06-25 13:51:14,472 [qtp382627885-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:51:15,328 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:51:15,406 [qtp382627885-21] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-83FCB5DBE7E1->ee31bb40-6981-4b57-b8d7-3be03fa0c81d
s3g_1        | 2021-06-25 13:51:15,406 [qtp382627885-21] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-25 13:51:16,628 [qtp382627885-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:51:16,706 [qtp382627885-24] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-94439F943CDC->ee31bb40-6981-4b57-b8d7-3be03fa0c81d
s3g_1        | 2021-06-25 13:51:16,706 [qtp382627885-24] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-25 13:51:17,559 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:51:18,366 [qtp382627885-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:51:19,153 [qtp382627885-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:51:19,870 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:51:20,833 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:51:21,048 [qtp382627885-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:51:21,251 [qtp382627885-19] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:51:21,259 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:51:21,325 [qtp382627885-24] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-BE1FEDACE017->d7f71981-d306-415b-992d-ee4808a385fa
s3g_1        | 2021-06-25 13:51:21,327 [qtp382627885-24] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-25 13:51:21,495 [qtp382627885-21] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-0DC7A96349EB->ee31bb40-6981-4b57-b8d7-3be03fa0c81d
s3g_1        | 2021-06-25 13:51:21,504 [qtp382627885-21] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-25 13:51:21,510 [qtp382627885-19] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-AE319528F451->ee31bb40-6981-4b57-b8d7-3be03fa0c81d
s3g_1        | 2021-06-25 13:51:21,510 [qtp382627885-19] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-25 13:51:22,936 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:51:23,516 [qtp382627885-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:51:23,676 [qtp382627885-22] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:51:23,690 [qtp382627885-23] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:51:23,691 [qtp382627885-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:51:24,903 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:51:25,780 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:51:25,874 [qtp382627885-20] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-7FF2260A6400->ee31bb40-6981-4b57-b8d7-3be03fa0c81d
s3g_1        | 2021-06-25 13:51:25,874 [qtp382627885-20] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-25 13:51:27,062 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:51:27,787 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:51:28,093 [qtp382627885-21] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-C68526E0E1C4->d7f71981-d306-415b-992d-ee4808a385fa
s3g_1        | 2021-06-25 13:51:28,094 [qtp382627885-21] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-25 13:51:29,320 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:51:29,984 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:51:31,260 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:51:31,347 [qtp382627885-20] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-5B0ED835482A->d7f71981-d306-415b-992d-ee4808a385fa
s3g_1        | 2021-06-25 13:51:31,347 [qtp382627885-20] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-25 13:51:32,844 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:51:33,581 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:51:33,794 [qtp382627885-20] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-BDD49C800F06->d7f71981-d306-415b-992d-ee4808a385fa
s3g_1        | 2021-06-25 13:51:33,794 [qtp382627885-20] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-25 13:51:35,183 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:51:35,338 [qtp382627885-21] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-3B4B73498110->ee31bb40-6981-4b57-b8d7-3be03fa0c81d
s3g_1        | 2021-06-25 13:51:35,338 [qtp382627885-21] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-25 13:51:36,191 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:51:36,932 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:51:38,413 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:51:38,478 [qtp382627885-20] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-9663853669DC->ee31bb40-6981-4b57-b8d7-3be03fa0c81d
s3g_1        | 2021-06-25 13:51:38,479 [qtp382627885-20] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-25 13:51:39,781 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:51:40,518 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:51:40,564 [qtp382627885-20] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>PreconditionFailed</Code>
s3g_1        |   <Message>At least one of the pre-conditions you specified did not hold</Message>
s3g_1        |   <Resource>bucket-04686/06248/copyrange/source</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:115)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-06-25 13:51:41,309 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:51:41,358 [qtp382627885-21] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>PreconditionFailed</Code>
s3g_1        |   <Message>At least one of the pre-conditions you specified did not hold</Message>
s3g_1        |   <Resource>bucket-04686/06248/copyrange/source</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:115)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-06-25 13:51:42,017 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:51:42,216 [qtp382627885-20] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-4C76172F50A3->d7f71981-d306-415b-992d-ee4808a385fa
s3g_1        | 2021-06-25 13:51:42,216 [qtp382627885-20] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-25 13:51:43,925 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:51:44,089 [qtp382627885-21] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-0C44236CBDEE->d7f71981-d306-415b-992d-ee4808a385fa
s3g_1        | 2021-06-25 13:51:44,091 [qtp382627885-21] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-25 13:51:45,013 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:51:45,689 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:51:46,676 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:51:47,398 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:51:48,180 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:51:55,809 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:51:55,816 [qtp382627885-21] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-30357, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2021-06-25 13:51:55,822 [qtp382627885-21] INFO endpoint.BucketEndpoint: Location is /bucket-30357
s3g_1        | 2021-06-25 13:51:56,447 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:51:56,460 [qtp382627885-21] INFO rpc.RpcClient: Creating Bucket: s3v/destbucket-17497, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2021-06-25 13:51:56,471 [qtp382627885-21] INFO endpoint.BucketEndpoint: Location is /destbucket-17497
s3g_1        | 2021-06-25 13:51:57,130 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:51:57,186 [qtp382627885-20] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-3F243D2C767E->d7f71981-d306-415b-992d-ee4808a385fa
s3g_1        | 2021-06-25 13:51:57,188 [qtp382627885-20] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-25 13:51:58,083 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:51:58,727 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:51:58,852 [qtp382627885-20] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-C463FA896950->d7f71981-d306-415b-992d-ee4808a385fa
s3g_1        | 2021-06-25 13:51:58,853 [qtp382627885-20] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-25 13:51:59,606 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:52:00,257 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:52:00,449 [qtp382627885-20] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-B4BECE935814->d7f71981-d306-415b-992d-ee4808a385fa
s3g_1        | 2021-06-25 13:52:00,451 [qtp382627885-20] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-25 13:52:01,702 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:52:02,335 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:52:02,350 [qtp382627885-20] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>NoSuchBucket</Code>
s3g_1        |   <Message>The specified bucket does not exist</Message>
s3g_1        |   <Resource>dfdfdfdfdfnonexistent</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:51)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-06-25 13:52:02,955 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:52:02,970 [qtp382627885-21] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>NoSuchBucket</Code>
s3g_1        |   <Message>The specified bucket does not exist</Message>
s3g_1        |   <Resource>dfdfdfdfdfnonexistent</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:51)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-06-25 13:52:03,617 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:52:04,271 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:52:04,291 [qtp382627885-21] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>NoSuchKey</Code>
s3g_1        |   <Message>The specified key does not exist</Message>
s3g_1        |   <Resource>nonnonexistentkey</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:70)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-06-25 13:52:12,064 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:52:12,076 [qtp382627885-21] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-17009, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2021-06-25 13:52:12,089 [qtp382627885-21] INFO endpoint.BucketEndpoint: Location is /bucket-17009
s3g_1        | 2021-06-25 13:52:12,776 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:52:12,854 [qtp382627885-20] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-57D79E2A4F37->d7f71981-d306-415b-992d-ee4808a385fa
s3g_1        | 2021-06-25 13:52:12,854 [qtp382627885-20] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-25 13:52:13,602 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:52:14,275 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:52:14,947 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:52:15,589 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:52:16,218 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:52:16,830 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:52:17,480 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:52:17,537 [qtp382627885-21] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-E9DC29877CE5->ee31bb40-6981-4b57-b8d7-3be03fa0c81d
s3g_1        | 2021-06-25 13:52:17,537 [qtp382627885-21] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-25 13:52:18,332 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:52:18,975 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:52:19,622 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:52:20,262 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:52:20,903 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:52:20,959 [qtp382627885-21] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-E05E9EF047CD->d7f71981-d306-415b-992d-ee4808a385fa
s3g_1        | 2021-06-25 13:52:20,960 [qtp382627885-21] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-25 13:52:21,702 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:52:22,362 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:52:23,030 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:52:23,660 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:52:24,301 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:52:24,309 [qtp382627885-20] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>NoSuchBucket</Code>
s3g_1        |   <Message>The specified bucket does not exist</Message>
s3g_1        |   <Resource>bucket-17009-nosuchbucket</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:51)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-06-25 13:52:30,831 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:52:30,858 [qtp382627885-21] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-96700, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2021-06-25 13:52:30,878 [qtp382627885-21] INFO endpoint.BucketEndpoint: Location is /bucket-96700
s3g_1        | 2021-06-25 13:52:31,527 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:52:31,582 [qtp382627885-21] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-A52D6329B305->ee31bb40-6981-4b57-b8d7-3be03fa0c81d
s3g_1        | 2021-06-25 13:52:31,582 [qtp382627885-21] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-25 13:52:32,332 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:52:32,368 [qtp382627885-20] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-7A474E924B89->d7f71981-d306-415b-992d-ee4808a385fa
s3g_1        | 2021-06-25 13:52:32,368 [qtp382627885-20] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-25 13:52:33,066 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:52:33,113 [qtp382627885-20] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-0F281DB0C940->ee31bb40-6981-4b57-b8d7-3be03fa0c81d
s3g_1        | 2021-06-25 13:52:33,113 [qtp382627885-20] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-25 13:52:33,827 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:52:34,469 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:52:35,175 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:52:42,526 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:52:42,534 [qtp382627885-20] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-96121, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2021-06-25 13:52:42,545 [qtp382627885-20] INFO endpoint.BucketEndpoint: Location is /bucket-96121
s3g_1        | 2021-06-25 13:52:43,202 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:52:43,282 [qtp382627885-21] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-531DE35A69BF->ee31bb40-6981-4b57-b8d7-3be03fa0c81d
s3g_1        | 2021-06-25 13:52:43,283 [qtp382627885-21] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-25 13:52:44,006 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:52:44,625 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:52:45,325 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:52:45,971 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:52:46,663 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:52:47,364 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:52:48,088 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:52:49,046 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:52:49,063 [qtp382627885-21] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>InvalidRange</Code>
s3g_1        |   <Message>The requested range is not satisfiable</Message>
s3g_1        |   <Resource>bytes=10000-10000</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:79)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-06-25 13:52:49,625 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:52:50,331 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:52:51,012 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:52:51,683 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:52:52,422 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:52:53,210 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:52:53,903 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:52:54,598 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:52:55,311 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:52:55,332 [qtp382627885-20] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>InvalidRange</Code>
s3g_1        |   <Message>The requested range is not satisfiable</Message>
s3g_1        |   <Resource>bytes=0-0</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:79)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-06-25 13:52:55,957 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:52:55,971 [qtp382627885-21] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>InvalidRange</Code>
s3g_1        |   <Message>The requested range is not satisfiable</Message>
s3g_1        |   <Resource>bytes=0-1</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:79)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-06-25 13:52:56,606 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:52:56,623 [qtp382627885-20] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>InvalidRange</Code>
s3g_1        |   <Message>The requested range is not satisfiable</Message>
s3g_1        |   <Resource>bytes=0-10000</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:79)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-06-25 13:53:04,358 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-25 13:53:04,375 [qtp382627885-21] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-15068, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2021-06-25 13:53:04,391 [qtp382627885-21] INFO endpoint.BucketEndpoint: Location is /bucket-15068
