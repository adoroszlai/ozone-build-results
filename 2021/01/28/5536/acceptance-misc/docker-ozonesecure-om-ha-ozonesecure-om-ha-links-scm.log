Attaching to ozonesecure-om-ha_kdc_1, ozonesecure-om-ha_datanode3_1, ozonesecure-om-ha_kms_1, ozonesecure-om-ha_datanode1_1, ozonesecure-om-ha_scm_1, ozonesecure-om-ha_s3g_1, ozonesecure-om-ha_datanode2_1, ozonesecure-om-ha_om1_1, ozonesecure-om-ha_om2_1, ozonesecure-om-ha_recon_1, ozonesecure-om-ha_om3_1
datanode1_1  | Sleeping for 5 seconds
datanode1_1  | Setting up kerberos!!
datanode1_1  | KDC ISSUER_SERVER => kdc:8081
datanode1_1  | Sleeping for 5 seconds
datanode1_1  | Got 200, KDC service ready!!
datanode1_1  | Download dn/d20fde691356@EXAMPLE.COM keytab file to /etc/security/keytabs/dn.keytab
datanode1_1  | --2021-01-28 02:31:43--  http://kdc:8081/keytab/d20fde691356/dn
datanode1_1  | Resolving kdc (kdc)... 172.25.0.100
datanode1_1  | Connecting to kdc (kdc)|172.25.0.100|:8081... connected.
datanode1_1  | HTTP request sent, awaiting response... 200 OK
datanode1_1  | Length: 158 [application/octet-stream]
datanode1_1  | Saving to: '/etc/security/keytabs/dn.keytab'
datanode1_1  | 
datanode1_1  |      0K                                                       100% 25.5M=0s
datanode1_1  | 
datanode1_1  | 2021-01-28 02:31:44 (25.5 MB/s) - '/etc/security/keytabs/dn.keytab' saved [158/158]
datanode1_1  | 
datanode1_1  | Keytab name: FILE:/etc/security/keytabs/dn.keytab
datanode1_1  | KVNO Timestamp         Principal
datanode1_1  | ---- ----------------- --------------------------------------------------------
datanode1_1  |    2 01/28/21 02:31:44 dn/d20fde691356@EXAMPLE.COM
datanode1_1  |    2 01/28/21 02:31:44 dn/d20fde691356@EXAMPLE.COM
datanode1_1  | Download HTTP/d20fde691356@EXAMPLE.COM keytab file to /etc/security/keytabs/HTTP.keytab
datanode1_1  | --2021-01-28 02:31:44--  http://kdc:8081/keytab/d20fde691356/HTTP
datanode1_1  | Resolving kdc (kdc)... 172.25.0.100
datanode1_1  | Connecting to kdc (kdc)|172.25.0.100|:8081... connected.
datanode1_1  | HTTP request sent, awaiting response... 200 OK
datanode1_1  | Length: 162 [application/octet-stream]
datanode1_1  | Saving to: '/etc/security/keytabs/HTTP.keytab'
datanode1_1  | 
datanode1_1  |      0K                                                       100% 4.68M=0s
datanode1_1  | 
datanode1_1  | 2021-01-28 02:31:44 (4.68 MB/s) - '/etc/security/keytabs/HTTP.keytab' saved [162/162]
datanode1_1  | 
datanode1_1  | Keytab name: FILE:/etc/security/keytabs/HTTP.keytab
datanode1_1  | KVNO Timestamp         Principal
datanode1_1  | ---- ----------------- --------------------------------------------------------
datanode1_1  |    2 01/28/21 02:31:44 HTTP/d20fde691356@EXAMPLE.COM
datanode1_1  |    2 01/28/21 02:31:44 HTTP/d20fde691356@EXAMPLE.COM
datanode1_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode1_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode1_1  | 2021-01-28 02:31:54,474 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode1_1  | /************************************************************
datanode1_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode1_1  | STARTUP_MSG:   host = d20fde691356/172.25.0.102
datanode1_1  | STARTUP_MSG:   args = []
datanode1_1  | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
datanode1_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/javax.activation-api-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.2.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-1.1.0-SNAPSHOT.jar
datanode1_1  | STARTUP_MSG:   build = https://github.com/apache/ozone/42171e669d6c7f302fa379fc0289c4341f1cbf75 ; compiled by 'runner' on 2021-01-28T01:42Z
datanode1_1  | STARTUP_MSG:   java = 11.0.7
datanode1_1  | ************************************************************/
datanode1_1  | 2021-01-28 02:31:54,573 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode1_1  | 2021-01-28 02:31:56,708 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode1_1  | 2021-01-28 02:31:57,426 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode1_1  | 2021-01-28 02:31:58,423 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode1_1  | 2021-01-28 02:31:58,424 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode1_1  | 2021-01-28 02:31:59,217 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:d20fde691356 ip:172.25.0.102
datanode1_1  | 2021-01-28 02:32:03,036 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/_HOST@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode1_1  | 2021-01-28 02:32:04,622 [main] INFO security.UserGroupInformation: Login successful for user dn/d20fde691356@EXAMPLE.COM using keytab file /etc/security/keytabs/dn.keytab
datanode1_1  | 2021-01-28 02:32:04,622 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
datanode1_1  | 2021-01-28 02:32:04,622 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
datanode1_1  | 2021-01-28 02:32:04,622 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode1_1  | 2021-01-28 02:32:04,622 [main] INFO client.DNCertificateClient: Certificate client init case: 0
datanode1_1  | 2021-01-28 02:32:04,625 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode1_1  | 2021-01-28 02:32:08,784 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
datanode1_1  | 2021-01-28 02:32:08,865 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.102,host:d20fde691356
datanode1_1  | 2021-01-28 02:32:08,879 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode1_1  | 2021-01-28 02:32:08,900 [main] INFO ozone.HddsDatanodeService: Creating csr for DN-> subject:root@d20fde691356
datanode1_1  | 2021-01-28 02:32:11,333 [main] INFO ipc.Client: Retrying connect to server: scm/172.25.0.116:9961. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-01-28 02:32:12,335 [main] INFO ipc.Client: Retrying connect to server: scm/172.25.0.116:9961. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-01-28 02:32:13,336 [main] INFO ipc.Client: Retrying connect to server: scm/172.25.0.116:9961. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-01-28 02:32:14,337 [main] INFO ipc.Client: Retrying connect to server: scm/172.25.0.116:9961. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-01-28 02:32:15,338 [main] INFO ipc.Client: Retrying connect to server: scm/172.25.0.116:9961. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-01-28 02:32:16,340 [main] INFO ipc.Client: Retrying connect to server: scm/172.25.0.116:9961. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-01-28 02:32:17,340 [main] INFO ipc.Client: Retrying connect to server: scm/172.25.0.116:9961. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-01-28 02:32:18,341 [main] INFO ipc.Client: Retrying connect to server: scm/172.25.0.116:9961. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-01-28 02:32:22,193 [main] INFO client.DNCertificateClient: Loading certificate from location:/data/metadata/dn/certs.
datanode1_1  | 2021-01-28 02:32:22,260 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/2411674243301.crt.
datanode1_1  | 2021-01-28 02:32:22,264 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/CA-1.crt.
datanode1_1  | 2021-01-28 02:32:22,282 [main] INFO ozone.HddsDatanodeService: Successfully stored SCM signed certificate, case:GETCERT.
datanode1_1  | 2021-01-28 02:32:23,162 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode1_1  | 2021-01-28 02:32:23,213 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode1_1  | 2021-01-28 02:32:23,223 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode1_1  | 2021-01-28 02:32:23,373 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode1_1  | 2021-01-28 02:32:23,589 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode1_1  | 2021-01-28 02:32:23,750 [Thread-7] INFO ozoneimpl.ContainerReader: Start to verify containers on volume /data/hdds/hdds
datanode1_1  | 2021-01-28 02:32:23,753 [Thread-7] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode1_1  | 2021-01-28 02:32:23,757 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode1_1  | 2021-01-28 02:32:28,774 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode1_1  | 2021-01-28 02:32:29,104 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode1_1  | 2021-01-28 02:32:30,040 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
datanode1_1  | 2021-01-28 02:32:30,071 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode1_1  | 2021-01-28 02:32:30,075 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
datanode1_1  | 2021-01-28 02:32:30,076 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode1_1  | 2021-01-28 02:32:30,076 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode1_1  | 2021-01-28 02:32:30,076 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode1_1  | 2021-01-28 02:32:30,080 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2021-01-28 02:32:30,085 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode1_1  | 2021-01-28 02:32:30,086 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode1_1  | 2021-01-28 02:32:31,503 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode1_1  | 2021-01-28 02:32:31,533 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode1_1  | 2021-01-28 02:32:31,535 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode1_1  | 2021-01-28 02:32:31,634 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode1_1  | 2021-01-28 02:32:31,641 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode1_1  | 2021-01-28 02:32:35,144 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode1_1  | 2021-01-28 02:32:35,144 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode1_1  | 2021-01-28 02:32:35,144 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.datanode.http.auth.type = kerberos
datanode1_1  | 2021-01-28 02:32:35,353 [main] INFO util.log: Logging initialized @50180ms to org.eclipse.jetty.util.log.Slf4jLog
datanode1_1  | 2021-01-28 02:32:35,984 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode1_1  | 2021-01-28 02:32:36,019 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode1_1  | 2021-01-28 02:32:36,021 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode1_1  | 2021-01-28 02:32:36,021 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode1_1  | 2021-01-28 02:32:36,028 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode1_1  | 2021-01-28 02:32:36,032 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.datanode.http.auth.kerberos.principal keytabKey: hdds.datanode.http.auth.kerberos.keytab
datanode1_1  | 2021-01-28 02:32:36,234 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode1_1  | 2021-01-28 02:32:36,244 [main] INFO server.Server: jetty-9.4.34.v20201102; built: 2020-11-02T14:15:39.302Z; git: e46af88704a893fc12cb0e3bf46e2c7b48a009e7; jvm 11.0.7+10-LTS
datanode1_1  | 2021-01-28 02:32:36,503 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode1_1  | 2021-01-28 02:32:36,503 [main] INFO server.session: No SessionScavenger set, using defaults
datanode1_1  | 2021-01-28 02:32:36,504 [main] INFO server.session: node0 Scavenging every 660000ms
datanode1_1  | 2021-01-28 02:32:36,584 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/d20fde691356@EXAMPLE.COM
datanode1_1  | 2021-01-28 02:32:36,612 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@270be080{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode1_1  | 2021-01-28 02:32:36,620 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@468646ea{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode1_1  | 2021-01-28 02:32:37,114 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/d20fde691356@EXAMPLE.COM
datanode1_1  | 2021-01-28 02:32:37,174 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@3b9a2629{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-1_1_0-SNAPSHOT_jar-_-any-16456804439704494612/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode1_1  | 2021-01-28 02:32:37,232 [main] INFO server.AbstractConnector: Started ServerConnector@65cc3902{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode1_1  | 2021-01-28 02:32:37,254 [main] INFO server.Server: Started @52059ms
datanode1_1  | 2021-01-28 02:32:37,275 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode1_1  | 2021-01-28 02:32:37,275 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode1_1  | 2021-01-28 02:32:37,280 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode1_1  | 2021-01-28 02:32:37,510 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@d093f9b] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode1_1  | 2021-01-28 02:32:38,020 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.25.0.115:9891
datanode1_1  | 2021-01-28 02:32:40,941 [EndpointStateMachine task thread for scm/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode1_1  | 2021-01-28 02:32:40,943 [EndpointStateMachine task thread for scm/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode1_1  | 2021-01-28 02:32:41,246 [EndpointStateMachine task thread for scm/172.25.0.116:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis bb31b8e2-b35d-4b3b-ae90-43363de8a349 at port 9858
datanode1_1  | 2021-01-28 02:32:41,390 [EndpointStateMachine task thread for scm/172.25.0.116:9861 - 0 ] INFO server.RaftServer: bb31b8e2-b35d-4b3b-ae90-43363de8a349: start RPC server
datanode1_1  | 2021-01-28 02:32:41,431 [EndpointStateMachine task thread for scm/172.25.0.116:9861 - 0 ] INFO server.GrpcService: bb31b8e2-b35d-4b3b-ae90-43363de8a349: GrpcService started, listening on 9858
datanode1_1  | 2021-01-28 02:32:41,451 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$301/0x000000084052e840@46b8c515] INFO util.JvmPauseMonitor: JvmPauseMonitor-bb31b8e2-b35d-4b3b-ae90-43363de8a349: Started
datanode1_1  | 2021-01-28 02:32:50,839 [grpc-default-executor-0] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server_message_metrics.bb31b8e2-b35d-4b3b-ae90-43363de8a349
datanode1_1  | 2021-01-28 02:32:51,163 [grpc-default-executor-0] INFO server.RaftServer: bb31b8e2-b35d-4b3b-ae90-43363de8a349: addNew group-A71B52063026:[feb6bea5-edd2-410b-8ad4-c920818f117a|rpc:172.25.0.104:9858|admin:|client:|dataStream:|priority:0, bb31b8e2-b35d-4b3b-ae90-43363de8a349|rpc:172.25.0.102:9858|admin:|client:|dataStream:|priority:1, 6bab7c5a-f782-4236-88e0-70f071e2bf9c|rpc:172.25.0.103:9858|admin:|client:|dataStream:|priority:0] returns group-A71B52063026:java.util.concurrent.CompletableFuture@3c848054[Not completed]
datanode1_1  | 2021-01-28 02:32:51,248 [pool-20-thread-1] INFO server.RaftServer$Division: bb31b8e2-b35d-4b3b-ae90-43363de8a349: new RaftServerImpl for group-A71B52063026:[feb6bea5-edd2-410b-8ad4-c920818f117a|rpc:172.25.0.104:9858|admin:|client:|dataStream:|priority:0, bb31b8e2-b35d-4b3b-ae90-43363de8a349|rpc:172.25.0.102:9858|admin:|client:|dataStream:|priority:1, 6bab7c5a-f782-4236-88e0-70f071e2bf9c|rpc:172.25.0.103:9858|admin:|client:|dataStream:|priority:0] with ContainerStateMachine:uninitialized
datanode1_1  | 2021-01-28 02:32:51,257 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode1_1  | 2021-01-28 02:32:51,257 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode1_1  | 2021-01-28 02:32:51,257 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode1_1  | 2021-01-28 02:32:51,257 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode1_1  | 2021-01-28 02:32:51,257 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode1_1  | 2021-01-28 02:32:51,257 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode1_1  | 2021-01-28 02:32:51,258 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode1_1  | 2021-01-28 02:32:51,277 [pool-20-thread-1] INFO server.RaftServer$Division: bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026: ConfigurationManager, init=-1: [feb6bea5-edd2-410b-8ad4-c920818f117a|rpc:172.25.0.104:9858|admin:|client:|dataStream:|priority:0, bb31b8e2-b35d-4b3b-ae90-43363de8a349|rpc:172.25.0.102:9858|admin:|client:|dataStream:|priority:1, 6bab7c5a-f782-4236-88e0-70f071e2bf9c|rpc:172.25.0.103:9858|admin:|client:|dataStream:|priority:0], old=null, confs=<EMPTY_MAP>
datanode1_1  | 2021-01-28 02:32:51,278 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode1_1  | 2021-01-28 02:32:51,309 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode1_1  | 2021-01-28 02:32:51,315 [pool-20-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/45d6c387-0d5e-4ec1-887d-a71b52063026 does not exist. Creating ...
datanode1_1  | 2021-01-28 02:32:51,329 [pool-20-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/45d6c387-0d5e-4ec1-887d-a71b52063026/in_use.lock acquired by nodename 7@d20fde691356
datanode1_1  | 2021-01-28 02:32:51,441 [pool-20-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/45d6c387-0d5e-4ec1-887d-a71b52063026 has been successfully formatted.
datanode1_1  | 2021-01-28 02:32:51,466 [pool-20-thread-1] INFO ratis.ContainerStateMachine: group-A71B52063026: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode1_1  | 2021-01-28 02:32:51,466 [pool-20-thread-1] ERROR storage.RaftStorage: Failed reading configuration from file:/data/metadata/ratis/45d6c387-0d5e-4ec1-887d-a71b52063026/current/raft-meta.conf
datanode1_1  | java.io.FileNotFoundException: /data/metadata/ratis/45d6c387-0d5e-4ec1-887d-a71b52063026/current/raft-meta.conf (No such file or directory)
datanode1_1  | 	at java.base/java.io.FileInputStream.open0(Native Method)
datanode1_1  | 	at java.base/java.io.FileInputStream.open(FileInputStream.java:219)
datanode1_1  | 	at java.base/java.io.FileInputStream.<init>(FileInputStream.java:157)
datanode1_1  | 	at org.apache.ratis.server.storage.RaftStorageImpl.readRaftConfiguration(RaftStorageImpl.java:143)
datanode1_1  | 	at org.apache.ratis.server.impl.ServerState.<init>(ServerState.java:122)
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerImpl.<init>(RaftServerImpl.java:193)
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.lambda$newRaftServerImpl$4(RaftServerProxy.java:266)
datanode1_1  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode1_1  | 2021-01-28 02:32:51,482 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode1_1  | 2021-01-28 02:32:51,491 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode1_1  | 2021-01-28 02:32:51,512 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode1_1  | 2021-01-28 02:32:51,512 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2021-01-28 02:32:51,558 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026
datanode1_1  | 2021-01-28 02:32:51,570 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2021-01-28 02:32:51,617 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode1_1  | 2021-01-28 02:32:51,628 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode1_1  | 2021-01-28 02:32:51,642 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: new bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/45d6c387-0d5e-4ec1-887d-a71b52063026
datanode1_1  | 2021-01-28 02:32:51,657 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode1_1  | 2021-01-28 02:32:51,659 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode1_1  | 2021-01-28 02:32:51,661 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2021-01-28 02:32:51,662 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode1_1  | 2021-01-28 02:32:51,671 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode1_1  | 2021-01-28 02:32:51,672 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode1_1  | 2021-01-28 02:32:51,674 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode1_1  | 2021-01-28 02:32:51,678 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode1_1  | 2021-01-28 02:32:51,736 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode1_1  | 2021-01-28 02:32:51,740 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode1_1  | 2021-01-28 02:32:51,793 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode1_1  | 2021-01-28 02:32:51,794 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode1_1  | 2021-01-28 02:32:51,808 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode1_1  | 2021-01-28 02:32:51,810 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode1_1  | 2021-01-28 02:32:51,820 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode1_1  | 2021-01-28 02:32:51,824 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode1_1  | 2021-01-28 02:32:51,833 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode1_1  | 2021-01-28 02:32:51,835 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode1_1  | 2021-01-28 02:32:51,919 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026
datanode1_1  | 2021-01-28 02:32:51,922 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026
datanode1_1  | 2021-01-28 02:32:51,935 [pool-20-thread-1] INFO server.RaftServer$Division: bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026: start as a follower, conf=-1: [feb6bea5-edd2-410b-8ad4-c920818f117a|rpc:172.25.0.104:9858|admin:|client:|dataStream:|priority:0, bb31b8e2-b35d-4b3b-ae90-43363de8a349|rpc:172.25.0.102:9858|admin:|client:|dataStream:|priority:1, 6bab7c5a-f782-4236-88e0-70f071e2bf9c|rpc:172.25.0.103:9858|admin:|client:|dataStream:|priority:0], old=null
datanode1_1  | 2021-01-28 02:32:51,948 [pool-20-thread-1] INFO server.RaftServer$Division: bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode1_1  | 2021-01-28 02:32:51,949 [pool-20-thread-1] INFO impl.RoleInfo: bb31b8e2-b35d-4b3b-ae90-43363de8a349: start bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026-FollowerState
datanode1_1  | 2021-01-28 02:32:51,996 [pool-20-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A71B52063026,id=bb31b8e2-b35d-4b3b-ae90-43363de8a349
datanode1_1  | 2021-01-28 02:32:51,999 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026
datanode1_1  | 2021-01-28 02:32:52,546 [grpc-default-executor-0] INFO server.RaftServer: bb31b8e2-b35d-4b3b-ae90-43363de8a349: addNew group-8E19C9AA218C:[feb6bea5-edd2-410b-8ad4-c920818f117a|rpc:172.25.0.104:9858|admin:|client:|dataStream:|priority:1, bb31b8e2-b35d-4b3b-ae90-43363de8a349|rpc:172.25.0.102:9858|admin:|client:|dataStream:|priority:0, 6bab7c5a-f782-4236-88e0-70f071e2bf9c|rpc:172.25.0.103:9858|admin:|client:|dataStream:|priority:0] returns group-8E19C9AA218C:java.util.concurrent.CompletableFuture@3e600ff3[Not completed]
datanode1_1  | 2021-01-28 02:32:52,548 [pool-20-thread-1] INFO server.RaftServer$Division: bb31b8e2-b35d-4b3b-ae90-43363de8a349: new RaftServerImpl for group-8E19C9AA218C:[feb6bea5-edd2-410b-8ad4-c920818f117a|rpc:172.25.0.104:9858|admin:|client:|dataStream:|priority:1, bb31b8e2-b35d-4b3b-ae90-43363de8a349|rpc:172.25.0.102:9858|admin:|client:|dataStream:|priority:0, 6bab7c5a-f782-4236-88e0-70f071e2bf9c|rpc:172.25.0.103:9858|admin:|client:|dataStream:|priority:0] with ContainerStateMachine:uninitialized
datanode1_1  | 2021-01-28 02:32:52,548 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode1_1  | 2021-01-28 02:32:52,548 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode1_1  | 2021-01-28 02:32:52,548 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode1_1  | 2021-01-28 02:32:52,548 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode1_1  | 2021-01-28 02:32:52,548 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode1_1  | 2021-01-28 02:32:52,548 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode1_1  | 2021-01-28 02:32:52,548 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode1_1  | 2021-01-28 02:32:52,548 [pool-20-thread-1] INFO server.RaftServer$Division: bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-8E19C9AA218C: ConfigurationManager, init=-1: [feb6bea5-edd2-410b-8ad4-c920818f117a|rpc:172.25.0.104:9858|admin:|client:|dataStream:|priority:1, bb31b8e2-b35d-4b3b-ae90-43363de8a349|rpc:172.25.0.102:9858|admin:|client:|dataStream:|priority:0, 6bab7c5a-f782-4236-88e0-70f071e2bf9c|rpc:172.25.0.103:9858|admin:|client:|dataStream:|priority:0], old=null, confs=<EMPTY_MAP>
datanode1_1  | 2021-01-28 02:32:52,549 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode1_1  | 2021-01-28 02:32:52,549 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode1_1  | 2021-01-28 02:32:52,549 [pool-20-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/4954273f-2502-40bd-89f2-8e19c9aa218c does not exist. Creating ...
datanode1_1  | 2021-01-28 02:32:52,550 [pool-20-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/4954273f-2502-40bd-89f2-8e19c9aa218c/in_use.lock acquired by nodename 7@d20fde691356
datanode1_1  | 2021-01-28 02:32:52,555 [pool-20-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/4954273f-2502-40bd-89f2-8e19c9aa218c has been successfully formatted.
datanode1_1  | 2021-01-28 02:32:52,556 [pool-20-thread-1] INFO ratis.ContainerStateMachine: group-8E19C9AA218C: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode1_1  | 2021-01-28 02:32:52,556 [pool-20-thread-1] ERROR storage.RaftStorage: Failed reading configuration from file:/data/metadata/ratis/4954273f-2502-40bd-89f2-8e19c9aa218c/current/raft-meta.conf
datanode1_1  | java.io.FileNotFoundException: /data/metadata/ratis/4954273f-2502-40bd-89f2-8e19c9aa218c/current/raft-meta.conf (No such file or directory)
datanode1_1  | 	at java.base/java.io.FileInputStream.open0(Native Method)
datanode1_1  | 	at java.base/java.io.FileInputStream.open(FileInputStream.java:219)
datanode1_1  | 	at java.base/java.io.FileInputStream.<init>(FileInputStream.java:157)
datanode1_1  | 	at org.apache.ratis.server.storage.RaftStorageImpl.readRaftConfiguration(RaftStorageImpl.java:143)
datanode1_1  | 	at org.apache.ratis.server.impl.ServerState.<init>(ServerState.java:122)
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerImpl.<init>(RaftServerImpl.java:193)
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.lambda$newRaftServerImpl$4(RaftServerProxy.java:266)
datanode1_1  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode1_1  | 2021-01-28 02:32:52,569 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode1_1  | 2021-01-28 02:32:52,569 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode1_1  | 2021-01-28 02:32:52,569 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode1_1  | 2021-01-28 02:32:52,569 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | Sleeping for 5 seconds
datanode2_1  | Setting up kerberos!!
datanode2_1  | KDC ISSUER_SERVER => kdc:8081
datanode2_1  | Sleeping for 5 seconds
datanode2_1  | Got 200, KDC service ready!!
datanode2_1  | Download dn/db0158eeb642@EXAMPLE.COM keytab file to /etc/security/keytabs/dn.keytab
datanode2_1  | --2021-01-28 02:31:42--  http://kdc:8081/keytab/db0158eeb642/dn
datanode2_1  | Resolving kdc (kdc)... 172.25.0.100
datanode2_1  | Connecting to kdc (kdc)|172.25.0.100|:8081... connected.
datanode2_1  | HTTP request sent, awaiting response... 200 OK
datanode2_1  | Length: 158 [application/octet-stream]
datanode2_1  | Saving to: '/etc/security/keytabs/dn.keytab'
datanode2_1  | 
datanode2_1  |      0K                                                       100% 27.9M=0s
datanode2_1  | 
datanode2_1  | 2021-01-28 02:31:42 (27.9 MB/s) - '/etc/security/keytabs/dn.keytab' saved [158/158]
datanode2_1  | 
datanode2_1  | Keytab name: FILE:/etc/security/keytabs/dn.keytab
datanode2_1  | KVNO Timestamp         Principal
datanode2_1  | ---- ----------------- --------------------------------------------------------
datanode2_1  |    2 01/28/21 02:31:42 dn/db0158eeb642@EXAMPLE.COM
datanode2_1  |    2 01/28/21 02:31:42 dn/db0158eeb642@EXAMPLE.COM
datanode2_1  | Download HTTP/db0158eeb642@EXAMPLE.COM keytab file to /etc/security/keytabs/HTTP.keytab
datanode2_1  | --2021-01-28 02:31:42--  http://kdc:8081/keytab/db0158eeb642/HTTP
datanode2_1  | Resolving kdc (kdc)... 172.25.0.100
datanode2_1  | Connecting to kdc (kdc)|172.25.0.100|:8081... connected.
datanode2_1  | HTTP request sent, awaiting response... 200 OK
datanode2_1  | Length: 162 [application/octet-stream]
datanode2_1  | Saving to: '/etc/security/keytabs/HTTP.keytab'
datanode2_1  | 
datanode2_1  |      0K                                                       100% 27.6M=0s
datanode2_1  | 
datanode2_1  | 2021-01-28 02:31:43 (27.6 MB/s) - '/etc/security/keytabs/HTTP.keytab' saved [162/162]
datanode2_1  | 
datanode2_1  | Keytab name: FILE:/etc/security/keytabs/HTTP.keytab
datanode2_1  | KVNO Timestamp         Principal
datanode2_1  | ---- ----------------- --------------------------------------------------------
datanode2_1  |    2 01/28/21 02:31:43 HTTP/db0158eeb642@EXAMPLE.COM
datanode2_1  |    2 01/28/21 02:31:43 HTTP/db0158eeb642@EXAMPLE.COM
datanode2_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode2_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode2_1  | 2021-01-28 02:31:52,381 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode2_1  | /************************************************************
datanode2_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode2_1  | STARTUP_MSG:   host = db0158eeb642/172.25.0.103
datanode2_1  | STARTUP_MSG:   args = []
datanode2_1  | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
datanode1_1  | 2021-01-28 02:32:52,569 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-8E19C9AA218C
datanode1_1  | 2021-01-28 02:32:52,569 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2021-01-28 02:32:52,569 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode1_1  | 2021-01-28 02:32:52,569 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode1_1  | 2021-01-28 02:32:52,569 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: new bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-8E19C9AA218C-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/4954273f-2502-40bd-89f2-8e19c9aa218c
datanode1_1  | 2021-01-28 02:32:52,569 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode1_1  | 2021-01-28 02:32:52,569 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode1_1  | 2021-01-28 02:32:52,569 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2021-01-28 02:32:52,570 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode1_1  | 2021-01-28 02:32:52,570 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode1_1  | 2021-01-28 02:32:52,570 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode1_1  | 2021-01-28 02:32:52,570 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode1_1  | 2021-01-28 02:32:52,570 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode1_1  | 2021-01-28 02:32:52,570 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode1_1  | 2021-01-28 02:32:52,571 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode1_1  | 2021-01-28 02:32:52,571 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-8E19C9AA218C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode1_1  | 2021-01-28 02:32:52,571 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-8E19C9AA218C-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode1_1  | 2021-01-28 02:32:52,573 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode1_1  | 2021-01-28 02:32:52,573 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode1_1  | 2021-01-28 02:32:52,573 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode1_1  | 2021-01-28 02:32:52,573 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode1_1  | 2021-01-28 02:32:52,573 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode1_1  | 2021-01-28 02:32:52,573 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode1_1  | 2021-01-28 02:32:52,573 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-8E19C9AA218C
datanode1_1  | 2021-01-28 02:32:52,574 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-8E19C9AA218C
datanode1_1  | 2021-01-28 02:32:52,581 [pool-20-thread-1] INFO server.RaftServer$Division: bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-8E19C9AA218C: start as a follower, conf=-1: [feb6bea5-edd2-410b-8ad4-c920818f117a|rpc:172.25.0.104:9858|admin:|client:|dataStream:|priority:1, bb31b8e2-b35d-4b3b-ae90-43363de8a349|rpc:172.25.0.102:9858|admin:|client:|dataStream:|priority:0, 6bab7c5a-f782-4236-88e0-70f071e2bf9c|rpc:172.25.0.103:9858|admin:|client:|dataStream:|priority:0], old=null
datanode1_1  | 2021-01-28 02:32:52,581 [pool-20-thread-1] INFO server.RaftServer$Division: bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-8E19C9AA218C: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode1_1  | 2021-01-28 02:32:52,581 [pool-20-thread-1] INFO impl.RoleInfo: bb31b8e2-b35d-4b3b-ae90-43363de8a349: start bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-8E19C9AA218C-FollowerState
datanode1_1  | 2021-01-28 02:32:52,583 [pool-20-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-8E19C9AA218C,id=bb31b8e2-b35d-4b3b-ae90-43363de8a349
datanode1_1  | 2021-01-28 02:32:52,583 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-8E19C9AA218C
datanode1_1  | 2021-01-28 02:32:52,627 [grpc-default-executor-0] INFO server.RaftServer$Division: bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026: receive requestVote(PRE_VOTE, feb6bea5-edd2-410b-8ad4-c920818f117a, group-A71B52063026, 0, (t:0, i:0))
datanode1_1  | 2021-01-28 02:32:52,630 [grpc-default-executor-0] INFO impl.VoteContext: bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026-FOLLOWER: reject PRE_VOTE from feb6bea5-edd2-410b-8ad4-c920818f117a: our priority 1 > candidate's priority 0
datanode1_1  | 2021-01-28 02:32:52,684 [grpc-default-executor-0] INFO server.RaftServer$Division: bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026 replies to PRE_VOTE vote request: feb6bea5-edd2-410b-8ad4-c920818f117a<-bb31b8e2-b35d-4b3b-ae90-43363de8a349#0:FAIL-t0. Peer's state: bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026:t0, leader=null, voted=, raftlog=bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [feb6bea5-edd2-410b-8ad4-c920818f117a|rpc:172.25.0.104:9858|admin:|client:|dataStream:|priority:0, bb31b8e2-b35d-4b3b-ae90-43363de8a349|rpc:172.25.0.102:9858|admin:|client:|dataStream:|priority:1, 6bab7c5a-f782-4236-88e0-70f071e2bf9c|rpc:172.25.0.103:9858|admin:|client:|dataStream:|priority:0], old=null
datanode1_1  | 2021-01-28 02:32:57,039 [Thread-25] INFO impl.FollowerState: bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5089904727ns, electionTimeout:5043ms
datanode1_1  | 2021-01-28 02:32:57,039 [Thread-25] INFO impl.RoleInfo: bb31b8e2-b35d-4b3b-ae90-43363de8a349: shutdown bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026-FollowerState
datanode1_1  | 2021-01-28 02:32:57,040 [Thread-25] INFO server.RaftServer$Division: bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode1_1  | 2021-01-28 02:32:57,042 [Thread-25] INFO impl.RoleInfo: bb31b8e2-b35d-4b3b-ae90-43363de8a349: start bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026-LeaderElection1
datanode1_1  | 2021-01-28 02:32:57,049 [bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026-LeaderElection1] INFO impl.LeaderElection: bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026-LeaderElection1 PRE_VOTE round 0: submit vote requests at term 0 for -1: [feb6bea5-edd2-410b-8ad4-c920818f117a|rpc:172.25.0.104:9858|admin:|client:|dataStream:|priority:0, bb31b8e2-b35d-4b3b-ae90-43363de8a349|rpc:172.25.0.102:9858|admin:|client:|dataStream:|priority:1, 6bab7c5a-f782-4236-88e0-70f071e2bf9c|rpc:172.25.0.103:9858|admin:|client:|dataStream:|priority:0], old=null
datanode2_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/javax.activation-api-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.2.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-1.1.0-SNAPSHOT.jar
datanode2_1  | STARTUP_MSG:   build = https://github.com/apache/ozone/42171e669d6c7f302fa379fc0289c4341f1cbf75 ; compiled by 'runner' on 2021-01-28T01:42Z
datanode2_1  | STARTUP_MSG:   java = 11.0.7
datanode2_1  | ************************************************************/
datanode2_1  | 2021-01-28 02:31:52,451 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode2_1  | 2021-01-28 02:31:54,464 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode2_1  | 2021-01-28 02:31:55,289 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode2_1  | 2021-01-28 02:31:56,360 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode2_1  | 2021-01-28 02:31:56,360 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode2_1  | 2021-01-28 02:31:57,272 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:db0158eeb642 ip:172.25.0.103
datanode2_1  | 2021-01-28 02:32:01,107 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/_HOST@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode2_1  | 2021-01-28 02:32:02,322 [main] INFO security.UserGroupInformation: Login successful for user dn/db0158eeb642@EXAMPLE.COM using keytab file /etc/security/keytabs/dn.keytab
datanode2_1  | 2021-01-28 02:32:02,339 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
datanode2_1  | 2021-01-28 02:32:02,347 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
datanode2_1  | 2021-01-28 02:32:02,354 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode2_1  | 2021-01-28 02:32:02,355 [main] INFO client.DNCertificateClient: Certificate client init case: 0
datanode2_1  | 2021-01-28 02:32:02,358 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode2_1  | 2021-01-28 02:32:07,821 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
datanode2_1  | 2021-01-28 02:32:07,928 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.103,host:db0158eeb642
datanode2_1  | 2021-01-28 02:32:07,938 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode2_1  | 2021-01-28 02:32:07,944 [main] INFO ozone.HddsDatanodeService: Creating csr for DN-> subject:root@db0158eeb642
datanode2_1  | 2021-01-28 02:32:10,725 [main] INFO ipc.Client: Retrying connect to server: scm/172.25.0.116:9961. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-01-28 02:32:11,726 [main] INFO ipc.Client: Retrying connect to server: scm/172.25.0.116:9961. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-01-28 02:32:12,727 [main] INFO ipc.Client: Retrying connect to server: scm/172.25.0.116:9961. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-01-28 02:32:13,728 [main] INFO ipc.Client: Retrying connect to server: scm/172.25.0.116:9961. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-01-28 02:32:14,729 [main] INFO ipc.Client: Retrying connect to server: scm/172.25.0.116:9961. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-01-28 02:32:15,730 [main] INFO ipc.Client: Retrying connect to server: scm/172.25.0.116:9961. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-01-28 02:32:16,731 [main] INFO ipc.Client: Retrying connect to server: scm/172.25.0.116:9961. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-01-28 02:32:17,731 [main] INFO ipc.Client: Retrying connect to server: scm/172.25.0.116:9961. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-01-28 02:32:18,734 [main] INFO ipc.Client: Retrying connect to server: scm/172.25.0.116:9961. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-01-28 02:32:22,353 [main] INFO client.DNCertificateClient: Loading certificate from location:/data/metadata/dn/certs.
datanode2_1  | 2021-01-28 02:32:22,377 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/2411778267491.crt.
datanode2_1  | 2021-01-28 02:32:22,385 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/CA-1.crt.
datanode2_1  | 2021-01-28 02:32:22,393 [main] INFO ozone.HddsDatanodeService: Successfully stored SCM signed certificate, case:GETCERT.
datanode2_1  | 2021-01-28 02:32:23,338 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode2_1  | 2021-01-28 02:32:23,361 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode1_1  | 2021-01-28 02:32:57,488 [grpc-default-executor-0] INFO server.RaftServer$Division: bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-8E19C9AA218C: receive requestVote(PRE_VOTE, feb6bea5-edd2-410b-8ad4-c920818f117a, group-8E19C9AA218C, 0, (t:0, i:0))
datanode1_1  | 2021-01-28 02:32:57,488 [grpc-default-executor-0] INFO impl.VoteContext: bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-8E19C9AA218C-FOLLOWER: accept PRE_VOTE from feb6bea5-edd2-410b-8ad4-c920818f117a: our priority 0 <= candidate's priority 1
datanode1_1  | 2021-01-28 02:32:57,490 [grpc-default-executor-0] INFO server.RaftServer$Division: bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-8E19C9AA218C replies to PRE_VOTE vote request: feb6bea5-edd2-410b-8ad4-c920818f117a<-bb31b8e2-b35d-4b3b-ae90-43363de8a349#0:OK-t0. Peer's state: bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-8E19C9AA218C:t0, leader=null, voted=, raftlog=bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-8E19C9AA218C-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [feb6bea5-edd2-410b-8ad4-c920818f117a|rpc:172.25.0.104:9858|admin:|client:|dataStream:|priority:1, bb31b8e2-b35d-4b3b-ae90-43363de8a349|rpc:172.25.0.102:9858|admin:|client:|dataStream:|priority:0, 6bab7c5a-f782-4236-88e0-70f071e2bf9c|rpc:172.25.0.103:9858|admin:|client:|dataStream:|priority:0], old=null
datanode1_1  | 2021-01-28 02:32:57,619 [bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026-LeaderElection1] INFO impl.LeaderElection: bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026-LeaderElection1: PRE_VOTE PASSED received 1 response(s) and 0 exception(s):
datanode1_1  | 2021-01-28 02:32:57,624 [bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026-LeaderElection1] INFO impl.LeaderElection:   Response 0: bb31b8e2-b35d-4b3b-ae90-43363de8a349<-6bab7c5a-f782-4236-88e0-70f071e2bf9c#0:OK-t0
datanode1_1  | 2021-01-28 02:32:57,625 [bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026-LeaderElection1] INFO impl.LeaderElection: bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026-LeaderElection1 PRE_VOTE round 0: result PASSED
datanode1_1  | 2021-01-28 02:32:57,630 [bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026-LeaderElection1] INFO impl.LeaderElection: bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [feb6bea5-edd2-410b-8ad4-c920818f117a|rpc:172.25.0.104:9858|admin:|client:|dataStream:|priority:0, bb31b8e2-b35d-4b3b-ae90-43363de8a349|rpc:172.25.0.102:9858|admin:|client:|dataStream:|priority:1, 6bab7c5a-f782-4236-88e0-70f071e2bf9c|rpc:172.25.0.103:9858|admin:|client:|dataStream:|priority:0], old=null
datanode1_1  | 2021-01-28 02:32:57,661 [grpc-default-executor-0] INFO server.RaftServer$Division: bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-8E19C9AA218C: receive requestVote(ELECTION, feb6bea5-edd2-410b-8ad4-c920818f117a, group-8E19C9AA218C, 1, (t:0, i:0))
datanode1_1  | 2021-01-28 02:32:57,662 [grpc-default-executor-0] INFO impl.VoteContext: bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-8E19C9AA218C-FOLLOWER: accept ELECTION from feb6bea5-edd2-410b-8ad4-c920818f117a: our priority 0 <= candidate's priority 1
datanode1_1  | 2021-01-28 02:32:57,663 [grpc-default-executor-0] INFO server.RaftServer$Division: bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-8E19C9AA218C: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:feb6bea5-edd2-410b-8ad4-c920818f117a
datanode1_1  | 2021-01-28 02:32:57,663 [grpc-default-executor-0] INFO impl.RoleInfo: bb31b8e2-b35d-4b3b-ae90-43363de8a349: shutdown bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-8E19C9AA218C-FollowerState
datanode1_1  | 2021-01-28 02:32:57,663 [grpc-default-executor-0] INFO impl.RoleInfo: bb31b8e2-b35d-4b3b-ae90-43363de8a349: start bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-8E19C9AA218C-FollowerState
datanode1_1  | 2021-01-28 02:32:57,663 [Thread-28] INFO impl.FollowerState: bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-8E19C9AA218C-FollowerState was interrupted: {}
datanode1_1  | java.lang.InterruptedException: sleep interrupted
datanode1_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode1_1  | 	at java.base/java.lang.Thread.sleep(Thread.java:339)
datanode1_1  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode1_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
datanode1_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode1_1  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:117)
datanode1_1  | 2021-01-28 02:32:57,666 [grpc-default-executor-0] INFO server.RaftServer$Division: bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-8E19C9AA218C replies to ELECTION vote request: feb6bea5-edd2-410b-8ad4-c920818f117a<-bb31b8e2-b35d-4b3b-ae90-43363de8a349#0:OK-t1. Peer's state: bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-8E19C9AA218C:t1, leader=null, voted=feb6bea5-edd2-410b-8ad4-c920818f117a, raftlog=bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-8E19C9AA218C-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [feb6bea5-edd2-410b-8ad4-c920818f117a|rpc:172.25.0.104:9858|admin:|client:|dataStream:|priority:1, bb31b8e2-b35d-4b3b-ae90-43363de8a349|rpc:172.25.0.102:9858|admin:|client:|dataStream:|priority:0, 6bab7c5a-f782-4236-88e0-70f071e2bf9c|rpc:172.25.0.103:9858|admin:|client:|dataStream:|priority:0], old=null
datanode1_1  | 2021-01-28 02:32:57,698 [bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026-LeaderElection1] INFO impl.LeaderElection: bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026-LeaderElection1: ELECTION PASSED received 1 response(s) and 0 exception(s):
datanode1_1  | 2021-01-28 02:32:57,700 [bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026-LeaderElection1] INFO impl.LeaderElection:   Response 0: bb31b8e2-b35d-4b3b-ae90-43363de8a349<-6bab7c5a-f782-4236-88e0-70f071e2bf9c#0:OK-t1
datanode1_1  | 2021-01-28 02:32:57,700 [bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026-LeaderElection1] INFO impl.LeaderElection: bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026-LeaderElection1 ELECTION round 0: result PASSED
datanode1_1  | 2021-01-28 02:32:57,700 [bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026-LeaderElection1] INFO impl.RoleInfo: bb31b8e2-b35d-4b3b-ae90-43363de8a349: shutdown bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026-LeaderElection1
datanode1_1  | 2021-01-28 02:32:57,701 [bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026-LeaderElection1] INFO server.RaftServer$Division: bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode1_1  | 2021-01-28 02:32:57,701 [bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-A71B52063026 with new leaderId: bb31b8e2-b35d-4b3b-ae90-43363de8a349
datanode1_1  | 2021-01-28 02:32:57,702 [bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026-LeaderElection1] INFO server.RaftServer$Division: bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026: change Leader from null to bb31b8e2-b35d-4b3b-ae90-43363de8a349 at term 1 for becomeLeader, leader elected after 6219ms
datanode1_1  | 2021-01-28 02:32:57,848 [bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode1_1  | 2021-01-28 02:32:57,869 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-8E19C9AA218C with new leaderId: feb6bea5-edd2-410b-8ad4-c920818f117a
datanode1_1  | 2021-01-28 02:32:57,879 [grpc-default-executor-0] INFO server.RaftServer$Division: bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-8E19C9AA218C: change Leader from null to feb6bea5-edd2-410b-8ad4-c920818f117a at term 1 for appendEntries, leader elected after 5300ms
datanode1_1  | 2021-01-28 02:32:57,903 [bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026
datanode1_1  | 2021-01-28 02:32:57,916 [bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode1_1  | 2021-01-28 02:32:57,929 [bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode1_1  | 2021-01-28 02:32:58,050 [grpc-default-executor-0] INFO server.RaftServer$Division: bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-8E19C9AA218C: set configuration 0: [feb6bea5-edd2-410b-8ad4-c920818f117a|rpc:172.25.0.104:9858|admin:|client:|dataStream:|priority:1, bb31b8e2-b35d-4b3b-ae90-43363de8a349|rpc:172.25.0.102:9858|admin:|client:|dataStream:|priority:0, 6bab7c5a-f782-4236-88e0-70f071e2bf9c|rpc:172.25.0.103:9858|admin:|client:|dataStream:|priority:0], old=null
datanode1_1  | 2021-01-28 02:32:58,061 [bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode1_1  | 2021-01-28 02:32:58,067 [bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode1_1  | 2021-01-28 02:32:58,072 [bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode1_1  | 2021-01-28 02:32:58,077 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-8E19C9AA218C-SegmentedRaftLogWorker: Starting segment from index:0
datanode1_1  | 2021-01-28 02:32:58,247 [bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode1_1  | 2021-01-28 02:32:58,248 [bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2021-01-28 02:32:58,248 [bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode1_1  | 2021-01-28 02:32:58,270 [bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026-LeaderElection1] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode1_1  | 2021-01-28 02:32:58,274 [bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode1_1  | 2021-01-28 02:32:58,274 [bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode1_1  | 2021-01-28 02:32:58,287 [bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis_grpc.log_appender.bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026
datanode1_1  | 2021-01-28 02:32:58,316 [bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode1_1  | 2021-01-28 02:32:58,317 [bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2021-01-28 02:32:58,317 [bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode1_1  | 2021-01-28 02:32:58,318 [bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026-LeaderElection1] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode1_1  | 2021-01-28 02:32:58,318 [bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode1_1  | 2021-01-28 02:32:58,318 [bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode1_1  | 2021-01-28 02:32:58,332 [bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026-LeaderElection1] INFO impl.RoleInfo: bb31b8e2-b35d-4b3b-ae90-43363de8a349: start bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026-LeaderStateImpl
datanode1_1  | 2021-01-28 02:32:58,365 [bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026-SegmentedRaftLogWorker: Starting segment from index:0
datanode1_1  | 2021-01-28 02:32:58,404 [bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026-LeaderElection1] INFO server.RaftServer$Division: bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026: set configuration 0: [feb6bea5-edd2-410b-8ad4-c920818f117a|rpc:172.25.0.104:9858|admin:|client:|dataStream:|priority:0, bb31b8e2-b35d-4b3b-ae90-43363de8a349|rpc:172.25.0.102:9858|admin:|client:|dataStream:|priority:1, 6bab7c5a-f782-4236-88e0-70f071e2bf9c|rpc:172.25.0.103:9858|admin:|client:|dataStream:|priority:0], old=null
datanode1_1  | 2021-01-28 02:32:58,717 [bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-A71B52063026-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/45d6c387-0d5e-4ec1-887d-a71b52063026/current/log_inprogress_0
datanode1_1  | 2021-01-28 02:32:58,744 [bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-8E19C9AA218C-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-8E19C9AA218C-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/4954273f-2502-40bd-89f2-8e19c9aa218c/current/log_inprogress_0
datanode1_1  | 2021-01-28 02:33:14,520 [Command processor thread] INFO server.RaftServer: bb31b8e2-b35d-4b3b-ae90-43363de8a349: addNew group-1F92667E218D:[bb31b8e2-b35d-4b3b-ae90-43363de8a349|rpc:172.25.0.102:9858|priority:1] returns group-1F92667E218D:java.util.concurrent.CompletableFuture@24a8abbf[Not completed]
datanode1_1  | 2021-01-28 02:33:14,521 [pool-20-thread-1] INFO server.RaftServer$Division: bb31b8e2-b35d-4b3b-ae90-43363de8a349: new RaftServerImpl for group-1F92667E218D:[bb31b8e2-b35d-4b3b-ae90-43363de8a349|rpc:172.25.0.102:9858|priority:1] with ContainerStateMachine:uninitialized
datanode1_1  | 2021-01-28 02:33:14,521 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode1_1  | 2021-01-28 02:33:14,521 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode1_1  | 2021-01-28 02:33:14,521 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode1_1  | 2021-01-28 02:33:14,521 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode1_1  | 2021-01-28 02:33:14,521 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode1_1  | 2021-01-28 02:33:14,521 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode1_1  | 2021-01-28 02:33:14,521 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode1_1  | 2021-01-28 02:33:14,521 [pool-20-thread-1] INFO server.RaftServer$Division: bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-1F92667E218D: ConfigurationManager, init=-1: [bb31b8e2-b35d-4b3b-ae90-43363de8a349|rpc:172.25.0.102:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode1_1  | 2021-01-28 02:33:14,522 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode1_1  | 2021-01-28 02:33:14,522 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode1_1  | 2021-01-28 02:33:14,522 [pool-20-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/f85be9de-7cd2-4361-be7a-1f92667e218d does not exist. Creating ...
datanode1_1  | 2021-01-28 02:33:14,526 [pool-20-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/f85be9de-7cd2-4361-be7a-1f92667e218d/in_use.lock acquired by nodename 7@d20fde691356
datanode1_1  | 2021-01-28 02:33:14,528 [pool-20-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/f85be9de-7cd2-4361-be7a-1f92667e218d has been successfully formatted.
datanode1_1  | 2021-01-28 02:33:14,528 [pool-20-thread-1] INFO ratis.ContainerStateMachine: group-1F92667E218D: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode1_1  | 2021-01-28 02:33:14,528 [pool-20-thread-1] ERROR storage.RaftStorage: Failed reading configuration from file:/data/metadata/ratis/f85be9de-7cd2-4361-be7a-1f92667e218d/current/raft-meta.conf
datanode1_1  | java.io.FileNotFoundException: /data/metadata/ratis/f85be9de-7cd2-4361-be7a-1f92667e218d/current/raft-meta.conf (No such file or directory)
datanode1_1  | 	at java.base/java.io.FileInputStream.open0(Native Method)
datanode1_1  | 	at java.base/java.io.FileInputStream.open(FileInputStream.java:219)
datanode1_1  | 	at java.base/java.io.FileInputStream.<init>(FileInputStream.java:157)
datanode1_1  | 	at org.apache.ratis.server.storage.RaftStorageImpl.readRaftConfiguration(RaftStorageImpl.java:143)
datanode1_1  | 	at org.apache.ratis.server.impl.ServerState.<init>(ServerState.java:122)
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerImpl.<init>(RaftServerImpl.java:193)
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.lambda$newRaftServerImpl$4(RaftServerProxy.java:266)
datanode1_1  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode1_1  | 2021-01-28 02:33:14,529 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode1_1  | 2021-01-28 02:33:14,529 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode1_1  | 2021-01-28 02:33:14,529 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode1_1  | 2021-01-28 02:33:14,529 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2021-01-28 02:33:14,529 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-1F92667E218D
datanode1_1  | 2021-01-28 02:33:14,529 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2021-01-28 02:33:14,529 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode1_1  | 2021-01-28 02:33:14,555 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode1_1  | 2021-01-28 02:33:14,556 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: new bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-1F92667E218D-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/f85be9de-7cd2-4361-be7a-1f92667e218d
datanode1_1  | 2021-01-28 02:33:14,559 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode1_1  | 2021-01-28 02:33:14,559 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode1_1  | 2021-01-28 02:33:14,559 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2021-01-28 02:33:14,560 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode1_1  | 2021-01-28 02:33:14,560 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode1_1  | 2021-01-28 02:33:14,560 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode1_1  | 2021-01-28 02:33:14,567 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode1_1  | 2021-01-28 02:33:14,567 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode1_1  | 2021-01-28 02:33:14,577 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode1_1  | 2021-01-28 02:33:14,578 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode1_1  | 2021-01-28 02:33:14,608 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-1F92667E218D-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode1_1  | 2021-01-28 02:33:14,608 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-1F92667E218D-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode1_1  | 2021-01-28 02:33:14,609 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode1_1  | 2021-01-28 02:33:14,609 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode1_1  | 2021-01-28 02:33:14,610 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode1_1  | 2021-01-28 02:33:14,610 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode1_1  | 2021-01-28 02:33:14,610 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode1_1  | 2021-01-28 02:33:14,610 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode1_1  | 2021-01-28 02:33:14,611 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-1F92667E218D
datanode1_1  | 2021-01-28 02:33:14,611 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-1F92667E218D
datanode1_1  | 2021-01-28 02:33:14,612 [pool-20-thread-1] INFO server.RaftServer$Division: bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-1F92667E218D: start as a follower, conf=-1: [bb31b8e2-b35d-4b3b-ae90-43363de8a349|rpc:172.25.0.102:9858|priority:1], old=null
datanode1_1  | 2021-01-28 02:33:14,612 [pool-20-thread-1] INFO server.RaftServer$Division: bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-1F92667E218D: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode1_1  | 2021-01-28 02:33:14,612 [pool-20-thread-1] INFO impl.RoleInfo: bb31b8e2-b35d-4b3b-ae90-43363de8a349: start bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-1F92667E218D-FollowerState
datanode1_1  | 2021-01-28 02:33:14,616 [pool-20-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-1F92667E218D,id=bb31b8e2-b35d-4b3b-ae90-43363de8a349
datanode1_1  | 2021-01-28 02:33:14,616 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-1F92667E218D
datanode1_1  | 2021-01-28 02:33:14,637 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=f85be9de-7cd2-4361-be7a-1f92667e218d.
datanode1_1  | 2021-01-28 02:33:19,722 [Thread-51] INFO impl.FollowerState: bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-1F92667E218D-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5109958219ns, electionTimeout:5099ms
datanode1_1  | 2021-01-28 02:33:19,722 [Thread-51] INFO impl.RoleInfo: bb31b8e2-b35d-4b3b-ae90-43363de8a349: shutdown bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-1F92667E218D-FollowerState
datanode1_1  | 2021-01-28 02:33:19,722 [Thread-51] INFO server.RaftServer$Division: bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-1F92667E218D: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode1_1  | 2021-01-28 02:33:19,725 [Thread-51] INFO impl.RoleInfo: bb31b8e2-b35d-4b3b-ae90-43363de8a349: start bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-1F92667E218D-LeaderElection2
datanode1_1  | 2021-01-28 02:33:19,737 [bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-1F92667E218D-LeaderElection2] INFO impl.LeaderElection: bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-1F92667E218D-LeaderElection2 PRE_VOTE round 0: submit vote requests at term 0 for -1: [bb31b8e2-b35d-4b3b-ae90-43363de8a349|rpc:172.25.0.102:9858|priority:1], old=null
datanode1_1  | 2021-01-28 02:33:19,737 [bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-1F92667E218D-LeaderElection2] INFO impl.LeaderElection: bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-1F92667E218D-LeaderElection2 PRE_VOTE round 0: result PASSED (term=0)
datanode1_1  | 2021-01-28 02:33:19,738 [bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-1F92667E218D-LeaderElection2] INFO impl.LeaderElection: bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-1F92667E218D-LeaderElection2 ELECTION round 0: submit vote requests at term 1 for -1: [bb31b8e2-b35d-4b3b-ae90-43363de8a349|rpc:172.25.0.102:9858|priority:1], old=null
datanode1_1  | 2021-01-28 02:33:19,742 [bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-1F92667E218D-LeaderElection2] INFO impl.LeaderElection: bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-1F92667E218D-LeaderElection2 ELECTION round 0: result PASSED (term=1)
datanode1_1  | 2021-01-28 02:33:19,742 [bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-1F92667E218D-LeaderElection2] INFO impl.RoleInfo: bb31b8e2-b35d-4b3b-ae90-43363de8a349: shutdown bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-1F92667E218D-LeaderElection2
datanode1_1  | 2021-01-28 02:33:19,742 [bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-1F92667E218D-LeaderElection2] INFO server.RaftServer$Division: bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-1F92667E218D: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode1_1  | 2021-01-28 02:33:19,742 [bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-1F92667E218D-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-1F92667E218D with new leaderId: bb31b8e2-b35d-4b3b-ae90-43363de8a349
datanode1_1  | 2021-01-28 02:33:19,742 [bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-1F92667E218D-LeaderElection2] INFO server.RaftServer$Division: bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-1F92667E218D: change Leader from null to bb31b8e2-b35d-4b3b-ae90-43363de8a349 at term 1 for becomeLeader, leader elected after 5213ms
datanode1_1  | 2021-01-28 02:33:19,746 [bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-1F92667E218D-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode1_1  | 2021-01-28 02:33:19,746 [bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-1F92667E218D-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-1F92667E218D
datanode1_1  | 2021-01-28 02:33:19,746 [bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-1F92667E218D-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode1_1  | 2021-01-28 02:33:19,746 [bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-1F92667E218D-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode1_1  | 2021-01-28 02:33:19,746 [bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-1F92667E218D-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode1_1  | 2021-01-28 02:33:19,747 [bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-1F92667E218D-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode1_1  | 2021-01-28 02:33:19,747 [bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-1F92667E218D-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode1_1  | 2021-01-28 02:33:19,747 [bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-1F92667E218D-LeaderElection2] INFO impl.RoleInfo: bb31b8e2-b35d-4b3b-ae90-43363de8a349: start bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-1F92667E218D-LeaderStateImpl
datanode1_1  | 2021-01-28 02:33:19,755 [bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-1F92667E218D-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-1F92667E218D-SegmentedRaftLogWorker: Starting segment from index:0
datanode1_1  | 2021-01-28 02:33:19,765 [bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-1F92667E218D-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-1F92667E218D-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/f85be9de-7cd2-4361-be7a-1f92667e218d/current/log_inprogress_0
datanode1_1  | 2021-01-28 02:33:19,779 [bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-1F92667E218D-LeaderElection2] INFO server.RaftServer$Division: bb31b8e2-b35d-4b3b-ae90-43363de8a349@group-1F92667E218D: set configuration 0: [bb31b8e2-b35d-4b3b-ae90-43363de8a349|rpc:172.25.0.102:9858|admin:|client:|dataStream:|priority:1], old=null
datanode1_1  | 2021-01-28 02:33:20,047 [ChunkWriter-3-0] INFO client.DNCertificateClient: Getting certificate with certSerialId:2420822746268.
datanode2_1  | 2021-01-28 02:32:23,368 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode2_1  | 2021-01-28 02:32:23,394 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode2_1  | 2021-01-28 02:32:23,763 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode2_1  | 2021-01-28 02:32:23,939 [Thread-7] INFO ozoneimpl.ContainerReader: Start to verify containers on volume /data/hdds/hdds
datanode2_1  | 2021-01-28 02:32:23,940 [Thread-7] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode2_1  | 2021-01-28 02:32:23,940 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode2_1  | 2021-01-28 02:32:28,666 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode2_1  | 2021-01-28 02:32:28,934 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode2_1  | 2021-01-28 02:32:29,897 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
datanode2_1  | 2021-01-28 02:32:29,902 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode2_1  | 2021-01-28 02:32:29,918 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
datanode2_1  | 2021-01-28 02:32:29,919 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode2_1  | 2021-01-28 02:32:29,919 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode2_1  | 2021-01-28 02:32:29,920 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode2_1  | 2021-01-28 02:32:29,921 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2021-01-28 02:32:29,930 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode2_1  | 2021-01-28 02:32:29,931 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode2_1  | 2021-01-28 02:32:31,262 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode2_1  | 2021-01-28 02:32:31,299 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode2_1  | 2021-01-28 02:32:31,341 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode2_1  | 2021-01-28 02:32:31,452 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2021-01-28 02:32:31,463 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode2_1  | 2021-01-28 02:32:35,073 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode2_1  | 2021-01-28 02:32:35,079 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode2_1  | 2021-01-28 02:32:35,079 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.datanode.http.auth.type = kerberos
datanode2_1  | 2021-01-28 02:32:35,270 [main] INFO util.log: Logging initialized @51785ms to org.eclipse.jetty.util.log.Slf4jLog
datanode2_1  | 2021-01-28 02:32:35,916 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode2_1  | 2021-01-28 02:32:35,961 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode2_1  | 2021-01-28 02:32:35,967 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode2_1  | 2021-01-28 02:32:35,967 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode2_1  | 2021-01-28 02:32:35,968 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode2_1  | 2021-01-28 02:32:35,990 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.datanode.http.auth.kerberos.principal keytabKey: hdds.datanode.http.auth.kerberos.keytab
datanode2_1  | 2021-01-28 02:32:36,202 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode2_1  | 2021-01-28 02:32:36,243 [main] INFO server.Server: jetty-9.4.34.v20201102; built: 2020-11-02T14:15:39.302Z; git: e46af88704a893fc12cb0e3bf46e2c7b48a009e7; jvm 11.0.7+10-LTS
datanode2_1  | 2021-01-28 02:32:36,383 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode2_1  | 2021-01-28 02:32:36,383 [main] INFO server.session: No SessionScavenger set, using defaults
datanode2_1  | 2021-01-28 02:32:36,399 [main] INFO server.session: node0 Scavenging every 600000ms
datanode2_1  | 2021-01-28 02:32:36,508 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db0158eeb642@EXAMPLE.COM
datanode2_1  | 2021-01-28 02:32:36,523 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@76219fe{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode2_1  | 2021-01-28 02:32:36,531 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@270be080{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode2_1  | 2021-01-28 02:32:37,158 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db0158eeb642@EXAMPLE.COM
datanode2_1  | 2021-01-28 02:32:37,253 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@3dc14f80{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-1_1_0-SNAPSHOT_jar-_-any-2081478060880155957/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode2_1  | 2021-01-28 02:32:37,319 [main] INFO server.AbstractConnector: Started ServerConnector@4e35a219{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode2_1  | 2021-01-28 02:32:37,326 [main] INFO server.Server: Started @53842ms
datanode2_1  | 2021-01-28 02:32:37,370 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode2_1  | 2021-01-28 02:32:37,370 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode2_1  | 2021-01-28 02:32:37,379 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode2_1  | 2021-01-28 02:32:37,514 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1ffea5] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode2_1  | 2021-01-28 02:32:37,948 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.25.0.115:9891
datanode2_1  | 2021-01-28 02:32:40,924 [EndpointStateMachine task thread for scm/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode2_1  | 2021-01-28 02:32:40,932 [EndpointStateMachine task thread for scm/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode2_1  | 2021-01-28 02:32:41,335 [EndpointStateMachine task thread for scm/172.25.0.116:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 6bab7c5a-f782-4236-88e0-70f071e2bf9c at port 9858
datanode2_1  | 2021-01-28 02:32:41,432 [EndpointStateMachine task thread for scm/172.25.0.116:9861 - 0 ] INFO server.RaftServer: 6bab7c5a-f782-4236-88e0-70f071e2bf9c: start RPC server
datanode2_1  | 2021-01-28 02:32:41,508 [EndpointStateMachine task thread for scm/172.25.0.116:9861 - 0 ] INFO server.GrpcService: 6bab7c5a-f782-4236-88e0-70f071e2bf9c: GrpcService started, listening on 9858
datanode2_1  | 2021-01-28 02:32:41,517 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$301/0x000000084052e840@784f251f] INFO util.JvmPauseMonitor: JvmPauseMonitor-6bab7c5a-f782-4236-88e0-70f071e2bf9c: Started
datanode2_1  | 2021-01-28 02:32:48,614 [grpc-default-executor-0] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server_message_metrics.6bab7c5a-f782-4236-88e0-70f071e2bf9c
datanode2_1  | 2021-01-28 02:32:48,824 [grpc-default-executor-0] INFO server.RaftServer: 6bab7c5a-f782-4236-88e0-70f071e2bf9c: addNew group-A71B52063026:[feb6bea5-edd2-410b-8ad4-c920818f117a|rpc:172.25.0.104:9858|admin:|client:|dataStream:|priority:0, bb31b8e2-b35d-4b3b-ae90-43363de8a349|rpc:172.25.0.102:9858|admin:|client:|dataStream:|priority:1, 6bab7c5a-f782-4236-88e0-70f071e2bf9c|rpc:172.25.0.103:9858|admin:|client:|dataStream:|priority:0] returns group-A71B52063026:java.util.concurrent.CompletableFuture@11df068e[Not completed]
datanode2_1  | 2021-01-28 02:32:48,936 [pool-20-thread-1] INFO server.RaftServer$Division: 6bab7c5a-f782-4236-88e0-70f071e2bf9c: new RaftServerImpl for group-A71B52063026:[feb6bea5-edd2-410b-8ad4-c920818f117a|rpc:172.25.0.104:9858|admin:|client:|dataStream:|priority:0, bb31b8e2-b35d-4b3b-ae90-43363de8a349|rpc:172.25.0.102:9858|admin:|client:|dataStream:|priority:1, 6bab7c5a-f782-4236-88e0-70f071e2bf9c|rpc:172.25.0.103:9858|admin:|client:|dataStream:|priority:0] with ContainerStateMachine:uninitialized
datanode2_1  | 2021-01-28 02:32:48,965 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode2_1  | 2021-01-28 02:32:48,966 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode2_1  | 2021-01-28 02:32:48,966 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode2_1  | 2021-01-28 02:32:48,966 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode2_1  | 2021-01-28 02:32:48,966 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode2_1  | 2021-01-28 02:32:48,968 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode2_1  | 2021-01-28 02:32:48,971 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | 2021-01-28 02:32:48,984 [pool-20-thread-1] INFO server.RaftServer$Division: 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-A71B52063026: ConfigurationManager, init=-1: [feb6bea5-edd2-410b-8ad4-c920818f117a|rpc:172.25.0.104:9858|admin:|client:|dataStream:|priority:0, bb31b8e2-b35d-4b3b-ae90-43363de8a349|rpc:172.25.0.102:9858|admin:|client:|dataStream:|priority:1, 6bab7c5a-f782-4236-88e0-70f071e2bf9c|rpc:172.25.0.103:9858|admin:|client:|dataStream:|priority:0], old=null, confs=<EMPTY_MAP>
datanode2_1  | 2021-01-28 02:32:48,984 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2021-01-28 02:32:48,987 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode2_1  | 2021-01-28 02:32:48,994 [pool-20-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/45d6c387-0d5e-4ec1-887d-a71b52063026 does not exist. Creating ...
datanode2_1  | 2021-01-28 02:32:49,020 [pool-20-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/45d6c387-0d5e-4ec1-887d-a71b52063026/in_use.lock acquired by nodename 6@db0158eeb642
datanode2_1  | 2021-01-28 02:32:49,055 [pool-20-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/45d6c387-0d5e-4ec1-887d-a71b52063026 has been successfully formatted.
datanode2_1  | 2021-01-28 02:32:49,220 [pool-20-thread-1] INFO ratis.ContainerStateMachine: group-A71B52063026: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode2_1  | 2021-01-28 02:32:49,220 [pool-20-thread-1] ERROR storage.RaftStorage: Failed reading configuration from file:/data/metadata/ratis/45d6c387-0d5e-4ec1-887d-a71b52063026/current/raft-meta.conf
datanode2_1  | java.io.FileNotFoundException: /data/metadata/ratis/45d6c387-0d5e-4ec1-887d-a71b52063026/current/raft-meta.conf (No such file or directory)
datanode2_1  | 	at java.base/java.io.FileInputStream.open0(Native Method)
datanode2_1  | 	at java.base/java.io.FileInputStream.open(FileInputStream.java:219)
datanode2_1  | 	at java.base/java.io.FileInputStream.<init>(FileInputStream.java:157)
datanode2_1  | 	at org.apache.ratis.server.storage.RaftStorageImpl.readRaftConfiguration(RaftStorageImpl.java:143)
datanode2_1  | 	at org.apache.ratis.server.impl.ServerState.<init>(ServerState.java:122)
datanode2_1  | 	at org.apache.ratis.server.impl.RaftServerImpl.<init>(RaftServerImpl.java:193)
datanode2_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.lambda$newRaftServerImpl$4(RaftServerProxy.java:266)
datanode2_1  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode2_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode2_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode2_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode2_1  | 2021-01-28 02:32:49,230 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode2_1  | 2021-01-28 02:32:49,247 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode2_1  | 2021-01-28 02:32:49,330 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode2_1  | 2021-01-28 02:32:49,331 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2021-01-28 02:32:49,336 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-A71B52063026
datanode2_1  | 2021-01-28 02:32:49,340 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2021-01-28 02:32:49,364 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode2_1  | 2021-01-28 02:32:49,367 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode2_1  | 2021-01-28 02:32:49,374 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: new 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-A71B52063026-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/45d6c387-0d5e-4ec1-887d-a71b52063026
datanode2_1  | 2021-01-28 02:32:49,384 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode2_1  | 2021-01-28 02:32:49,387 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode2_1  | 2021-01-28 02:32:49,402 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2021-01-28 02:32:49,416 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode2_1  | 2021-01-28 02:32:49,419 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode2_1  | 2021-01-28 02:32:49,420 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode2_1  | 2021-01-28 02:32:49,423 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode2_1  | 2021-01-28 02:32:49,426 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode2_1  | 2021-01-28 02:32:49,457 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode2_1  | 2021-01-28 02:32:49,464 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode2_1  | 2021-01-28 02:32:49,484 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-A71B52063026-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode2_1  | 2021-01-28 02:32:49,484 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-A71B52063026-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode2_1  | 2021-01-28 02:32:49,501 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode2_1  | 2021-01-28 02:32:49,504 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode2_1  | 2021-01-28 02:32:49,506 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode2_1  | 2021-01-28 02:32:49,516 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode2_1  | 2021-01-28 02:32:49,518 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode2_1  | 2021-01-28 02:32:49,518 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode2_1  | 2021-01-28 02:32:49,636 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-A71B52063026
datanode2_1  | 2021-01-28 02:32:49,641 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-A71B52063026
datanode2_1  | 2021-01-28 02:32:49,675 [pool-20-thread-1] INFO server.RaftServer$Division: 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-A71B52063026: start as a follower, conf=-1: [feb6bea5-edd2-410b-8ad4-c920818f117a|rpc:172.25.0.104:9858|admin:|client:|dataStream:|priority:0, bb31b8e2-b35d-4b3b-ae90-43363de8a349|rpc:172.25.0.102:9858|admin:|client:|dataStream:|priority:1, 6bab7c5a-f782-4236-88e0-70f071e2bf9c|rpc:172.25.0.103:9858|admin:|client:|dataStream:|priority:0], old=null
datanode2_1  | 2021-01-28 02:32:49,686 [pool-20-thread-1] INFO server.RaftServer$Division: 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-A71B52063026: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode2_1  | 2021-01-28 02:32:49,686 [pool-20-thread-1] INFO impl.RoleInfo: 6bab7c5a-f782-4236-88e0-70f071e2bf9c: start 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-A71B52063026-FollowerState
datanode2_1  | 2021-01-28 02:32:49,714 [pool-20-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A71B52063026,id=6bab7c5a-f782-4236-88e0-70f071e2bf9c
datanode2_1  | 2021-01-28 02:32:49,715 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-A71B52063026
datanode2_1  | 2021-01-28 02:32:52,785 [grpc-default-executor-0] INFO server.RaftServer: 6bab7c5a-f782-4236-88e0-70f071e2bf9c: addNew group-8E19C9AA218C:[feb6bea5-edd2-410b-8ad4-c920818f117a|rpc:172.25.0.104:9858|admin:|client:|dataStream:|priority:1, bb31b8e2-b35d-4b3b-ae90-43363de8a349|rpc:172.25.0.102:9858|admin:|client:|dataStream:|priority:0, 6bab7c5a-f782-4236-88e0-70f071e2bf9c|rpc:172.25.0.103:9858|admin:|client:|dataStream:|priority:0] returns group-8E19C9AA218C:java.util.concurrent.CompletableFuture@1662e09[Not completed]
datanode2_1  | 2021-01-28 02:32:52,787 [pool-20-thread-1] INFO server.RaftServer$Division: 6bab7c5a-f782-4236-88e0-70f071e2bf9c: new RaftServerImpl for group-8E19C9AA218C:[feb6bea5-edd2-410b-8ad4-c920818f117a|rpc:172.25.0.104:9858|admin:|client:|dataStream:|priority:1, bb31b8e2-b35d-4b3b-ae90-43363de8a349|rpc:172.25.0.102:9858|admin:|client:|dataStream:|priority:0, 6bab7c5a-f782-4236-88e0-70f071e2bf9c|rpc:172.25.0.103:9858|admin:|client:|dataStream:|priority:0] with ContainerStateMachine:uninitialized
datanode2_1  | 2021-01-28 02:32:52,787 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode2_1  | 2021-01-28 02:32:52,787 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode2_1  | 2021-01-28 02:32:52,787 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode2_1  | 2021-01-28 02:32:52,787 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode2_1  | 2021-01-28 02:32:52,788 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode2_1  | 2021-01-28 02:32:52,788 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode2_1  | 2021-01-28 02:32:52,788 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | 2021-01-28 02:32:52,788 [pool-20-thread-1] INFO server.RaftServer$Division: 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-8E19C9AA218C: ConfigurationManager, init=-1: [feb6bea5-edd2-410b-8ad4-c920818f117a|rpc:172.25.0.104:9858|admin:|client:|dataStream:|priority:1, bb31b8e2-b35d-4b3b-ae90-43363de8a349|rpc:172.25.0.102:9858|admin:|client:|dataStream:|priority:0, 6bab7c5a-f782-4236-88e0-70f071e2bf9c|rpc:172.25.0.103:9858|admin:|client:|dataStream:|priority:0], old=null, confs=<EMPTY_MAP>
datanode2_1  | 2021-01-28 02:32:52,788 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2021-01-28 02:32:52,788 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode2_1  | 2021-01-28 02:32:52,788 [pool-20-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/4954273f-2502-40bd-89f2-8e19c9aa218c does not exist. Creating ...
datanode2_1  | 2021-01-28 02:32:52,789 [pool-20-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/4954273f-2502-40bd-89f2-8e19c9aa218c/in_use.lock acquired by nodename 6@db0158eeb642
datanode2_1  | 2021-01-28 02:32:52,791 [pool-20-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/4954273f-2502-40bd-89f2-8e19c9aa218c has been successfully formatted.
datanode2_1  | 2021-01-28 02:32:52,791 [pool-20-thread-1] INFO ratis.ContainerStateMachine: group-8E19C9AA218C: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode2_1  | 2021-01-28 02:32:52,791 [pool-20-thread-1] ERROR storage.RaftStorage: Failed reading configuration from file:/data/metadata/ratis/4954273f-2502-40bd-89f2-8e19c9aa218c/current/raft-meta.conf
datanode2_1  | java.io.FileNotFoundException: /data/metadata/ratis/4954273f-2502-40bd-89f2-8e19c9aa218c/current/raft-meta.conf (No such file or directory)
datanode2_1  | 	at java.base/java.io.FileInputStream.open0(Native Method)
datanode2_1  | 	at java.base/java.io.FileInputStream.open(FileInputStream.java:219)
datanode2_1  | 	at java.base/java.io.FileInputStream.<init>(FileInputStream.java:157)
datanode2_1  | 	at org.apache.ratis.server.storage.RaftStorageImpl.readRaftConfiguration(RaftStorageImpl.java:143)
datanode2_1  | 	at org.apache.ratis.server.impl.ServerState.<init>(ServerState.java:122)
datanode2_1  | 	at org.apache.ratis.server.impl.RaftServerImpl.<init>(RaftServerImpl.java:193)
datanode2_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.lambda$newRaftServerImpl$4(RaftServerProxy.java:266)
datanode2_1  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode2_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode2_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode2_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode2_1  | 2021-01-28 02:32:52,792 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode2_1  | 2021-01-28 02:32:52,792 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode2_1  | 2021-01-28 02:32:52,792 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode2_1  | 2021-01-28 02:32:52,792 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2021-01-28 02:32:52,792 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-8E19C9AA218C
datanode2_1  | 2021-01-28 02:32:52,792 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2021-01-28 02:32:52,793 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode2_1  | 2021-01-28 02:32:52,793 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode2_1  | 2021-01-28 02:32:52,793 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: new 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-8E19C9AA218C-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/4954273f-2502-40bd-89f2-8e19c9aa218c
datanode2_1  | 2021-01-28 02:32:52,793 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode2_1  | 2021-01-28 02:32:52,793 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode2_1  | 2021-01-28 02:32:52,793 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2021-01-28 02:32:52,794 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode2_1  | 2021-01-28 02:32:52,794 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode2_1  | 2021-01-28 02:32:52,794 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode2_1  | 2021-01-28 02:32:52,794 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode2_1  | 2021-01-28 02:32:52,794 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode2_1  | 2021-01-28 02:32:52,795 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode2_1  | 2021-01-28 02:32:52,795 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode2_1  | 2021-01-28 02:32:52,796 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-8E19C9AA218C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode2_1  | 2021-01-28 02:32:52,796 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-8E19C9AA218C-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode2_1  | 2021-01-28 02:32:52,825 [grpc-default-executor-0] INFO server.RaftServer$Division: 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-A71B52063026: receive requestVote(PRE_VOTE, feb6bea5-edd2-410b-8ad4-c920818f117a, group-A71B52063026, 0, (t:0, i:0))
datanode2_1  | 2021-01-28 02:32:52,827 [grpc-default-executor-0] INFO impl.VoteContext: 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-A71B52063026-FOLLOWER: accept PRE_VOTE from feb6bea5-edd2-410b-8ad4-c920818f117a: our priority 0 <= candidate's priority 0
datanode2_1  | 2021-01-28 02:32:52,839 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode2_1  | 2021-01-28 02:32:52,840 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode2_1  | 2021-01-28 02:32:52,840 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode2_1  | 2021-01-28 02:32:52,840 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode2_1  | 2021-01-28 02:32:52,840 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode2_1  | 2021-01-28 02:32:52,841 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode2_1  | 2021-01-28 02:32:52,841 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-8E19C9AA218C
datanode2_1  | 2021-01-28 02:32:52,841 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-8E19C9AA218C
datanode2_1  | 2021-01-28 02:32:52,842 [pool-20-thread-1] INFO server.RaftServer$Division: 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-8E19C9AA218C: start as a follower, conf=-1: [feb6bea5-edd2-410b-8ad4-c920818f117a|rpc:172.25.0.104:9858|admin:|client:|dataStream:|priority:1, bb31b8e2-b35d-4b3b-ae90-43363de8a349|rpc:172.25.0.102:9858|admin:|client:|dataStream:|priority:0, 6bab7c5a-f782-4236-88e0-70f071e2bf9c|rpc:172.25.0.103:9858|admin:|client:|dataStream:|priority:0], old=null
datanode2_1  | 2021-01-28 02:32:52,842 [pool-20-thread-1] INFO server.RaftServer$Division: 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-8E19C9AA218C: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode2_1  | 2021-01-28 02:32:52,842 [pool-20-thread-1] INFO impl.RoleInfo: 6bab7c5a-f782-4236-88e0-70f071e2bf9c: start 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-8E19C9AA218C-FollowerState
datanode2_1  | 2021-01-28 02:32:52,843 [pool-20-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-8E19C9AA218C,id=6bab7c5a-f782-4236-88e0-70f071e2bf9c
datanode2_1  | 2021-01-28 02:32:52,843 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-8E19C9AA218C
datanode2_1  | 2021-01-28 02:32:52,879 [grpc-default-executor-0] INFO server.RaftServer$Division: 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-A71B52063026 replies to PRE_VOTE vote request: feb6bea5-edd2-410b-8ad4-c920818f117a<-6bab7c5a-f782-4236-88e0-70f071e2bf9c#0:OK-t0. Peer's state: 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-A71B52063026:t0, leader=null, voted=, raftlog=6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-A71B52063026-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [feb6bea5-edd2-410b-8ad4-c920818f117a|rpc:172.25.0.104:9858|admin:|client:|dataStream:|priority:0, bb31b8e2-b35d-4b3b-ae90-43363de8a349|rpc:172.25.0.102:9858|admin:|client:|dataStream:|priority:1, 6bab7c5a-f782-4236-88e0-70f071e2bf9c|rpc:172.25.0.103:9858|admin:|client:|dataStream:|priority:0], old=null
datanode2_1  | 2021-01-28 02:32:57,482 [grpc-default-executor-0] INFO server.RaftServer$Division: 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-8E19C9AA218C: receive requestVote(PRE_VOTE, feb6bea5-edd2-410b-8ad4-c920818f117a, group-8E19C9AA218C, 0, (t:0, i:0))
datanode2_1  | 2021-01-28 02:32:57,482 [grpc-default-executor-0] INFO impl.VoteContext: 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-8E19C9AA218C-FOLLOWER: accept PRE_VOTE from feb6bea5-edd2-410b-8ad4-c920818f117a: our priority 0 <= candidate's priority 1
datanode2_1  | 2021-01-28 02:32:57,482 [grpc-default-executor-0] INFO server.RaftServer$Division: 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-8E19C9AA218C replies to PRE_VOTE vote request: feb6bea5-edd2-410b-8ad4-c920818f117a<-6bab7c5a-f782-4236-88e0-70f071e2bf9c#0:OK-t0. Peer's state: 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-8E19C9AA218C:t0, leader=null, voted=, raftlog=6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-8E19C9AA218C-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [feb6bea5-edd2-410b-8ad4-c920818f117a|rpc:172.25.0.104:9858|admin:|client:|dataStream:|priority:1, bb31b8e2-b35d-4b3b-ae90-43363de8a349|rpc:172.25.0.102:9858|admin:|client:|dataStream:|priority:0, 6bab7c5a-f782-4236-88e0-70f071e2bf9c|rpc:172.25.0.103:9858|admin:|client:|dataStream:|priority:0], old=null
datanode2_1  | 2021-01-28 02:32:57,545 [grpc-default-executor-0] INFO server.RaftServer$Division: 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-8E19C9AA218C: receive requestVote(ELECTION, feb6bea5-edd2-410b-8ad4-c920818f117a, group-8E19C9AA218C, 1, (t:0, i:0))
datanode2_1  | 2021-01-28 02:32:57,545 [grpc-default-executor-0] INFO impl.VoteContext: 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-8E19C9AA218C-FOLLOWER: accept ELECTION from feb6bea5-edd2-410b-8ad4-c920818f117a: our priority 0 <= candidate's priority 1
datanode2_1  | 2021-01-28 02:32:57,546 [grpc-default-executor-0] INFO server.RaftServer$Division: 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-8E19C9AA218C: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:feb6bea5-edd2-410b-8ad4-c920818f117a
datanode2_1  | 2021-01-28 02:32:57,546 [grpc-default-executor-0] INFO impl.RoleInfo: 6bab7c5a-f782-4236-88e0-70f071e2bf9c: shutdown 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-8E19C9AA218C-FollowerState
datanode2_1  | 2021-01-28 02:32:57,546 [grpc-default-executor-0] INFO impl.RoleInfo: 6bab7c5a-f782-4236-88e0-70f071e2bf9c: start 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-8E19C9AA218C-FollowerState
datanode2_1  | 2021-01-28 02:32:57,547 [Thread-28] INFO impl.FollowerState: 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-8E19C9AA218C-FollowerState was interrupted: {}
datanode2_1  | java.lang.InterruptedException: sleep interrupted
datanode2_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode2_1  | 	at java.base/java.lang.Thread.sleep(Thread.java:339)
datanode2_1  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode2_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
datanode2_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode2_1  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:117)
datanode2_1  | 2021-01-28 02:32:57,560 [grpc-default-executor-0] INFO server.RaftServer$Division: 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-8E19C9AA218C replies to ELECTION vote request: feb6bea5-edd2-410b-8ad4-c920818f117a<-6bab7c5a-f782-4236-88e0-70f071e2bf9c#0:OK-t1. Peer's state: 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-8E19C9AA218C:t1, leader=null, voted=feb6bea5-edd2-410b-8ad4-c920818f117a, raftlog=6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-8E19C9AA218C-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [feb6bea5-edd2-410b-8ad4-c920818f117a|rpc:172.25.0.104:9858|admin:|client:|dataStream:|priority:1, bb31b8e2-b35d-4b3b-ae90-43363de8a349|rpc:172.25.0.102:9858|admin:|client:|dataStream:|priority:0, 6bab7c5a-f782-4236-88e0-70f071e2bf9c|rpc:172.25.0.103:9858|admin:|client:|dataStream:|priority:0], old=null
datanode2_1  | 2021-01-28 02:32:57,584 [grpc-default-executor-1] INFO server.RaftServer$Division: 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-A71B52063026: receive requestVote(PRE_VOTE, bb31b8e2-b35d-4b3b-ae90-43363de8a349, group-A71B52063026, 0, (t:0, i:0))
datanode2_1  | 2021-01-28 02:32:57,586 [grpc-default-executor-1] INFO impl.VoteContext: 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-A71B52063026-FOLLOWER: accept PRE_VOTE from bb31b8e2-b35d-4b3b-ae90-43363de8a349: our priority 0 <= candidate's priority 1
datanode2_1  | 2021-01-28 02:32:57,586 [grpc-default-executor-1] INFO server.RaftServer$Division: 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-A71B52063026 replies to PRE_VOTE vote request: bb31b8e2-b35d-4b3b-ae90-43363de8a349<-6bab7c5a-f782-4236-88e0-70f071e2bf9c#0:OK-t0. Peer's state: 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-A71B52063026:t0, leader=null, voted=, raftlog=6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-A71B52063026-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [feb6bea5-edd2-410b-8ad4-c920818f117a|rpc:172.25.0.104:9858|admin:|client:|dataStream:|priority:0, bb31b8e2-b35d-4b3b-ae90-43363de8a349|rpc:172.25.0.102:9858|admin:|client:|dataStream:|priority:1, 6bab7c5a-f782-4236-88e0-70f071e2bf9c|rpc:172.25.0.103:9858|admin:|client:|dataStream:|priority:0], old=null
datanode2_1  | 2021-01-28 02:32:57,685 [grpc-default-executor-1] INFO server.RaftServer$Division: 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-A71B52063026: receive requestVote(ELECTION, bb31b8e2-b35d-4b3b-ae90-43363de8a349, group-A71B52063026, 1, (t:0, i:0))
datanode2_1  | 2021-01-28 02:32:57,686 [grpc-default-executor-1] INFO impl.VoteContext: 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-A71B52063026-FOLLOWER: accept ELECTION from bb31b8e2-b35d-4b3b-ae90-43363de8a349: our priority 0 <= candidate's priority 1
datanode2_1  | 2021-01-28 02:32:57,686 [grpc-default-executor-1] INFO server.RaftServer$Division: 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-A71B52063026: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:bb31b8e2-b35d-4b3b-ae90-43363de8a349
datanode2_1  | 2021-01-28 02:32:57,686 [grpc-default-executor-1] INFO impl.RoleInfo: 6bab7c5a-f782-4236-88e0-70f071e2bf9c: shutdown 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-A71B52063026-FollowerState
datanode2_1  | 2021-01-28 02:32:57,686 [grpc-default-executor-1] INFO impl.RoleInfo: 6bab7c5a-f782-4236-88e0-70f071e2bf9c: start 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-A71B52063026-FollowerState
datanode2_1  | 2021-01-28 02:32:57,686 [Thread-25] INFO impl.FollowerState: 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-A71B52063026-FollowerState was interrupted: {}
datanode2_1  | java.lang.InterruptedException: sleep interrupted
datanode2_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode2_1  | 	at java.base/java.lang.Thread.sleep(Thread.java:339)
datanode2_1  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode2_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
datanode2_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode2_1  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:117)
datanode2_1  | 2021-01-28 02:32:57,689 [grpc-default-executor-1] INFO server.RaftServer$Division: 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-A71B52063026 replies to ELECTION vote request: bb31b8e2-b35d-4b3b-ae90-43363de8a349<-6bab7c5a-f782-4236-88e0-70f071e2bf9c#0:OK-t1. Peer's state: 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-A71B52063026:t1, leader=null, voted=bb31b8e2-b35d-4b3b-ae90-43363de8a349, raftlog=6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-A71B52063026-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [feb6bea5-edd2-410b-8ad4-c920818f117a|rpc:172.25.0.104:9858|admin:|client:|dataStream:|priority:0, bb31b8e2-b35d-4b3b-ae90-43363de8a349|rpc:172.25.0.102:9858|admin:|client:|dataStream:|priority:1, 6bab7c5a-f782-4236-88e0-70f071e2bf9c|rpc:172.25.0.103:9858|admin:|client:|dataStream:|priority:0], old=null
datanode2_1  | 2021-01-28 02:32:57,878 [grpc-default-executor-1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-8E19C9AA218C with new leaderId: feb6bea5-edd2-410b-8ad4-c920818f117a
datanode2_1  | 2021-01-28 02:32:57,879 [grpc-default-executor-1] INFO server.RaftServer$Division: 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-8E19C9AA218C: change Leader from null to feb6bea5-edd2-410b-8ad4-c920818f117a at term 1 for appendEntries, leader elected after 5086ms
datanode2_1  | 2021-01-28 02:32:57,968 [grpc-default-executor-1] INFO server.RaftServer$Division: 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-8E19C9AA218C: set configuration 0: [feb6bea5-edd2-410b-8ad4-c920818f117a|rpc:172.25.0.104:9858|admin:|client:|dataStream:|priority:1, bb31b8e2-b35d-4b3b-ae90-43363de8a349|rpc:172.25.0.102:9858|admin:|client:|dataStream:|priority:0, 6bab7c5a-f782-4236-88e0-70f071e2bf9c|rpc:172.25.0.103:9858|admin:|client:|dataStream:|priority:0], old=null
datanode2_1  | 2021-01-28 02:32:57,989 [grpc-default-executor-1] INFO segmented.SegmentedRaftLogWorker: 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-8E19C9AA218C-SegmentedRaftLogWorker: Starting segment from index:0
datanode2_1  | 2021-01-28 02:32:58,208 [6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-8E19C9AA218C-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-8E19C9AA218C-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/4954273f-2502-40bd-89f2-8e19c9aa218c/current/log_inprogress_0
datanode2_1  | 2021-01-28 02:32:58,480 [grpc-default-executor-1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-A71B52063026 with new leaderId: bb31b8e2-b35d-4b3b-ae90-43363de8a349
datanode2_1  | 2021-01-28 02:32:58,481 [grpc-default-executor-1] INFO server.RaftServer$Division: 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-A71B52063026: change Leader from null to bb31b8e2-b35d-4b3b-ae90-43363de8a349 at term 1 for appendEntries, leader elected after 9250ms
datanode2_1  | 2021-01-28 02:32:58,595 [grpc-default-executor-1] INFO server.RaftServer$Division: 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-A71B52063026: set configuration 0: [feb6bea5-edd2-410b-8ad4-c920818f117a|rpc:172.25.0.104:9858|admin:|client:|dataStream:|priority:0, bb31b8e2-b35d-4b3b-ae90-43363de8a349|rpc:172.25.0.102:9858|admin:|client:|dataStream:|priority:1, 6bab7c5a-f782-4236-88e0-70f071e2bf9c|rpc:172.25.0.103:9858|admin:|client:|dataStream:|priority:0], old=null
datanode2_1  | 2021-01-28 02:32:58,596 [grpc-default-executor-1] INFO segmented.SegmentedRaftLogWorker: 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-A71B52063026-SegmentedRaftLogWorker: Starting segment from index:0
datanode2_1  | 2021-01-28 02:32:58,598 [6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-A71B52063026-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-A71B52063026-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/45d6c387-0d5e-4ec1-887d-a71b52063026/current/log_inprogress_0
datanode2_1  | 2021-01-28 02:33:14,550 [Command processor thread] INFO server.RaftServer: 6bab7c5a-f782-4236-88e0-70f071e2bf9c: addNew group-B28675BAAFBC:[6bab7c5a-f782-4236-88e0-70f071e2bf9c|rpc:172.25.0.103:9858|priority:1] returns group-B28675BAAFBC:java.util.concurrent.CompletableFuture@90582f[Not completed]
datanode2_1  | 2021-01-28 02:33:14,552 [pool-20-thread-1] INFO server.RaftServer$Division: 6bab7c5a-f782-4236-88e0-70f071e2bf9c: new RaftServerImpl for group-B28675BAAFBC:[6bab7c5a-f782-4236-88e0-70f071e2bf9c|rpc:172.25.0.103:9858|priority:1] with ContainerStateMachine:uninitialized
datanode2_1  | 2021-01-28 02:33:14,552 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode2_1  | 2021-01-28 02:33:14,552 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode2_1  | 2021-01-28 02:33:14,552 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode2_1  | 2021-01-28 02:33:14,553 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode2_1  | 2021-01-28 02:33:14,553 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode2_1  | 2021-01-28 02:33:14,553 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode2_1  | 2021-01-28 02:33:14,553 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | 2021-01-28 02:33:14,553 [pool-20-thread-1] INFO server.RaftServer$Division: 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-B28675BAAFBC: ConfigurationManager, init=-1: [6bab7c5a-f782-4236-88e0-70f071e2bf9c|rpc:172.25.0.103:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode2_1  | 2021-01-28 02:33:14,553 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2021-01-28 02:33:14,553 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode2_1  | 2021-01-28 02:33:14,554 [pool-20-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/f3928597-5304-49a3-b7ac-b28675baafbc does not exist. Creating ...
datanode2_1  | 2021-01-28 02:33:14,555 [pool-20-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/f3928597-5304-49a3-b7ac-b28675baafbc/in_use.lock acquired by nodename 6@db0158eeb642
datanode2_1  | 2021-01-28 02:33:14,560 [pool-20-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/f3928597-5304-49a3-b7ac-b28675baafbc has been successfully formatted.
datanode2_1  | 2021-01-28 02:33:14,560 [pool-20-thread-1] INFO ratis.ContainerStateMachine: group-B28675BAAFBC: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode2_1  | 2021-01-28 02:33:14,560 [pool-20-thread-1] ERROR storage.RaftStorage: Failed reading configuration from file:/data/metadata/ratis/f3928597-5304-49a3-b7ac-b28675baafbc/current/raft-meta.conf
datanode2_1  | java.io.FileNotFoundException: /data/metadata/ratis/f3928597-5304-49a3-b7ac-b28675baafbc/current/raft-meta.conf (No such file or directory)
datanode2_1  | 	at java.base/java.io.FileInputStream.open0(Native Method)
datanode2_1  | 	at java.base/java.io.FileInputStream.open(FileInputStream.java:219)
datanode2_1  | 	at java.base/java.io.FileInputStream.<init>(FileInputStream.java:157)
datanode2_1  | 	at org.apache.ratis.server.storage.RaftStorageImpl.readRaftConfiguration(RaftStorageImpl.java:143)
datanode2_1  | 	at org.apache.ratis.server.impl.ServerState.<init>(ServerState.java:122)
datanode2_1  | 	at org.apache.ratis.server.impl.RaftServerImpl.<init>(RaftServerImpl.java:193)
datanode2_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.lambda$newRaftServerImpl$4(RaftServerProxy.java:266)
datanode2_1  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode2_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode2_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode2_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode2_1  | 2021-01-28 02:33:14,560 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode2_1  | 2021-01-28 02:33:14,560 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode2_1  | 2021-01-28 02:33:14,561 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode2_1  | 2021-01-28 02:33:14,561 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2021-01-28 02:33:14,561 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-B28675BAAFBC
datanode2_1  | 2021-01-28 02:33:14,561 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2021-01-28 02:33:14,561 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode2_1  | 2021-01-28 02:33:14,561 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode2_1  | 2021-01-28 02:33:14,561 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: new 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-B28675BAAFBC-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/f3928597-5304-49a3-b7ac-b28675baafbc
datanode2_1  | 2021-01-28 02:33:14,562 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode2_1  | 2021-01-28 02:33:14,562 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode2_1  | 2021-01-28 02:33:14,562 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2021-01-28 02:33:14,562 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
kdc_1        | krb5kdc: starting...
kdc_1        | Checking the availablility of the keytab
kdc_1        | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1        | KDC is not yet available.  Shell return code is 1
kdc_1        | kadmin: Communication failure with server while initializing kadmin interface
kdc_1        | Checking the availablility of the keytab
kdc_1        | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1        | KDC is not yet available.  Shell return code is 1
kdc_1        | kadmin: Communication failure with server while initializing kadmin interface
kdc_1        | Checking the availablility of the keytab
kdc_1        | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1        | kadmin: Communication failure with server while initializing kadmin interface
kdc_1        | KDC is not yet available.  Shell return code is 1
kdc_1        | Checking the availablility of the keytab
kdc_1        | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1        | kadmin: Communication failure with server while initializing kadmin interface
kdc_1        | KDC is not yet available.  Shell return code is 1
kdc_1        | kadmind: starting...
kdc_1        | Checking the availablility of the keytab
kdc_1        | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1        | K/M@EXAMPLE.COM
kdc_1        | admin/admin@EXAMPLE.COM
kdc_1        | kadmin/3b3f709987d1@EXAMPLE.COM
kdc_1        | kadmin/admin@EXAMPLE.COM
kdc_1        | kadmin/changepw@EXAMPLE.COM
kdc_1        | kiprop/3b3f709987d1@EXAMPLE.COM
kdc_1        | krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 28 02:31:32 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 28 02:31:32 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1611801092, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1        | Jan 28 02:31:33 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 28 02:31:33 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1611801093, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1        | Jan 28 02:31:34 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 28 02:31:34 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1611801094, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1        | Jan 28 02:31:35 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 28 02:31:35 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1611801095, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1        | Jan 28 02:31:36 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 28 02:31:36 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1611801096, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1        | Jan 28 02:31:36 kdc kadmind[24](info): setting up network...
kdc_1        | kadmind: setsockopt(9,IPV6_V6ONLY,1) worked
kdc_1        | kadmind: setsockopt(11,IPV6_V6ONLY,1) worked
kdc_1        | kadmind: setsockopt(13,IPV6_V6ONLY,1) worked
kdc_1        | Jan 28 02:31:36 kdc kadmind[24](info): set up 6 sockets
kdc_1        | Jan 28 02:31:36 kdc kadmind[24](info): Seeding random number generator
kdc_1        | Jan 28 02:31:36 kdc kadmind[24](info): starting
kdc_1        | Jan 28 02:31:36 kdc kadmind[24](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1        | Jan 28 02:31:36 kdc kadmind[24](Notice): Request: kadm5_get_principals, *, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:36 kdc kadmind[24](info): closing down fd 18
kdc_1        | Generating keytab
kdc_1        | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1        | Issuer is listening on : 8081WARNING: no policy specified for test/test@EXAMPLE.COM; defaulting to no policy
kdc_1        | Principal "test/test@EXAMPLE.COM" created.
kdc_1        | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1        | Entry for principal test/test@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/test.test.keytab.
kdc_1        | Entry for principal test/test@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/test.test.keytab.
kdc_1        | Generating keytab
kdc_1        | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1        | WARNING: no policy specified for dn/d5a2d8142681@EXAMPLE.COM; defaulting to no policy
kdc_1        | Principal "dn/d5a2d8142681@EXAMPLE.COM" created.
kdc_1        | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1        | Entry for principal dn/d5a2d8142681@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.d5a2d8142681.keytab.
kdc_1        | Entry for principal dn/d5a2d8142681@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.d5a2d8142681.keytab.
kdc_1        | Generating keytab
kdc_1        | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1        | WARNING: no policy specified for HTTP/d5a2d8142681@EXAMPLE.COM; defaulting to no policy
kdc_1        | Principal "HTTP/d5a2d8142681@EXAMPLE.COM" created.
kdc_1        | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1        | Entry for principal HTTP/d5a2d8142681@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.d5a2d8142681.keytab.
kdc_1        | Entry for principal HTTP/d5a2d8142681@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.d5a2d8142681.keytab.
kdc_1        | Generating keytab
kdc_1        | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1        | WARNING: no policy specified for om/om1@EXAMPLE.COM; defaulting to no policy
kdc_1        | Principal "om/om1@EXAMPLE.COM" created.
kdc_1        | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1        | Entry for principal om/om1@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.om1.keytab.
kdc_1        | Entry for principal om/om1@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.om1.keytab.
kdc_1        | Generating keytab
kdc_1        | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1        | WARNING: no policy specified for HTTP/om1@EXAMPLE.COM; defaulting to no policy
kdc_1        | Principal "HTTP/om1@EXAMPLE.COM" created.
kdc_1        | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode2_1  | 2021-01-28 02:33:14,562 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode2_1  | 2021-01-28 02:33:14,562 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode2_1  | 2021-01-28 02:33:14,563 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode2_1  | 2021-01-28 02:33:14,563 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode2_1  | 2021-01-28 02:33:14,563 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode2_1  | 2021-01-28 02:33:14,568 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode2_1  | 2021-01-28 02:33:14,571 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-B28675BAAFBC-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode2_1  | 2021-01-28 02:33:14,572 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-B28675BAAFBC-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode2_1  | 2021-01-28 02:33:14,580 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode2_1  | 2021-01-28 02:33:14,628 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode2_1  | 2021-01-28 02:33:14,629 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode2_1  | 2021-01-28 02:33:14,629 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode2_1  | 2021-01-28 02:33:14,630 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode2_1  | 2021-01-28 02:33:14,630 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode2_1  | 2021-01-28 02:33:14,632 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-B28675BAAFBC
datanode2_1  | 2021-01-28 02:33:14,632 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-B28675BAAFBC
datanode2_1  | 2021-01-28 02:33:14,633 [pool-20-thread-1] INFO server.RaftServer$Division: 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-B28675BAAFBC: start as a follower, conf=-1: [6bab7c5a-f782-4236-88e0-70f071e2bf9c|rpc:172.25.0.103:9858|priority:1], old=null
datanode2_1  | 2021-01-28 02:33:14,635 [pool-20-thread-1] INFO server.RaftServer$Division: 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-B28675BAAFBC: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode2_1  | 2021-01-28 02:33:14,638 [pool-20-thread-1] INFO impl.RoleInfo: 6bab7c5a-f782-4236-88e0-70f071e2bf9c: start 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-B28675BAAFBC-FollowerState
datanode2_1  | 2021-01-28 02:33:14,654 [pool-20-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-B28675BAAFBC,id=6bab7c5a-f782-4236-88e0-70f071e2bf9c
datanode2_1  | 2021-01-28 02:33:14,655 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-B28675BAAFBC
datanode2_1  | 2021-01-28 02:33:14,656 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=f3928597-5304-49a3-b7ac-b28675baafbc.
datanode2_1  | 2021-01-28 02:33:19,731 [Thread-51] INFO impl.FollowerState: 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-B28675BAAFBC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5093072634ns, electionTimeout:5068ms
datanode2_1  | 2021-01-28 02:33:19,731 [Thread-51] INFO impl.RoleInfo: 6bab7c5a-f782-4236-88e0-70f071e2bf9c: shutdown 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-B28675BAAFBC-FollowerState
datanode2_1  | 2021-01-28 02:33:19,731 [Thread-51] INFO server.RaftServer$Division: 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-B28675BAAFBC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode2_1  | 2021-01-28 02:33:19,734 [Thread-51] INFO impl.RoleInfo: 6bab7c5a-f782-4236-88e0-70f071e2bf9c: start 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-B28675BAAFBC-LeaderElection1
datanode2_1  | 2021-01-28 02:33:19,750 [6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-B28675BAAFBC-LeaderElection1] INFO impl.LeaderElection: 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-B28675BAAFBC-LeaderElection1 PRE_VOTE round 0: submit vote requests at term 0 for -1: [6bab7c5a-f782-4236-88e0-70f071e2bf9c|rpc:172.25.0.103:9858|priority:1], old=null
datanode2_1  | 2021-01-28 02:33:19,750 [6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-B28675BAAFBC-LeaderElection1] INFO impl.LeaderElection: 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-B28675BAAFBC-LeaderElection1 PRE_VOTE round 0: result PASSED (term=0)
datanode2_1  | 2021-01-28 02:33:19,753 [6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-B28675BAAFBC-LeaderElection1] INFO impl.LeaderElection: 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-B28675BAAFBC-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [6bab7c5a-f782-4236-88e0-70f071e2bf9c|rpc:172.25.0.103:9858|priority:1], old=null
datanode2_1  | 2021-01-28 02:33:19,753 [6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-B28675BAAFBC-LeaderElection1] INFO impl.LeaderElection: 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-B28675BAAFBC-LeaderElection1 ELECTION round 0: result PASSED (term=1)
datanode2_1  | 2021-01-28 02:33:19,753 [6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-B28675BAAFBC-LeaderElection1] INFO impl.RoleInfo: 6bab7c5a-f782-4236-88e0-70f071e2bf9c: shutdown 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-B28675BAAFBC-LeaderElection1
datanode2_1  | 2021-01-28 02:33:19,754 [6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-B28675BAAFBC-LeaderElection1] INFO server.RaftServer$Division: 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-B28675BAAFBC: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode2_1  | 2021-01-28 02:33:19,754 [6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-B28675BAAFBC-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-B28675BAAFBC with new leaderId: 6bab7c5a-f782-4236-88e0-70f071e2bf9c
datanode2_1  | 2021-01-28 02:33:19,754 [6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-B28675BAAFBC-LeaderElection1] INFO server.RaftServer$Division: 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-B28675BAAFBC: change Leader from null to 6bab7c5a-f782-4236-88e0-70f071e2bf9c at term 1 for becomeLeader, leader elected after 5193ms
datanode2_1  | 2021-01-28 02:33:19,765 [6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-B28675BAAFBC-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode2_1  | 2021-01-28 02:33:19,783 [6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-B28675BAAFBC-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-B28675BAAFBC
datanode2_1  | 2021-01-28 02:33:19,785 [6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-B28675BAAFBC-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode2_1  | 2021-01-28 02:33:19,793 [6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-B28675BAAFBC-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode2_1  | 2021-01-28 02:33:19,853 [6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-B28675BAAFBC-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode2_1  | 2021-01-28 02:33:19,853 [6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-B28675BAAFBC-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode2_1  | 2021-01-28 02:33:19,857 [6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-B28675BAAFBC-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode2_1  | 2021-01-28 02:33:19,874 [6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-B28675BAAFBC-LeaderElection1] INFO impl.RoleInfo: 6bab7c5a-f782-4236-88e0-70f071e2bf9c: start 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-B28675BAAFBC-LeaderStateImpl
datanode2_1  | 2021-01-28 02:33:19,883 [6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-B28675BAAFBC-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-B28675BAAFBC-SegmentedRaftLogWorker: Starting segment from index:0
datanode2_1  | 2021-01-28 02:33:19,886 [6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-B28675BAAFBC-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-B28675BAAFBC-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/f3928597-5304-49a3-b7ac-b28675baafbc/current/log_inprogress_0
datanode2_1  | 2021-01-28 02:33:19,910 [6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-B28675BAAFBC-LeaderElection1] INFO server.RaftServer$Division: 6bab7c5a-f782-4236-88e0-70f071e2bf9c@group-B28675BAAFBC: set configuration 0: [6bab7c5a-f782-4236-88e0-70f071e2bf9c|rpc:172.25.0.103:9858|admin:|client:|dataStream:|priority:1], old=null
datanode2_1  | 2021-01-28 02:33:20,103 [ChunkWriter-0-0] INFO client.DNCertificateClient: Getting certificate with certSerialId:2420822746268.
datanode3_1  | Sleeping for 5 seconds
datanode3_1  | Setting up kerberos!!
datanode3_1  | KDC ISSUER_SERVER => kdc:8081
datanode3_1  | Sleeping for 5 seconds
datanode3_1  | Got 200, KDC service ready!!
datanode3_1  | Download dn/d5a2d8142681@EXAMPLE.COM keytab file to /etc/security/keytabs/dn.keytab
datanode3_1  | --2021-01-28 02:31:41--  http://kdc:8081/keytab/d5a2d8142681/dn
datanode3_1  | Resolving kdc (kdc)... 172.25.0.100
datanode3_1  | Connecting to kdc (kdc)|172.25.0.100|:8081... connected.
datanode3_1  | HTTP request sent, awaiting response... 200 OK
datanode3_1  | Length: 158 [application/octet-stream]
datanode3_1  | Saving to: '/etc/security/keytabs/dn.keytab'
datanode3_1  | 
datanode3_1  |      0K                                                       100% 27.4M=0s
datanode3_1  | 
datanode3_1  | 2021-01-28 02:31:42 (27.4 MB/s) - '/etc/security/keytabs/dn.keytab' saved [158/158]
datanode3_1  | 
datanode3_1  | Keytab name: FILE:/etc/security/keytabs/dn.keytab
datanode3_1  | KVNO Timestamp         Principal
datanode3_1  | ---- ----------------- --------------------------------------------------------
datanode3_1  |    2 01/28/21 02:31:42 dn/d5a2d8142681@EXAMPLE.COM
datanode3_1  |    2 01/28/21 02:31:42 dn/d5a2d8142681@EXAMPLE.COM
datanode3_1  | Download HTTP/d5a2d8142681@EXAMPLE.COM keytab file to /etc/security/keytabs/HTTP.keytab
datanode3_1  | --2021-01-28 02:31:42--  http://kdc:8081/keytab/d5a2d8142681/HTTP
datanode3_1  | Resolving kdc (kdc)... 172.25.0.100
datanode3_1  | Connecting to kdc (kdc)|172.25.0.100|:8081... connected.
datanode3_1  | HTTP request sent, awaiting response... 200 OK
datanode3_1  | Length: 162 [application/octet-stream]
datanode3_1  | Saving to: '/etc/security/keytabs/HTTP.keytab'
datanode3_1  | 
datanode3_1  |      0K                                                       100% 32.2M=0s
datanode3_1  | 
datanode3_1  | 2021-01-28 02:31:42 (32.2 MB/s) - '/etc/security/keytabs/HTTP.keytab' saved [162/162]
datanode3_1  | 
datanode3_1  | Keytab name: FILE:/etc/security/keytabs/HTTP.keytab
datanode3_1  | KVNO Timestamp         Principal
datanode3_1  | ---- ----------------- --------------------------------------------------------
datanode3_1  |    2 01/28/21 02:31:42 HTTP/d5a2d8142681@EXAMPLE.COM
datanode3_1  |    2 01/28/21 02:31:42 HTTP/d5a2d8142681@EXAMPLE.COM
datanode3_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode3_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode3_1  | 2021-01-28 02:31:48,782 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode3_1  | /************************************************************
datanode3_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode3_1  | STARTUP_MSG:   host = d5a2d8142681/172.25.0.104
datanode3_1  | STARTUP_MSG:   args = []
datanode3_1  | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
datanode3_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/javax.activation-api-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.2.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-1.1.0-SNAPSHOT.jar
datanode3_1  | STARTUP_MSG:   build = https://github.com/apache/ozone/42171e669d6c7f302fa379fc0289c4341f1cbf75 ; compiled by 'runner' on 2021-01-28T01:42Z
datanode3_1  | STARTUP_MSG:   java = 11.0.7
datanode3_1  | ************************************************************/
datanode3_1  | 2021-01-28 02:31:48,899 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode3_1  | 2021-01-28 02:31:50,977 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode3_1  | 2021-01-28 02:31:51,775 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode3_1  | 2021-01-28 02:31:52,743 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode3_1  | 2021-01-28 02:31:52,747 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode3_1  | 2021-01-28 02:31:53,620 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:d5a2d8142681 ip:172.25.0.104
datanode3_1  | 2021-01-28 02:31:57,904 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/_HOST@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode3_1  | 2021-01-28 02:31:59,301 [main] INFO security.UserGroupInformation: Login successful for user dn/d5a2d8142681@EXAMPLE.COM using keytab file /etc/security/keytabs/dn.keytab
datanode3_1  | 2021-01-28 02:31:59,327 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
datanode3_1  | 2021-01-28 02:31:59,328 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
datanode3_1  | 2021-01-28 02:31:59,329 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode3_1  | 2021-01-28 02:31:59,329 [main] INFO client.DNCertificateClient: Certificate client init case: 0
datanode3_1  | 2021-01-28 02:31:59,337 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode3_1  | 2021-01-28 02:32:02,339 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
datanode3_1  | 2021-01-28 02:32:02,409 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.104,host:d5a2d8142681
datanode3_1  | 2021-01-28 02:32:02,415 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode3_1  | 2021-01-28 02:32:02,418 [main] INFO ozone.HddsDatanodeService: Creating csr for DN-> subject:root@d5a2d8142681
datanode3_1  | 2021-01-28 02:32:05,981 [main] INFO ipc.Client: Retrying connect to server: scm/172.25.0.116:9961. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-01-28 02:32:06,982 [main] INFO ipc.Client: Retrying connect to server: scm/172.25.0.116:9961. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-01-28 02:32:07,983 [main] INFO ipc.Client: Retrying connect to server: scm/172.25.0.116:9961. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-01-28 02:32:08,984 [main] INFO ipc.Client: Retrying connect to server: scm/172.25.0.116:9961. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-01-28 02:32:09,985 [main] INFO ipc.Client: Retrying connect to server: scm/172.25.0.116:9961. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-01-28 02:32:10,986 [main] INFO ipc.Client: Retrying connect to server: scm/172.25.0.116:9961. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-01-28 02:32:11,987 [main] INFO ipc.Client: Retrying connect to server: scm/172.25.0.116:9961. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-01-28 02:32:12,988 [main] INFO ipc.Client: Retrying connect to server: scm/172.25.0.116:9961. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-01-28 02:32:13,989 [main] INFO ipc.Client: Retrying connect to server: scm/172.25.0.116:9961. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-01-28 02:32:14,990 [main] INFO ipc.Client: Retrying connect to server: scm/172.25.0.116:9961. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-01-28 02:32:15,991 [main] INFO ipc.Client: Retrying connect to server: scm/172.25.0.116:9961. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-01-28 02:32:16,992 [main] INFO ipc.Client: Retrying connect to server: scm/172.25.0.116:9961. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
kdc_1        | Entry for principal HTTP/om1@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.om1.keytab.
kdc_1        | Entry for principal HTTP/om1@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.om1.keytab.
kdc_1        | Generating keytab
kdc_1        | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1        | WARNING: no policy specified for scm/scm@EXAMPLE.COM; defaulting to no policy
kdc_1        | Principal "scm/scm@EXAMPLE.COM" created.
kdc_1        | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1        | Entry for principal scm/scm@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.scm.keytab.
kdc_1        | Entry for principal scm/scm@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.scm.keytab.
kdc_1        | Generating keytab
kdc_1        | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1        | WARNING: no policy specified for HTTP/scm@EXAMPLE.COM; defaulting to no policy
kdc_1        | Principal "HTTP/scm@EXAMPLE.COM" created.
kdc_1        | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1        | Jan 28 02:31:41 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 28 02:31:41 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1611801101, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1        | Jan 28 02:31:41 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 28 02:31:41 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1611801101, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1        | Jan 28 02:31:41 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 28 02:31:41 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1611801101, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1        | Jan 28 02:31:42 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 28 02:31:42 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1611801102, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1        | Jan 28 02:31:42 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 28 02:31:42 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1611801102, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1        | Jan 28 02:31:42 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 28 02:31:42 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1611801102, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1        | Jan 28 02:31:42 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 28 02:31:42 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1611801102, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1        | Jan 28 02:31:42 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 28 02:31:42 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1611801102, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1        | Jan 28 02:31:42 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 28 02:31:42 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1611801102, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1        | Jan 28 02:31:42 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 28 02:31:42 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1611801102, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1        | Jan 28 02:31:42 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 28 02:31:42 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1611801102, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1        | Jan 28 02:31:42 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 28 02:31:42 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1611801102, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1        | Jan 28 02:31:42 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 28 02:31:42 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1611801102, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1        | Jan 28 02:31:42 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 28 02:31:41 kdc kadmind[24](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1        | Jan 28 02:31:41 kdc kadmind[24](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:41 kdc kadmind[24](Notice): Request: kadm5_create_principal, test/test@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:41 kdc kadmind[24](info): closing down fd 18
kdc_1        | Jan 28 02:31:41 kdc kadmind[24](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1        | Jan 28 02:31:41 kdc kadmind[24](Notice): Request: kadm5_randkey_principal, test/test@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:41 kdc kadmind[24](Notice): Request: kadm5_get_principal, test/test@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:41 kdc kadmind[24](info): closing down fd 18
kdc_1        | Jan 28 02:31:41 kdc kadmind[24](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1        | Jan 28 02:31:41 kdc kadmind[24](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:41 kdc kadmind[24](Notice): Request: kadm5_create_principal, dn/d5a2d8142681@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:41 kdc kadmind[24](info): closing down fd 18
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](Notice): Request: kadm5_randkey_principal, dn/d5a2d8142681@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](Notice): Request: kadm5_get_principal, dn/d5a2d8142681@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](info): closing down fd 18
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](Notice): Request: kadm5_create_principal, HTTP/d5a2d8142681@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](info): closing down fd 18
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](Notice): Request: kadm5_randkey_principal, HTTP/d5a2d8142681@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](Notice): Request: kadm5_get_principal, HTTP/d5a2d8142681@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](info): closing down fd 18
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](Notice): Request: kadm5_create_principal, om/om1@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](info): closing down fd 18
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](Notice): Request: kadm5_randkey_principal, om/om1@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](Notice): Request: kadm5_get_principal, om/om1@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](info): closing down fd 18
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](Notice): Request: kadm5_create_principal, HTTP/om1@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](info): closing down fd 18
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](Notice): Request: kadm5_randkey_principal, HTTP/om1@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](Notice): Request: kadm5_get_principal, HTTP/om1@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](info): closing down fd 18
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](Notice): Request: kadm5_create_principal, scm/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](info): closing down fd 18
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](Notice): Request: kadm5_randkey_principal, scm/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](Notice): Request: kadm5_get_principal, scm/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](info): closing down fd 18
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](Notice): Request: kadm5_create_principal, HTTP/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](info): closing down fd 18
kdc_1        | Entry for principal HTTP/scm@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.scm.keytab.
kdc_1        | Entry for principal HTTP/scm@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.scm.keytab.
kdc_1        | Generating keytab
datanode3_1  | 2021-01-28 02:32:17,993 [main] INFO ipc.Client: Retrying connect to server: scm/172.25.0.116:9961. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-01-28 02:32:21,990 [main] INFO client.DNCertificateClient: Loading certificate from location:/data/metadata/dn/certs.
datanode3_1  | 2021-01-28 02:32:22,034 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/CA-1.crt.
datanode3_1  | 2021-01-28 02:32:22,047 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/2411677671379.crt.
datanode3_1  | 2021-01-28 02:32:22,047 [main] INFO ozone.HddsDatanodeService: Successfully stored SCM signed certificate, case:GETCERT.
datanode3_1  | 2021-01-28 02:32:22,968 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode3_1  | 2021-01-28 02:32:22,979 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode3_1  | 2021-01-28 02:32:22,983 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode3_1  | 2021-01-28 02:32:23,042 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode3_1  | 2021-01-28 02:32:23,265 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode3_1  | 2021-01-28 02:32:23,603 [Thread-7] INFO ozoneimpl.ContainerReader: Start to verify containers on volume /data/hdds/hdds
datanode3_1  | 2021-01-28 02:32:23,749 [Thread-7] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode3_1  | 2021-01-28 02:32:23,749 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode3_1  | 2021-01-28 02:32:28,644 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode3_1  | 2021-01-28 02:32:28,977 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode3_1  | 2021-01-28 02:32:29,394 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
datanode3_1  | 2021-01-28 02:32:29,411 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode3_1  | 2021-01-28 02:32:29,412 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
datanode3_1  | 2021-01-28 02:32:29,415 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode3_1  | 2021-01-28 02:32:29,415 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode3_1  | 2021-01-28 02:32:29,416 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode3_1  | 2021-01-28 02:32:29,418 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2021-01-28 02:32:29,421 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode3_1  | 2021-01-28 02:32:29,422 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode3_1  | 2021-01-28 02:32:31,535 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode3_1  | 2021-01-28 02:32:31,563 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode3_1  | 2021-01-28 02:32:31,579 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode3_1  | 2021-01-28 02:32:31,670 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode3_1  | 2021-01-28 02:32:31,680 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode3_1  | 2021-01-28 02:32:36,384 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode3_1  | 2021-01-28 02:32:36,385 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode3_1  | 2021-01-28 02:32:36,385 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.datanode.http.auth.type = kerberos
datanode3_1  | 2021-01-28 02:32:36,542 [main] INFO util.log: Logging initialized @54313ms to org.eclipse.jetty.util.log.Slf4jLog
datanode3_1  | 2021-01-28 02:32:37,323 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode3_1  | 2021-01-28 02:32:37,371 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode3_1  | 2021-01-28 02:32:37,373 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode3_1  | 2021-01-28 02:32:37,389 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode3_1  | 2021-01-28 02:32:37,395 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode3_1  | 2021-01-28 02:32:37,401 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.datanode.http.auth.kerberos.principal keytabKey: hdds.datanode.http.auth.kerberos.keytab
datanode3_1  | 2021-01-28 02:32:37,606 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode3_1  | 2021-01-28 02:32:37,608 [main] INFO server.Server: jetty-9.4.34.v20201102; built: 2020-11-02T14:15:39.302Z; git: e46af88704a893fc12cb0e3bf46e2c7b48a009e7; jvm 11.0.7+10-LTS
datanode3_1  | 2021-01-28 02:32:37,751 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode3_1  | 2021-01-28 02:32:37,751 [main] INFO server.session: No SessionScavenger set, using defaults
datanode3_1  | 2021-01-28 02:32:37,763 [main] INFO server.session: node0 Scavenging every 660000ms
datanode3_1  | 2021-01-28 02:32:37,885 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/d5a2d8142681@EXAMPLE.COM
datanode3_1  | 2021-01-28 02:32:37,897 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@9715d26{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode3_1  | 2021-01-28 02:32:37,904 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@79ae3fb1{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode3_1  | 2021-01-28 02:32:38,355 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/d5a2d8142681@EXAMPLE.COM
datanode3_1  | 2021-01-28 02:32:38,419 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@3083e6ef{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-1_1_0-SNAPSHOT_jar-_-any-11932111912403076426/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode3_1  | 2021-01-28 02:32:38,455 [main] INFO server.AbstractConnector: Started ServerConnector@6b170692{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode3_1  | 2021-01-28 02:32:38,471 [main] INFO server.Server: Started @56225ms
datanode3_1  | 2021-01-28 02:32:38,499 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode3_1  | 2021-01-28 02:32:38,499 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode3_1  | 2021-01-28 02:32:38,564 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode3_1  | 2021-01-28 02:32:38,680 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@44097df9] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode3_1  | 2021-01-28 02:32:38,963 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.25.0.115:9891
datanode3_1  | 2021-01-28 02:32:41,327 [EndpointStateMachine task thread for scm/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
kms_1        | Sleeping for 5 seconds
kms_1        | Setting up kerberos!!
kms_1        | KDC ISSUER_SERVER => kdc:8081
kms_1        | /opt/starter.sh: line 66: SLEEP_SECONDS: command not found
kms_1        | Sleeping for  seconds
kms_1        | Got 200, KDC service ready!!
kms_1        | # Licensed to the Apache Software Foundation (ASF) under one or more
kms_1        | # contributor license agreements.  See the NOTICE file distributed with
kms_1        | # this work for additional information regarding copyright ownership.
kms_1        | # The ASF licenses this file to You under the Apache License, Version 2.0
kms_1        | # (the "License"); you may not use this file except in compliance with
kms_1        | # the License.  You may obtain a copy of the License at
kms_1        | #
kms_1        | #     http://www.apache.org/licenses/LICENSE-2.0
kms_1        | #
kms_1        | # Unless required by applicable law or agreed to in writing, software
kms_1        | # distributed under the License is distributed on an "AS IS" BASIS,
kms_1        | # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
kms_1        | # See the License for the specific language governing permissions and
kms_1        | # limitations under the License.
kms_1        | 
kms_1        | [logging]
kms_1        |  default = FILE:/var/log/krb5libs.log
kms_1        |  kdc = FILE:/var/log/krb5kdc.log
kms_1        |  admin_server = FILE:/var/log/kadmind.log
kms_1        | 
kms_1        | [libdefaults]
kms_1        |  dns_canonicalize_hostname = false
kms_1        |  dns_lookup_realm = false
kms_1        |  ticket_lifetime = 24h
kms_1        |  renew_lifetime = 7d
kms_1        |  forwardable = true
kms_1        |  rdns = false
kms_1        |  default_realm = EXAMPLE.COM
kms_1        | 
kms_1        | [realms]
kms_1        |  EXAMPLE.COM = {
kms_1        |   kdc = kdc
kms_1        |   admin_server = kdc
kms_1        |  }
kms_1        | 
kms_1        | [domain_realm]
kms_1        |  .example.com = EXAMPLE.COM
kms_1        | WARNING: /opt/hadoop/temp does not exist. Creating.
kdc_1        | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1        | WARNING: no policy specified for testuser/scm@EXAMPLE.COM; defaulting to no policy
kdc_1        | Principal "testuser/scm@EXAMPLE.COM" created.
kdc_1        | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1        | Entry for principal testuser/scm@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.scm.keytab.
kdc_1        | Entry for principal testuser/scm@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.scm.keytab.
kdc_1        | Generating keytab
kdc_1        | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1        | WARNING: no policy specified for testuser2/scm@EXAMPLE.COM; defaulting to no policy
kdc_1        | Principal "testuser2/scm@EXAMPLE.COM" created.
kdc_1        | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1        | Entry for principal testuser2/scm@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.scm.keytab.
kdc_1        | Entry for principal testuser2/scm@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.scm.keytab.
kdc_1        | Generating keytab
kdc_1        | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1        | WARNING: no policy specified for s3g/s3g@EXAMPLE.COM; defaulting to no policy
kdc_1        | Principal "s3g/s3g@EXAMPLE.COM" created.
kdc_1        | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1        | Entry for principal s3g/s3g@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.s3g.keytab.
kdc_1        | Entry for principal s3g/s3g@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.s3g.keytab.
kdc_1        | Generating keytab
kdc_1        | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1        | WARNING: no policy specified for dn/db0158eeb642@EXAMPLE.COM; defaulting to no policy
kdc_1        | Principal "dn/db0158eeb642@EXAMPLE.COM" created.
kdc_1        | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1        | Entry for principal dn/db0158eeb642@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.db0158eeb642.keytab.
kdc_1        | Entry for principal dn/db0158eeb642@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.db0158eeb642.keytab.
kdc_1        | Generating keytab
kdc_1        | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1        | WARNING: no policy specified for HTTP/s3g@EXAMPLE.COM; defaulting to no policy
kdc_1        | Principal "HTTP/s3g@EXAMPLE.COM" created.
kdc_1        | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1        | Entry for principal HTTP/s3g@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.s3g.keytab.
kdc_1        | Entry for principal HTTP/s3g@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.s3g.keytab.
kdc_1        | Generating keytab
kdc_1        | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1        | WARNING: no policy specified for HTTP/db0158eeb642@EXAMPLE.COM; defaulting to no policy
kdc_1        | Principal "HTTP/db0158eeb642@EXAMPLE.COM" created.
kdc_1        | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1        | Entry for principal HTTP/db0158eeb642@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.db0158eeb642.keytab.
kdc_1        | Entry for principal HTTP/db0158eeb642@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.db0158eeb642.keytab.
kdc_1        | Generating keytab
kdc_1        | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1        | WARNING: no policy specified for testuser/s3g@EXAMPLE.COM; defaulting to no policy
kdc_1        | Principal "testuser/s3g@EXAMPLE.COM" created.
kdc_1        | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1        | Entry for principal testuser/s3g@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.s3g.keytab.
kdc_1        | Entry for principal testuser/s3g@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.s3g.keytab.
kdc_1        | Jan 28 02:31:42 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1611801102, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1        | Jan 28 02:31:42 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 28 02:31:42 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1611801102, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1        | Jan 28 02:31:42 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 28 02:31:42 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1611801102, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1        | Jan 28 02:31:42 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 28 02:31:42 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1611801102, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1        | Jan 28 02:31:42 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 28 02:31:42 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1611801102, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1        | Jan 28 02:31:42 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 28 02:31:42 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1611801102, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1        | Jan 28 02:31:42 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 28 02:31:42 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1611801102, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1        | Jan 28 02:31:42 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 28 02:31:42 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1611801102, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1        | Jan 28 02:31:42 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 28 02:31:42 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1611801102, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1        | Jan 28 02:31:42 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 28 02:31:42 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1611801102, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1        | Jan 28 02:31:42 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 28 02:31:42 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1611801102, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1        | Jan 28 02:31:42 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 28 02:31:42 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1611801102, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1        | Jan 28 02:31:42 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 28 02:31:43 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1611801103, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1        | Jan 28 02:31:43 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 28 02:31:43 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1611801103, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1        | Jan 28 02:31:43 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 28 02:31:43 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1611801103, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](Notice): Request: kadm5_randkey_principal, HTTP/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](Notice): Request: kadm5_get_principal, HTTP/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](info): closing down fd 18
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](Notice): Request: kadm5_create_principal, testuser/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](info): closing down fd 18
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](Notice): Request: kadm5_randkey_principal, testuser/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](Notice): Request: kadm5_get_principal, testuser/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](info): closing down fd 18
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](Notice): Request: kadm5_create_principal, testuser2/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](info): closing down fd 18
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](Notice): Request: kadm5_randkey_principal, testuser2/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](Notice): Request: kadm5_get_principal, testuser2/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](info): closing down fd 18
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](Notice): Request: kadm5_create_principal, s3g/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](info): closing down fd 18
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](Notice): Request: kadm5_randkey_principal, s3g/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](Notice): Request: kadm5_get_principal, s3g/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](info): closing down fd 18
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode3_1  | 2021-01-28 02:32:41,333 [EndpointStateMachine task thread for scm/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode3_1  | 2021-01-28 02:32:41,685 [EndpointStateMachine task thread for scm/172.25.0.116:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis feb6bea5-edd2-410b-8ad4-c920818f117a at port 9858
datanode3_1  | 2021-01-28 02:32:41,774 [EndpointStateMachine task thread for scm/172.25.0.116:9861 - 0 ] INFO server.RaftServer: feb6bea5-edd2-410b-8ad4-c920818f117a: start RPC server
datanode3_1  | 2021-01-28 02:32:41,789 [EndpointStateMachine task thread for scm/172.25.0.116:9861 - 0 ] INFO server.GrpcService: feb6bea5-edd2-410b-8ad4-c920818f117a: GrpcService started, listening on 9858
datanode3_1  | 2021-01-28 02:32:41,840 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$301/0x000000084052e840@791db9ac] INFO util.JvmPauseMonitor: JvmPauseMonitor-feb6bea5-edd2-410b-8ad4-c920818f117a: Started
datanode3_1  | 2021-01-28 02:32:45,891 [Command processor thread] INFO server.RaftServer: feb6bea5-edd2-410b-8ad4-c920818f117a: addNew group-97A240718454:[feb6bea5-edd2-410b-8ad4-c920818f117a|rpc:172.25.0.104:9858|priority:1] returns group-97A240718454:java.util.concurrent.CompletableFuture@5696ddfd[Not completed]
datanode3_1  | 2021-01-28 02:32:46,044 [pool-20-thread-1] INFO server.RaftServer$Division: feb6bea5-edd2-410b-8ad4-c920818f117a: new RaftServerImpl for group-97A240718454:[feb6bea5-edd2-410b-8ad4-c920818f117a|rpc:172.25.0.104:9858|priority:1] with ContainerStateMachine:uninitialized
datanode3_1  | 2021-01-28 02:32:46,048 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode3_1  | 2021-01-28 02:32:46,050 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode3_1  | 2021-01-28 02:32:46,051 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode3_1  | 2021-01-28 02:32:46,051 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode3_1  | 2021-01-28 02:32:46,051 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode3_1  | 2021-01-28 02:32:46,051 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode3_1  | 2021-01-28 02:32:46,067 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2021-01-28 02:32:46,074 [pool-20-thread-1] INFO server.RaftServer$Division: feb6bea5-edd2-410b-8ad4-c920818f117a@group-97A240718454: ConfigurationManager, init=-1: [feb6bea5-edd2-410b-8ad4-c920818f117a|rpc:172.25.0.104:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode3_1  | 2021-01-28 02:32:46,087 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode3_1  | 2021-01-28 02:32:46,131 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode3_1  | 2021-01-28 02:32:46,133 [pool-20-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/39c789b6-0c46-456e-8a71-97a240718454 does not exist. Creating ...
datanode3_1  | 2021-01-28 02:32:46,148 [pool-20-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/39c789b6-0c46-456e-8a71-97a240718454/in_use.lock acquired by nodename 6@d5a2d8142681
datanode3_1  | 2021-01-28 02:32:46,180 [pool-20-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/39c789b6-0c46-456e-8a71-97a240718454 has been successfully formatted.
datanode3_1  | 2021-01-28 02:32:46,218 [pool-20-thread-1] INFO ratis.ContainerStateMachine: group-97A240718454: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode3_1  | 2021-01-28 02:32:46,219 [pool-20-thread-1] ERROR storage.RaftStorage: Failed reading configuration from file:/data/metadata/ratis/39c789b6-0c46-456e-8a71-97a240718454/current/raft-meta.conf
datanode3_1  | java.io.FileNotFoundException: /data/metadata/ratis/39c789b6-0c46-456e-8a71-97a240718454/current/raft-meta.conf (No such file or directory)
datanode3_1  | 	at java.base/java.io.FileInputStream.open0(Native Method)
datanode3_1  | 	at java.base/java.io.FileInputStream.open(FileInputStream.java:219)
datanode3_1  | 	at java.base/java.io.FileInputStream.<init>(FileInputStream.java:157)
datanode3_1  | 	at org.apache.ratis.server.storage.RaftStorageImpl.readRaftConfiguration(RaftStorageImpl.java:143)
datanode3_1  | 	at org.apache.ratis.server.impl.ServerState.<init>(ServerState.java:122)
datanode3_1  | 	at org.apache.ratis.server.impl.RaftServerImpl.<init>(RaftServerImpl.java:193)
datanode3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.lambda$newRaftServerImpl$4(RaftServerProxy.java:266)
datanode3_1  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode3_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode3_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode3_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode3_1  | 2021-01-28 02:32:46,264 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode3_1  | 2021-01-28 02:32:46,272 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode3_1  | 2021-01-28 02:32:46,327 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode3_1  | 2021-01-28 02:32:46,327 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2021-01-28 02:32:46,341 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.feb6bea5-edd2-410b-8ad4-c920818f117a@group-97A240718454
datanode3_1  | 2021-01-28 02:32:46,413 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2021-01-28 02:32:46,447 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode3_1  | 2021-01-28 02:32:46,470 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode3_1  | 2021-01-28 02:32:46,494 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: new feb6bea5-edd2-410b-8ad4-c920818f117a@group-97A240718454-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/39c789b6-0c46-456e-8a71-97a240718454
datanode3_1  | 2021-01-28 02:32:46,495 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode3_1  | 2021-01-28 02:32:46,496 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode3_1  | 2021-01-28 02:32:46,512 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2021-01-28 02:32:46,513 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode3_1  | 2021-01-28 02:32:46,513 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode3_1  | 2021-01-28 02:32:46,518 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode3_1  | 2021-01-28 02:32:46,530 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode3_1  | 2021-01-28 02:32:46,531 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode3_1  | 2021-01-28 02:32:46,602 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](Notice): Request: kadm5_create_principal, dn/db0158eeb642@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](info): closing down fd 18
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](Notice): Request: kadm5_randkey_principal, dn/db0158eeb642@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](Notice): Request: kadm5_get_principal, dn/db0158eeb642@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](info): closing down fd 18
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](Notice): Request: kadm5_create_principal, HTTP/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](info): closing down fd 18
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](Notice): Request: kadm5_randkey_principal, HTTP/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](Notice): Request: kadm5_get_principal, HTTP/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](info): closing down fd 18
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](Notice): Request: kadm5_create_principal, HTTP/db0158eeb642@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:42 kdc kadmind[24](info): closing down fd 18
kdc_1        | Jan 28 02:31:43 kdc kadmind[24](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1        | Jan 28 02:31:43 kdc kadmind[24](Notice): Request: kadm5_randkey_principal, HTTP/db0158eeb642@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:43 kdc kadmind[24](Notice): Request: kadm5_get_principal, HTTP/db0158eeb642@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:43 kdc kadmind[24](info): closing down fd 18
kdc_1        | Jan 28 02:31:43 kdc kadmind[24](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1        | Jan 28 02:31:43 kdc kadmind[24](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:43 kdc kadmind[24](Notice): Request: kadm5_create_principal, testuser/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:43 kdc kadmind[24](info): closing down fd 18
kdc_1        | Jan 28 02:31:43 kdc kadmind[24](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1        | Jan 28 02:31:43 kdc kadmind[24](Notice): Request: kadm5_randkey_principal, testuser/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:43 kdc kadmind[24](Notice): Request: kadm5_get_principal, testuser/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:43 kdc kadmind[24](info): closing down fd 18
kdc_1        | Generating keytab
kdc_1        | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1        | WARNING: no policy specified for recon/recon@EXAMPLE.COM; defaulting to no policy
kdc_1        | Principal "recon/recon@EXAMPLE.COM" created.
kdc_1        | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1        | Entry for principal recon/recon@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/recon.recon.keytab.
kdc_1        | Entry for principal recon/recon@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/recon.recon.keytab.
kdc_1        | Generating keytab
kdc_1        | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1        | WARNING: no policy specified for om/om3@EXAMPLE.COM; defaulting to no policy
kdc_1        | Principal "om/om3@EXAMPLE.COM" created.
kdc_1        | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1        | Entry for principal om/om3@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.om3.keytab.
kdc_1        | Entry for principal om/om3@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.om3.keytab.
kdc_1        | Generating keytab
kdc_1        | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1        | WARNING: no policy specified for dn/d20fde691356@EXAMPLE.COM; defaulting to no policy
kdc_1        | Principal "dn/d20fde691356@EXAMPLE.COM" created.
kdc_1        | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1        | Entry for principal dn/d20fde691356@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.d20fde691356.keytab.
kdc_1        | Entry for principal dn/d20fde691356@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.d20fde691356.keytab.
kdc_1        | Generating keytab
kdc_1        | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1        | WARNING: no policy specified for HTTP/recon@EXAMPLE.COM; defaulting to no policy
kdc_1        | Principal "HTTP/recon@EXAMPLE.COM" created.
kdc_1        | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1        | Entry for principal HTTP/recon@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.recon.keytab.
kdc_1        | Entry for principal HTTP/recon@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.recon.keytab.
kdc_1        | Generating keytab
kdc_1        | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1        | WARNING: no policy specified for HTTP/om3@EXAMPLE.COM; defaulting to no policy
kdc_1        | Principal "HTTP/om3@EXAMPLE.COM" created.
kdc_1        | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1        | Entry for principal HTTP/om3@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.om3.keytab.
kdc_1        | Entry for principal HTTP/om3@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.om3.keytab.
kdc_1        | Generating keytab
kdc_1        | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1        | WARNING: no policy specified for HTTP/d20fde691356@EXAMPLE.COM; defaulting to no policy
kdc_1        | Principal "HTTP/d20fde691356@EXAMPLE.COM" created.
kdc_1        | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1        | Entry for principal HTTP/d20fde691356@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.d20fde691356.keytab.
kdc_1        | Entry for principal HTTP/d20fde691356@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.d20fde691356.keytab.
kdc_1        | Jan 28 02:31:43 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 28 02:31:43 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1611801103, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1        | Jan 28 02:31:43 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 28 02:31:43 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1611801103, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1        | Jan 28 02:31:43 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 28 02:31:43 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1611801103, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1        | Jan 28 02:31:43 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 28 02:31:43 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1611801103, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1        | Jan 28 02:31:44 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 28 02:31:44 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1611801104, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1        | Jan 28 02:31:44 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 28 02:31:44 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1611801104, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1        | Jan 28 02:31:44 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 28 02:31:44 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1611801104, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1        | Jan 28 02:31:44 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 28 02:31:44 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1611801104, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1        | Jan 28 02:31:44 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 28 02:31:44 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1611801104, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1        | Jan 28 02:31:44 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 28 02:31:44 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1611801104, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1        | Jan 28 02:31:44 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 28 02:31:44 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1611801104, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1        | Jan 28 02:31:44 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 28 02:31:44 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1611801104, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1        | Jan 28 02:31:43 kdc kadmind[24](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1        | Jan 28 02:31:43 kdc kadmind[24](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:43 kdc kadmind[24](Notice): Request: kadm5_create_principal, recon/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:43 kdc kadmind[24](info): closing down fd 18
kdc_1        | Jan 28 02:31:43 kdc kadmind[24](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1        | Jan 28 02:31:43 kdc kadmind[24](Notice): Request: kadm5_randkey_principal, recon/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:43 kdc kadmind[24](Notice): Request: kadm5_get_principal, recon/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:43 kdc kadmind[24](info): closing down fd 18
kdc_1        | Jan 28 02:31:43 kdc kadmind[24](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1        | Jan 28 02:31:43 kdc kadmind[24](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:43 kdc kadmind[24](Notice): Request: kadm5_create_principal, om/om3@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:43 kdc kadmind[24](info): closing down fd 18
kdc_1        | Jan 28 02:31:43 kdc kadmind[24](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1        | Jan 28 02:31:43 kdc kadmind[24](Notice): Request: kadm5_randkey_principal, om/om3@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:43 kdc kadmind[24](Notice): Request: kadm5_get_principal, om/om3@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:43 kdc kadmind[24](info): closing down fd 18
kdc_1        | Jan 28 02:31:44 kdc kadmind[24](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1        | Jan 28 02:31:44 kdc kadmind[24](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:44 kdc kadmind[24](Notice): Request: kadm5_create_principal, dn/d20fde691356@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:44 kdc kadmind[24](info): closing down fd 18
kdc_1        | Jan 28 02:31:44 kdc kadmind[24](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1        | Jan 28 02:31:44 kdc kadmind[24](Notice): Request: kadm5_randkey_principal, dn/d20fde691356@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:44 kdc kadmind[24](Notice): Request: kadm5_get_principal, dn/d20fde691356@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:44 kdc kadmind[24](info): closing down fd 18
kdc_1        | Jan 28 02:31:44 kdc kadmind[24](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1        | Jan 28 02:31:44 kdc kadmind[24](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:44 kdc kadmind[24](Notice): Request: kadm5_create_principal, HTTP/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:44 kdc kadmind[24](info): closing down fd 18
kdc_1        | Jan 28 02:31:44 kdc kadmind[24](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1        | Jan 28 02:31:44 kdc kadmind[24](Notice): Request: kadm5_randkey_principal, HTTP/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:44 kdc kadmind[24](Notice): Request: kadm5_get_principal, HTTP/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:44 kdc kadmind[24](info): closing down fd 18
kdc_1        | Jan 28 02:31:44 kdc kadmind[24](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1        | Jan 28 02:31:44 kdc kadmind[24](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:44 kdc kadmind[24](Notice): Request: kadm5_create_principal, HTTP/om3@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:44 kdc kadmind[24](info): closing down fd 18
kdc_1        | Jan 28 02:31:44 kdc kadmind[24](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1        | Jan 28 02:31:44 kdc kadmind[24](Notice): Request: kadm5_randkey_principal, HTTP/om3@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:44 kdc kadmind[24](Notice): Request: kadm5_get_principal, HTTP/om3@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:44 kdc kadmind[24](info): closing down fd 18
kdc_1        | Jan 28 02:31:44 kdc kadmind[24](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1        | Jan 28 02:31:44 kdc kadmind[24](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:44 kdc kadmind[24](Notice): Request: kadm5_create_principal, HTTP/d20fde691356@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:44 kdc kadmind[24](info): closing down fd 18
kdc_1        | Jan 28 02:31:44 kdc kadmind[24](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1        | Jan 28 02:31:44 kdc kadmind[24](Notice): Request: kadm5_randkey_principal, HTTP/d20fde691356@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:44 kdc kadmind[24](Notice): Request: kadm5_get_principal, HTTP/d20fde691356@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:44 kdc kadmind[24](info): closing down fd 18
kdc_1        | Generating keytab
kdc_1        | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1        | WARNING: no policy specified for om/om2@EXAMPLE.COM; defaulting to no policy
kdc_1        | Principal "om/om2@EXAMPLE.COM" created.
kdc_1        | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1        | Entry for principal om/om2@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.om2.keytab.
kdc_1        | Entry for principal om/om2@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.om2.keytab.
kdc_1        | Generating keytab
kdc_1        | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1        | WARNING: no policy specified for HTTP/om2@EXAMPLE.COM; defaulting to no policy
datanode3_1  | 2021-01-28 02:32:46,605 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode3_1  | 2021-01-28 02:32:46,641 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: feb6bea5-edd2-410b-8ad4-c920818f117a@group-97A240718454-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode3_1  | 2021-01-28 02:32:46,642 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: feb6bea5-edd2-410b-8ad4-c920818f117a@group-97A240718454-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode3_1  | 2021-01-28 02:32:46,664 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode3_1  | 2021-01-28 02:32:46,668 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode3_1  | 2021-01-28 02:32:46,672 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode3_1  | 2021-01-28 02:32:46,680 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode3_1  | 2021-01-28 02:32:46,682 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode3_1  | 2021-01-28 02:32:46,687 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode3_1  | 2021-01-28 02:32:46,789 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.feb6bea5-edd2-410b-8ad4-c920818f117a@group-97A240718454
datanode3_1  | 2021-01-28 02:32:46,824 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.feb6bea5-edd2-410b-8ad4-c920818f117a@group-97A240718454
datanode3_1  | 2021-01-28 02:32:46,858 [pool-20-thread-1] INFO server.RaftServer$Division: feb6bea5-edd2-410b-8ad4-c920818f117a@group-97A240718454: start as a follower, conf=-1: [feb6bea5-edd2-410b-8ad4-c920818f117a|rpc:172.25.0.104:9858|priority:1], old=null
datanode3_1  | 2021-01-28 02:32:46,864 [pool-20-thread-1] INFO server.RaftServer$Division: feb6bea5-edd2-410b-8ad4-c920818f117a@group-97A240718454: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode3_1  | 2021-01-28 02:32:46,866 [pool-20-thread-1] INFO impl.RoleInfo: feb6bea5-edd2-410b-8ad4-c920818f117a: start feb6bea5-edd2-410b-8ad4-c920818f117a@group-97A240718454-FollowerState
datanode3_1  | 2021-01-28 02:32:46,887 [pool-20-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-97A240718454,id=feb6bea5-edd2-410b-8ad4-c920818f117a
datanode3_1  | 2021-01-28 02:32:46,896 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.feb6bea5-edd2-410b-8ad4-c920818f117a@group-97A240718454
datanode3_1  | 2021-01-28 02:32:46,959 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=39c789b6-0c46-456e-8a71-97a240718454.
datanode3_1  | 2021-01-28 02:32:46,963 [Command processor thread] INFO server.RaftServer: feb6bea5-edd2-410b-8ad4-c920818f117a: addNew group-A71B52063026:[feb6bea5-edd2-410b-8ad4-c920818f117a|rpc:172.25.0.104:9858|priority:0, bb31b8e2-b35d-4b3b-ae90-43363de8a349|rpc:172.25.0.102:9858|priority:1, 6bab7c5a-f782-4236-88e0-70f071e2bf9c|rpc:172.25.0.103:9858|priority:0] returns group-A71B52063026:java.util.concurrent.CompletableFuture@24b8e5d7[Not completed]
datanode3_1  | 2021-01-28 02:32:46,979 [pool-20-thread-1] INFO server.RaftServer$Division: feb6bea5-edd2-410b-8ad4-c920818f117a: new RaftServerImpl for group-A71B52063026:[feb6bea5-edd2-410b-8ad4-c920818f117a|rpc:172.25.0.104:9858|priority:0, bb31b8e2-b35d-4b3b-ae90-43363de8a349|rpc:172.25.0.102:9858|priority:1, 6bab7c5a-f782-4236-88e0-70f071e2bf9c|rpc:172.25.0.103:9858|priority:0] with ContainerStateMachine:uninitialized
datanode3_1  | 2021-01-28 02:32:46,984 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode3_1  | 2021-01-28 02:32:46,984 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode3_1  | 2021-01-28 02:32:46,985 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode3_1  | 2021-01-28 02:32:46,985 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode3_1  | 2021-01-28 02:32:46,986 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode3_1  | 2021-01-28 02:32:46,986 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode3_1  | 2021-01-28 02:32:46,986 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2021-01-28 02:32:46,986 [pool-20-thread-1] INFO server.RaftServer$Division: feb6bea5-edd2-410b-8ad4-c920818f117a@group-A71B52063026: ConfigurationManager, init=-1: [feb6bea5-edd2-410b-8ad4-c920818f117a|rpc:172.25.0.104:9858|priority:0, bb31b8e2-b35d-4b3b-ae90-43363de8a349|rpc:172.25.0.102:9858|priority:1, 6bab7c5a-f782-4236-88e0-70f071e2bf9c|rpc:172.25.0.103:9858|priority:0], old=null, confs=<EMPTY_MAP>
datanode3_1  | 2021-01-28 02:32:46,986 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode3_1  | 2021-01-28 02:32:46,987 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode3_1  | 2021-01-28 02:32:46,987 [pool-20-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/45d6c387-0d5e-4ec1-887d-a71b52063026 does not exist. Creating ...
datanode3_1  | 2021-01-28 02:32:46,988 [pool-20-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/45d6c387-0d5e-4ec1-887d-a71b52063026/in_use.lock acquired by nodename 6@d5a2d8142681
datanode3_1  | 2021-01-28 02:32:46,995 [pool-20-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/45d6c387-0d5e-4ec1-887d-a71b52063026 has been successfully formatted.
datanode3_1  | 2021-01-28 02:32:46,998 [pool-20-thread-1] INFO ratis.ContainerStateMachine: group-A71B52063026: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode3_1  | 2021-01-28 02:32:47,000 [pool-20-thread-1] ERROR storage.RaftStorage: Failed reading configuration from file:/data/metadata/ratis/45d6c387-0d5e-4ec1-887d-a71b52063026/current/raft-meta.conf
datanode3_1  | java.io.FileNotFoundException: /data/metadata/ratis/45d6c387-0d5e-4ec1-887d-a71b52063026/current/raft-meta.conf (No such file or directory)
datanode3_1  | 	at java.base/java.io.FileInputStream.open0(Native Method)
datanode3_1  | 	at java.base/java.io.FileInputStream.open(FileInputStream.java:219)
datanode3_1  | 	at java.base/java.io.FileInputStream.<init>(FileInputStream.java:157)
datanode3_1  | 	at org.apache.ratis.server.storage.RaftStorageImpl.readRaftConfiguration(RaftStorageImpl.java:143)
datanode3_1  | 	at org.apache.ratis.server.impl.ServerState.<init>(ServerState.java:122)
datanode3_1  | 	at org.apache.ratis.server.impl.RaftServerImpl.<init>(RaftServerImpl.java:193)
datanode3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.lambda$newRaftServerImpl$4(RaftServerProxy.java:266)
datanode3_1  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode3_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode3_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode3_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode3_1  | 2021-01-28 02:32:47,007 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode3_1  | 2021-01-28 02:32:47,007 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
kdc_1        | Principal "HTTP/om2@EXAMPLE.COM" created.
kdc_1        | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1        | Entry for principal HTTP/om2@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.om2.keytab.
kdc_1        | Entry for principal HTTP/om2@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.om2.keytab.
kdc_1        | Jan 28 02:31:44 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 28 02:31:44 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.25.0.116: ISSUE: authtime 1611801104, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 28 02:31:44 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1611801104, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1        | Jan 28 02:31:44 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 28 02:31:44 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1611801104, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1        | Jan 28 02:31:44 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 28 02:31:44 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1611801104, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1        | Jan 28 02:31:44 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 28 02:31:44 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1611801104, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1        | Jan 28 02:31:44 kdc kadmind[24](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1        | Jan 28 02:31:44 kdc kadmind[24](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:44 kdc kadmind[24](Notice): Request: kadm5_create_principal, om/om2@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:44 kdc kadmind[24](info): closing down fd 18
kdc_1        | Jan 28 02:31:44 kdc kadmind[24](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1        | Jan 28 02:31:44 kdc kadmind[24](Notice): Request: kadm5_randkey_principal, om/om2@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:44 kdc kadmind[24](Notice): Request: kadm5_get_principal, om/om2@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:44 kdc kadmind[24](info): closing down fd 18
kdc_1        | Jan 28 02:31:44 kdc kadmind[24](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1        | Jan 28 02:31:44 kdc kadmind[24](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:44 kdc kadmind[24](Notice): Request: kadm5_create_principal, HTTP/om2@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:44 kdc kadmind[24](info): closing down fd 18
kdc_1        | Jan 28 02:31:44 kdc kadmind[24](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1        | Jan 28 02:31:44 kdc kadmind[24](Notice): Request: kadm5_randkey_principal, HTTP/om2@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:44 kdc kadmind[24](Notice): Request: kadm5_get_principal, HTTP/om2@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1        | Jan 28 02:31:44 kdc kadmind[24](info): closing down fd 18
kdc_1        | Jan 28 02:31:58 kdc krb5kdc[8](info): AS_REQ (2 etypes {18 17}) 172.25.0.104: ISSUE: authtime 1611801118, etypes {rep=18 tkt=18 ses=18}, dn/d5a2d8142681@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 28 02:32:01 kdc krb5kdc[8](info): AS_REQ (2 etypes {18 17}) 172.25.0.103: ISSUE: authtime 1611801121, etypes {rep=18 tkt=18 ses=18}, dn/db0158eeb642@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 28 02:32:02 kdc krb5kdc[8](info): AS_REQ (2 etypes {18 17}) 172.25.0.115: ISSUE: authtime 1611801122, etypes {rep=18 tkt=18 ses=18}, recon/recon@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 28 02:32:03 kdc krb5kdc[8](info): AS_REQ (2 etypes {18 17}) 172.25.0.111: ISSUE: authtime 1611801123, etypes {rep=18 tkt=18 ses=18}, om/om1@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 28 02:32:04 kdc krb5kdc[8](info): AS_REQ (2 etypes {18 17}) 172.25.0.102: ISSUE: authtime 1611801124, etypes {rep=18 tkt=18 ses=18}, dn/d20fde691356@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 28 02:32:06 kdc krb5kdc[8](info): AS_REQ (2 etypes {18 17}) 172.25.0.113: ISSUE: authtime 1611801126, etypes {rep=18 tkt=18 ses=18}, om/om3@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 28 02:32:07 kdc krb5kdc[8](info): AS_REQ (2 etypes {18 17}) 172.25.0.112: ISSUE: authtime 1611801127, etypes {rep=18 tkt=18 ses=18}, om/om2@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 28 02:32:14 kdc krb5kdc[8](info): AS_REQ (2 etypes {18 17}) 172.25.0.116: ISSUE: authtime 1611801134, etypes {rep=18 tkt=18 ses=18}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 28 02:32:20 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.115: ISSUE: authtime 1611801122, etypes {rep=18 tkt=18 ses=18}, recon/recon@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jan 28 02:32:20 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.104: ISSUE: authtime 1611801118, etypes {rep=18 tkt=18 ses=18}, dn/d5a2d8142681@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jan 28 02:32:20 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.102: ISSUE: authtime 1611801124, etypes {rep=18 tkt=18 ses=18}, dn/d20fde691356@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jan 28 02:32:20 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.103: ISSUE: authtime 1611801121, etypes {rep=18 tkt=18 ses=18}, dn/db0158eeb642@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jan 28 02:32:21 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.116: ISSUE: authtime 1611801104, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jan 28 02:32:21 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.111: ISSUE: authtime 1611801123, etypes {rep=18 tkt=18 ses=18}, om/om1@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jan 28 02:32:24 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.113: ISSUE: authtime 1611801126, etypes {rep=18 tkt=18 ses=18}, om/om3@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jan 28 02:32:24 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.112: ISSUE: authtime 1611801127, etypes {rep=18 tkt=18 ses=18}, om/om2@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jan 28 02:32:27 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.25.0.116: ISSUE: authtime 1611801147, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 28 02:32:39 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.103: ISSUE: authtime 1611801121, etypes {rep=18 tkt=18 ses=18}, dn/db0158eeb642@EXAMPLE.COM for recon/recon@EXAMPLE.COM
kdc_1        | Jan 28 02:32:39 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.102: ISSUE: authtime 1611801124, etypes {rep=18 tkt=18 ses=18}, dn/d20fde691356@EXAMPLE.COM for recon/recon@EXAMPLE.COM
kdc_1        | Jan 28 02:32:40 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.104: ISSUE: authtime 1611801118, etypes {rep=18 tkt=18 ses=18}, dn/d5a2d8142681@EXAMPLE.COM for recon/recon@EXAMPLE.COM
datanode3_1  | 2021-01-28 02:32:47,007 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode3_1  | 2021-01-28 02:32:47,008 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2021-01-28 02:32:47,008 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.feb6bea5-edd2-410b-8ad4-c920818f117a@group-A71B52063026
datanode3_1  | 2021-01-28 02:32:47,008 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2021-01-28 02:32:47,008 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode3_1  | 2021-01-28 02:32:47,009 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode3_1  | 2021-01-28 02:32:47,009 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: new feb6bea5-edd2-410b-8ad4-c920818f117a@group-A71B52063026-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/45d6c387-0d5e-4ec1-887d-a71b52063026
datanode3_1  | 2021-01-28 02:32:47,009 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode3_1  | 2021-01-28 02:32:47,009 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode3_1  | 2021-01-28 02:32:47,009 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2021-01-28 02:32:47,009 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode3_1  | 2021-01-28 02:32:47,009 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode3_1  | 2021-01-28 02:32:47,010 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode3_1  | 2021-01-28 02:32:47,010 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode3_1  | 2021-01-28 02:32:47,010 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode3_1  | 2021-01-28 02:32:47,012 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode3_1  | 2021-01-28 02:32:47,020 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode3_1  | 2021-01-28 02:32:47,027 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: feb6bea5-edd2-410b-8ad4-c920818f117a@group-A71B52063026-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode3_1  | 2021-01-28 02:32:47,027 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: feb6bea5-edd2-410b-8ad4-c920818f117a@group-A71B52063026-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode3_1  | 2021-01-28 02:32:47,034 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode3_1  | 2021-01-28 02:32:47,034 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode3_1  | 2021-01-28 02:32:47,034 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode3_1  | 2021-01-28 02:32:47,035 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode3_1  | 2021-01-28 02:32:47,035 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode3_1  | 2021-01-28 02:32:47,035 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode3_1  | 2021-01-28 02:32:47,035 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.feb6bea5-edd2-410b-8ad4-c920818f117a@group-A71B52063026
datanode3_1  | 2021-01-28 02:32:47,036 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.feb6bea5-edd2-410b-8ad4-c920818f117a@group-A71B52063026
datanode3_1  | 2021-01-28 02:32:47,037 [pool-20-thread-1] INFO server.RaftServer$Division: feb6bea5-edd2-410b-8ad4-c920818f117a@group-A71B52063026: start as a follower, conf=-1: [feb6bea5-edd2-410b-8ad4-c920818f117a|rpc:172.25.0.104:9858|priority:0, bb31b8e2-b35d-4b3b-ae90-43363de8a349|rpc:172.25.0.102:9858|priority:1, 6bab7c5a-f782-4236-88e0-70f071e2bf9c|rpc:172.25.0.103:9858|priority:0], old=null
datanode3_1  | 2021-01-28 02:32:47,038 [pool-20-thread-1] INFO server.RaftServer$Division: feb6bea5-edd2-410b-8ad4-c920818f117a@group-A71B52063026: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode3_1  | 2021-01-28 02:32:47,038 [pool-20-thread-1] INFO impl.RoleInfo: feb6bea5-edd2-410b-8ad4-c920818f117a: start feb6bea5-edd2-410b-8ad4-c920818f117a@group-A71B52063026-FollowerState
datanode3_1  | 2021-01-28 02:32:47,039 [pool-20-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A71B52063026,id=feb6bea5-edd2-410b-8ad4-c920818f117a
datanode3_1  | 2021-01-28 02:32:47,039 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.feb6bea5-edd2-410b-8ad4-c920818f117a@group-A71B52063026
datanode3_1  | 2021-01-28 02:32:47,185 [Command processor thread] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-2211B4A8081E->6bab7c5a-f782-4236-88e0-70f071e2bf9c
datanode3_1  | 2021-01-28 02:32:50,014 [Command processor thread] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-EE8D56BBC457->bb31b8e2-b35d-4b3b-ae90-43363de8a349
datanode3_1  | 2021-01-28 02:32:51,953 [Thread-25] INFO impl.FollowerState: feb6bea5-edd2-410b-8ad4-c920818f117a@group-97A240718454-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5087705237ns, electionTimeout:5056ms
datanode3_1  | 2021-01-28 02:32:51,954 [Thread-25] INFO impl.RoleInfo: feb6bea5-edd2-410b-8ad4-c920818f117a: shutdown feb6bea5-edd2-410b-8ad4-c920818f117a@group-97A240718454-FollowerState
datanode3_1  | 2021-01-28 02:32:51,954 [Thread-25] INFO server.RaftServer$Division: feb6bea5-edd2-410b-8ad4-c920818f117a@group-97A240718454: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode3_1  | 2021-01-28 02:32:51,956 [Thread-25] INFO impl.RoleInfo: feb6bea5-edd2-410b-8ad4-c920818f117a: start feb6bea5-edd2-410b-8ad4-c920818f117a@group-97A240718454-LeaderElection1
datanode3_1  | 2021-01-28 02:32:51,960 [feb6bea5-edd2-410b-8ad4-c920818f117a@group-97A240718454-LeaderElection1] INFO impl.LeaderElection: feb6bea5-edd2-410b-8ad4-c920818f117a@group-97A240718454-LeaderElection1 PRE_VOTE round 0: submit vote requests at term 0 for -1: [feb6bea5-edd2-410b-8ad4-c920818f117a|rpc:172.25.0.104:9858|priority:1], old=null
datanode3_1  | 2021-01-28 02:32:51,961 [feb6bea5-edd2-410b-8ad4-c920818f117a@group-97A240718454-LeaderElection1] INFO impl.LeaderElection: feb6bea5-edd2-410b-8ad4-c920818f117a@group-97A240718454-LeaderElection1 PRE_VOTE round 0: result PASSED (term=0)
datanode3_1  | 2021-01-28 02:32:51,963 [feb6bea5-edd2-410b-8ad4-c920818f117a@group-97A240718454-LeaderElection1] INFO impl.LeaderElection: feb6bea5-edd2-410b-8ad4-c920818f117a@group-97A240718454-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [feb6bea5-edd2-410b-8ad4-c920818f117a|rpc:172.25.0.104:9858|priority:1], old=null
datanode3_1  | 2021-01-28 02:32:51,963 [feb6bea5-edd2-410b-8ad4-c920818f117a@group-97A240718454-LeaderElection1] INFO impl.LeaderElection: feb6bea5-edd2-410b-8ad4-c920818f117a@group-97A240718454-LeaderElection1 ELECTION round 0: result PASSED (term=1)
datanode3_1  | 2021-01-28 02:32:51,976 [feb6bea5-edd2-410b-8ad4-c920818f117a@group-97A240718454-LeaderElection1] INFO impl.RoleInfo: feb6bea5-edd2-410b-8ad4-c920818f117a: shutdown feb6bea5-edd2-410b-8ad4-c920818f117a@group-97A240718454-LeaderElection1
kdc_1        | Jan 28 02:32:45 kdc krb5kdc[8](info): AS_REQ (2 etypes {18 17}) 172.25.0.111: ISSUE: authtime 1611801165, etypes {rep=18 tkt=18 ses=18}, om/om1@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 28 02:32:47 kdc krb5kdc[8](info): AS_REQ (2 etypes {18 17}) 172.25.0.113: ISSUE: authtime 1611801167, etypes {rep=18 tkt=18 ses=18}, om/om3@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 28 02:32:48 kdc krb5kdc[8](info): AS_REQ (2 etypes {18 17}) 172.25.0.112: ISSUE: authtime 1611801168, etypes {rep=18 tkt=18 ses=18}, om/om2@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 28 02:32:48 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.111: ISSUE: authtime 1611801165, etypes {rep=18 tkt=18 ses=18}, om/om1@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jan 28 02:32:49 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.113: ISSUE: authtime 1611801167, etypes {rep=18 tkt=18 ses=18}, om/om3@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jan 28 02:32:50 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.116: ISSUE: authtime 1611801147, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jan 28 02:32:51 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.112: ISSUE: authtime 1611801168, etypes {rep=18 tkt=18 ses=18}, om/om2@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jan 28 02:32:55 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.25.0.116: ISSUE: authtime 1611801175, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 28 02:33:03 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.116: ISSUE: authtime 1611801175, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jan 28 02:33:05 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.25.0.116: ISSUE: authtime 1611801185, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 28 02:33:13 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.116: ISSUE: authtime 1611801185, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om1@EXAMPLE.COM
kdc_1        | Jan 28 02:33:24 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.116: ISSUE: authtime 1611801185, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om1@EXAMPLE.COM
kdc_1        | Jan 28 02:33:29 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.116: ISSUE: authtime 1611801185, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om1@EXAMPLE.COM
kdc_1        | Jan 28 02:33:33 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.116: ISSUE: authtime 1611801185, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om1@EXAMPLE.COM
kdc_1        | Jan 28 02:33:44 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.116: ISSUE: authtime 1611801185, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om1@EXAMPLE.COM
kdc_1        | Jan 28 02:33:47 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.116: ISSUE: authtime 1611801185, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om1@EXAMPLE.COM
kdc_1        | Jan 28 02:33:49 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.115: ISSUE: authtime 1611801122, etypes {rep=18 tkt=18 ses=18}, recon/recon@EXAMPLE.COM for om/om1@EXAMPLE.COM
kdc_1        | Jan 28 02:33:49 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.115: ISSUE: authtime 1611801122, etypes {rep=18 tkt=18 ses=18}, recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM
kdc_1        | Jan 28 02:33:50 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.116: ISSUE: authtime 1611801185, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om1@EXAMPLE.COM
kdc_1        | Jan 28 02:33:53 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.116: ISSUE: authtime 1611801185, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om1@EXAMPLE.COM
kdc_1        | Jan 28 02:33:59 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.116: ISSUE: authtime 1611801185, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om1@EXAMPLE.COM
kdc_1        | Jan 28 02:34:02 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.116: ISSUE: authtime 1611801185, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om1@EXAMPLE.COM
kdc_1        | Jan 28 02:34:04 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.116: ISSUE: authtime 1611801185, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om1@EXAMPLE.COM
kdc_1        | Jan 28 02:34:07 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.116: ISSUE: authtime 1611801185, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om1@EXAMPLE.COM
kdc_1        | Jan 28 02:34:10 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.116: ISSUE: authtime 1611801185, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om1@EXAMPLE.COM
kdc_1        | Jan 28 02:34:13 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.116: ISSUE: authtime 1611801185, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om1@EXAMPLE.COM
kdc_1        | Jan 28 02:34:16 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.116: ISSUE: authtime 1611801185, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om1@EXAMPLE.COM
kdc_1        | Jan 28 02:34:19 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.116: ISSUE: authtime 1611801185, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om1@EXAMPLE.COM
kdc_1        | Jan 28 02:34:22 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.116: ISSUE: authtime 1611801185, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om1@EXAMPLE.COM
kdc_1        | Jan 28 02:34:23 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.25.0.116: ISSUE: authtime 1611801263, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 28 02:34:25 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.116: ISSUE: authtime 1611801263, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om1@EXAMPLE.COM
kdc_1        | Jan 28 02:34:28 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.116: ISSUE: authtime 1611801263, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om1@EXAMPLE.COM
kdc_1        | Jan 28 02:34:29 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.25.0.116: ISSUE: authtime 1611801269, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 28 02:34:31 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.116: ISSUE: authtime 1611801269, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om1@EXAMPLE.COM
kdc_1        | Jan 28 02:34:34 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.116: ISSUE: authtime 1611801269, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om1@EXAMPLE.COM
kdc_1        | Jan 28 02:34:38 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.116: ISSUE: authtime 1611801269, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om1@EXAMPLE.COM
kdc_1        | Jan 28 02:34:43 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.116: ISSUE: authtime 1611801269, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om1@EXAMPLE.COM
kdc_1        | Jan 28 02:34:45 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.25.0.116: ISSUE: authtime 1611801285, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
datanode3_1  | 2021-01-28 02:32:51,976 [feb6bea5-edd2-410b-8ad4-c920818f117a@group-97A240718454-LeaderElection1] INFO server.RaftServer$Division: feb6bea5-edd2-410b-8ad4-c920818f117a@group-97A240718454: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode3_1  | 2021-01-28 02:32:51,977 [feb6bea5-edd2-410b-8ad4-c920818f117a@group-97A240718454-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-97A240718454 with new leaderId: feb6bea5-edd2-410b-8ad4-c920818f117a
datanode3_1  | 2021-01-28 02:32:51,987 [feb6bea5-edd2-410b-8ad4-c920818f117a@group-97A240718454-LeaderElection1] INFO server.RaftServer$Division: feb6bea5-edd2-410b-8ad4-c920818f117a@group-97A240718454: change Leader from null to feb6bea5-edd2-410b-8ad4-c920818f117a at term 1 for becomeLeader, leader elected after 5712ms
datanode3_1  | 2021-01-28 02:32:52,032 [feb6bea5-edd2-410b-8ad4-c920818f117a@group-97A240718454-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode3_1  | 2021-01-28 02:32:52,047 [feb6bea5-edd2-410b-8ad4-c920818f117a@group-97A240718454-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.feb6bea5-edd2-410b-8ad4-c920818f117a@group-97A240718454
datanode3_1  | 2021-01-28 02:32:52,048 [feb6bea5-edd2-410b-8ad4-c920818f117a@group-97A240718454-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode3_1  | 2021-01-28 02:32:52,066 [feb6bea5-edd2-410b-8ad4-c920818f117a@group-97A240718454-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode3_1  | 2021-01-28 02:32:52,079 [feb6bea5-edd2-410b-8ad4-c920818f117a@group-97A240718454-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode3_1  | 2021-01-28 02:32:52,095 [feb6bea5-edd2-410b-8ad4-c920818f117a@group-97A240718454-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode3_1  | 2021-01-28 02:32:52,096 [feb6bea5-edd2-410b-8ad4-c920818f117a@group-97A240718454-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode3_1  | 2021-01-28 02:32:52,149 [feb6bea5-edd2-410b-8ad4-c920818f117a@group-97A240718454-LeaderElection1] INFO impl.RoleInfo: feb6bea5-edd2-410b-8ad4-c920818f117a: start feb6bea5-edd2-410b-8ad4-c920818f117a@group-97A240718454-LeaderStateImpl
datanode3_1  | 2021-01-28 02:32:52,215 [Thread-27] INFO impl.FollowerState: feb6bea5-edd2-410b-8ad4-c920818f117a@group-A71B52063026-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5176688073ns, electionTimeout:5175ms
datanode3_1  | 2021-01-28 02:32:52,221 [Thread-27] INFO impl.RoleInfo: feb6bea5-edd2-410b-8ad4-c920818f117a: shutdown feb6bea5-edd2-410b-8ad4-c920818f117a@group-A71B52063026-FollowerState
datanode3_1  | 2021-01-28 02:32:52,221 [Thread-27] INFO server.RaftServer$Division: feb6bea5-edd2-410b-8ad4-c920818f117a@group-A71B52063026: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode3_1  | 2021-01-28 02:32:52,224 [Thread-27] INFO impl.RoleInfo: feb6bea5-edd2-410b-8ad4-c920818f117a: start feb6bea5-edd2-410b-8ad4-c920818f117a@group-A71B52063026-LeaderElection2
datanode3_1  | 2021-01-28 02:32:52,225 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=45d6c387-0d5e-4ec1-887d-a71b52063026.
datanode3_1  | 2021-01-28 02:32:52,231 [Command processor thread] INFO server.RaftServer: feb6bea5-edd2-410b-8ad4-c920818f117a: addNew group-8E19C9AA218C:[feb6bea5-edd2-410b-8ad4-c920818f117a|rpc:172.25.0.104:9858|priority:1, bb31b8e2-b35d-4b3b-ae90-43363de8a349|rpc:172.25.0.102:9858|priority:0, 6bab7c5a-f782-4236-88e0-70f071e2bf9c|rpc:172.25.0.103:9858|priority:0] returns group-8E19C9AA218C:java.util.concurrent.CompletableFuture@6c445bf0[Not completed]
datanode3_1  | 2021-01-28 02:32:52,240 [pool-20-thread-1] INFO server.RaftServer$Division: feb6bea5-edd2-410b-8ad4-c920818f117a: new RaftServerImpl for group-8E19C9AA218C:[feb6bea5-edd2-410b-8ad4-c920818f117a|rpc:172.25.0.104:9858|priority:1, bb31b8e2-b35d-4b3b-ae90-43363de8a349|rpc:172.25.0.102:9858|priority:0, 6bab7c5a-f782-4236-88e0-70f071e2bf9c|rpc:172.25.0.103:9858|priority:0] with ContainerStateMachine:uninitialized
datanode3_1  | 2021-01-28 02:32:52,241 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode3_1  | 2021-01-28 02:32:52,242 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode3_1  | 2021-01-28 02:32:52,247 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode3_1  | 2021-01-28 02:32:52,247 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode3_1  | 2021-01-28 02:32:52,247 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode3_1  | 2021-01-28 02:32:52,250 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode3_1  | 2021-01-28 02:32:52,250 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2021-01-28 02:32:52,250 [pool-20-thread-1] INFO server.RaftServer$Division: feb6bea5-edd2-410b-8ad4-c920818f117a@group-8E19C9AA218C: ConfigurationManager, init=-1: [feb6bea5-edd2-410b-8ad4-c920818f117a|rpc:172.25.0.104:9858|priority:1, bb31b8e2-b35d-4b3b-ae90-43363de8a349|rpc:172.25.0.102:9858|priority:0, 6bab7c5a-f782-4236-88e0-70f071e2bf9c|rpc:172.25.0.103:9858|priority:0], old=null, confs=<EMPTY_MAP>
datanode3_1  | 2021-01-28 02:32:52,250 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode3_1  | 2021-01-28 02:32:52,251 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode3_1  | 2021-01-28 02:32:52,251 [pool-20-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/4954273f-2502-40bd-89f2-8e19c9aa218c does not exist. Creating ...
datanode3_1  | 2021-01-28 02:32:52,259 [pool-20-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/4954273f-2502-40bd-89f2-8e19c9aa218c/in_use.lock acquired by nodename 6@d5a2d8142681
datanode3_1  | 2021-01-28 02:32:52,264 [pool-20-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/4954273f-2502-40bd-89f2-8e19c9aa218c has been successfully formatted.
datanode3_1  | 2021-01-28 02:32:52,266 [pool-20-thread-1] INFO ratis.ContainerStateMachine: group-8E19C9AA218C: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode3_1  | 2021-01-28 02:32:52,279 [pool-20-thread-1] ERROR storage.RaftStorage: Failed reading configuration from file:/data/metadata/ratis/4954273f-2502-40bd-89f2-8e19c9aa218c/current/raft-meta.conf
datanode3_1  | java.io.FileNotFoundException: /data/metadata/ratis/4954273f-2502-40bd-89f2-8e19c9aa218c/current/raft-meta.conf (No such file or directory)
datanode3_1  | 	at java.base/java.io.FileInputStream.open0(Native Method)
datanode3_1  | 	at java.base/java.io.FileInputStream.open(FileInputStream.java:219)
datanode3_1  | 	at java.base/java.io.FileInputStream.<init>(FileInputStream.java:157)
datanode3_1  | 	at org.apache.ratis.server.storage.RaftStorageImpl.readRaftConfiguration(RaftStorageImpl.java:143)
datanode3_1  | 	at org.apache.ratis.server.impl.ServerState.<init>(ServerState.java:122)
datanode3_1  | 	at org.apache.ratis.server.impl.RaftServerImpl.<init>(RaftServerImpl.java:193)
datanode3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.lambda$newRaftServerImpl$4(RaftServerProxy.java:266)
datanode3_1  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode3_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
kdc_1        | Jan 28 02:34:47 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.116: ISSUE: authtime 1611801285, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om1@EXAMPLE.COM
kdc_1        | Jan 28 02:34:52 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.116: ISSUE: authtime 1611801285, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om1@EXAMPLE.COM
kdc_1        | Jan 28 02:34:54 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.25.0.116: ISSUE: authtime 1611801294, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 28 02:34:57 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.116: ISSUE: authtime 1611801294, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om1@EXAMPLE.COM
kdc_1        | Jan 28 02:35:00 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.116: ISSUE: authtime 1611801294, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om1@EXAMPLE.COM
kdc_1        | Jan 28 02:35:01 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.25.0.116: ISSUE: authtime 1611801301, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 28 02:35:03 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.116: ISSUE: authtime 1611801301, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om1@EXAMPLE.COM
kdc_1        | Jan 28 02:35:07 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.116: ISSUE: authtime 1611801301, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om1@EXAMPLE.COM
kdc_1        | Jan 28 02:35:07 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.25.0.116: ISSUE: authtime 1611801307, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 28 02:35:10 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.116: ISSUE: authtime 1611801307, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om1@EXAMPLE.COM
kdc_1        | Jan 28 02:35:10 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.25.0.116: ISSUE: authtime 1611801310, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 28 02:35:13 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.116: ISSUE: authtime 1611801310, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om1@EXAMPLE.COM
kdc_1        | Jan 28 02:35:14 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.25.0.116: ISSUE: authtime 1611801314, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 28 02:35:16 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.116: ISSUE: authtime 1611801314, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om1@EXAMPLE.COM
kdc_1        | Jan 28 02:35:19 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.116: ISSUE: authtime 1611801314, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om1@EXAMPLE.COM
kdc_1        | Jan 28 02:35:23 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.116: ISSUE: authtime 1611801314, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om1@EXAMPLE.COM
kdc_1        | Jan 28 02:35:25 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.116: ISSUE: authtime 1611801314, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om1@EXAMPLE.COM
kdc_1        | Jan 28 02:35:28 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.116: ISSUE: authtime 1611801314, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om1@EXAMPLE.COM
kdc_1        | Jan 28 02:35:31 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.116: ISSUE: authtime 1611801314, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om1@EXAMPLE.COM
kdc_1        | Jan 28 02:35:32 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.25.0.116: ISSUE: authtime 1611801332, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 28 02:35:34 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.116: ISSUE: authtime 1611801332, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om1@EXAMPLE.COM
kdc_1        | Jan 28 02:35:37 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.116: ISSUE: authtime 1611801332, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om1@EXAMPLE.COM
kdc_1        | Jan 28 02:35:40 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.116: ISSUE: authtime 1611801332, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om1@EXAMPLE.COM
kdc_1        | Jan 28 02:35:43 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.116: ISSUE: authtime 1611801332, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om1@EXAMPLE.COM
kdc_1        | Jan 28 02:35:44 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.25.0.116: ISSUE: authtime 1611801344, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 28 02:35:44 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.25.0.116: ISSUE: authtime 1611801344, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 28 02:35:46 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.116: ISSUE: authtime 1611801344, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for om/om1@EXAMPLE.COM
kdc_1        | Jan 28 02:35:47 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.25.0.116: ISSUE: authtime 1611801347, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 28 02:35:47 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.25.0.116: ISSUE: authtime 1611801347, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 28 02:35:49 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.116: ISSUE: authtime 1611801347, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for om/om1@EXAMPLE.COM
kdc_1        | Jan 28 02:35:50 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.25.0.116: ISSUE: authtime 1611801350, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 28 02:35:50 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.25.0.116: ISSUE: authtime 1611801350, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 28 02:35:52 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.116: ISSUE: authtime 1611801350, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for om/om1@EXAMPLE.COM
kdc_1        | Jan 28 02:35:55 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.116: ISSUE: authtime 1611801350, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for om/om1@EXAMPLE.COM
kdc_1        | Jan 28 02:35:56 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.25.0.116: ISSUE: authtime 1611801356, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 28 02:35:59 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.116: ISSUE: authtime 1611801356, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om1@EXAMPLE.COM
kdc_1        | Jan 28 02:36:02 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.116: ISSUE: authtime 1611801356, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om1@EXAMPLE.COM
kdc_1        | Jan 28 02:36:05 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.116: ISSUE: authtime 1611801356, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om1@EXAMPLE.COM
datanode3_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode3_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode3_1  | 2021-01-28 02:32:52,236 [feb6bea5-edd2-410b-8ad4-c920818f117a@group-97A240718454-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: feb6bea5-edd2-410b-8ad4-c920818f117a@group-97A240718454-SegmentedRaftLogWorker: Starting segment from index:0
datanode3_1  | 2021-01-28 02:32:52,280 [feb6bea5-edd2-410b-8ad4-c920818f117a@group-A71B52063026-LeaderElection2] INFO impl.LeaderElection: feb6bea5-edd2-410b-8ad4-c920818f117a@group-A71B52063026-LeaderElection2 PRE_VOTE round 0: submit vote requests at term 0 for -1: [feb6bea5-edd2-410b-8ad4-c920818f117a|rpc:172.25.0.104:9858|priority:0, bb31b8e2-b35d-4b3b-ae90-43363de8a349|rpc:172.25.0.102:9858|priority:1, 6bab7c5a-f782-4236-88e0-70f071e2bf9c|rpc:172.25.0.103:9858|priority:0], old=null
datanode3_1  | 2021-01-28 02:32:52,335 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode3_1  | 2021-01-28 02:32:52,335 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode3_1  | 2021-01-28 02:32:52,335 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode3_1  | 2021-01-28 02:32:52,335 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2021-01-28 02:32:52,335 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.feb6bea5-edd2-410b-8ad4-c920818f117a@group-8E19C9AA218C
datanode3_1  | 2021-01-28 02:32:52,335 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2021-01-28 02:32:52,336 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode3_1  | 2021-01-28 02:32:52,336 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode3_1  | 2021-01-28 02:32:52,336 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: new feb6bea5-edd2-410b-8ad4-c920818f117a@group-8E19C9AA218C-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/4954273f-2502-40bd-89f2-8e19c9aa218c
datanode3_1  | 2021-01-28 02:32:52,336 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode3_1  | 2021-01-28 02:32:52,336 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode3_1  | 2021-01-28 02:32:52,336 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2021-01-28 02:32:52,336 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode3_1  | 2021-01-28 02:32:52,336 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode3_1  | 2021-01-28 02:32:52,336 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode3_1  | 2021-01-28 02:32:52,336 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode3_1  | 2021-01-28 02:32:52,336 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode3_1  | 2021-01-28 02:32:52,336 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode3_1  | 2021-01-28 02:32:52,337 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode3_1  | 2021-01-28 02:32:52,337 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: feb6bea5-edd2-410b-8ad4-c920818f117a@group-8E19C9AA218C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode3_1  | 2021-01-28 02:32:52,337 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: feb6bea5-edd2-410b-8ad4-c920818f117a@group-8E19C9AA218C-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode3_1  | 2021-01-28 02:32:52,374 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode3_1  | 2021-01-28 02:32:52,374 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode3_1  | 2021-01-28 02:32:52,375 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode3_1  | 2021-01-28 02:32:52,375 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode3_1  | 2021-01-28 02:32:52,375 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode3_1  | 2021-01-28 02:32:52,375 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode3_1  | 2021-01-28 02:32:52,375 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.feb6bea5-edd2-410b-8ad4-c920818f117a@group-8E19C9AA218C
datanode3_1  | 2021-01-28 02:32:52,376 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.feb6bea5-edd2-410b-8ad4-c920818f117a@group-8E19C9AA218C
datanode3_1  | 2021-01-28 02:32:52,376 [pool-20-thread-1] INFO server.RaftServer$Division: feb6bea5-edd2-410b-8ad4-c920818f117a@group-8E19C9AA218C: start as a follower, conf=-1: [feb6bea5-edd2-410b-8ad4-c920818f117a|rpc:172.25.0.104:9858|priority:1, bb31b8e2-b35d-4b3b-ae90-43363de8a349|rpc:172.25.0.102:9858|priority:0, 6bab7c5a-f782-4236-88e0-70f071e2bf9c|rpc:172.25.0.103:9858|priority:0], old=null
datanode3_1  | 2021-01-28 02:32:52,409 [pool-20-thread-1] INFO server.RaftServer$Division: feb6bea5-edd2-410b-8ad4-c920818f117a@group-8E19C9AA218C: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode3_1  | 2021-01-28 02:32:52,409 [pool-20-thread-1] INFO impl.RoleInfo: feb6bea5-edd2-410b-8ad4-c920818f117a: start feb6bea5-edd2-410b-8ad4-c920818f117a@group-8E19C9AA218C-FollowerState
datanode3_1  | 2021-01-28 02:32:52,410 [pool-20-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-8E19C9AA218C,id=feb6bea5-edd2-410b-8ad4-c920818f117a
datanode3_1  | 2021-01-28 02:32:52,410 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.feb6bea5-edd2-410b-8ad4-c920818f117a@group-8E19C9AA218C
datanode3_1  | 2021-01-28 02:32:52,428 [Command processor thread] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-4868B9443334->bb31b8e2-b35d-4b3b-ae90-43363de8a349
datanode3_1  | 2021-01-28 02:32:52,479 [feb6bea5-edd2-410b-8ad4-c920818f117a@group-97A240718454-LeaderElection1] INFO server.RaftServer$Division: feb6bea5-edd2-410b-8ad4-c920818f117a@group-97A240718454: set configuration 0: [feb6bea5-edd2-410b-8ad4-c920818f117a|rpc:172.25.0.104:9858|admin:|client:|dataStream:|priority:1], old=null
datanode3_1  | 2021-01-28 02:32:52,715 [Command processor thread] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-EDFF51CCBD72->6bab7c5a-f782-4236-88e0-70f071e2bf9c
datanode3_1  | 2021-01-28 02:32:52,732 [feb6bea5-edd2-410b-8ad4-c920818f117a@group-A71B52063026-LeaderElection2] INFO impl.LeaderElection: feb6bea5-edd2-410b-8ad4-c920818f117a@group-A71B52063026-LeaderElection2: PRE_VOTE REJECTED received 1 response(s) and 0 exception(s):
datanode3_1  | 2021-01-28 02:32:52,733 [feb6bea5-edd2-410b-8ad4-c920818f117a@group-A71B52063026-LeaderElection2] INFO impl.LeaderElection:   Response 0: feb6bea5-edd2-410b-8ad4-c920818f117a<-bb31b8e2-b35d-4b3b-ae90-43363de8a349#0:FAIL-t0
om3_1        | Sleeping for 5 seconds
om3_1        | Setting up kerberos!!
om3_1        | KDC ISSUER_SERVER => kdc:8081
om3_1        | Sleeping for 5 seconds
om3_1        | Got 200, KDC service ready!!
om3_1        | Download om/om3@EXAMPLE.COM keytab file to /etc/security/keytabs/om.keytab
om3_1        | --2021-01-28 02:31:43--  http://kdc:8081/keytab/om3/om
om3_1        | Resolving kdc (kdc)... 172.25.0.100
om3_1        | Connecting to kdc (kdc)|172.25.0.100|:8081... connected.
om3_1        | HTTP request sent, awaiting response... 200 OK
om3_1        | Length: 140 [application/octet-stream]
om3_1        | Saving to: '/etc/security/keytabs/om.keytab'
om3_1        | 
om3_1        |      0K                                                       100% 29.0M=0s
om3_1        | 
om3_1        | 2021-01-28 02:31:43 (29.0 MB/s) - '/etc/security/keytabs/om.keytab' saved [140/140]
om3_1        | 
om3_1        | Keytab name: FILE:/etc/security/keytabs/om.keytab
om3_1        | KVNO Timestamp         Principal
om3_1        | ---- ----------------- --------------------------------------------------------
om3_1        |    2 01/28/21 02:31:43 om/om3@EXAMPLE.COM
om3_1        |    2 01/28/21 02:31:43 om/om3@EXAMPLE.COM
om3_1        | Download HTTP/om3@EXAMPLE.COM keytab file to /etc/security/keytabs/HTTP.keytab
om3_1        | --2021-01-28 02:31:44--  http://kdc:8081/keytab/om3/HTTP
om3_1        | Resolving kdc (kdc)... 172.25.0.100
om3_1        | Connecting to kdc (kdc)|172.25.0.100|:8081... connected.
om3_1        | HTTP request sent, awaiting response... 200 OK
om3_1        | Length: 144 [application/octet-stream]
om3_1        | Saving to: '/etc/security/keytabs/HTTP.keytab'
om3_1        | 
om3_1        |      0K                                                       100% 29.2M=0s
om3_1        | 
om3_1        | 2021-01-28 02:31:44 (29.2 MB/s) - '/etc/security/keytabs/HTTP.keytab' saved [144/144]
om3_1        | 
om3_1        | Keytab name: FILE:/etc/security/keytabs/HTTP.keytab
om3_1        | KVNO Timestamp         Principal
om3_1        | ---- ----------------- --------------------------------------------------------
om3_1        |    2 01/28/21 02:31:44 HTTP/om3@EXAMPLE.COM
om3_1        |    2 01/28/21 02:31:44 HTTP/om3@EXAMPLE.COM
om3_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om3_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om3_1        | 2021-01-28 02:31:54,428 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om3_1        | /************************************************************
om3_1        | STARTUP_MSG: Starting OzoneManager
datanode3_1  | 2021-01-28 02:32:52,735 [feb6bea5-edd2-410b-8ad4-c920818f117a@group-A71B52063026-LeaderElection2] INFO impl.LeaderElection: feb6bea5-edd2-410b-8ad4-c920818f117a@group-A71B52063026-LeaderElection2 PRE_VOTE round 0: result REJECTED
datanode3_1  | 2021-01-28 02:32:52,751 [feb6bea5-edd2-410b-8ad4-c920818f117a@group-A71B52063026-LeaderElection2] INFO server.RaftServer$Division: feb6bea5-edd2-410b-8ad4-c920818f117a@group-A71B52063026: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
datanode3_1  | 2021-01-28 02:32:52,755 [feb6bea5-edd2-410b-8ad4-c920818f117a@group-A71B52063026-LeaderElection2] INFO impl.RoleInfo: feb6bea5-edd2-410b-8ad4-c920818f117a: shutdown feb6bea5-edd2-410b-8ad4-c920818f117a@group-A71B52063026-LeaderElection2
datanode3_1  | 2021-01-28 02:32:52,755 [feb6bea5-edd2-410b-8ad4-c920818f117a@group-A71B52063026-LeaderElection2] INFO impl.RoleInfo: feb6bea5-edd2-410b-8ad4-c920818f117a: start feb6bea5-edd2-410b-8ad4-c920818f117a@group-A71B52063026-FollowerState
datanode3_1  | 2021-01-28 02:32:52,900 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=4954273f-2502-40bd-89f2-8e19c9aa218c.
datanode3_1  | 2021-01-28 02:32:52,924 [feb6bea5-edd2-410b-8ad4-c920818f117a@group-97A240718454-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: feb6bea5-edd2-410b-8ad4-c920818f117a@group-97A240718454-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/39c789b6-0c46-456e-8a71-97a240718454/current/log_inprogress_0
datanode3_1  | 2021-01-28 02:32:57,451 [Thread-34] INFO impl.FollowerState: feb6bea5-edd2-410b-8ad4-c920818f117a@group-8E19C9AA218C-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5041199706ns, electionTimeout:5040ms
datanode3_1  | 2021-01-28 02:32:57,451 [Thread-34] INFO impl.RoleInfo: feb6bea5-edd2-410b-8ad4-c920818f117a: shutdown feb6bea5-edd2-410b-8ad4-c920818f117a@group-8E19C9AA218C-FollowerState
datanode3_1  | 2021-01-28 02:32:57,451 [Thread-34] INFO server.RaftServer$Division: feb6bea5-edd2-410b-8ad4-c920818f117a@group-8E19C9AA218C: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode3_1  | 2021-01-28 02:32:57,452 [Thread-34] INFO impl.RoleInfo: feb6bea5-edd2-410b-8ad4-c920818f117a: start feb6bea5-edd2-410b-8ad4-c920818f117a@group-8E19C9AA218C-LeaderElection3
datanode3_1  | 2021-01-28 02:32:57,458 [feb6bea5-edd2-410b-8ad4-c920818f117a@group-8E19C9AA218C-LeaderElection3] INFO impl.LeaderElection: feb6bea5-edd2-410b-8ad4-c920818f117a@group-8E19C9AA218C-LeaderElection3 PRE_VOTE round 0: submit vote requests at term 0 for -1: [feb6bea5-edd2-410b-8ad4-c920818f117a|rpc:172.25.0.104:9858|priority:1, bb31b8e2-b35d-4b3b-ae90-43363de8a349|rpc:172.25.0.102:9858|priority:0, 6bab7c5a-f782-4236-88e0-70f071e2bf9c|rpc:172.25.0.103:9858|priority:0], old=null
datanode3_1  | 2021-01-28 02:32:57,515 [feb6bea5-edd2-410b-8ad4-c920818f117a@group-8E19C9AA218C-LeaderElection3] INFO impl.LeaderElection: feb6bea5-edd2-410b-8ad4-c920818f117a@group-8E19C9AA218C-LeaderElection3: PRE_VOTE PASSED received 1 response(s) and 0 exception(s):
datanode3_1  | 2021-01-28 02:32:57,516 [feb6bea5-edd2-410b-8ad4-c920818f117a@group-8E19C9AA218C-LeaderElection3] INFO impl.LeaderElection:   Response 0: feb6bea5-edd2-410b-8ad4-c920818f117a<-6bab7c5a-f782-4236-88e0-70f071e2bf9c#0:OK-t0
datanode3_1  | 2021-01-28 02:32:57,516 [feb6bea5-edd2-410b-8ad4-c920818f117a@group-8E19C9AA218C-LeaderElection3] INFO impl.LeaderElection: feb6bea5-edd2-410b-8ad4-c920818f117a@group-8E19C9AA218C-LeaderElection3 PRE_VOTE round 0: result PASSED
datanode3_1  | 2021-01-28 02:32:57,520 [feb6bea5-edd2-410b-8ad4-c920818f117a@group-8E19C9AA218C-LeaderElection3] INFO impl.LeaderElection: feb6bea5-edd2-410b-8ad4-c920818f117a@group-8E19C9AA218C-LeaderElection3 ELECTION round 0: submit vote requests at term 1 for -1: [feb6bea5-edd2-410b-8ad4-c920818f117a|rpc:172.25.0.104:9858|priority:1, bb31b8e2-b35d-4b3b-ae90-43363de8a349|rpc:172.25.0.102:9858|priority:0, 6bab7c5a-f782-4236-88e0-70f071e2bf9c|rpc:172.25.0.103:9858|priority:0], old=null
datanode3_1  | 2021-01-28 02:32:57,575 [feb6bea5-edd2-410b-8ad4-c920818f117a@group-8E19C9AA218C-LeaderElection3] INFO impl.LeaderElection: feb6bea5-edd2-410b-8ad4-c920818f117a@group-8E19C9AA218C-LeaderElection3: ELECTION PASSED received 1 response(s) and 0 exception(s):
datanode3_1  | 2021-01-28 02:32:57,575 [feb6bea5-edd2-410b-8ad4-c920818f117a@group-8E19C9AA218C-LeaderElection3] INFO impl.LeaderElection:   Response 0: feb6bea5-edd2-410b-8ad4-c920818f117a<-6bab7c5a-f782-4236-88e0-70f071e2bf9c#0:OK-t1
datanode3_1  | 2021-01-28 02:32:57,575 [feb6bea5-edd2-410b-8ad4-c920818f117a@group-8E19C9AA218C-LeaderElection3] INFO impl.LeaderElection: feb6bea5-edd2-410b-8ad4-c920818f117a@group-8E19C9AA218C-LeaderElection3 ELECTION round 0: result PASSED
datanode3_1  | 2021-01-28 02:32:57,575 [feb6bea5-edd2-410b-8ad4-c920818f117a@group-8E19C9AA218C-LeaderElection3] INFO impl.RoleInfo: feb6bea5-edd2-410b-8ad4-c920818f117a: shutdown feb6bea5-edd2-410b-8ad4-c920818f117a@group-8E19C9AA218C-LeaderElection3
datanode3_1  | 2021-01-28 02:32:57,575 [feb6bea5-edd2-410b-8ad4-c920818f117a@group-8E19C9AA218C-LeaderElection3] INFO server.RaftServer$Division: feb6bea5-edd2-410b-8ad4-c920818f117a@group-8E19C9AA218C: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode3_1  | 2021-01-28 02:32:57,576 [feb6bea5-edd2-410b-8ad4-c920818f117a@group-8E19C9AA218C-LeaderElection3] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-8E19C9AA218C with new leaderId: feb6bea5-edd2-410b-8ad4-c920818f117a
datanode3_1  | 2021-01-28 02:32:57,576 [feb6bea5-edd2-410b-8ad4-c920818f117a@group-8E19C9AA218C-LeaderElection3] INFO server.RaftServer$Division: feb6bea5-edd2-410b-8ad4-c920818f117a@group-8E19C9AA218C: change Leader from null to feb6bea5-edd2-410b-8ad4-c920818f117a at term 1 for becomeLeader, leader elected after 5240ms
datanode3_1  | 2021-01-28 02:32:57,577 [feb6bea5-edd2-410b-8ad4-c920818f117a@group-8E19C9AA218C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode3_1  | 2021-01-28 02:32:57,577 [feb6bea5-edd2-410b-8ad4-c920818f117a@group-8E19C9AA218C-LeaderElection3] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.feb6bea5-edd2-410b-8ad4-c920818f117a@group-8E19C9AA218C
datanode3_1  | 2021-01-28 02:32:57,577 [feb6bea5-edd2-410b-8ad4-c920818f117a@group-8E19C9AA218C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode3_1  | 2021-01-28 02:32:57,578 [feb6bea5-edd2-410b-8ad4-c920818f117a@group-8E19C9AA218C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode3_1  | 2021-01-28 02:32:57,578 [feb6bea5-edd2-410b-8ad4-c920818f117a@group-8E19C9AA218C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode3_1  | 2021-01-28 02:32:57,578 [feb6bea5-edd2-410b-8ad4-c920818f117a@group-8E19C9AA218C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode3_1  | 2021-01-28 02:32:57,578 [feb6bea5-edd2-410b-8ad4-c920818f117a@group-8E19C9AA218C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode3_1  | 2021-01-28 02:32:57,595 [feb6bea5-edd2-410b-8ad4-c920818f117a@group-8E19C9AA218C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode3_1  | 2021-01-28 02:32:57,597 [feb6bea5-edd2-410b-8ad4-c920818f117a@group-8E19C9AA218C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2021-01-28 02:32:57,597 [feb6bea5-edd2-410b-8ad4-c920818f117a@group-8E19C9AA218C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode3_1  | 2021-01-28 02:32:57,603 [feb6bea5-edd2-410b-8ad4-c920818f117a@group-8E19C9AA218C-LeaderElection3] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode3_1  | 2021-01-28 02:32:57,628 [feb6bea5-edd2-410b-8ad4-c920818f117a@group-8E19C9AA218C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode3_1  | 2021-01-28 02:32:57,628 [feb6bea5-edd2-410b-8ad4-c920818f117a@group-8E19C9AA218C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2021-01-28 02:32:57,629 [feb6bea5-edd2-410b-8ad4-c920818f117a@group-8E19C9AA218C-LeaderElection3] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis_grpc.log_appender.feb6bea5-edd2-410b-8ad4-c920818f117a@group-8E19C9AA218C
datanode3_1  | 2021-01-28 02:32:57,673 [grpc-default-executor-0] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server_message_metrics.feb6bea5-edd2-410b-8ad4-c920818f117a
datanode3_1  | 2021-01-28 02:32:57,681 [feb6bea5-edd2-410b-8ad4-c920818f117a@group-8E19C9AA218C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode3_1  | 2021-01-28 02:32:57,689 [feb6bea5-edd2-410b-8ad4-c920818f117a@group-8E19C9AA218C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2021-01-28 02:32:57,694 [feb6bea5-edd2-410b-8ad4-c920818f117a@group-8E19C9AA218C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode3_1  | 2021-01-28 02:32:57,694 [feb6bea5-edd2-410b-8ad4-c920818f117a@group-8E19C9AA218C-LeaderElection3] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode3_1  | 2021-01-28 02:32:57,694 [feb6bea5-edd2-410b-8ad4-c920818f117a@group-8E19C9AA218C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode3_1  | 2021-01-28 02:32:57,694 [feb6bea5-edd2-410b-8ad4-c920818f117a@group-8E19C9AA218C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2021-01-28 02:32:57,699 [feb6bea5-edd2-410b-8ad4-c920818f117a@group-8E19C9AA218C-LeaderElection3] INFO impl.RoleInfo: feb6bea5-edd2-410b-8ad4-c920818f117a: start feb6bea5-edd2-410b-8ad4-c920818f117a@group-8E19C9AA218C-LeaderStateImpl
datanode3_1  | 2021-01-28 02:32:57,700 [feb6bea5-edd2-410b-8ad4-c920818f117a@group-8E19C9AA218C-LeaderElection3] INFO segmented.SegmentedRaftLogWorker: feb6bea5-edd2-410b-8ad4-c920818f117a@group-8E19C9AA218C-SegmentedRaftLogWorker: Starting segment from index:0
datanode3_1  | 2021-01-28 02:32:57,717 [feb6bea5-edd2-410b-8ad4-c920818f117a@group-8E19C9AA218C-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: feb6bea5-edd2-410b-8ad4-c920818f117a@group-8E19C9AA218C-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/4954273f-2502-40bd-89f2-8e19c9aa218c/current/log_inprogress_0
datanode3_1  | 2021-01-28 02:32:57,743 [feb6bea5-edd2-410b-8ad4-c920818f117a@group-8E19C9AA218C-LeaderElection3] INFO server.RaftServer$Division: feb6bea5-edd2-410b-8ad4-c920818f117a@group-8E19C9AA218C: set configuration 0: [feb6bea5-edd2-410b-8ad4-c920818f117a|rpc:172.25.0.104:9858|admin:|client:|dataStream:|priority:1, bb31b8e2-b35d-4b3b-ae90-43363de8a349|rpc:172.25.0.102:9858|admin:|client:|dataStream:|priority:0, 6bab7c5a-f782-4236-88e0-70f071e2bf9c|rpc:172.25.0.103:9858|admin:|client:|dataStream:|priority:0], old=null
datanode3_1  | 2021-01-28 02:32:57,782 [grpc-default-executor-0] INFO server.RaftServer$Division: feb6bea5-edd2-410b-8ad4-c920818f117a@group-A71B52063026: receive requestVote(PRE_VOTE, bb31b8e2-b35d-4b3b-ae90-43363de8a349, group-A71B52063026, 0, (t:0, i:0))
datanode3_1  | 2021-01-28 02:32:57,783 [grpc-default-executor-0] INFO impl.VoteContext: feb6bea5-edd2-410b-8ad4-c920818f117a@group-A71B52063026-FOLLOWER: accept PRE_VOTE from bb31b8e2-b35d-4b3b-ae90-43363de8a349: our priority 0 <= candidate's priority 1
datanode3_1  | 2021-01-28 02:32:57,791 [grpc-default-executor-0] INFO server.RaftServer$Division: feb6bea5-edd2-410b-8ad4-c920818f117a@group-A71B52063026 replies to PRE_VOTE vote request: bb31b8e2-b35d-4b3b-ae90-43363de8a349<-feb6bea5-edd2-410b-8ad4-c920818f117a#0:OK-t0. Peer's state: feb6bea5-edd2-410b-8ad4-c920818f117a@group-A71B52063026:t0, leader=null, voted=, raftlog=feb6bea5-edd2-410b-8ad4-c920818f117a@group-A71B52063026-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [feb6bea5-edd2-410b-8ad4-c920818f117a|rpc:172.25.0.104:9858|priority:0, bb31b8e2-b35d-4b3b-ae90-43363de8a349|rpc:172.25.0.102:9858|priority:1, 6bab7c5a-f782-4236-88e0-70f071e2bf9c|rpc:172.25.0.103:9858|priority:0], old=null
datanode3_1  | 2021-01-28 02:32:57,855 [grpc-default-executor-1] INFO server.RaftServer$Division: feb6bea5-edd2-410b-8ad4-c920818f117a@group-A71B52063026: receive requestVote(ELECTION, bb31b8e2-b35d-4b3b-ae90-43363de8a349, group-A71B52063026, 1, (t:0, i:0))
datanode3_1  | 2021-01-28 02:32:57,856 [grpc-default-executor-1] INFO impl.VoteContext: feb6bea5-edd2-410b-8ad4-c920818f117a@group-A71B52063026-FOLLOWER: accept ELECTION from bb31b8e2-b35d-4b3b-ae90-43363de8a349: our priority 0 <= candidate's priority 1
datanode3_1  | 2021-01-28 02:32:57,934 [grpc-default-executor-1] INFO server.RaftServer$Division: feb6bea5-edd2-410b-8ad4-c920818f117a@group-A71B52063026: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:bb31b8e2-b35d-4b3b-ae90-43363de8a349
datanode3_1  | 2021-01-28 02:32:57,934 [grpc-default-executor-1] INFO impl.RoleInfo: feb6bea5-edd2-410b-8ad4-c920818f117a: shutdown feb6bea5-edd2-410b-8ad4-c920818f117a@group-A71B52063026-FollowerState
datanode3_1  | 2021-01-28 02:32:57,942 [grpc-default-executor-1] INFO impl.RoleInfo: feb6bea5-edd2-410b-8ad4-c920818f117a: start feb6bea5-edd2-410b-8ad4-c920818f117a@group-A71B52063026-FollowerState
datanode3_1  | 2021-01-28 02:32:57,990 [grpc-default-executor-1] INFO server.RaftServer$Division: feb6bea5-edd2-410b-8ad4-c920818f117a@group-A71B52063026 replies to ELECTION vote request: bb31b8e2-b35d-4b3b-ae90-43363de8a349<-feb6bea5-edd2-410b-8ad4-c920818f117a#0:OK-t1. Peer's state: feb6bea5-edd2-410b-8ad4-c920818f117a@group-A71B52063026:t1, leader=null, voted=bb31b8e2-b35d-4b3b-ae90-43363de8a349, raftlog=feb6bea5-edd2-410b-8ad4-c920818f117a@group-A71B52063026-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [feb6bea5-edd2-410b-8ad4-c920818f117a|rpc:172.25.0.104:9858|priority:0, bb31b8e2-b35d-4b3b-ae90-43363de8a349|rpc:172.25.0.102:9858|priority:1, 6bab7c5a-f782-4236-88e0-70f071e2bf9c|rpc:172.25.0.103:9858|priority:0], old=null
datanode3_1  | 2021-01-28 02:32:58,485 [grpc-default-executor-2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-A71B52063026 with new leaderId: bb31b8e2-b35d-4b3b-ae90-43363de8a349
datanode3_1  | 2021-01-28 02:32:58,495 [grpc-default-executor-2] INFO server.RaftServer$Division: feb6bea5-edd2-410b-8ad4-c920818f117a@group-A71B52063026: change Leader from null to bb31b8e2-b35d-4b3b-ae90-43363de8a349 at term 1 for appendEntries, leader elected after 11477ms
datanode3_1  | 2021-01-28 02:32:58,572 [grpc-default-executor-2] INFO server.RaftServer$Division: feb6bea5-edd2-410b-8ad4-c920818f117a@group-A71B52063026: set configuration 0: [feb6bea5-edd2-410b-8ad4-c920818f117a|rpc:172.25.0.104:9858|admin:|client:|dataStream:|priority:0, bb31b8e2-b35d-4b3b-ae90-43363de8a349|rpc:172.25.0.102:9858|admin:|client:|dataStream:|priority:1, 6bab7c5a-f782-4236-88e0-70f071e2bf9c|rpc:172.25.0.103:9858|admin:|client:|dataStream:|priority:0], old=null
datanode3_1  | 2021-01-28 02:32:58,575 [grpc-default-executor-2] INFO segmented.SegmentedRaftLogWorker: feb6bea5-edd2-410b-8ad4-c920818f117a@group-A71B52063026-SegmentedRaftLogWorker: Starting segment from index:0
datanode3_1  | 2021-01-28 02:32:58,579 [feb6bea5-edd2-410b-8ad4-c920818f117a@group-A71B52063026-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: feb6bea5-edd2-410b-8ad4-c920818f117a@group-A71B52063026-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/45d6c387-0d5e-4ec1-887d-a71b52063026/current/log_inprogress_0
datanode3_1  | 2021-01-28 02:33:19,172 [ChunkWriter-2-0] INFO client.DNCertificateClient: Getting certificate with certSerialId:2420822746268.
kdc_1        | Jan 28 02:36:08 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.116: ISSUE: authtime 1611801356, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om1@EXAMPLE.COM
kdc_1        | Jan 28 02:36:08 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.25.0.116: ISSUE: authtime 1611801368, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 28 02:36:10 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.116: ISSUE: authtime 1611801368, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om1@EXAMPLE.COM
kdc_1        | Jan 28 02:36:13 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.116: ISSUE: authtime 1611801368, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om1@EXAMPLE.COM
kdc_1        | Jan 28 02:36:18 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.116: ISSUE: authtime 1611801368, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om1@EXAMPLE.COM
kdc_1        | Jan 28 02:36:20 kdc krb5kdc[8](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.25.0.116: ISSUE: authtime 1611801380, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 28 02:36:23 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.116: ISSUE: authtime 1611801380, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om1@EXAMPLE.COM
kdc_1        | Jan 28 02:36:26 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.116: ISSUE: authtime 1611801380, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om1@EXAMPLE.COM
kdc_1        | Jan 28 02:36:29 kdc krb5kdc[8](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.25.0.116: ISSUE: authtime 1611801380, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om1@EXAMPLE.COM
om2_1        | Sleeping for 5 seconds
om2_1        | Setting up kerberos!!
om2_1        | KDC ISSUER_SERVER => kdc:8081
om2_1        | Sleeping for 5 seconds
om2_1        | Got 200, KDC service ready!!
om2_1        | Download om/om2@EXAMPLE.COM keytab file to /etc/security/keytabs/om.keytab
om2_1        | --2021-01-28 02:31:44--  http://kdc:8081/keytab/om2/om
om2_1        | Resolving kdc (kdc)... 172.25.0.100
om2_1        | Connecting to kdc (kdc)|172.25.0.100|:8081... connected.
om2_1        | HTTP request sent, awaiting response... 200 OK
om2_1        | Length: 140 [application/octet-stream]
om2_1        | Saving to: '/etc/security/keytabs/om.keytab'
om2_1        | 
om2_1        |      0K                                                       100% 10.6M=0s
om2_1        | 
om2_1        | 2021-01-28 02:31:44 (10.6 MB/s) - '/etc/security/keytabs/om.keytab' saved [140/140]
om2_1        | 
om2_1        | Keytab name: FILE:/etc/security/keytabs/om.keytab
om2_1        | KVNO Timestamp         Principal
om2_1        | ---- ----------------- --------------------------------------------------------
om2_1        |    2 01/28/21 02:31:44 om/om2@EXAMPLE.COM
om2_1        |    2 01/28/21 02:31:44 om/om2@EXAMPLE.COM
om2_1        | Download HTTP/om2@EXAMPLE.COM keytab file to /etc/security/keytabs/HTTP.keytab
om2_1        | --2021-01-28 02:31:44--  http://kdc:8081/keytab/om2/HTTP
om2_1        | Resolving kdc (kdc)... 172.25.0.100
om2_1        | Connecting to kdc (kdc)|172.25.0.100|:8081... connected.
om2_1        | HTTP request sent, awaiting response... 200 OK
om2_1        | Length: 144 [application/octet-stream]
om2_1        | Saving to: '/etc/security/keytabs/HTTP.keytab'
om2_1        | 
om2_1        |      0K                                                       100% 25.9M=0s
om2_1        | 
om2_1        | 2021-01-28 02:31:44 (25.9 MB/s) - '/etc/security/keytabs/HTTP.keytab' saved [144/144]
om2_1        | 
om2_1        | Keytab name: FILE:/etc/security/keytabs/HTTP.keytab
om2_1        | KVNO Timestamp         Principal
om2_1        | ---- ----------------- --------------------------------------------------------
om2_1        |    2 01/28/21 02:31:44 HTTP/om2@EXAMPLE.COM
om2_1        |    2 01/28/21 02:31:44 HTTP/om2@EXAMPLE.COM
om2_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om2_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om2_1        | 2021-01-28 02:31:55,619 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om2_1        | /************************************************************
om2_1        | STARTUP_MSG: Starting OzoneManager
om2_1        | STARTUP_MSG:   host = om2/172.25.0.112
om2_1        | STARTUP_MSG:   args = [--init]
om2_1        | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
om3_1        | STARTUP_MSG:   host = om3/172.25.0.113
om3_1        | STARTUP_MSG:   args = [--init]
om3_1        | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
om3_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/javax.activation-api-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-storage-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.2.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-1.1.0-SNAPSHOT.jar
om3_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/42171e669d6c7f302fa379fc0289c4341f1cbf75 ; compiled by 'runner' on 2021-01-28T01:42Z
om3_1        | STARTUP_MSG:   java = 11.0.7
om3_1        | ************************************************************/
om3_1        | 2021-01-28 02:31:54,498 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om3_1        | 2021-01-28 02:32:04,722 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om3_1        | 2021-01-28 02:32:05,539 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om3, RPC Address: om3:9862 and Ratis port: 9872
om3_1        | 2021-01-28 02:32:05,545 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.om3: om3
om3_1        | 2021-01-28 02:32:05,547 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.om3: om3
om3_1        | 2021-01-28 02:32:07,373 [main] INFO security.UserGroupInformation: Login successful for user om/om3@EXAMPLE.COM using keytab file /etc/security/keytabs/om.keytab
om3_1        | 2021-01-28 02:32:07,373 [main] INFO om.OzoneManager: Ozone Manager login successful.
om3_1        | 2021-01-28 02:32:07,459 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2021-01-28 02:32:09,995 [main] INFO ipc.Client: Retrying connect to server: scm/172.25.0.116:9863. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-01-28 02:32:10,996 [main] INFO ipc.Client: Retrying connect to server: scm/172.25.0.116:9863. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-01-28 02:32:11,997 [main] INFO ipc.Client: Retrying connect to server: scm/172.25.0.116:9863. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-01-28 02:32:12,998 [main] INFO ipc.Client: Retrying connect to server: scm/172.25.0.116:9863. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-01-28 02:32:13,999 [main] INFO ipc.Client: Retrying connect to server: scm/172.25.0.116:9863. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-01-28 02:32:15,000 [main] INFO ipc.Client: Retrying connect to server: scm/172.25.0.116:9863. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-01-28 02:32:16,001 [main] INFO ipc.Client: Retrying connect to server: scm/172.25.0.116:9863. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-01-28 02:32:17,002 [main] INFO ipc.Client: Retrying connect to server: scm/172.25.0.116:9863. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-01-28 02:32:18,003 [main] INFO ipc.Client: Retrying connect to server: scm/172.25.0.116:9863. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-01-28 02:32:19,003 [main] INFO ipc.Client: Retrying connect to server: scm/172.25.0.116:9863. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-01-28 02:32:19,005 [main] INFO utils.RetriableTask: Execution of task OM#getScmInfo failed, will be retried in 5000 ms
om3_1        | 2021-01-28 02:32:24,714 [main] INFO om.OzoneManager: Initializing secure OzoneManager.
om3_1        | 2021-01-28 02:32:27,591 [main] ERROR client.OMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
om3_1        | 2021-01-28 02:32:27,623 [main] INFO client.OMCertificateClient: Certificate client init case: 0
om3_1        | 2021-01-28 02:32:27,625 [main] INFO client.OMCertificateClient: Creating keypair for client as keypair and certificate not found.
om3_1        | 2021-01-28 02:32:31,327 [main] INFO om.OzoneManager: Init response: GETCERT
om3_1        | 2021-01-28 02:32:31,591 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.113,host:om3
om3_1        | 2021-01-28 02:32:31,599 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
om3_1        | 2021-01-28 02:32:31,615 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om3_1        | 2021-01-28 02:32:31,624 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om3, RPC Address: om3:9862 and Ratis port: 9872
om3_1        | 2021-01-28 02:32:31,631 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.om3: om3
om3_1        | 2021-01-28 02:32:31,632 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.om3: om3
om3_1        | 2021-01-28 02:32:31,633 [main] INFO om.OzoneManager: Creating csr for OM->dns:om3,ip:172.25.0.113,scmId:d25f76ca-50d0-4328-9e5c-3def84e9335b,clusterId:CID-e189ce55-503e-4392-a6f1-64d4ccea7222,subject:root@om3
om3_1        | 2021-01-28 02:32:32,384 [main] INFO om.OzoneManager: OzoneManager ports added:[name: "RPC"
om3_1        | value: 9862
om2_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/javax.activation-api-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-storage-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.2.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-1.1.0-SNAPSHOT.jar
om2_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/42171e669d6c7f302fa379fc0289c4341f1cbf75 ; compiled by 'runner' on 2021-01-28T01:42Z
om2_1        | STARTUP_MSG:   java = 11.0.7
om2_1        | ************************************************************/
om2_1        | 2021-01-28 02:31:55,655 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om2_1        | 2021-01-28 02:32:06,266 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om2_1        | 2021-01-28 02:32:06,776 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om2, RPC Address: om2:9862 and Ratis port: 9872
om2_1        | 2021-01-28 02:32:06,783 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.om2: om2
om2_1        | 2021-01-28 02:32:06,783 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.om2: om2
om2_1        | 2021-01-28 02:32:08,157 [main] INFO security.UserGroupInformation: Login successful for user om/om2@EXAMPLE.COM using keytab file /etc/security/keytabs/om.keytab
om2_1        | 2021-01-28 02:32:08,171 [main] INFO om.OzoneManager: Ozone Manager login successful.
om2_1        | 2021-01-28 02:32:08,202 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2021-01-28 02:32:10,269 [main] INFO ipc.Client: Retrying connect to server: scm/172.25.0.116:9863. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-01-28 02:32:11,270 [main] INFO ipc.Client: Retrying connect to server: scm/172.25.0.116:9863. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-01-28 02:32:12,271 [main] INFO ipc.Client: Retrying connect to server: scm/172.25.0.116:9863. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-01-28 02:32:13,272 [main] INFO ipc.Client: Retrying connect to server: scm/172.25.0.116:9863. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-01-28 02:32:14,272 [main] INFO ipc.Client: Retrying connect to server: scm/172.25.0.116:9863. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-01-28 02:32:15,273 [main] INFO ipc.Client: Retrying connect to server: scm/172.25.0.116:9863. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-01-28 02:32:16,274 [main] INFO ipc.Client: Retrying connect to server: scm/172.25.0.116:9863. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-01-28 02:32:17,275 [main] INFO ipc.Client: Retrying connect to server: scm/172.25.0.116:9863. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-01-28 02:32:18,276 [main] INFO ipc.Client: Retrying connect to server: scm/172.25.0.116:9863. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-01-28 02:32:19,277 [main] INFO ipc.Client: Retrying connect to server: scm/172.25.0.116:9863. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-01-28 02:32:19,279 [main] INFO utils.RetriableTask: Execution of task OM#getScmInfo failed, will be retried in 5000 ms
om2_1        | 2021-01-28 02:32:24,876 [main] INFO om.OzoneManager: Initializing secure OzoneManager.
om2_1        | 2021-01-28 02:32:27,582 [main] ERROR client.OMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
om2_1        | 2021-01-28 02:32:27,583 [main] INFO client.OMCertificateClient: Certificate client init case: 0
om2_1        | 2021-01-28 02:32:27,589 [main] INFO client.OMCertificateClient: Creating keypair for client as keypair and certificate not found.
om2_1        | 2021-01-28 02:32:31,166 [main] INFO om.OzoneManager: Init response: GETCERT
om2_1        | 2021-01-28 02:32:31,339 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.112,host:om2
om2_1        | 2021-01-28 02:32:31,339 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
om2_1        | 2021-01-28 02:32:31,344 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om2_1        | 2021-01-28 02:32:31,351 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om2, RPC Address: om2:9862 and Ratis port: 9872
om2_1        | 2021-01-28 02:32:31,369 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.om2: om2
om2_1        | 2021-01-28 02:32:31,369 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.om2: om2
om2_1        | 2021-01-28 02:32:31,374 [main] INFO om.OzoneManager: Creating csr for OM->dns:om2,ip:172.25.0.112,scmId:d25f76ca-50d0-4328-9e5c-3def84e9335b,clusterId:CID-e189ce55-503e-4392-a6f1-64d4ccea7222,subject:root@om2
om2_1        | 2021-01-28 02:32:32,125 [main] INFO om.OzoneManager: OzoneManager ports added:[name: "RPC"
om2_1        | value: 9862
om2_1        | ]
om2_1        | 2021-01-28 02:32:33,391 [main] INFO om.OzoneManager: Successfully stored SCM signed certificate.
recon_1      | Sleeping for 5 seconds
recon_1      | Setting up kerberos!!
recon_1      | KDC ISSUER_SERVER => kdc:8081
recon_1      | Sleeping for 5 seconds
recon_1      | Got 200, KDC service ready!!
recon_1      | Download recon/recon@EXAMPLE.COM keytab file to /etc/security/keytabs/recon.keytab
recon_1      | --2021-01-28 02:31:43--  http://kdc:8081/keytab/recon/recon
recon_1      | Resolving kdc (kdc)... 172.25.0.100
recon_1      | Connecting to kdc (kdc)|172.25.0.100|:8081... connected.
recon_1      | Keytab name: FILE:/etc/security/keytabs/recon.keytab
recon_1      | KVNO Timestamp         Principal
recon_1      | ---- ----------------- --------------------------------------------------------
recon_1      |    2 01/28/21 02:31:43 recon/recon@EXAMPLE.COM
recon_1      |    2 01/28/21 02:31:43 recon/recon@EXAMPLE.COM
recon_1      | Download HTTP/recon@EXAMPLE.COM keytab file to /etc/security/keytabs/HTTP.keytab
recon_1      | HTTP request sent, awaiting response... 200 OK
recon_1      | Length: 150 [application/octet-stream]
recon_1      | Saving to: '/etc/security/keytabs/recon.keytab'
recon_1      | 
recon_1      |      0K                                                       100% 34.1M=0s
recon_1      | 
recon_1      | 2021-01-28 02:31:43 (34.1 MB/s) - '/etc/security/keytabs/recon.keytab' saved [150/150]
recon_1      | 
recon_1      | --2021-01-28 02:31:43--  http://kdc:8081/keytab/recon/HTTP
recon_1      | Resolving kdc (kdc)... 172.25.0.100
recon_1      | Connecting to kdc (kdc)|172.25.0.100|:8081... connected.
recon_1      | HTTP request sent, awaiting response... 200 OK
recon_1      | Length: 148 [application/octet-stream]
recon_1      | Saving to: '/etc/security/keytabs/HTTP.keytab'
recon_1      | 
recon_1      |      0K                                                       100% 32.1M=0s
recon_1      | 
recon_1      | 2021-01-28 02:31:44 (32.1 MB/s) - '/etc/security/keytabs/HTTP.keytab' saved [148/148]
recon_1      | 
recon_1      | Keytab name: FILE:/etc/security/keytabs/HTTP.keytab
recon_1      | KVNO Timestamp         Principal
recon_1      | ---- ----------------- --------------------------------------------------------
recon_1      |    2 01/28/21 02:31:44 HTTP/recon@EXAMPLE.COM
recon_1      |    2 01/28/21 02:31:44 HTTP/recon@EXAMPLE.COM
recon_1      | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
recon_1      | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
recon_1      | 2021-01-28 02:31:51,843 [main] INFO recon.ReconServer: STARTUP_MSG: 
recon_1      | /************************************************************
recon_1      | STARTUP_MSG: Starting ReconServer
recon_1      | STARTUP_MSG:   host = recon/172.25.0.115
recon_1      | STARTUP_MSG:   args = []
recon_1      | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
recon_1      | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/aopalliance-1.0.jar:/opt/hadoop/share/ozone/lib/sqlite-jdbc-3.25.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/spring-beans-5.2.11.RELEASE.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-reconcodegen-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/guice-4.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/javassist-3.22.0-CR2.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/spring-jdbc-5.2.11.RELEASE.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/javax.activation-api-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/spring-core-5.2.11.RELEASE.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.5.0.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/validation-api-1.1.0.Final.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.2.jar:/opt/hadoop/share/ozone/lib/guice-multibindings-4.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.27.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-tools-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/bonecp-0.8.0.RELEASE.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/javax.inject-2.5.0-b42.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.27.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.27.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-storage-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/javax.ws.rs-api-2.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-entity-filtering-2.27.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/jooq-3.11.10.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/derby-10.14.2.0.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/jooq-codegen-3.11.10.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.4.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/spring-tx-5.2.11.RELEASE.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/guice-assistedinject-4.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.2.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/guice-servlet-4.0.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-2.27.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.5.0-b42.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guice-bridge-2.5.0.jar:/opt/hadoop/share/ozone/lib/jooq-meta-3.11.10.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.2.jar:/opt/hadoop/share/ozone/lib/jersey-media-json-jackson-2.27.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.27.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.27.jar:/opt/hadoop/share/ozone/lib/spring-jcl-5.2.11.RELEASE.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.27.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-recon-1.1.0-SNAPSHOT.jar
recon_1      | STARTUP_MSG:   build = https://github.com/apache/ozone/42171e669d6c7f302fa379fc0289c4341f1cbf75 ; compiled by 'runner' on 2021-01-28T01:42Z
recon_1      | STARTUP_MSG:   java = 11.0.7
recon_1      | ************************************************************/
recon_1      | 2021-01-28 02:31:51,972 [main] INFO recon.ReconServer: registered UNIX signal handlers for [TERM, HUP, INT]
recon_1      | 2021-01-28 02:31:57,403 [main] INFO recon.ReconRestServletModule: rest([/api/v1/*]).packages(org.apache.hadoop.ozone.recon.api)
recon_1      | 2021-01-28 02:32:00,513 [main] INFO recon.ReconServer: Initializing Recon server...
recon_1      | 2021-01-28 02:32:01,528 [main] INFO recon.ReconServer: Ozone security is enabled. Attempting login for Recon service. Principal: recon/recon@EXAMPLE.COM, keytab: /etc/security/keytabs/recon.keytab
recon_1      | 2021-01-28 02:32:03,129 [main] INFO security.UserGroupInformation: Login successful for user recon/recon@EXAMPLE.COM using keytab file /etc/security/keytabs/recon.keytab
recon_1      | 2021-01-28 02:32:03,153 [main] INFO recon.ReconServer: Recon login successful.
recon_1      | 2021-01-28 02:32:04,855 [main] INFO persistence.DefaultDataSourceProvider: JDBC Url for Recon : jdbc:derby:/data/metadata/recon/ozone_recon_derby.db 
recon_1      | 2021-01-28 02:32:10,413 [main] INFO codegen.SqlDbUtils: Created derby database at jdbc:derby:/data/metadata/recon/ozone_recon_derby.db.
recon_1      | WARNING: An illegal reflective access operation has occurred
recon_1      | WARNING: Illegal reflective access by org.jooq.tools.reflect.Reflect (file:/opt/hadoop/share/ozone/lib/jooq-3.11.10.jar) to constructor java.lang.invoke.MethodHandles$Lookup(java.lang.Class)
recon_1      | WARNING: Please consider reporting this to the maintainers of org.jooq.tools.reflect.Reflect
recon_1      | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
recon_1      | WARNING: All illegal access operations will be denied in a future release
recon_1      | 2021-01-28 02:32:11,139 [main] INFO persistence.DefaultDataSourceProvider: JDBC Url for Recon : jdbc:derby:/data/metadata/recon/ozone_recon_derby.db 
recon_1      | 2021-01-28 02:32:11,184 [main] INFO codegen.SqlDbUtils: Created derby database at jdbc:derby:/data/metadata/recon/ozone_recon_derby.db.
recon_1      | 2021-01-28 02:32:11,188 [main] INFO recon.ReconServer: Creating Recon Schema.
recon_1      | 2021-01-28 02:32:13,243 [main] INFO http.BaseHttpServer: Starting Web-server for recon at: http://0.0.0.0:9888
recon_1      | 2021-01-28 02:32:13,243 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
recon_1      | 2021-01-28 02:32:13,243 [main] INFO http.BaseHttpServer: HttpAuthType: ozone.recon.http.auth.type = kerberos
recon_1      | 2021-01-28 02:32:13,274 [main] INFO util.log: Logging initialized @28245ms to org.eclipse.jetty.util.log.Slf4jLog
recon_1      | 2021-01-28 02:32:13,499 [main] WARN http.HttpRequestLog: Jetty request log can only be enabled using Log4j
om2_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-e189ce55-503e-4392-a6f1-64d4ccea7222;layoutVersion=0
om2_1        | 2021-01-28 02:32:33,583 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om2_1        | /************************************************************
om2_1        | SHUTDOWN_MSG: Shutting down OzoneManager at om2/172.25.0.112
om2_1        | ************************************************************/
om2_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om2_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om2_1        | 2021-01-28 02:32:40,976 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om2_1        | /************************************************************
om2_1        | STARTUP_MSG: Starting OzoneManager
om2_1        | STARTUP_MSG:   host = om2/172.25.0.112
om2_1        | STARTUP_MSG:   args = []
om2_1        | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
om2_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/javax.activation-api-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-storage-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.2.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-1.1.0-SNAPSHOT.jar
om2_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/42171e669d6c7f302fa379fc0289c4341f1cbf75 ; compiled by 'runner' on 2021-01-28T01:42Z
om2_1        | STARTUP_MSG:   java = 11.0.7
om2_1        | ************************************************************/
om2_1        | 2021-01-28 02:32:41,047 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om2_1        | 2021-01-28 02:32:46,866 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om2_1        | 2021-01-28 02:32:47,290 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om2, RPC Address: om2:9862 and Ratis port: 9872
om2_1        | 2021-01-28 02:32:47,291 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.om2: om2
om2_1        | 2021-01-28 02:32:47,291 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.om2: om2
om2_1        | 2021-01-28 02:32:47,339 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2021-01-28 02:32:48,546 [main] INFO security.UserGroupInformation: Login successful for user om/om2@EXAMPLE.COM using keytab file /etc/security/keytabs/om.keytab
om2_1        | 2021-01-28 02:32:48,550 [main] INFO om.OzoneManager: Ozone Manager login successful.
om2_1        | 2021-01-28 02:32:48,550 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2021-01-28 02:32:53,213 [main] INFO client.OMCertificateClient: Loading certificate from location:/data/metadata/om/certs.
om2_1        | 2021-01-28 02:32:53,453 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/CA-1.crt.
om2_1        | 2021-01-28 02:32:53,467 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/2423157350642.crt.
om2_1        | 2021-01-28 02:32:53,698 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2021-01-28 02:32:54,102 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om2_1        | 2021-01-28 02:32:54,110 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om2_1        | 2021-01-28 02:32:54,392 [main] INFO Configuration.deprecation: No unit for ozone.manager.delegation.remover.scan.interval(3600000) assuming MILLISECONDS
om2_1        | 2021-01-28 02:32:54,396 [main] INFO security.OzoneSecretStore: Loaded 0 tokens
om2_1        | 2021-01-28 02:32:54,415 [main] INFO security.OzoneDelegationTokenSecretManager: Loading token state into token manager.
om2_1        | 2021-01-28 02:32:54,685 [main] INFO om.OzoneManager: Created Volume s3v With Owner root required for S3Gateway operations.
om2_1        | 2021-01-28 02:32:54,695 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om2_1        | 2021-01-28 02:32:54,707 [main] WARN ratis.OzoneManagerRatisServer: ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
om2_1        | 2021-01-28 02:32:54,710 [main] INFO snapshot.OzoneManagerSnapshotProvider: Initializing OM Snapshot Provider
om2_1        | 2021-01-28 02:32:55,400 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om2_1        | 2021-01-28 02:32:55,500 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om2_1        | 2021-01-28 02:32:55,597 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with GroupID: id1 and Raft Peers: om2:9872, om1:9872, om3:9872
om2_1        | 2021-01-28 02:32:55,640 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
om2_1        | 2021-01-28 02:32:55,740 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
om2_1        | 2021-01-28 02:32:56,026 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
om2_1        | 2021-01-28 02:32:56,027 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om2_1        | 2021-01-28 02:32:56,027 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
om2_1        | 2021-01-28 02:32:56,027 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om2_1        | 2021-01-28 02:32:56,027 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om2_1        | 2021-01-28 02:32:56,028 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om2_1        | 2021-01-28 02:32:56,038 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om2_1        | 2021-01-28 02:32:56,038 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om2_1        | 2021-01-28 02:32:56,053 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om2_1        | 2021-01-28 02:32:56,748 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om2_1        | 2021-01-28 02:32:56,749 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om2_1        | 2021-01-28 02:32:56,749 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om2_1        | 2021-01-28 02:32:56,795 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om2_1        | 2021-01-28 02:32:56,828 [main] INFO server.RaftServer: om2: addNew group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] returns group-562213E44849:java.util.concurrent.CompletableFuture@1a6a4595[Not completed]
om2_1        | 2021-01-28 02:32:56,828 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om2_1        | 2021-01-28 02:32:56,908 [pool-18-thread-1] INFO server.RaftServer$Division: om2: new RaftServerImpl for group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] with OzoneManagerStateMachine:uninitialized
om2_1        | 2021-01-28 02:32:56,956 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om2_1        | 2021-01-28 02:32:56,963 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om2_1        | 2021-01-28 02:32:56,963 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om2_1        | 2021-01-28 02:32:56,963 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om2_1        | 2021-01-28 02:32:56,965 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om2_1        | 2021-01-28 02:32:56,965 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om2_1        | 2021-01-28 02:32:56,965 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om3_1        | ]
om3_1        | 2021-01-28 02:32:33,151 [main] INFO om.OzoneManager: Successfully stored SCM signed certificate.
om3_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-e189ce55-503e-4392-a6f1-64d4ccea7222;layoutVersion=0
om3_1        | 2021-01-28 02:32:33,311 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om3_1        | /************************************************************
om3_1        | SHUTDOWN_MSG: Shutting down OzoneManager at om3/172.25.0.113
om3_1        | ************************************************************/
om3_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om3_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om3_1        | 2021-01-28 02:32:40,225 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om3_1        | /************************************************************
om3_1        | STARTUP_MSG: Starting OzoneManager
om3_1        | STARTUP_MSG:   host = om3/172.25.0.113
om3_1        | STARTUP_MSG:   args = []
om3_1        | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
recon_1      | 2021-01-28 02:32:13,522 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
recon_1      | 2021-01-28 02:32:13,523 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context recon
recon_1      | 2021-01-28 02:32:13,523 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
recon_1      | 2021-01-28 02:32:13,524 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
recon_1      | 2021-01-28 02:32:13,531 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.recon.http.auth.kerberos.principal keytabKey: ozone.recon.http.auth.kerberos.keytab
recon_1      | 2021-01-28 02:32:13,777 [main] INFO tasks.ReconTaskControllerImpl: Registered task ContainerKeyMapperTask with controller.
recon_1      | 2021-01-28 02:32:14,137 [main] INFO tasks.ReconTaskControllerImpl: Registered task FileSizeCountTask with controller.
recon_1      | 2021-01-28 02:32:14,159 [main] INFO tasks.ReconTaskControllerImpl: Registered task TableCountTask with controller.
recon_1      | 2021-01-28 02:32:14,204 [main] INFO ozone.OmUtils: Using OzoneManager ServiceID 'id1'.
recon_1      | 2021-01-28 02:32:14,812 [main] INFO Configuration.deprecation: No unit for ozone.recon.om.connection.request.timeout(5000) assuming MILLISECONDS
recon_1      | 2021-01-28 02:32:15,074 [main] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 2021-01-28 02:32:15,385 [main] WARN recon.ReconUtils: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 2021-01-28 02:32:15,412 [main] INFO net.NodeSchemaLoader: Loading file from java.lang.CompoundEnumeration@75a6cdb
recon_1      | 2021-01-28 02:32:15,417 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
recon_1      | 2021-01-28 02:32:15,535 [main] WARN db.DBStoreBuilder: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 2021-01-28 02:32:15,670 [main] INFO node.SCMNodeManager: Entering startup safe mode.
recon_1      | 2021-01-28 02:32:15,691 [main] INFO scm.ReconNodeManager: Loaded 0 nodes from node DB.
recon_1      | 2021-01-28 02:32:15,702 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
recon_1      | 2021-01-28 02:32:15,774 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
recon_1      | 2021-01-28 02:32:15,812 [Socket Reader #1 for port 9891] INFO ipc.Server: Starting Socket Reader #1 for port 9891
recon_1      | 2021-01-28 02:32:15,896 [Listener at 0.0.0.0/9891] INFO pipeline.SCMPipelineManager: No pipeline exists in current db
recon_1      | 2021-01-28 02:32:15,984 [Listener at 0.0.0.0/9891] INFO recon.ReconServer: Recon server initialized successfully!
recon_1      | 2021-01-28 02:32:15,985 [Listener at 0.0.0.0/9891] INFO recon.ReconServer: Starting Recon server
recon_1      | 2021-01-28 02:32:16,070 [Listener at 0.0.0.0/9891] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
recon_1      | 2021-01-28 02:32:16,081 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
recon_1      | 2021-01-28 02:32:16,081 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Recon metrics system started
recon_1      | 2021-01-28 02:32:16,355 [Listener at 0.0.0.0/9891] INFO http.HttpServer2: Jetty bound to port 9888
recon_1      | 2021-01-28 02:32:16,356 [Listener at 0.0.0.0/9891] INFO server.Server: jetty-9.4.34.v20201102; built: 2020-11-02T14:15:39.302Z; git: e46af88704a893fc12cb0e3bf46e2c7b48a009e7; jvm 11.0.7+10-LTS
recon_1      | 2021-01-28 02:32:16,427 [Listener at 0.0.0.0/9891] INFO server.session: DefaultSessionIdManager workerName=node0
recon_1      | 2021-01-28 02:32:16,427 [Listener at 0.0.0.0/9891] INFO server.session: No SessionScavenger set, using defaults
recon_1      | 2021-01-28 02:32:16,429 [Listener at 0.0.0.0/9891] INFO server.session: node0 Scavenging every 660000ms
recon_1      | 2021-01-28 02:32:16,474 [Listener at 0.0.0.0/9891] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/recon@EXAMPLE.COM
recon_1      | 2021-01-28 02:32:16,486 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@177ddd24{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
recon_1      | 2021-01-28 02:32:16,488 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@615bad16{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-recon-1.1.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
recon_1      | 2021-01-28 02:32:17,084 [Listener at 0.0.0.0/9891] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/recon@EXAMPLE.COM
recon_1      | 2021-01-28 02:32:18,739 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@45bf1ee3{recon,/,file:///tmp/jetty-0_0_0_0-9888-hadoop-ozone-recon-1_1_0-SNAPSHOT_jar-_-any-14693211383483876510/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-recon-1.1.0-SNAPSHOT.jar!/webapps/recon}
recon_1      | 2021-01-28 02:32:18,841 [Listener at 0.0.0.0/9891] INFO server.AbstractConnector: Started ServerConnector@246de37e{HTTP/1.1, (http/1.1)}{0.0.0.0:9888}
recon_1      | 2021-01-28 02:32:18,842 [Listener at 0.0.0.0/9891] INFO server.Server: Started @33813ms
recon_1      | 2021-01-28 02:32:18,851 [Listener at 0.0.0.0/9891] INFO impl.MetricsSinkAdapter: Sink prometheus started
recon_1      | 2021-01-28 02:32:18,851 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Registered sink prometheus
recon_1      | 2021-01-28 02:32:18,857 [Listener at 0.0.0.0/9891] INFO http.BaseHttpServer: HTTP server of recon listening at http://0.0.0.0:9888
recon_1      | 2021-01-28 02:32:18,857 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Starting Ozone Manager Service Provider.
recon_1      | 2021-01-28 02:32:18,880 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Registered OmDeltaRequest task 
recon_1      | 2021-01-28 02:32:18,906 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Registered OmSnapshotRequest task 
recon_1      | 2021-01-28 02:32:18,906 [Listener at 0.0.0.0/9891] INFO recovery.ReconOmMetadataManagerImpl: Starting ReconOMMetadataManagerImpl
recon_1      | 2021-01-28 02:32:18,906 [Listener at 0.0.0.0/9891] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 2021-01-28 02:32:18,907 [Listener at 0.0.0.0/9891] INFO tasks.ReconTaskControllerImpl: Starting Recon Task Controller.
recon_1      | 2021-01-28 02:32:18,908 [Listener at 0.0.0.0/9891] INFO scm.ReconStorageContainerManagerFacade: Recon ScmDatanodeProtocol RPC server is listening at /0.0.0.0:9891
recon_1      | 2021-01-28 02:32:20,012 [Listener at 0.0.0.0/9891] INFO ipc.Client: Retrying connect to server: scm/172.25.0.116:9860. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
recon_1      | 2021-01-28 02:32:22,953 [Listener at 0.0.0.0/9891] INFO scm.ReconStorageContainerManagerFacade: Obtained 0 pipelines from SCM.
recon_1      | 2021-01-28 02:32:22,963 [Listener at 0.0.0.0/9891] INFO scm.ReconPipelineManager: Recon has 0 pipelines in house.
recon_1      | 2021-01-28 02:32:22,963 [Listener at 0.0.0.0/9891] INFO server.SCMDatanodeProtocolServer: RPC server for DataNodes is listening at /0.0.0.0:9891
om2_1        | 2021-01-28 02:32:56,975 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om2_1        | 2021-01-28 02:32:56,994 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om2_1        | 2021-01-28 02:32:57,003 [pool-18-thread-1] INFO server.RaftServer$Division: om2@group-562213E44849: ConfigurationManager, init=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null, confs=<EMPTY_MAP>
om2_1        | 2021-01-28 02:32:57,005 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om2_1        | 2021-01-28 02:32:57,031 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om2_1        | 2021-01-28 02:32:57,032 [pool-18-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 does not exist. Creating ...
om2_1        | 2021-01-28 02:32:57,155 [pool-18-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/in_use.lock acquired by nodename 6@om2
om2_1        | 2021-01-28 02:32:57,292 [pool-18-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 has been successfully formatted.
om2_1        | 2021-01-28 02:32:57,327 [pool-18-thread-1] ERROR storage.RaftStorage: Failed reading configuration from file:/data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/current/raft-meta.conf
om2_1        | java.io.FileNotFoundException: /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/current/raft-meta.conf (No such file or directory)
om2_1        | 	at java.base/java.io.FileInputStream.open0(Native Method)
om2_1        | 	at java.base/java.io.FileInputStream.open(FileInputStream.java:219)
om2_1        | 	at java.base/java.io.FileInputStream.<init>(FileInputStream.java:157)
om2_1        | 	at org.apache.ratis.server.storage.RaftStorageImpl.readRaftConfiguration(RaftStorageImpl.java:143)
om2_1        | 	at org.apache.ratis.server.impl.ServerState.<init>(ServerState.java:122)
om2_1        | 	at org.apache.ratis.server.impl.RaftServerImpl.<init>(RaftServerImpl.java:193)
om2_1        | 	at org.apache.ratis.server.impl.RaftServerProxy.lambda$newRaftServerImpl$4(RaftServerProxy.java:266)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om2_1        | 2021-01-28 02:32:57,335 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om2_1        | 2021-01-28 02:32:57,337 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om2_1        | 2021-01-28 02:32:57,414 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om2_1        | 2021-01-28 02:32:57,414 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om2_1        | 2021-01-28 02:32:57,624 [pool-18-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.om2@group-562213E44849
om2_1        | 2021-01-28 02:32:57,740 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om2_1        | 2021-01-28 02:32:58,045 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om2_1        | 2021-01-28 02:32:58,053 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om2_1        | 2021-01-28 02:32:58,148 [pool-18-thread-1] INFO segmented.SegmentedRaftLogWorker: new om2@group-562213E44849-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849
om2_1        | 2021-01-28 02:32:58,151 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om2_1        | 2021-01-28 02:32:58,155 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om2_1        | 2021-01-28 02:32:58,156 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om2_1        | 2021-01-28 02:32:58,159 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om2_1        | 2021-01-28 02:32:58,163 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om2_1        | 2021-01-28 02:32:58,169 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om2_1        | 2021-01-28 02:32:58,193 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om2_1        | 2021-01-28 02:32:58,203 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om2_1        | 2021-01-28 02:32:58,311 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om2_1        | 2021-01-28 02:32:58,316 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om2_1        | 2021-01-28 02:32:58,393 [pool-18-thread-1] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
om2_1        | 2021-01-28 02:32:58,393 [pool-18-thread-1] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om2_1        | 2021-01-28 02:32:58,428 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om2_1        | 2021-01-28 02:32:58,434 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om2_1        | 2021-01-28 02:32:58,438 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om2_1        | 2021-01-28 02:32:58,439 [Listener at om2/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om2_1        | 2021-01-28 02:32:58,445 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om2_1        | 2021-01-28 02:32:58,460 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
om2_1        | 2021-01-28 02:32:58,460 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om2_1        | 2021-01-28 02:32:58,620 [Listener at om2/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om2_1        | 2021-01-28 02:32:58,620 [Listener at om2/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om2_1        | 2021-01-28 02:32:58,707 [pool-18-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.om2@group-562213E44849
om2_1        | 2021-01-28 02:32:58,714 [pool-18-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.om2@group-562213E44849
om2_1        | 2021-01-28 02:32:58,837 [Listener at om2/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om2/172.25.0.112:9862
om2_1        | 2021-01-28 02:32:58,837 [Listener at om2/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om2 at port 9872
om2_1        | 2021-01-28 02:32:58,846 [Listener at om2/9862] INFO server.RaftServer$Division: om2@group-562213E44849: start as a follower, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
recon_1      | 2021-01-28 02:32:22,991 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
recon_1      | 2021-01-28 02:32:22,992 [IPC Server listener on 9891] INFO ipc.Server: IPC Server listener on 9891: starting
recon_1      | 2021-01-28 02:32:23,363 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Registered ContainerHealthTask task 
recon_1      | 2021-01-28 02:32:23,364 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Starting ContainerHealthTask Thread.
recon_1      | 2021-01-28 02:32:23,428 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Registered PipelineSyncTask task 
recon_1      | 2021-01-28 02:32:23,428 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Starting PipelineSyncTask Thread.
recon_1      | 2021-01-28 02:32:23,487 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 0 pipelines in house.
recon_1      | 2021-01-28 02:32:23,487 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 48 milliseconds.
recon_1      | 2021-01-28 02:32:23,701 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 322 milliseconds to process 0 existing database records.
recon_1      | 2021-01-28 02:32:23,756 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 46 milliseconds for processing 0 containers.
recon_1      | 2021-01-28 02:32:38,908 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2021-01-28 02:32:38,908 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2021-01-28 02:32:39,053 [pool-16-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy41.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
recon_1      | 2021-01-28 02:32:39,068 [pool-16-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy41.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-01-28 02:32:39,895 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/db0158eeb642@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38365
recon_1      | 2021-01-28 02:32:39,908 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/d20fde691356@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35883
recon_1      | 2021-01-28 02:32:39,916 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/db0158eeb642@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2021-01-28 02:32:39,940 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/d20fde691356@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2021-01-28 02:32:40,972 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/d5a2d8142681@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:38333
recon_1      | 2021-01-28 02:32:41,003 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/d5a2d8142681@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2021-01-28 02:32:41,069 [pool-16-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy41.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 3 failover attempts. Trying to failover immediately.
recon_1      | 2021-01-28 02:32:41,070 [pool-16-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy41.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 4 failover attempts. Trying to failover immediately.
recon_1      | 2021-01-28 02:32:41,070 [pool-16-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy41.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-01-28 02:32:41,736 [IPC Server handler 3 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/bb31b8e2-b35d-4b3b-ae90-43363de8a349
recon_1      | 2021-01-28 02:32:41,752 [IPC Server handler 3 on default port 9891] INFO node.SCMNodeManager: Registered Data node : bb31b8e2-b35d-4b3b-ae90-43363de8a349{ip: 172.25.0.102, host: ozonesecure-om-ha_datanode1_1.ozonesecure-om-ha_ozone_net, networkLocation: /default-rack, certSerialId: 2411674243301, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2021-01-28 02:32:41,768 [IPC Server handler 2 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/6bab7c5a-f782-4236-88e0-70f071e2bf9c
recon_1      | 2021-01-28 02:32:41,804 [IPC Server handler 2 on default port 9891] INFO node.SCMNodeManager: Registered Data node : 6bab7c5a-f782-4236-88e0-70f071e2bf9c{ip: 172.25.0.103, host: ozonesecure-om-ha_datanode2_1.ozonesecure-om-ha_ozone_net, networkLocation: /default-rack, certSerialId: 2411778267491, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2021-01-28 02:32:42,046 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node bb31b8e2-b35d-4b3b-ae90-43363de8a349 to Node DB.
recon_1      | 2021-01-28 02:32:42,047 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 6bab7c5a-f782-4236-88e0-70f071e2bf9c to Node DB.
recon_1      | 2021-01-28 02:32:42,853 [IPC Server handler 2 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/feb6bea5-edd2-410b-8ad4-c920818f117a
recon_1      | 2021-01-28 02:32:42,854 [IPC Server handler 2 on default port 9891] INFO node.SCMNodeManager: Registered Data node : feb6bea5-edd2-410b-8ad4-c920818f117a{ip: 172.25.0.104, host: ozonesecure-om-ha_datanode3_1.ozonesecure-om-ha_ozone_net, networkLocation: /default-rack, certSerialId: 2411677671379, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2021-01-28 02:32:42,854 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node feb6bea5-edd2-410b-8ad4-c920818f117a to Node DB.
recon_1      | 2021-01-28 02:32:43,071 [pool-16-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy41.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 6 failover attempts. Trying to failover immediately.
recon_1      | 2021-01-28 02:32:43,072 [pool-16-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy41.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 7 failover attempts. Trying to failover immediately.
recon_1      | 2021-01-28 02:32:43,073 [pool-16-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy41.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 8 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-01-28 02:32:45,074 [pool-16-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy41.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 9 failover attempts. Trying to failover immediately.
recon_1      | 2021-01-28 02:32:45,075 [pool-16-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy41.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 10 failover attempts. Trying to failover immediately.
recon_1      | 2021-01-28 02:32:45,076 [pool-16-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy41.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 11 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-01-28 02:32:46,302 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=39c789b6-0c46-456e-8a71-97a240718454. Trying to get from SCM.
recon_1      | 2021-01-28 02:32:46,578 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: 39c789b6-0c46-456e-8a71-97a240718454, Nodes: feb6bea5-edd2-410b-8ad4-c920818f117a{ip: 172.25.0.104, host: ozonesecure-om-ha_datanode3_1.ozonesecure-om-ha_ozone_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:ONE, State:OPEN, leaderId:feb6bea5-edd2-410b-8ad4-c920818f117a, CreationTimestamp2021-01-28T02:32:42.862Z] to Recon pipeline metadata.
recon_1      | 2021-01-28 02:32:46,610 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 39c789b6-0c46-456e-8a71-97a240718454, Nodes: feb6bea5-edd2-410b-8ad4-c920818f117a{ip: 172.25.0.104, host: ozonesecure-om-ha_datanode3_1.ozonesecure-om-ha_ozone_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:ONE, State:OPEN, leaderId:feb6bea5-edd2-410b-8ad4-c920818f117a, CreationTimestamp2021-01-28T02:32:42.862Z]
recon_1      | 2021-01-28 02:32:46,999 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=45d6c387-0d5e-4ec1-887d-a71b52063026. Trying to get from SCM.
recon_1      | 2021-01-28 02:32:47,003 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: 45d6c387-0d5e-4ec1-887d-a71b52063026, Nodes: feb6bea5-edd2-410b-8ad4-c920818f117a{ip: 172.25.0.104, host: ozonesecure-om-ha_datanode3_1.ozonesecure-om-ha_ozone_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}6bab7c5a-f782-4236-88e0-70f071e2bf9c{ip: 172.25.0.103, host: ozonesecure-om-ha_datanode2_1.ozonesecure-om-ha_ozone_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}bb31b8e2-b35d-4b3b-ae90-43363de8a349{ip: 172.25.0.102, host: ozonesecure-om-ha_datanode1_1.ozonesecure-om-ha_ozone_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:, CreationTimestamp2021-01-28T02:32:42.878Z] to Recon pipeline metadata.
recon_1      | 2021-01-28 02:32:47,004 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 45d6c387-0d5e-4ec1-887d-a71b52063026, Nodes: feb6bea5-edd2-410b-8ad4-c920818f117a{ip: 172.25.0.104, host: ozonesecure-om-ha_datanode3_1.ozonesecure-om-ha_ozone_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}6bab7c5a-f782-4236-88e0-70f071e2bf9c{ip: 172.25.0.103, host: ozonesecure-om-ha_datanode2_1.ozonesecure-om-ha_ozone_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}bb31b8e2-b35d-4b3b-ae90-43363de8a349{ip: 172.25.0.102, host: ozonesecure-om-ha_datanode1_1.ozonesecure-om-ha_ozone_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:, CreationTimestamp2021-01-28T02:32:42.878Z]
recon_1      | 2021-01-28 02:32:47,004 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=45d6c387-0d5e-4ec1-887d-a71b52063026 reported by feb6bea5-edd2-410b-8ad4-c920818f117a{ip: 172.25.0.104, host: ozonesecure-om-ha_datanode3_1.ozonesecure-om-ha_ozone_net, networkLocation: /default-rack, certSerialId: 2411677671379, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2021-01-28 02:32:47,077 [pool-16-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy41.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 12 failover attempts. Trying to failover immediately.
recon_1      | 2021-01-28 02:32:47,078 [pool-16-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy41.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 13 failover attempts. Trying to failover immediately.
recon_1      | 2021-01-28 02:32:47,079 [pool-16-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy41.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 14 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-01-28 02:32:49,082 [pool-16-thread-1] ERROR ha.OMFailoverProxyProvider: Failed to connect to OMs: [nodeId=om1,nodeAddress=om1:9862, nodeId=om3,nodeAddress=om3:9862, nodeId=om2,nodeAddress=om2:9862]. Attempted 15 failovers. Got following exceptions during retries: 
om3_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/javax.activation-api-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-storage-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.2.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-1.1.0-SNAPSHOT.jar
om3_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/42171e669d6c7f302fa379fc0289c4341f1cbf75 ; compiled by 'runner' on 2021-01-28T01:42Z
om3_1        | STARTUP_MSG:   java = 11.0.7
om3_1        | ************************************************************/
om3_1        | 2021-01-28 02:32:40,268 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om3_1        | 2021-01-28 02:32:46,213 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om3_1        | 2021-01-28 02:32:46,676 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om3, RPC Address: om3:9862 and Ratis port: 9872
om3_1        | 2021-01-28 02:32:46,677 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.om3: om3
om3_1        | 2021-01-28 02:32:46,677 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.om3: om3
om3_1        | 2021-01-28 02:32:46,727 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2021-01-28 02:32:47,864 [main] INFO security.UserGroupInformation: Login successful for user om/om3@EXAMPLE.COM using keytab file /etc/security/keytabs/om.keytab
om3_1        | 2021-01-28 02:32:47,864 [main] INFO om.OzoneManager: Ozone Manager login successful.
om3_1        | 2021-01-28 02:32:47,867 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2021-01-28 02:32:52,182 [main] INFO client.OMCertificateClient: Loading certificate from location:/data/metadata/om/certs.
om3_1        | 2021-01-28 02:32:52,614 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/2422875312971.crt.
om3_1        | 2021-01-28 02:32:52,672 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/CA-1.crt.
om3_1        | 2021-01-28 02:32:52,910 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2021-01-28 02:32:53,414 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om3_1        | 2021-01-28 02:32:53,415 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om3_1        | 2021-01-28 02:32:53,701 [main] INFO Configuration.deprecation: No unit for ozone.manager.delegation.remover.scan.interval(3600000) assuming MILLISECONDS
om3_1        | 2021-01-28 02:32:53,712 [main] INFO security.OzoneSecretStore: Loaded 0 tokens
om3_1        | 2021-01-28 02:32:53,722 [main] INFO security.OzoneDelegationTokenSecretManager: Loading token state into token manager.
om3_1        | 2021-01-28 02:32:54,019 [main] INFO om.OzoneManager: Created Volume s3v With Owner root required for S3Gateway operations.
om3_1        | 2021-01-28 02:32:54,053 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om3_1        | 2021-01-28 02:32:54,058 [main] WARN ratis.OzoneManagerRatisServer: ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
om3_1        | 2021-01-28 02:32:54,062 [main] INFO snapshot.OzoneManagerSnapshotProvider: Initializing OM Snapshot Provider
om3_1        | 2021-01-28 02:32:54,424 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om3_1        | 2021-01-28 02:32:54,506 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om3_1        | 2021-01-28 02:32:54,594 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with GroupID: id1 and Raft Peers: om3:9872, om1:9872, om2:9872
om3_1        | 2021-01-28 02:32:54,630 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
om3_1        | 2021-01-28 02:32:54,700 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
om3_1        | 2021-01-28 02:32:54,980 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
om3_1        | 2021-01-28 02:32:54,982 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om3_1        | 2021-01-28 02:32:54,984 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
om3_1        | 2021-01-28 02:32:54,986 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om3_1        | 2021-01-28 02:32:54,986 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om3_1        | 2021-01-28 02:32:54,987 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om3_1        | 2021-01-28 02:32:54,997 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om3_1        | 2021-01-28 02:32:55,001 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om3_1        | 2021-01-28 02:32:55,018 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om3_1        | 2021-01-28 02:32:55,796 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om3_1        | 2021-01-28 02:32:55,798 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om3_1        | 2021-01-28 02:32:55,803 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om3_1        | 2021-01-28 02:32:55,835 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om3_1        | 2021-01-28 02:32:55,862 [main] INFO server.RaftServer: om3: addNew group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] returns group-562213E44849:java.util.concurrent.CompletableFuture@4965454c[Not completed]
om3_1        | 2021-01-28 02:32:55,863 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om3_1        | 2021-01-28 02:32:55,956 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om3_1        | 2021-01-28 02:32:55,954 [pool-18-thread-1] INFO server.RaftServer$Division: om3: new RaftServerImpl for group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] with OzoneManagerStateMachine:uninitialized
om3_1        | 2021-01-28 02:32:55,963 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om3_1        | 2021-01-28 02:32:55,966 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om3_1        | 2021-01-28 02:32:55,966 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om3_1        | 2021-01-28 02:32:55,966 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om3_1        | 2021-01-28 02:32:55,966 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om1_1        | Sleeping for 5 seconds
om1_1        | Setting up kerberos!!
om1_1        | KDC ISSUER_SERVER => kdc:8081
om1_1        | Sleeping for 5 seconds
om1_1        | Got 200, KDC service ready!!
om1_1        | Download om/om1@EXAMPLE.COM keytab file to /etc/security/keytabs/om.keytab
om1_1        | --2021-01-28 02:31:42--  http://kdc:8081/keytab/om1/om
om1_1        | Resolving kdc (kdc)... 172.25.0.100
om1_1        | Connecting to kdc (kdc)|172.25.0.100|:8081... connected.
om1_1        | HTTP request sent, awaiting response... 200 OK
om1_1        | Length: 140 [application/octet-stream]
om1_1        | Saving to: '/etc/security/keytabs/om.keytab'
om1_1        | 
om1_1        |      0K                                                       100% 23.4M=0s
om1_1        | 
om1_1        | 2021-01-28 02:31:42 (23.4 MB/s) - '/etc/security/keytabs/om.keytab' saved [140/140]
om1_1        | 
om1_1        | Keytab name: FILE:/etc/security/keytabs/om.keytab
om1_1        | KVNO Timestamp         Principal
om1_1        | ---- ----------------- --------------------------------------------------------
om1_1        |    2 01/28/21 02:31:42 om/om1@EXAMPLE.COM
om1_1        |    2 01/28/21 02:31:42 om/om1@EXAMPLE.COM
om1_1        | Download HTTP/om1@EXAMPLE.COM keytab file to /etc/security/keytabs/HTTP.keytab
om1_1        | --2021-01-28 02:31:42--  http://kdc:8081/keytab/om1/HTTP
om1_1        | Resolving kdc (kdc)... 172.25.0.100
om1_1        | Connecting to kdc (kdc)|172.25.0.100|:8081... connected.
om1_1        | HTTP request sent, awaiting response... 200 OK
om1_1        | Length: 144 [application/octet-stream]
om1_1        | Saving to: '/etc/security/keytabs/HTTP.keytab'
om1_1        | 
om1_1        |      0K                                                       100% 26.4M=0s
om1_1        | 
om1_1        | 2021-01-28 02:31:42 (26.4 MB/s) - '/etc/security/keytabs/HTTP.keytab' saved [144/144]
om1_1        | 
om1_1        | Keytab name: FILE:/etc/security/keytabs/HTTP.keytab
om1_1        | KVNO Timestamp         Principal
om1_1        | ---- ----------------- --------------------------------------------------------
om1_1        |    2 01/28/21 02:31:42 HTTP/om1@EXAMPLE.COM
om1_1        |    2 01/28/21 02:31:42 HTTP/om1@EXAMPLE.COM
om1_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om1_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om1_1        | 2021-01-28 02:31:51,215 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om1_1        | /************************************************************
om1_1        | STARTUP_MSG: Starting OzoneManager
om1_1        | STARTUP_MSG:   host = om1/172.25.0.111
om1_1        | STARTUP_MSG:   args = [--init]
om1_1        | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
om3_1        | 2021-01-28 02:32:55,967 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om3_1        | 2021-01-28 02:32:55,973 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om3_1        | 2021-01-28 02:32:55,979 [pool-18-thread-1] INFO server.RaftServer$Division: om3@group-562213E44849: ConfigurationManager, init=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null, confs=<EMPTY_MAP>
om3_1        | 2021-01-28 02:32:55,987 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om3_1        | 2021-01-28 02:32:56,000 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om3_1        | 2021-01-28 02:32:56,002 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om3_1        | 2021-01-28 02:32:56,029 [pool-18-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 does not exist. Creating ...
om3_1        | 2021-01-28 02:32:56,104 [pool-18-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/in_use.lock acquired by nodename 6@om3
om3_1        | 2021-01-28 02:32:56,215 [pool-18-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 has been successfully formatted.
om3_1        | 2021-01-28 02:32:56,221 [pool-18-thread-1] ERROR storage.RaftStorage: Failed reading configuration from file:/data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/current/raft-meta.conf
om3_1        | java.io.FileNotFoundException: /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/current/raft-meta.conf (No such file or directory)
om3_1        | 	at java.base/java.io.FileInputStream.open0(Native Method)
om3_1        | 	at java.base/java.io.FileInputStream.open(FileInputStream.java:219)
om3_1        | 	at java.base/java.io.FileInputStream.<init>(FileInputStream.java:157)
om3_1        | 	at org.apache.ratis.server.storage.RaftStorageImpl.readRaftConfiguration(RaftStorageImpl.java:143)
om3_1        | 	at org.apache.ratis.server.impl.ServerState.<init>(ServerState.java:122)
om3_1        | 	at org.apache.ratis.server.impl.RaftServerImpl.<init>(RaftServerImpl.java:193)
om3_1        | 	at org.apache.ratis.server.impl.RaftServerProxy.lambda$newRaftServerImpl$4(RaftServerProxy.java:266)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om3_1        | 2021-01-28 02:32:56,227 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om3_1        | 2021-01-28 02:32:56,237 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om3_1        | 2021-01-28 02:32:56,286 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om3_1        | 2021-01-28 02:32:56,286 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om3_1        | 2021-01-28 02:32:56,311 [pool-18-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.om3@group-562213E44849
om3_1        | 2021-01-28 02:32:56,372 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om3_1        | 2021-01-28 02:32:56,425 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om3_1        | 2021-01-28 02:32:56,427 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om3_1        | 2021-01-28 02:32:56,452 [pool-18-thread-1] INFO segmented.SegmentedRaftLogWorker: new om3@group-562213E44849-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849
om3_1        | 2021-01-28 02:32:56,459 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om3_1        | 2021-01-28 02:32:56,465 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om3_1        | 2021-01-28 02:32:56,467 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om3_1        | 2021-01-28 02:32:56,474 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om3_1        | 2021-01-28 02:32:56,487 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om3_1        | 2021-01-28 02:32:56,489 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om3_1        | 2021-01-28 02:32:56,495 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om3_1        | 2021-01-28 02:32:56,495 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om3_1        | 2021-01-28 02:32:56,525 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om3_1        | 2021-01-28 02:32:56,527 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om3_1        | 2021-01-28 02:32:56,542 [pool-18-thread-1] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
om3_1        | 2021-01-28 02:32:56,560 [pool-18-thread-1] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om3_1        | 2021-01-28 02:32:56,566 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om3_1        | 2021-01-28 02:32:56,572 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om3_1        | 2021-01-28 02:32:56,574 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om3_1        | 2021-01-28 02:32:56,574 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om3_1        | 2021-01-28 02:32:56,664 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
om3_1        | 2021-01-28 02:32:56,666 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om3_1        | 2021-01-28 02:32:56,836 [pool-18-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.om3@group-562213E44849
om3_1        | 2021-01-28 02:32:56,850 [pool-18-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.om3@group-562213E44849
om3_1        | 2021-01-28 02:32:56,980 [Listener at om3/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om3_1        | 2021-01-28 02:32:57,107 [Listener at om3/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om3_1        | 2021-01-28 02:32:57,108 [Listener at om3/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om3_1        | 2021-01-28 02:32:57,343 [Listener at om3/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om3/172.25.0.113:9862
om3_1        | 2021-01-28 02:32:57,353 [Listener at om3/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om3 at port 9872
recon_1      | Retry Attempt 0 Exception - java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
recon_1      | Retry Attempt 1 Exception - java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
recon_1      | Retry Attempt 2 Exception - java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
recon_1      | Retry Attempt 3 Exception - java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
recon_1      | Retry Attempt 4 Exception - java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
recon_1      | Retry Attempt 5 Exception - java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
recon_1      | Retry Attempt 6 Exception - java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
recon_1      | Retry Attempt 7 Exception - java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
recon_1      | Retry Attempt 8 Exception - java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
recon_1      | Retry Attempt 9 Exception - java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
recon_1      | Retry Attempt 10 Exception - java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
recon_1      | Retry Attempt 11 Exception - java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
recon_1      | Retry Attempt 12 Exception - java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
recon_1      | Retry Attempt 13 Exception - java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
recon_1      | Retry Attempt 14 Exception - java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
recon_1      | Retry Attempt 15 Exception - java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
recon_1      | 
recon_1      | 2021-01-28 02:32:49,083 [pool-16-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to obtain Ozone Manager DB Snapshot. 
recon_1      | java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:836)
recon_1      | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:760)
recon_1      | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1566)
recon_1      | 	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
recon_1      | 	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
recon_1      | 	at com.sun.proxy.$Proxy41.submitRequest(Unknown Source)
recon_1      | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
recon_1      | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
recon_1      | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
recon_1      | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
recon_1      | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
recon_1      | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
recon_1      | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
recon_1      | 	at com.sun.proxy.$Proxy41.submitRequest(Unknown Source)
recon_1      | 	at org.apache.hadoop.ozone.om.protocolPB.Hadoop3OmTransport.submitRequest(Hadoop3OmTransport.java:80)
recon_1      | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:218)
recon_1      | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceList(OzoneManagerProtocolClientSideTranslatorPB.java:1049)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerSnapshotUrl(OzoneManagerServiceProviderImpl.java:264)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:299)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:535)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:516)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:297)
s3g_1        | Sleeping for 5 seconds
s3g_1        | Setting up kerberos!!
s3g_1        | KDC ISSUER_SERVER => kdc:8081
s3g_1        | Sleeping for 5 seconds
s3g_1        | Got 200, KDC service ready!!
s3g_1        | Download s3g/s3g@EXAMPLE.COM keytab file to /etc/security/keytabs/s3g.keytab
s3g_1        | --2021-01-28 02:31:42--  http://kdc:8081/keytab/s3g/s3g
s3g_1        | Resolving kdc (kdc)... 172.25.0.100
s3g_1        | Connecting to kdc (kdc)|172.25.0.100|:8081... connected.
s3g_1        | HTTP request sent, awaiting response... 200 OK
s3g_1        | Length: 142 [application/octet-stream]
s3g_1        | Saving to: '/etc/security/keytabs/s3g.keytab'
s3g_1        | 
s3g_1        |      0K                                                       100% 26.0M=0s
s3g_1        | 
s3g_1        | 2021-01-28 02:31:42 (26.0 MB/s) - '/etc/security/keytabs/s3g.keytab' saved [142/142]
s3g_1        | 
s3g_1        | Keytab name: FILE:/etc/security/keytabs/s3g.keytab
s3g_1        | KVNO Timestamp         Principal
s3g_1        | ---- ----------------- --------------------------------------------------------
s3g_1        |    2 01/28/21 02:31:42 s3g/s3g@EXAMPLE.COM
s3g_1        |    2 01/28/21 02:31:42 s3g/s3g@EXAMPLE.COM
s3g_1        | Download HTTP/s3g@EXAMPLE.COM keytab file to /etc/security/keytabs/HTTP.keytab
s3g_1        | --2021-01-28 02:31:42--  http://kdc:8081/keytab/s3g/HTTP
s3g_1        | Resolving kdc (kdc)... 172.25.0.100
s3g_1        | Connecting to kdc (kdc)|172.25.0.100|:8081... connected.
s3g_1        | HTTP request sent, awaiting response... 200 OK
s3g_1        | Length: 144 [application/octet-stream]
s3g_1        | Saving to: '/etc/security/keytabs/HTTP.keytab'
s3g_1        | 
s3g_1        |      0K                                                       100% 18.1M=0s
s3g_1        | 
s3g_1        | 2021-01-28 02:31:42 (18.1 MB/s) - '/etc/security/keytabs/HTTP.keytab' saved [144/144]
s3g_1        | 
s3g_1        | Keytab name: FILE:/etc/security/keytabs/HTTP.keytab
s3g_1        | KVNO Timestamp         Principal
s3g_1        | ---- ----------------- --------------------------------------------------------
s3g_1        |    2 01/28/21 02:31:42 HTTP/s3g@EXAMPLE.COM
s3g_1        |    2 01/28/21 02:31:42 HTTP/s3g@EXAMPLE.COM
s3g_1        | Download testuser/s3g@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser.keytab
s3g_1        | --2021-01-28 02:31:42--  http://kdc:8081/keytab/s3g/testuser
s3g_1        | Resolving kdc (kdc)... 172.25.0.100
s3g_1        | Connecting to kdc (kdc)|172.25.0.100|:8081... connected.
s3g_1        | HTTP request sent, awaiting response... 200 OK
s3g_1        | Length: 152 [application/octet-stream]
s3g_1        | Saving to: '/etc/security/keytabs/testuser.keytab'
s3g_1        | 
s3g_1        |      0K                                                       100% 23.4M=0s
s3g_1        | 
s3g_1        | 2021-01-28 02:31:43 (23.4 MB/s) - '/etc/security/keytabs/testuser.keytab' saved [152/152]
s3g_1        | 
s3g_1        | Keytab name: FILE:/etc/security/keytabs/testuser.keytab
s3g_1        | KVNO Timestamp         Principal
s3g_1        | ---- ----------------- --------------------------------------------------------
s3g_1        |    2 01/28/21 02:31:43 testuser/s3g@EXAMPLE.COM
s3g_1        |    2 01/28/21 02:31:43 testuser/s3g@EXAMPLE.COM
s3g_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
s3g_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
s3g_1        | 2021-01-28 02:31:54,302 [main] INFO http.BaseHttpServer: Starting Web-server for s3gateway at: http://0.0.0.0:9878
s3g_1        | 2021-01-28 02:31:54,324 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
s3g_1        | 2021-01-28 02:31:54,336 [main] INFO http.BaseHttpServer: HttpAuthType: ozone.s3g.http.auth.type = kerberos
s3g_1        | 2021-01-28 02:31:54,694 [main] INFO util.log: Logging initialized @10872ms to org.eclipse.jetty.util.log.Slf4jLog
s3g_1        | 2021-01-28 02:31:55,881 [main] INFO http.HttpRequestLog: Http request log for http.requests.s3gateway is not defined
s3g_1        | 2021-01-28 02:31:55,951 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
s3g_1        | 2021-01-28 02:31:55,972 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context s3gateway
s3g_1        | 2021-01-28 02:31:55,977 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
s3g_1        | 2021-01-28 02:31:55,988 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
s3g_1        | 2021-01-28 02:31:56,039 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.s3g.http.auth.kerberos.principal keytabKey: ozone.s3g.http.auth.kerberos.keytab
s3g_1        | 2021-01-28 02:31:56,648 [main] INFO s3.Gateway: STARTUP_MSG: 
s3g_1        | /************************************************************
s3g_1        | STARTUP_MSG: Starting Gateway
s3g_1        | STARTUP_MSG:   host = s3g/172.25.0.114
s3g_1        | STARTUP_MSG:   args = []
s3g_1        | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
s3g_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/javax.interceptor-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/javassist-3.22.0-CR2.jar:/opt/hadoop/share/ozone/lib/javax.el-api-3.0.0.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/javax.activation-api-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.5.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/validation-api-1.1.0.Final.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.27.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/cdi-api-1.2.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/javax.inject-2.5.0-b42.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.27.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.27.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/jersey-cdi1x-2.27.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.ws.rs-api-2.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-dataformat-xml-2.10.3.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.4.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.2.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.5.0-b42.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.2.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.27.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.27.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.27.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-s3gateway-1.1.0-SNAPSHOT.jar
s3g_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/42171e669d6c7f302fa379fc0289c4341f1cbf75 ; compiled by 'runner' on 2021-01-28T01:42Z
s3g_1        | STARTUP_MSG:   java = 11.0.7
s3g_1        | ************************************************************/
s3g_1        | 2021-01-28 02:31:56,712 [main] INFO s3.Gateway: registered UNIX signal handlers for [TERM, HUP, INT]
s3g_1        | 2021-01-28 02:31:57,058 [main] INFO s3.Gateway: Starting Ozone S3 gateway
s3g_1        | 2021-01-28 02:31:57,114 [main] INFO http.HttpServer2: Jetty bound to port 9878
s3g_1        | 2021-01-28 02:31:57,138 [main] INFO server.Server: jetty-9.4.34.v20201102; built: 2020-11-02T14:15:39.302Z; git: e46af88704a893fc12cb0e3bf46e2c7b48a009e7; jvm 11.0.7+10-LTS
s3g_1        | 2021-01-28 02:31:57,550 [main] INFO server.session: DefaultSessionIdManager workerName=node0
s3g_1        | 2021-01-28 02:31:57,557 [main] INFO server.session: No SessionScavenger set, using defaults
s3g_1        | 2021-01-28 02:31:57,569 [main] INFO server.session: node0 Scavenging every 660000ms
s3g_1        | 2021-01-28 02:31:57,923 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/s3g@EXAMPLE.COM
s3g_1        | 2021-01-28 02:31:58,160 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@a4ca3f6{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
s3g_1        | 2021-01-28 02:31:58,184 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@3543df7d{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-s3gateway-1.1.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:329)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:427)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:233)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:834)
recon_1      | Caused by: java.net.ConnectException: Connection refused
recon_1      | 	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
recon_1      | 	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:779)
recon_1      | 	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
recon_1      | 	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:534)
recon_1      | 	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:699)
recon_1      | 	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:812)
recon_1      | 	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:413)
recon_1      | 	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1636)
recon_1      | 	at org.apache.hadoop.ipc.Client.call(Client.java:1452)
recon_1      | 	... 34 more
recon_1      | 2021-01-28 02:32:49,085 [pool-16-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Null snapshot location got from OM.
recon_1      | 2021-01-28 02:32:49,329 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=45d6c387-0d5e-4ec1-887d-a71b52063026 reported by 6bab7c5a-f782-4236-88e0-70f071e2bf9c{ip: 172.25.0.103, host: ozonesecure-om-ha_datanode2_1.ozonesecure-om-ha_ozone_net, networkLocation: /default-rack, certSerialId: 2411778267491, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2021-01-28 02:32:51,610 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=45d6c387-0d5e-4ec1-887d-a71b52063026 reported by bb31b8e2-b35d-4b3b-ae90-43363de8a349{ip: 172.25.0.102, host: ozonesecure-om-ha_datanode1_1.ozonesecure-om-ha_ozone_net, networkLocation: /default-rack, certSerialId: 2411674243301, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2021-01-28 02:32:51,993 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=45d6c387-0d5e-4ec1-887d-a71b52063026 reported by feb6bea5-edd2-410b-8ad4-c920818f117a{ip: 172.25.0.104, host: ozonesecure-om-ha_datanode3_1.ozonesecure-om-ha_ozone_net, networkLocation: /default-rack, certSerialId: 2411677671379, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2021-01-28 02:32:52,274 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=45d6c387-0d5e-4ec1-887d-a71b52063026 reported by feb6bea5-edd2-410b-8ad4-c920818f117a{ip: 172.25.0.104, host: ozonesecure-om-ha_datanode3_1.ozonesecure-om-ha_ozone_net, networkLocation: /default-rack, certSerialId: 2411677671379, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2021-01-28 02:32:52,275 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=4954273f-2502-40bd-89f2-8e19c9aa218c. Trying to get from SCM.
recon_1      | 2021-01-28 02:32:52,292 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: 4954273f-2502-40bd-89f2-8e19c9aa218c, Nodes: feb6bea5-edd2-410b-8ad4-c920818f117a{ip: 172.25.0.104, host: ozonesecure-om-ha_datanode3_1.ozonesecure-om-ha_ozone_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}bb31b8e2-b35d-4b3b-ae90-43363de8a349{ip: 172.25.0.102, host: ozonesecure-om-ha_datanode1_1.ozonesecure-om-ha_ozone_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}6bab7c5a-f782-4236-88e0-70f071e2bf9c{ip: 172.25.0.103, host: ozonesecure-om-ha_datanode2_1.ozonesecure-om-ha_ozone_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:, CreationTimestamp2021-01-28T02:32:42.902Z] to Recon pipeline metadata.
recon_1      | 2021-01-28 02:32:52,293 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 4954273f-2502-40bd-89f2-8e19c9aa218c, Nodes: feb6bea5-edd2-410b-8ad4-c920818f117a{ip: 172.25.0.104, host: ozonesecure-om-ha_datanode3_1.ozonesecure-om-ha_ozone_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}bb31b8e2-b35d-4b3b-ae90-43363de8a349{ip: 172.25.0.102, host: ozonesecure-om-ha_datanode1_1.ozonesecure-om-ha_ozone_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}6bab7c5a-f782-4236-88e0-70f071e2bf9c{ip: 172.25.0.103, host: ozonesecure-om-ha_datanode2_1.ozonesecure-om-ha_ozone_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:, CreationTimestamp2021-01-28T02:32:42.902Z]
recon_1      | 2021-01-28 02:32:52,293 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=4954273f-2502-40bd-89f2-8e19c9aa218c reported by feb6bea5-edd2-410b-8ad4-c920818f117a{ip: 172.25.0.104, host: ozonesecure-om-ha_datanode3_1.ozonesecure-om-ha_ozone_net, networkLocation: /default-rack, certSerialId: 2411677671379, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2021-01-28 02:32:52,558 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=45d6c387-0d5e-4ec1-887d-a71b52063026 reported by bb31b8e2-b35d-4b3b-ae90-43363de8a349{ip: 172.25.0.102, host: ozonesecure-om-ha_datanode1_1.ozonesecure-om-ha_ozone_net, networkLocation: /default-rack, certSerialId: 2411674243301, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2021-01-28 02:32:52,558 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=4954273f-2502-40bd-89f2-8e19c9aa218c reported by bb31b8e2-b35d-4b3b-ae90-43363de8a349{ip: 172.25.0.102, host: ozonesecure-om-ha_datanode1_1.ozonesecure-om-ha_ozone_net, networkLocation: /default-rack, certSerialId: 2411674243301, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2021-01-28 02:32:52,841 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=45d6c387-0d5e-4ec1-887d-a71b52063026 reported by 6bab7c5a-f782-4236-88e0-70f071e2bf9c{ip: 172.25.0.103, host: ozonesecure-om-ha_datanode2_1.ozonesecure-om-ha_ozone_net, networkLocation: /default-rack, certSerialId: 2411778267491, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2021-01-28 02:32:52,841 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=4954273f-2502-40bd-89f2-8e19c9aa218c reported by 6bab7c5a-f782-4236-88e0-70f071e2bf9c{ip: 172.25.0.103, host: ozonesecure-om-ha_datanode2_1.ozonesecure-om-ha_ozone_net, networkLocation: /default-rack, certSerialId: 2411778267491, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2021-01-28 02:32:57,588 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=45d6c387-0d5e-4ec1-887d-a71b52063026 reported by feb6bea5-edd2-410b-8ad4-c920818f117a{ip: 172.25.0.104, host: ozonesecure-om-ha_datanode3_1.ozonesecure-om-ha_ozone_net, networkLocation: /default-rack, certSerialId: 2411677671379, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2021-01-28 02:32:57,589 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=4954273f-2502-40bd-89f2-8e19c9aa218c reported by feb6bea5-edd2-410b-8ad4-c920818f117a{ip: 172.25.0.104, host: ozonesecure-om-ha_datanode3_1.ozonesecure-om-ha_ozone_net, networkLocation: /default-rack, certSerialId: 2411677671379, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2021-01-28 02:32:57,589 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 4954273f-2502-40bd-89f2-8e19c9aa218c, Nodes: feb6bea5-edd2-410b-8ad4-c920818f117a{ip: 172.25.0.104, host: ozonesecure-om-ha_datanode3_1.ozonesecure-om-ha_ozone_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}bb31b8e2-b35d-4b3b-ae90-43363de8a349{ip: 172.25.0.102, host: ozonesecure-om-ha_datanode1_1.ozonesecure-om-ha_ozone_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}6bab7c5a-f782-4236-88e0-70f071e2bf9c{ip: 172.25.0.103, host: ozonesecure-om-ha_datanode2_1.ozonesecure-om-ha_ozone_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:feb6bea5-edd2-410b-8ad4-c920818f117a, CreationTimestamp2021-01-28T02:32:42.902Z] moved to OPEN state
recon_1      | 2021-01-28 02:32:57,829 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=45d6c387-0d5e-4ec1-887d-a71b52063026 reported by bb31b8e2-b35d-4b3b-ae90-43363de8a349{ip: 172.25.0.102, host: ozonesecure-om-ha_datanode1_1.ozonesecure-om-ha_ozone_net, networkLocation: /default-rack, certSerialId: 2411674243301, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2021-01-28 02:32:57,830 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 45d6c387-0d5e-4ec1-887d-a71b52063026, Nodes: feb6bea5-edd2-410b-8ad4-c920818f117a{ip: 172.25.0.104, host: ozonesecure-om-ha_datanode3_1.ozonesecure-om-ha_ozone_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}6bab7c5a-f782-4236-88e0-70f071e2bf9c{ip: 172.25.0.103, host: ozonesecure-om-ha_datanode2_1.ozonesecure-om-ha_ozone_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}bb31b8e2-b35d-4b3b-ae90-43363de8a349{ip: 172.25.0.102, host: ozonesecure-om-ha_datanode1_1.ozonesecure-om-ha_ozone_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:bb31b8e2-b35d-4b3b-ae90-43363de8a349, CreationTimestamp2021-01-28T02:32:42.878Z] moved to OPEN state
recon_1      | 2021-01-28 02:33:14,576 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/d20fde691356@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36797
recon_1      | 2021-01-28 02:33:14,607 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/d20fde691356@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2021-01-28 02:33:14,608 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=f85be9de-7cd2-4361-be7a-1f92667e218d. Trying to get from SCM.
recon_1      | 2021-01-28 02:33:14,633 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/db0158eeb642@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37021
recon_1      | 2021-01-28 02:33:14,650 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/db0158eeb642@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2021-01-28 02:33:14,659 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: f85be9de-7cd2-4361-be7a-1f92667e218d, Nodes: bb31b8e2-b35d-4b3b-ae90-43363de8a349{ip: 172.25.0.102, host: ozonesecure-om-ha_datanode1_1.ozonesecure-om-ha_ozone_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2021-01-28T02:32:42.119Z] to Recon pipeline metadata.
recon_1      | 2021-01-28 02:33:14,660 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: f85be9de-7cd2-4361-be7a-1f92667e218d, Nodes: bb31b8e2-b35d-4b3b-ae90-43363de8a349{ip: 172.25.0.102, host: ozonesecure-om-ha_datanode1_1.ozonesecure-om-ha_ozone_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2021-01-28T02:32:42.119Z]
recon_1      | 2021-01-28 02:33:14,660 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline ONE PipelineID=f85be9de-7cd2-4361-be7a-1f92667e218d reported by bb31b8e2-b35d-4b3b-ae90-43363de8a349{ip: 172.25.0.102, host: ozonesecure-om-ha_datanode1_1.ozonesecure-om-ha_ozone_net, networkLocation: /default-rack, certSerialId: 2411674243301, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2021-01-28 02:33:14,660 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: f85be9de-7cd2-4361-be7a-1f92667e218d, Nodes: bb31b8e2-b35d-4b3b-ae90-43363de8a349{ip: 172.25.0.102, host: ozonesecure-om-ha_datanode1_1.ozonesecure-om-ha_ozone_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:bb31b8e2-b35d-4b3b-ae90-43363de8a349, CreationTimestamp2021-01-28T02:32:42.119Z] moved to OPEN state
recon_1      | 2021-01-28 02:33:14,662 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=f3928597-5304-49a3-b7ac-b28675baafbc. Trying to get from SCM.
recon_1      | 2021-01-28 02:33:14,671 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: f3928597-5304-49a3-b7ac-b28675baafbc, Nodes: 6bab7c5a-f782-4236-88e0-70f071e2bf9c{ip: 172.25.0.103, host: ozonesecure-om-ha_datanode2_1.ozonesecure-om-ha_ozone_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2021-01-28T02:32:42.302Z] to Recon pipeline metadata.
recon_1      | 2021-01-28 02:33:14,671 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: f3928597-5304-49a3-b7ac-b28675baafbc, Nodes: 6bab7c5a-f782-4236-88e0-70f071e2bf9c{ip: 172.25.0.103, host: ozonesecure-om-ha_datanode2_1.ozonesecure-om-ha_ozone_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2021-01-28T02:32:42.302Z]
om3_1        | 2021-01-28 02:32:57,355 [Listener at om3/9862] INFO server.RaftServer$Division: om3@group-562213E44849: start as a follower, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1        | 2021-01-28 02:32:57,359 [Listener at om3/9862] INFO server.RaftServer$Division: om3@group-562213E44849: changes role from      null to FOLLOWER at term 0 for startAsFollower
om3_1        | 2021-01-28 02:32:57,379 [Listener at om3/9862] INFO impl.RoleInfo: om3: start om3@group-562213E44849-FollowerState
om3_1        | 2021-01-28 02:32:57,381 [Listener at om3/9862] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-562213E44849,id=om3
om3_1        | 2021-01-28 02:32:57,395 [Listener at om3/9862] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.om3@group-562213E44849
om3_1        | 2021-01-28 02:32:57,442 [Listener at om3/9862] INFO server.RaftServer: om3: start RPC server
om3_1        | 2021-01-28 02:32:57,957 [Listener at om3/9862] INFO server.GrpcService: om3: GrpcService started, listening on 9872
om3_1        | 2021-01-28 02:32:57,969 [Listener at om3/9862] INFO om.OzoneManager: Reading keypair and certificate from file system.
om3_1        | 2021-01-28 02:32:57,990 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$371/0x000000084050a840@42fb2be9] INFO util.JvmPauseMonitor: JvmPauseMonitor-om3: Started
om3_1        | 2021-01-28 02:32:58,035 [Listener at om3/9862] INFO om.OzoneManager: Starting OM block token secret manager
om3_1        | 2021-01-28 02:32:58,047 [Listener at om3/9862] INFO security.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
om3_1        | 2021-01-28 02:32:58,074 [Listener at om3/9862] INFO om.OzoneManager: Starting OM delegation token secret manager
om3_1        | 2021-01-28 02:32:58,074 [Listener at om3/9862] INFO security.OzoneDelegationTokenSecretManager: Updating the current master key for generating tokens
om3_1        | 2021-01-28 02:32:58,111 [Thread[Thread-14,5,main]] INFO security.OzoneDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
om3_1        | 2021-01-28 02:32:58,326 [Listener at om3/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om3_1        | 2021-01-28 02:32:58,327 [Listener at om3/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
om3_1        | 2021-01-28 02:32:58,327 [Listener at om3/9862] INFO http.BaseHttpServer: HttpAuthType: ozone.om.http.auth.type = kerberos
om3_1        | 2021-01-28 02:32:58,465 [Listener at om3/9862] INFO util.log: Logging initialized @24288ms to org.eclipse.jetty.util.log.Slf4jLog
om3_1        | 2021-01-28 02:32:59,200 [Listener at om3/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om3_1        | 2021-01-28 02:32:59,223 [Listener at om3/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om3_1        | 2021-01-28 02:32:59,250 [Listener at om3/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context ozoneManager
om3_1        | 2021-01-28 02:32:59,250 [Listener at om3/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
om3_1        | 2021-01-28 02:32:59,250 [Listener at om3/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
om3_1        | 2021-01-28 02:32:59,253 [Listener at om3/9862] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.om.http.auth.kerberos.principal keytabKey: ozone.om.http.auth.kerberos.keytab
om3_1        | 2021-01-28 02:32:59,509 [Listener at om3/9862] INFO http.HttpServer2: Jetty bound to port 9874
om3_1        | 2021-01-28 02:32:59,521 [Listener at om3/9862] INFO server.Server: jetty-9.4.34.v20201102; built: 2020-11-02T14:15:39.302Z; git: e46af88704a893fc12cb0e3bf46e2c7b48a009e7; jvm 11.0.7+10-LTS
om3_1        | 2021-01-28 02:32:59,643 [Listener at om3/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om3_1        | 2021-01-28 02:32:59,643 [Listener at om3/9862] INFO server.session: No SessionScavenger set, using defaults
om3_1        | 2021-01-28 02:32:59,644 [Listener at om3/9862] INFO server.session: node0 Scavenging every 600000ms
om3_1        | 2021-01-28 02:32:59,696 [Listener at om3/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om3@EXAMPLE.COM
om3_1        | 2021-01-28 02:32:59,702 [Listener at om3/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4c7b4a31{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om3_1        | 2021-01-28 02:32:59,707 [Listener at om3/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2e17a9e6{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-1.1.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om3_1        | 2021-01-28 02:33:00,074 [Listener at om3/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om3@EXAMPLE.COM
om3_1        | 2021-01-28 02:33:00,122 [Listener at om3/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@3c20abd6{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-hadoop-ozone-ozone-manager-1_1_0-SNAPSHOT_jar-_-any-14644150651663931318/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-1.1.0-SNAPSHOT.jar!/webapps/ozoneManager}
om3_1        | 2021-01-28 02:33:00,150 [Listener at om3/9862] INFO server.AbstractConnector: Started ServerConnector@219ec4b6{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
om3_1        | 2021-01-28 02:33:00,151 [Listener at om3/9862] INFO server.Server: Started @25974ms
om3_1        | 2021-01-28 02:33:00,158 [Listener at om3/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om3_1        | 2021-01-28 02:33:00,163 [Listener at om3/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om3_1        | 2021-01-28 02:33:00,167 [Listener at om3/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om3_1        | 2021-01-28 02:33:00,168 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om3_1        | 2021-01-28 02:33:00,208 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om3_1        | 2021-01-28 02:33:00,515 [Listener at om3/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted will not move to trash
om3_1        | 2021-01-28 02:33:00,576 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@106c3e0a] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om3_1        | 2021-01-28 02:33:02,392 [grpc-default-executor-0] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server_message_metrics.om3
om3_1        | 2021-01-28 02:33:02,451 [grpc-default-executor-0] INFO server.RaftServer$Division: om3@group-562213E44849: receive requestVote(PRE_VOTE, om1, group-562213E44849, 0, (t:0, i:~))
om3_1        | 2021-01-28 02:33:02,476 [grpc-default-executor-0] INFO impl.VoteContext: om3@group-562213E44849-FOLLOWER: accept PRE_VOTE from om1: our priority 0 <= candidate's priority 0
om3_1        | 2021-01-28 02:33:02,529 [grpc-default-executor-1] INFO server.RaftServer$Division: om3@group-562213E44849: receive requestVote(ELECTION, om1, group-562213E44849, 1, (t:0, i:~))
om3_1        | 2021-01-28 02:33:02,536 [grpc-default-executor-0] INFO server.RaftServer$Division: om3@group-562213E44849 replies to PRE_VOTE vote request: om1<-om3#0:OK-t0. Peer's state: om3@group-562213E44849:t0, leader=null, voted=, raftlog=om3@group-562213E44849-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/javax.activation-api-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-storage-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.2.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-1.1.0-SNAPSHOT.jar
om1_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/42171e669d6c7f302fa379fc0289c4341f1cbf75 ; compiled by 'runner' on 2021-01-28T01:42Z
om1_1        | STARTUP_MSG:   java = 11.0.7
om1_1        | ************************************************************/
om1_1        | 2021-01-28 02:31:51,272 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om1_1        | 2021-01-28 02:32:02,124 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om1_1        | 2021-01-28 02:32:02,662 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om1, RPC Address: om1:9862 and Ratis port: 9872
om1_1        | 2021-01-28 02:32:02,665 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.om1: om1
om1_1        | 2021-01-28 02:32:02,666 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.om1: om1
om1_1        | 2021-01-28 02:32:04,726 [main] INFO security.UserGroupInformation: Login successful for user om/om1@EXAMPLE.COM using keytab file /etc/security/keytabs/om.keytab
om1_1        | 2021-01-28 02:32:04,750 [main] INFO om.OzoneManager: Ozone Manager login successful.
om1_1        | 2021-01-28 02:32:04,881 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2021-01-28 02:32:07,766 [main] INFO ipc.Client: Retrying connect to server: scm/172.25.0.116:9863. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-01-28 02:32:08,768 [main] INFO ipc.Client: Retrying connect to server: scm/172.25.0.116:9863. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-01-28 02:32:09,769 [main] INFO ipc.Client: Retrying connect to server: scm/172.25.0.116:9863. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-01-28 02:32:10,771 [main] INFO ipc.Client: Retrying connect to server: scm/172.25.0.116:9863. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-01-28 02:32:11,772 [main] INFO ipc.Client: Retrying connect to server: scm/172.25.0.116:9863. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-01-28 02:32:12,773 [main] INFO ipc.Client: Retrying connect to server: scm/172.25.0.116:9863. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-01-28 02:32:13,774 [main] INFO ipc.Client: Retrying connect to server: scm/172.25.0.116:9863. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-01-28 02:32:14,775 [main] INFO ipc.Client: Retrying connect to server: scm/172.25.0.116:9863. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-01-28 02:32:15,776 [main] INFO ipc.Client: Retrying connect to server: scm/172.25.0.116:9863. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-01-28 02:32:16,777 [main] INFO ipc.Client: Retrying connect to server: scm/172.25.0.116:9863. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-01-28 02:32:16,778 [main] INFO utils.RetriableTask: Execution of task OM#getScmInfo failed, will be retried in 5000 ms
om1_1        | 2021-01-28 02:32:22,717 [main] INFO om.OzoneManager: Initializing secure OzoneManager.
om1_1        | 2021-01-28 02:32:25,356 [main] ERROR client.OMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
om1_1        | 2021-01-28 02:32:25,356 [main] INFO client.OMCertificateClient: Certificate client init case: 0
om1_1        | 2021-01-28 02:32:25,403 [main] INFO client.OMCertificateClient: Creating keypair for client as keypair and certificate not found.
om1_1        | 2021-01-28 02:32:28,579 [main] INFO om.OzoneManager: Init response: GETCERT
om1_1        | 2021-01-28 02:32:28,805 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.111,host:om1
om1_1        | 2021-01-28 02:32:28,812 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
om1_1        | 2021-01-28 02:32:28,833 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om1_1        | 2021-01-28 02:32:28,852 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om1, RPC Address: om1:9862 and Ratis port: 9872
om1_1        | 2021-01-28 02:32:28,852 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.om1: om1
om1_1        | 2021-01-28 02:32:28,859 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.om1: om1
om1_1        | 2021-01-28 02:32:28,861 [main] INFO om.OzoneManager: Creating csr for OM->dns:om1,ip:172.25.0.111,scmId:d25f76ca-50d0-4328-9e5c-3def84e9335b,clusterId:CID-e189ce55-503e-4392-a6f1-64d4ccea7222,subject:root@om1
om1_1        | 2021-01-28 02:32:29,870 [main] INFO om.OzoneManager: OzoneManager ports added:[name: "RPC"
om1_1        | value: 9862
om1_1        | ]
om1_1        | 2021-01-28 02:32:31,142 [main] INFO om.OzoneManager: Successfully stored SCM signed certificate.
recon_1      | 2021-01-28 02:33:14,672 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline ONE PipelineID=f3928597-5304-49a3-b7ac-b28675baafbc reported by 6bab7c5a-f782-4236-88e0-70f071e2bf9c{ip: 172.25.0.103, host: ozonesecure-om-ha_datanode2_1.ozonesecure-om-ha_ozone_net, networkLocation: /default-rack, certSerialId: 2411778267491, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2021-01-28 02:33:14,672 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: f3928597-5304-49a3-b7ac-b28675baafbc, Nodes: 6bab7c5a-f782-4236-88e0-70f071e2bf9c{ip: 172.25.0.103, host: ozonesecure-om-ha_datanode2_1.ozonesecure-om-ha_ozone_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:6bab7c5a-f782-4236-88e0-70f071e2bf9c, CreationTimestamp2021-01-28T02:32:42.302Z] moved to OPEN state
recon_1      | 2021-01-28 02:33:19,447 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/d5a2d8142681@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39697
recon_1      | 2021-01-28 02:33:19,464 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/d5a2d8142681@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2021-01-28 02:33:19,474 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #1 got from ozonesecure-om-ha_datanode3_1.ozonesecure-om-ha_ozone_net.
recon_1      | 2021-01-28 02:33:19,538 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: Successfully added container #1 to Recon.
recon_1      | 2021-01-28 02:33:49,085 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2021-01-28 02:33:49,085 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2021-01-28 02:33:49,466 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/d5a2d8142681@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41551
recon_1      | 2021-01-28 02:33:49,477 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/d5a2d8142681@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2021-01-28 02:33:49,829 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Got new checkpoint from OM : /data/metadata/om.snapshot.db_1611801229085
recon_1      | 2021-01-28 02:33:49,841 [pool-16-thread-1] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
recon_1      | 2021-01-28 02:33:49,842 [pool-16-thread-1] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
recon_1      | 2021-01-28 02:33:49,936 [pool-16-thread-1] INFO recovery.ReconOmMetadataManagerImpl: Created OM DB handle from snapshot at /data/metadata/om.snapshot.db_1611801229085.
recon_1      | 2021-01-28 02:33:50,026 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Calling reprocess on Recon tasks.
recon_1      | 2021-01-28 02:33:50,272 [pool-17-thread-1] INFO tasks.TableCountTask: Completed a 'reprocess' run of TableCountTask.
recon_1      | 2021-01-28 02:33:50,275 [pool-17-thread-1] INFO tasks.ContainerKeyMapperTask: Starting a 'reprocess' run of ContainerKeyMapperTask.
recon_1      | 2021-01-28 02:33:50,358 [pool-17-thread-1] INFO impl.ContainerDBServiceProviderImpl: Creating new Recon Container DB at /data/metadata/recon/recon-container-key.db_1611801230285
recon_1      | 2021-01-28 02:33:50,358 [pool-17-thread-1] INFO impl.ContainerDBServiceProviderImpl: Cleaning up old Recon Container key DB at /data/metadata/recon/recon-container-key.db_1611801123172.
recon_1      | 2021-01-28 02:33:50,450 [pool-17-thread-1] INFO tasks.ContainerKeyMapperTask: Completed 'reprocess' of ContainerKeyMapperTask.
recon_1      | 2021-01-28 02:33:50,451 [pool-17-thread-1] INFO tasks.ContainerKeyMapperTask: It took me 0.175 seconds to process 2 keys.
recon_1      | 2021-01-28 02:33:50,478 [pool-17-thread-1] INFO tasks.FileSizeCountTask: Deleted 0 records from "FILE_COUNT_BY_SIZE"
recon_1      | 2021-01-28 02:33:50,497 [pool-17-thread-1] INFO tasks.FileSizeCountTask: Completed a 'reprocess' run of FileSizeCountTask.
recon_1      | 2021-01-28 02:33:50,607 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/d20fde691356@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45395
recon_1      | 2021-01-28 02:33:50,621 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/d20fde691356@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2021-01-28 02:33:50,650 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/db0158eeb642@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:43975
recon_1      | 2021-01-28 02:33:50,659 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/db0158eeb642@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2021-01-28 02:34:19,447 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/d5a2d8142681@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:32817
recon_1      | 2021-01-28 02:34:19,459 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/d5a2d8142681@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2021-01-28 02:34:20,566 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/d20fde691356@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41033
recon_1      | 2021-01-28 02:34:20,583 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/d20fde691356@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2021-01-28 02:34:20,646 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/db0158eeb642@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36511
recon_1      | 2021-01-28 02:34:20,653 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/db0158eeb642@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2021-01-28 02:34:49,445 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/d5a2d8142681@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33979
recon_1      | 2021-01-28 02:34:49,461 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/d5a2d8142681@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2021-01-28 02:34:50,504 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2021-01-28 02:34:50,507 [pool-16-thread-1] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
recon_1      | 2021-01-28 02:34:50,507 [pool-16-thread-1] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
recon_1      | 2021-01-28 02:34:50,507 [pool-16-thread-1] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
recon_1      | 2021-01-28 02:34:50,507 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1      | 2021-01-28 02:34:50,552 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 19
recon_1      | 2021-01-28 02:34:50,572 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/d20fde691356@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36055
recon_1      | 2021-01-28 02:34:50,605 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/d20fde691356@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2021-01-28 02:34:50,646 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/db0158eeb642@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:35279
recon_1      | 2021-01-28 02:34:50,654 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/db0158eeb642@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2021-01-28 02:34:50,807 [pool-17-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1      | 2021-01-28 02:34:50,810 [pool-17-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 3 OM DB update event(s).
recon_1      | 2021-01-28 02:34:50,847 [pool-17-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1      | 2021-01-28 02:35:19,437 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/d5a2d8142681@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41641
recon_1      | 2021-01-28 02:35:19,474 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/d5a2d8142681@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2021-01-28 02:35:20,570 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/d20fde691356@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45321
recon_1      | 2021-01-28 02:35:20,580 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/d20fde691356@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2021-01-28 02:35:20,643 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/db0158eeb642@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:44751
recon_1      | 2021-01-28 02:35:20,654 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/db0158eeb642@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2021-01-28 02:35:49,448 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/d5a2d8142681@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35123
recon_1      | 2021-01-28 02:35:49,461 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/d5a2d8142681@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2021-01-28 02:35:50,582 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/d20fde691356@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46329
recon_1      | 2021-01-28 02:35:50,587 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/d20fde691356@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2021-01-28 02:35:50,652 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/db0158eeb642@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:35511
recon_1      | 2021-01-28 02:35:50,675 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/db0158eeb642@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2021-01-28 02:35:50,854 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2021-01-28 02:35:50,854 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1      | 2021-01-28 02:35:50,887 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 7
recon_1      | 2021-01-28 02:35:51,007 [pool-17-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1      | 2021-01-28 02:35:51,008 [pool-17-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 1 OM DB update event(s).
recon_1      | 2021-01-28 02:35:51,025 [pool-17-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1      | 2021-01-28 02:36:15,814 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/db0158eeb642@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:43207
recon_1      | 2021-01-28 02:36:15,843 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/d5a2d8142681@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41411
recon_1      | 2021-01-28 02:36:15,845 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/d20fde691356@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34259
recon_1      | 2021-01-28 02:36:15,855 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/db0158eeb642@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2021-01-28 02:36:15,856 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #2 got from ozonesecure-om-ha_datanode2_1.ozonesecure-om-ha_ozone_net.
recon_1      | 2021-01-28 02:36:15,894 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: Successfully added container #2 to Recon.
recon_1      | 2021-01-28 02:36:15,898 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/d20fde691356@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2021-01-28 02:36:15,899 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/d5a2d8142681@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om2_1        | 2021-01-28 02:32:58,847 [Listener at om2/9862] INFO server.RaftServer$Division: om2@group-562213E44849: changes role from      null to FOLLOWER at term 0 for startAsFollower
om2_1        | 2021-01-28 02:32:58,852 [Listener at om2/9862] INFO impl.RoleInfo: om2: start om2@group-562213E44849-FollowerState
om2_1        | 2021-01-28 02:32:58,876 [Listener at om2/9862] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-562213E44849,id=om2
om2_1        | 2021-01-28 02:32:58,887 [Listener at om2/9862] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.om2@group-562213E44849
om2_1        | 2021-01-28 02:32:58,912 [Listener at om2/9862] INFO server.RaftServer: om2: start RPC server
om2_1        | 2021-01-28 02:32:59,211 [Listener at om2/9862] INFO server.GrpcService: om2: GrpcService started, listening on 9872
om2_1        | 2021-01-28 02:32:59,224 [Listener at om2/9862] INFO om.OzoneManager: Reading keypair and certificate from file system.
om2_1        | 2021-01-28 02:32:59,230 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$371/0x0000000840514440@58038583] INFO util.JvmPauseMonitor: JvmPauseMonitor-om2: Started
om2_1        | 2021-01-28 02:32:59,277 [Listener at om2/9862] INFO om.OzoneManager: Starting OM block token secret manager
om2_1        | 2021-01-28 02:32:59,278 [Listener at om2/9862] INFO security.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
om2_1        | 2021-01-28 02:32:59,284 [Listener at om2/9862] INFO om.OzoneManager: Starting OM delegation token secret manager
om2_1        | 2021-01-28 02:32:59,284 [Listener at om2/9862] INFO security.OzoneDelegationTokenSecretManager: Updating the current master key for generating tokens
om2_1        | 2021-01-28 02:32:59,302 [Thread[Thread-14,5,main]] INFO security.OzoneDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
om2_1        | 2021-01-28 02:32:59,422 [Listener at om2/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om2_1        | 2021-01-28 02:32:59,422 [Listener at om2/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
om2_1        | 2021-01-28 02:32:59,422 [Listener at om2/9862] INFO http.BaseHttpServer: HttpAuthType: ozone.om.http.auth.type = kerberos
om2_1        | 2021-01-28 02:32:59,562 [Listener at om2/9862] INFO util.log: Logging initialized @24585ms to org.eclipse.jetty.util.log.Slf4jLog
om2_1        | 2021-01-28 02:33:00,015 [Listener at om2/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om2_1        | 2021-01-28 02:33:00,040 [Listener at om2/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om2_1        | 2021-01-28 02:33:00,052 [Listener at om2/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context ozoneManager
om2_1        | 2021-01-28 02:33:00,056 [Listener at om2/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
om2_1        | 2021-01-28 02:33:00,056 [Listener at om2/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
om2_1        | 2021-01-28 02:33:00,061 [Listener at om2/9862] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.om.http.auth.kerberos.principal keytabKey: ozone.om.http.auth.kerberos.keytab
om2_1        | 2021-01-28 02:33:00,194 [Listener at om2/9862] INFO http.HttpServer2: Jetty bound to port 9874
om2_1        | 2021-01-28 02:33:00,198 [Listener at om2/9862] INFO server.Server: jetty-9.4.34.v20201102; built: 2020-11-02T14:15:39.302Z; git: e46af88704a893fc12cb0e3bf46e2c7b48a009e7; jvm 11.0.7+10-LTS
om2_1        | 2021-01-28 02:33:00,290 [Listener at om2/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om2_1        | 2021-01-28 02:33:00,291 [Listener at om2/9862] INFO server.session: No SessionScavenger set, using defaults
om2_1        | 2021-01-28 02:33:00,292 [Listener at om2/9862] INFO server.session: node0 Scavenging every 660000ms
om2_1        | 2021-01-28 02:33:00,359 [Listener at om2/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om2@EXAMPLE.COM
om2_1        | 2021-01-28 02:33:00,362 [Listener at om2/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@732fa176{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om2_1        | 2021-01-28 02:33:00,368 [Listener at om2/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5f0bf0ed{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-1.1.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om2_1        | 2021-01-28 02:33:00,659 [Listener at om2/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om2@EXAMPLE.COM
om2_1        | 2021-01-28 02:33:00,689 [Listener at om2/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@375682a5{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-hadoop-ozone-ozone-manager-1_1_0-SNAPSHOT_jar-_-any-2909162329216355812/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-1.1.0-SNAPSHOT.jar!/webapps/ozoneManager}
om2_1        | 2021-01-28 02:33:00,728 [Listener at om2/9862] INFO server.AbstractConnector: Started ServerConnector@37a0c3c6{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
om2_1        | 2021-01-28 02:33:00,728 [Listener at om2/9862] INFO server.Server: Started @25751ms
om2_1        | 2021-01-28 02:33:00,794 [Listener at om2/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om2_1        | 2021-01-28 02:33:00,794 [Listener at om2/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om2_1        | 2021-01-28 02:33:00,808 [Listener at om2/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om2_1        | 2021-01-28 02:33:00,837 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om2_1        | 2021-01-28 02:33:00,818 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om2_1        | 2021-01-28 02:33:00,945 [Listener at om2/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted will not move to trash
om2_1        | 2021-01-28 02:33:00,974 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1b641c97] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om2_1        | 2021-01-28 02:33:02,289 [grpc-default-executor-0] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server_message_metrics.om2
om2_1        | 2021-01-28 02:33:02,352 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-562213E44849: receive requestVote(PRE_VOTE, om1, group-562213E44849, 0, (t:0, i:~))
om2_1        | 2021-01-28 02:33:02,359 [grpc-default-executor-0] INFO impl.VoteContext: om2@group-562213E44849-FOLLOWER: accept PRE_VOTE from om1: our priority 0 <= candidate's priority 0
om2_1        | 2021-01-28 02:33:02,417 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-562213E44849 replies to PRE_VOTE vote request: om1<-om2#0:OK-t0. Peer's state: om2@group-562213E44849:t0, leader=null, voted=, raftlog=om2@group-562213E44849-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om2_1        | 2021-01-28 02:33:02,535 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-562213E44849: receive requestVote(ELECTION, om1, group-562213E44849, 1, (t:0, i:~))
om2_1        | 2021-01-28 02:33:02,535 [grpc-default-executor-0] INFO impl.VoteContext: om2@group-562213E44849-FOLLOWER: accept ELECTION from om1: our priority 0 <= candidate's priority 0
om2_1        | 2021-01-28 02:33:02,536 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-562213E44849: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:om1
om2_1        | 2021-01-28 02:33:02,536 [grpc-default-executor-0] INFO impl.RoleInfo: om2: shutdown om2@group-562213E44849-FollowerState
om2_1        | 2021-01-28 02:33:02,537 [Thread-12] INFO impl.FollowerState: om2@group-562213E44849-FollowerState was interrupted: {}
om2_1        | java.lang.InterruptedException: sleep interrupted
om2_1        | 	at java.base/java.lang.Thread.sleep(Native Method)
om2_1        | 	at java.base/java.lang.Thread.sleep(Thread.java:339)
om2_1        | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
om2_1        | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
om2_1        | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
om2_1        | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:117)
om2_1        | 2021-01-28 02:33:02,537 [grpc-default-executor-0] INFO impl.RoleInfo: om2: start om2@group-562213E44849-FollowerState
om2_1        | 2021-01-28 02:33:02,557 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-562213E44849 replies to ELECTION vote request: om1<-om2#0:OK-t1. Peer's state: om2@group-562213E44849:t1, leader=null, voted=om1, raftlog=om2@group-562213E44849-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om2_1        | 2021-01-28 02:33:02,914 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-562213E44849: change Leader from null to om1 at term 1 for appendEntries, leader elected after 5578ms
om2_1        | 2021-01-28 02:33:03,011 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-562213E44849: set configuration 0: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om2_1        | 2021-01-28 02:33:03,026 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: Starting segment from index:0
om2_1        | 2021-01-28 02:33:03,379 [om2@group-562213E44849-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/current/log_inprogress_0
om2_1        | 2021-01-28 02:33:16,995 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:vol1 for user:testuser/scm@EXAMPLE.COM
om2_1        | 2021-01-28 02:33:44,691 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:79087-source for user:testuser/scm@EXAMPLE.COM
om2_1        | 2021-01-28 02:33:47,605 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:79087-target for user:testuser/scm@EXAMPLE.COM
om2_1        | 2021-01-28 02:35:38,353 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:link2 in volume:79087-target
om2_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om2_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:192)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:415)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:240)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om2_1        | 2021-01-28 02:35:44,279 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket3 in volume:79087-target
om2_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om2_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:192)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:415)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:240)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-e189ce55-503e-4392-a6f1-64d4ccea7222;layoutVersion=0
om1_1        | 2021-01-28 02:32:31,331 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om1_1        | /************************************************************
om1_1        | SHUTDOWN_MSG: Shutting down OzoneManager at om1/172.25.0.111
om1_1        | ************************************************************/
om1_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om1_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om1_1        | 2021-01-28 02:32:38,488 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om1_1        | /************************************************************
om1_1        | STARTUP_MSG: Starting OzoneManager
om1_1        | STARTUP_MSG:   host = om1/172.25.0.111
om1_1        | STARTUP_MSG:   args = []
om1_1        | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
s3g_1        | WARNING: An illegal reflective access operation has occurred
s3g_1        | WARNING: Illegal reflective access by org.jboss.weld.util.reflection.Formats (file:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar) to constructor com.sun.org.apache.bcel.internal.classfile.ClassParser(java.io.InputStream,java.lang.String)
s3g_1        | WARNING: Please consider reporting this to the maintainers of org.jboss.weld.util.reflection.Formats
s3g_1        | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
s3g_1        | WARNING: All illegal access operations will be denied in a future release
s3g_1        | 2021-01-28 02:32:11,106 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/s3g@EXAMPLE.COM
s3g_1        | Jan 28, 2021 2:32:12 AM org.glassfish.jersey.internal.Errors logErrors
s3g_1        | WARNING: The following warnings have been detected: WARNING: A HTTP GET method, public javax.ws.rs.core.Response org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.get(java.lang.String,java.lang.String,java.lang.String,int,java.lang.String,java.io.InputStream) throws java.io.IOException,org.apache.hadoop.ozone.s3.exception.OS3Exception, should not consume any entity.
s3g_1        | 
s3g_1        | 2021-01-28 02:32:12,987 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@6bd92538{s3gateway,/,file:///tmp/jetty-0_0_0_0-9878-hadoop-ozone-s3gateway-1_1_0-SNAPSHOT_jar-_-any-1808034705787819700/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-s3gateway-1.1.0-SNAPSHOT.jar!/webapps/s3gateway}
s3g_1        | 2021-01-28 02:32:13,014 [main] INFO server.AbstractConnector: Started ServerConnector@75e91545{HTTP/1.1, (http/1.1)}{0.0.0.0:9878}
s3g_1        | 2021-01-28 02:32:13,015 [main] INFO server.Server: Started @29194ms
s3g_1        | 2021-01-28 02:32:13,019 [main] INFO http.BaseHttpServer: HTTP server of s3gateway listening at http://0.0.0.0:9878
om1_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/javax.activation-api-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-storage-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.2.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-1.1.0-SNAPSHOT.jar
om1_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/42171e669d6c7f302fa379fc0289c4341f1cbf75 ; compiled by 'runner' on 2021-01-28T01:42Z
om1_1        | STARTUP_MSG:   java = 11.0.7
om1_1        | ************************************************************/
om1_1        | 2021-01-28 02:32:38,507 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om1_1        | 2021-01-28 02:32:44,707 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om1_1        | 2021-01-28 02:32:45,007 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om1, RPC Address: om1:9862 and Ratis port: 9872
om1_1        | 2021-01-28 02:32:45,008 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.om1: om1
om1_1        | 2021-01-28 02:32:45,008 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.om1: om1
om1_1        | 2021-01-28 02:32:45,082 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2021-01-28 02:32:46,206 [main] INFO security.UserGroupInformation: Login successful for user om/om1@EXAMPLE.COM using keytab file /etc/security/keytabs/om.keytab
om1_1        | 2021-01-28 02:32:46,232 [main] INFO om.OzoneManager: Ozone Manager login successful.
om1_1        | 2021-01-28 02:32:46,232 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2021-01-28 02:32:51,252 [main] INFO client.OMCertificateClient: Loading certificate from location:/data/metadata/om/certs.
om1_1        | 2021-01-28 02:32:51,572 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/2420822746268.crt.
om1_1        | 2021-01-28 02:32:51,590 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/CA-1.crt.
om1_1        | 2021-01-28 02:32:51,702 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2021-01-28 02:32:52,465 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om1_1        | 2021-01-28 02:32:52,480 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om1_1        | 2021-01-28 02:32:53,003 [main] INFO Configuration.deprecation: No unit for ozone.manager.delegation.remover.scan.interval(3600000) assuming MILLISECONDS
om1_1        | 2021-01-28 02:32:53,013 [main] INFO security.OzoneSecretStore: Loaded 0 tokens
om1_1        | 2021-01-28 02:32:53,013 [main] INFO security.OzoneDelegationTokenSecretManager: Loading token state into token manager.
om1_1        | 2021-01-28 02:32:53,280 [main] INFO om.OzoneManager: Created Volume s3v With Owner root required for S3Gateway operations.
om1_1        | 2021-01-28 02:32:53,294 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om1_1        | 2021-01-28 02:32:53,298 [main] WARN ratis.OzoneManagerRatisServer: ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
om1_1        | 2021-01-28 02:32:53,306 [main] INFO snapshot.OzoneManagerSnapshotProvider: Initializing OM Snapshot Provider
om1_1        | 2021-01-28 02:32:53,609 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om1_1        | 2021-01-28 02:32:53,709 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om1_1        | 2021-01-28 02:32:53,785 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with GroupID: id1 and Raft Peers: om1:9872, om2:9872, om3:9872
om1_1        | 2021-01-28 02:32:53,802 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
om1_1        | 2021-01-28 02:32:53,868 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
om1_1        | 2021-01-28 02:32:54,028 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
om1_1        | 2021-01-28 02:32:54,032 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om1_1        | 2021-01-28 02:32:54,032 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
om1_1        | 2021-01-28 02:32:54,032 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om1_1        | 2021-01-28 02:32:54,032 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om1_1        | 2021-01-28 02:32:54,039 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om1_1        | 2021-01-28 02:32:54,047 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om1_1        | 2021-01-28 02:32:54,048 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om1_1        | 2021-01-28 02:32:54,052 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om1_1        | 2021-01-28 02:32:54,461 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om1_1        | 2021-01-28 02:32:54,467 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om1_1        | 2021-01-28 02:32:54,467 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om1_1        | 2021-01-28 02:32:54,496 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om1_1        | 2021-01-28 02:32:54,515 [main] INFO server.RaftServer: om1: addNew group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] returns group-562213E44849:java.util.concurrent.CompletableFuture@1e4a4ed5[Not completed]
om1_1        | 2021-01-28 02:32:54,516 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om1_1        | 2021-01-28 02:32:54,565 [pool-18-thread-1] INFO server.RaftServer$Division: om1: new RaftServerImpl for group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] with OzoneManagerStateMachine:uninitialized
om1_1        | 2021-01-28 02:32:54,567 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om1_1        | 2021-01-28 02:32:54,571 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om1_1        | 2021-01-28 02:32:54,578 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om1_1        | 2021-01-28 02:32:54,578 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om1_1        | 2021-01-28 02:32:54,578 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om1_1        | 2021-01-28 02:32:54,578 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om1_1        | 2021-01-28 02:32:54,578 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om1_1        | 2021-01-28 02:32:54,589 [pool-18-thread-1] INFO server.RaftServer$Division: om1@group-562213E44849: ConfigurationManager, init=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null, confs=<EMPTY_MAP>
om1_1        | 2021-01-28 02:32:54,609 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om1_1        | 2021-01-28 02:32:54,609 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om1_1        | 2021-01-28 02:32:54,632 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om1_1        | 2021-01-28 02:32:54,633 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om1_1        | 2021-01-28 02:32:54,655 [pool-18-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 does not exist. Creating ...
om1_1        | 2021-01-28 02:32:54,696 [pool-18-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/in_use.lock acquired by nodename 6@om1
om1_1        | 2021-01-28 02:32:54,849 [pool-18-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 has been successfully formatted.
om1_1        | 2021-01-28 02:32:54,886 [pool-18-thread-1] ERROR storage.RaftStorage: Failed reading configuration from file:/data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/current/raft-meta.conf
om1_1        | java.io.FileNotFoundException: /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/current/raft-meta.conf (No such file or directory)
om1_1        | 	at java.base/java.io.FileInputStream.open0(Native Method)
om1_1        | 	at java.base/java.io.FileInputStream.open(FileInputStream.java:219)
om1_1        | 	at java.base/java.io.FileInputStream.<init>(FileInputStream.java:157)
om1_1        | 	at org.apache.ratis.server.storage.RaftStorageImpl.readRaftConfiguration(RaftStorageImpl.java:143)
om1_1        | 	at org.apache.ratis.server.impl.ServerState.<init>(ServerState.java:122)
om1_1        | 	at org.apache.ratis.server.impl.RaftServerImpl.<init>(RaftServerImpl.java:193)
om1_1        | 	at org.apache.ratis.server.impl.RaftServerProxy.lambda$newRaftServerImpl$4(RaftServerProxy.java:266)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1        | 2021-01-28 02:32:54,887 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om1_1        | 2021-01-28 02:32:54,923 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om1_1        | 2021-01-28 02:32:54,998 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om1_1        | 2021-01-28 02:32:55,009 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om1_1        | 2021-01-28 02:32:55,044 [pool-18-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.om1@group-562213E44849
om1_1        | 2021-01-28 02:32:55,160 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om1_1        | 2021-01-28 02:32:55,256 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om1_1        | 2021-01-28 02:32:55,257 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om1_1        | 2021-01-28 02:32:55,300 [pool-18-thread-1] INFO segmented.SegmentedRaftLogWorker: new om1@group-562213E44849-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849
om1_1        | 2021-01-28 02:32:55,335 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om1_1        | 2021-01-28 02:32:55,335 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om1_1        | 2021-01-28 02:32:55,340 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm_1        | Sleeping for 5 seconds
scm_1        | Setting up kerberos!!
scm_1        | KDC ISSUER_SERVER => kdc:8081
scm_1        | Sleeping for 5 seconds
scm_1        | Got 200, KDC service ready!!
scm_1        | Download scm/scm@EXAMPLE.COM keytab file to /etc/security/keytabs/scm.keytab
scm_1        | --2021-01-28 02:31:42--  http://kdc:8081/keytab/scm/scm
scm_1        | Resolving kdc (kdc)... 172.25.0.100
scm_1        | Connecting to kdc (kdc)|172.25.0.100|:8081... connected.
scm_1        | HTTP request sent, awaiting response... 200 OK
scm_1        | Length: 142 [application/octet-stream]
scm_1        | Saving to: '/etc/security/keytabs/scm.keytab'
scm_1        | 
scm_1        |      0K                                                       100% 23.0M=0s
scm_1        | 
scm_1        | 2021-01-28 02:31:42 (23.0 MB/s) - '/etc/security/keytabs/scm.keytab' saved [142/142]
scm_1        | 
scm_1        | Keytab name: FILE:/etc/security/keytabs/scm.keytab
scm_1        | KVNO Timestamp         Principal
scm_1        | ---- ----------------- --------------------------------------------------------
scm_1        |    2 01/28/21 02:31:42 scm/scm@EXAMPLE.COM
scm_1        |    2 01/28/21 02:31:42 scm/scm@EXAMPLE.COM
scm_1        | Download HTTP/scm@EXAMPLE.COM keytab file to /etc/security/keytabs/HTTP.keytab
scm_1        | --2021-01-28 02:31:42--  http://kdc:8081/keytab/scm/HTTP
scm_1        | Resolving kdc (kdc)... 172.25.0.100
scm_1        | Connecting to kdc (kdc)|172.25.0.100|:8081... connected.
scm_1        | HTTP request sent, awaiting response... 200 OK
scm_1        | Length: 144 [application/octet-stream]
scm_1        | Saving to: '/etc/security/keytabs/HTTP.keytab'
scm_1        | 
scm_1        |      0K                                                       100% 26.4M=0s
scm_1        | 
scm_1        | 2021-01-28 02:31:42 (26.4 MB/s) - '/etc/security/keytabs/HTTP.keytab' saved [144/144]
scm_1        | 
scm_1        | Keytab name: FILE:/etc/security/keytabs/HTTP.keytab
scm_1        | KVNO Timestamp         Principal
scm_1        | ---- ----------------- --------------------------------------------------------
scm_1        |    2 01/28/21 02:31:42 HTTP/scm@EXAMPLE.COM
scm_1        |    2 01/28/21 02:31:42 HTTP/scm@EXAMPLE.COM
scm_1        | Download testuser/scm@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser.keytab
scm_1        | --2021-01-28 02:31:42--  http://kdc:8081/keytab/scm/testuser
scm_1        | Resolving kdc (kdc)... 172.25.0.100
scm_1        | Connecting to kdc (kdc)|172.25.0.100|:8081... connected.
scm_1        | HTTP request sent, awaiting response... 200 OK
scm_1        | Length: 152 [application/octet-stream]
scm_1        | Saving to: '/etc/security/keytabs/testuser.keytab'
scm_1        | 
scm_1        |      0K                                                       100% 24.2M=0s
scm_1        | 
scm_1        | 2021-01-28 02:31:42 (24.2 MB/s) - '/etc/security/keytabs/testuser.keytab' saved [152/152]
scm_1        | 
scm_1        | Keytab name: FILE:/etc/security/keytabs/testuser.keytab
scm_1        | KVNO Timestamp         Principal
scm_1        | ---- ----------------- --------------------------------------------------------
scm_1        |    2 01/28/21 02:31:42 testuser/scm@EXAMPLE.COM
scm_1        |    2 01/28/21 02:31:42 testuser/scm@EXAMPLE.COM
scm_1        | Download testuser2/scm@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser2.keytab
scm_1        | --2021-01-28 02:31:42--  http://kdc:8081/keytab/scm/testuser2
scm_1        | Resolving kdc (kdc)... 172.25.0.100
scm_1        | Connecting to kdc (kdc)|172.25.0.100|:8081... connected.
scm_1        | HTTP request sent, awaiting response... 200 OK
scm_1        | Length: 154 [application/octet-stream]
scm_1        | Saving to: '/etc/security/keytabs/testuser2.keytab'
scm_1        | 
scm_1        |      0K                                                       100% 35.0M=0s
scm_1        | 
scm_1        | 2021-01-28 02:31:42 (35.0 MB/s) - '/etc/security/keytabs/testuser2.keytab' saved [154/154]
scm_1        | 
scm_1        | Keytab name: FILE:/etc/security/keytabs/testuser2.keytab
scm_1        | KVNO Timestamp         Principal
scm_1        | ---- ----------------- --------------------------------------------------------
scm_1        |    2 01/28/21 02:31:42 testuser2/scm@EXAMPLE.COM
scm_1        |    2 01/28/21 02:31:42 testuser2/scm@EXAMPLE.COM
scm_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm_1        | 2021-01-28 02:31:59,607 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm_1        | /************************************************************
scm_1        | STARTUP_MSG: Starting StorageContainerManager
scm_1        | STARTUP_MSG:   host = scm/172.25.0.116
scm_1        | STARTUP_MSG:   args = [--init]
scm_1        | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
om3_1        | 2021-01-28 02:33:02,540 [grpc-default-executor-1] INFO impl.VoteContext: om3@group-562213E44849-FOLLOWER: accept ELECTION from om1: our priority 0 <= candidate's priority 0
om3_1        | 2021-01-28 02:33:02,549 [grpc-default-executor-1] INFO server.RaftServer$Division: om3@group-562213E44849: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:om1
om3_1        | 2021-01-28 02:33:02,549 [grpc-default-executor-1] INFO impl.RoleInfo: om3: shutdown om3@group-562213E44849-FollowerState
om3_1        | 2021-01-28 02:33:02,551 [grpc-default-executor-1] INFO impl.RoleInfo: om3: start om3@group-562213E44849-FollowerState
om3_1        | 2021-01-28 02:33:02,586 [grpc-default-executor-1] INFO server.RaftServer$Division: om3@group-562213E44849 replies to ELECTION vote request: om1<-om3#0:OK-t1. Peer's state: om3@group-562213E44849:t1, leader=null, voted=om1, raftlog=om3@group-562213E44849-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1        | 2021-01-28 02:33:02,934 [grpc-default-executor-1] INFO server.RaftServer$Division: om3@group-562213E44849: change Leader from null to om1 at term 1 for appendEntries, leader elected after 6706ms
om3_1        | 2021-01-28 02:33:03,002 [grpc-default-executor-1] INFO server.RaftServer$Division: om3@group-562213E44849: set configuration 0: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om3_1        | 2021-01-28 02:33:03,015 [grpc-default-executor-1] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: Starting segment from index:0
om3_1        | 2021-01-28 02:33:03,223 [om3@group-562213E44849-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/current/log_inprogress_0
om3_1        | 2021-01-28 02:33:16,874 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:vol1 for user:testuser/scm@EXAMPLE.COM
om3_1        | 2021-01-28 02:33:44,697 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:79087-source for user:testuser/scm@EXAMPLE.COM
om3_1        | 2021-01-28 02:33:47,603 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:79087-target for user:testuser/scm@EXAMPLE.COM
om3_1        | 2021-01-28 02:35:38,349 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:link2 in volume:79087-target
om3_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om3_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:192)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:415)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:240)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om3_1        | 2021-01-28 02:35:44,273 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket3 in volume:79087-target
om3_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om3_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:192)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:415)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:240)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/ratis-metrics-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/javax.activation-api-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.2.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-1.1.0-SNAPSHOT.jar
scm_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/42171e669d6c7f302fa379fc0289c4341f1cbf75 ; compiled by 'runner' on 2021-01-28T01:42Z
scm_1        | STARTUP_MSG:   java = 11.0.7
scm_1        | ************************************************************/
scm_1        | 2021-01-28 02:31:59,980 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm_1        | 2021-01-28 02:32:01,702 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1        | 2021-01-28 02:32:02,677 [main] INFO server.StorageContainerManager: SCM initialization succeeded. Current cluster id for sd=/data/metadata/scm;cid=CID-e189ce55-503e-4392-a6f1-64d4ccea7222;layoutVersion=0
scm_1        | 2021-01-28 02:32:02,839 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm_1        | /************************************************************
scm_1        | SHUTDOWN_MSG: Shutting down StorageContainerManager at scm/172.25.0.116
scm_1        | ************************************************************/
scm_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm_1        | 2021-01-28 02:32:13,321 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm_1        | /************************************************************
scm_1        | STARTUP_MSG: Starting StorageContainerManager
scm_1        | STARTUP_MSG:   host = scm/172.25.0.116
scm_1        | STARTUP_MSG:   args = []
scm_1        | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
om1_1        | 2021-01-28 02:32:55,341 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om1_1        | 2021-01-28 02:32:55,341 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om1_1        | 2021-01-28 02:32:55,366 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om1_1        | 2021-01-28 02:32:55,367 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om1_1        | 2021-01-28 02:32:55,368 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om1_1        | 2021-01-28 02:32:55,478 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om1_1        | 2021-01-28 02:32:55,478 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om1_1        | 2021-01-28 02:32:55,571 [pool-18-thread-1] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
om1_1        | 2021-01-28 02:32:55,571 [pool-18-thread-1] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om1_1        | 2021-01-28 02:32:55,593 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om1_1        | 2021-01-28 02:32:55,593 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om1_1        | 2021-01-28 02:32:55,594 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om1_1        | 2021-01-28 02:32:55,594 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om1_1        | 2021-01-28 02:32:55,605 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
om1_1        | 2021-01-28 02:32:55,606 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om1_1        | 2021-01-28 02:32:55,824 [Listener at om1/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om1_1        | 2021-01-28 02:32:55,857 [pool-18-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.om1@group-562213E44849
om1_1        | 2021-01-28 02:32:55,893 [pool-18-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.om1@group-562213E44849
om1_1        | 2021-01-28 02:32:55,990 [Listener at om1/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om1_1        | 2021-01-28 02:32:55,990 [Listener at om1/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om1_1        | 2021-01-28 02:32:56,166 [Listener at om1/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om1/172.25.0.111:9862
om1_1        | 2021-01-28 02:32:56,167 [Listener at om1/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om1 at port 9872
om1_1        | 2021-01-28 02:32:56,177 [Listener at om1/9862] INFO server.RaftServer$Division: om1@group-562213E44849: start as a follower, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1        | 2021-01-28 02:32:56,177 [Listener at om1/9862] INFO server.RaftServer$Division: om1@group-562213E44849: changes role from      null to FOLLOWER at term 0 for startAsFollower
om1_1        | 2021-01-28 02:32:56,185 [Listener at om1/9862] INFO impl.RoleInfo: om1: start om1@group-562213E44849-FollowerState
om1_1        | 2021-01-28 02:32:56,191 [Listener at om1/9862] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-562213E44849,id=om1
om1_1        | 2021-01-28 02:32:56,193 [Listener at om1/9862] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.om1@group-562213E44849
om1_1        | 2021-01-28 02:32:56,211 [Listener at om1/9862] INFO server.RaftServer: om1: start RPC server
om1_1        | 2021-01-28 02:32:56,399 [Listener at om1/9862] INFO server.GrpcService: om1: GrpcService started, listening on 9872
om1_1        | 2021-01-28 02:32:56,420 [Listener at om1/9862] INFO om.OzoneManager: Reading keypair and certificate from file system.
om1_1        | 2021-01-28 02:32:56,434 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$371/0x0000000840513040@54816d7a] INFO util.JvmPauseMonitor: JvmPauseMonitor-om1: Started
om1_1        | 2021-01-28 02:32:56,444 [Listener at om1/9862] INFO om.OzoneManager: Starting OM block token secret manager
om1_1        | 2021-01-28 02:32:56,455 [Listener at om1/9862] INFO security.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
om1_1        | 2021-01-28 02:32:56,459 [Listener at om1/9862] INFO om.OzoneManager: Starting OM delegation token secret manager
om1_1        | 2021-01-28 02:32:56,460 [Listener at om1/9862] INFO security.OzoneDelegationTokenSecretManager: Updating the current master key for generating tokens
om1_1        | 2021-01-28 02:32:56,481 [Thread[Thread-14,5,main]] INFO security.OzoneDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
om1_1        | 2021-01-28 02:32:56,621 [Listener at om1/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om1_1        | 2021-01-28 02:32:56,622 [Listener at om1/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
om1_1        | 2021-01-28 02:32:56,623 [Listener at om1/9862] INFO http.BaseHttpServer: HttpAuthType: ozone.om.http.auth.type = kerberos
om1_1        | 2021-01-28 02:32:56,750 [Listener at om1/9862] INFO util.log: Logging initialized @24733ms to org.eclipse.jetty.util.log.Slf4jLog
om1_1        | 2021-01-28 02:32:57,378 [Listener at om1/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om1_1        | 2021-01-28 02:32:57,430 [Listener at om1/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om1_1        | 2021-01-28 02:32:57,444 [Listener at om1/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context ozoneManager
om1_1        | 2021-01-28 02:32:57,450 [Listener at om1/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
om1_1        | 2021-01-28 02:32:57,450 [Listener at om1/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
om1_1        | 2021-01-28 02:32:57,535 [Listener at om1/9862] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.om.http.auth.kerberos.principal keytabKey: ozone.om.http.auth.kerberos.keytab
om1_1        | 2021-01-28 02:32:57,917 [Listener at om1/9862] INFO http.HttpServer2: Jetty bound to port 9874
om1_1        | 2021-01-28 02:32:57,932 [Listener at om1/9862] INFO server.Server: jetty-9.4.34.v20201102; built: 2020-11-02T14:15:39.302Z; git: e46af88704a893fc12cb0e3bf46e2c7b48a009e7; jvm 11.0.7+10-LTS
om1_1        | 2021-01-28 02:32:58,292 [Listener at om1/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om1_1        | 2021-01-28 02:32:58,292 [Listener at om1/9862] INFO server.session: No SessionScavenger set, using defaults
om1_1        | 2021-01-28 02:32:58,304 [Listener at om1/9862] INFO server.session: node0 Scavenging every 600000ms
om1_1        | 2021-01-28 02:32:58,375 [Listener at om1/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om1@EXAMPLE.COM
om1_1        | 2021-01-28 02:32:58,381 [Listener at om1/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2df7766b{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om1_1        | 2021-01-28 02:32:58,385 [Listener at om1/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6a1b4854{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-1.1.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om1_1        | 2021-01-28 02:32:58,829 [Listener at om1/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om1@EXAMPLE.COM
om1_1        | 2021-01-28 02:32:58,881 [Listener at om1/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@7cd2d3b6{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-hadoop-ozone-ozone-manager-1_1_0-SNAPSHOT_jar-_-any-10728559099282661035/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-1.1.0-SNAPSHOT.jar!/webapps/ozoneManager}
om1_1        | 2021-01-28 02:32:58,940 [Listener at om1/9862] INFO server.AbstractConnector: Started ServerConnector@cdc09d{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
om1_1        | 2021-01-28 02:32:58,942 [Listener at om1/9862] INFO server.Server: Started @26925ms
om1_1        | 2021-01-28 02:32:58,959 [Listener at om1/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om1_1        | 2021-01-28 02:32:58,959 [Listener at om1/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om1_1        | 2021-01-28 02:32:58,965 [Listener at om1/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om1_1        | 2021-01-28 02:32:58,974 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om1_1        | 2021-01-28 02:32:58,980 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om1_1        | 2021-01-28 02:32:59,194 [Listener at om1/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted will not move to trash
om1_1        | 2021-01-28 02:32:59,229 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2e778abb] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om1_1        | 2021-01-28 02:33:01,197 [Thread-12] INFO impl.FollowerState: om1@group-562213E44849-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5012233399ns, electionTimeout:5007ms
om1_1        | 2021-01-28 02:33:01,198 [Thread-12] INFO impl.RoleInfo: om1: shutdown om1@group-562213E44849-FollowerState
om1_1        | 2021-01-28 02:33:01,198 [Thread-12] INFO server.RaftServer$Division: om1@group-562213E44849: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
om1_1        | 2021-01-28 02:33:01,200 [Thread-12] INFO impl.RoleInfo: om1: start om1@group-562213E44849-LeaderElection1
om1_1        | 2021-01-28 02:33:01,209 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection1 PRE_VOTE round 0: submit vote requests at term 0 for -1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1        | 2021-01-28 02:33:02,499 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection1: PRE_VOTE PASSED received 1 response(s) and 0 exception(s):
om1_1        | 2021-01-28 02:33:02,500 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 0: om1<-om2#0:OK-t0
scm_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/ratis-metrics-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/javax.activation-api-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.2.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.1.0-eb66796d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-1.1.0-SNAPSHOT.jar
scm_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/42171e669d6c7f302fa379fc0289c4341f1cbf75 ; compiled by 'runner' on 2021-01-28T01:42Z
scm_1        | STARTUP_MSG:   java = 11.0.7
scm_1        | ************************************************************/
scm_1        | 2021-01-28 02:32:13,367 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm_1        | 2021-01-28 02:32:13,784 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1        | 2021-01-28 02:32:14,634 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file /etc/security/keytabs/scm.keytab
scm_1        | 2021-01-28 02:32:14,634 [main] INFO server.StorageContainerManager: SCM login successful.
scm_1        | 2021-01-28 02:32:15,224 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1        | 2021-01-28 02:32:17,557 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.116,host:scm
scm_1        | 2021-01-28 02:32:17,558 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm_1        | 2021-01-28 02:32:17,790 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1        | 2021-01-28 02:32:17,839 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
scm_1        | 2021-01-28 02:32:18,008 [Listener at 0.0.0.0/9961] INFO net.NodeSchemaLoader: Loading file from java.lang.CompoundEnumeration@52b06bef
scm_1        | 2021-01-28 02:32:18,013 [Listener at 0.0.0.0/9961] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm_1        | 2021-01-28 02:32:18,189 [Listener at 0.0.0.0/9961] INFO node.SCMNodeManager: Entering startup safe mode.
scm_1        | 2021-01-28 02:32:18,339 [Listener at 0.0.0.0/9961] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm_1        | 2021-01-28 02:32:18,423 [Listener at 0.0.0.0/9961] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
scm_1        | 2021-01-28 02:32:18,436 [Listener at 0.0.0.0/9961] INFO pipeline.SCMPipelineManager: No pipeline exists in current db
om1_1        | 2021-01-28 02:33:02,500 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection1 PRE_VOTE round 0: result PASSED
om1_1        | 2021-01-28 02:33:02,513 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1        | 2021-01-28 02:33:02,573 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection1: ELECTION PASSED received 1 response(s) and 0 exception(s):
om1_1        | 2021-01-28 02:33:02,573 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 0: om1<-om2#0:OK-t1
om1_1        | 2021-01-28 02:33:02,573 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection1 ELECTION round 0: result PASSED
om1_1        | 2021-01-28 02:33:02,573 [om1@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om1: shutdown om1@group-562213E44849-LeaderElection1
om1_1        | 2021-01-28 02:33:02,574 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServer$Division: om1@group-562213E44849: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
om1_1        | 2021-01-28 02:33:02,574 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServer$Division: om1@group-562213E44849: change Leader from null to om1 at term 1 for becomeLeader, leader elected after 7686ms
om1_1        | 2021-01-28 02:33:02,588 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
om1_1        | 2021-01-28 02:33:02,590 [om1@group-562213E44849-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.om1@group-562213E44849
om1_1        | 2021-01-28 02:33:02,601 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
om1_1        | 2021-01-28 02:33:02,601 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
om1_1        | 2021-01-28 02:33:02,614 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
om1_1        | 2021-01-28 02:33:02,614 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
om1_1        | 2021-01-28 02:33:02,614 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
om1_1        | 2021-01-28 02:33:02,675 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
om1_1        | 2021-01-28 02:33:02,683 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om1_1        | 2021-01-28 02:33:02,684 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
om1_1        | 2021-01-28 02:33:02,686 [om1@group-562213E44849-LeaderElection1] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
om1_1        | 2021-01-28 02:33:02,690 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om1_1        | 2021-01-28 02:33:02,690 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om1_1        | 2021-01-28 02:33:02,690 [om1@group-562213E44849-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis_grpc.log_appender.om1@group-562213E44849
om1_1        | 2021-01-28 02:33:02,712 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
om1_1        | 2021-01-28 02:33:02,715 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om1_1        | 2021-01-28 02:33:02,718 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
om1_1        | 2021-01-28 02:33:02,723 [om1@group-562213E44849-LeaderElection1] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
om1_1        | 2021-01-28 02:33:02,731 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om1_1        | 2021-01-28 02:33:02,731 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om1_1        | 2021-01-28 02:33:02,733 [om1@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om1: start om1@group-562213E44849-LeaderStateImpl
om1_1        | 2021-01-28 02:33:02,811 [om1@group-562213E44849-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: Starting segment from index:0
om1_1        | 2021-01-28 02:33:02,871 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServer$Division: om1@group-562213E44849: set configuration 0: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om1_1        | 2021-01-28 02:33:03,129 [om1@group-562213E44849-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/current/log_inprogress_0
om1_1        | 2021-01-28 02:33:13,627 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33933
om1_1        | 2021-01-28 02:33:13,656 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-01-28 02:33:14,927 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:vol1 for user:testuser/scm@EXAMPLE.COM
om1_1        | 2021-01-28 02:33:24,849 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40929
om1_1        | 2021-01-28 02:33:24,869 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-01-28 02:33:25,290 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44115
om1_1        | 2021-01-28 02:33:25,302 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-01-28 02:33:29,194 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40863
om1_1        | 2021-01-28 02:33:29,202 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-01-28 02:33:29,612 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35843
scm_1        | 2021-01-28 02:32:18,504 [Listener at 0.0.0.0/9961] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
scm_1        | 2021-01-28 02:32:18,636 [Listener at 0.0.0.0/9961] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
scm_1        | 2021-01-28 02:32:18,638 [Listener at 0.0.0.0/9961] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm_1        | 2021-01-28 02:32:19,635 [Listener at 0.0.0.0/9961] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1        | 2021-01-28 02:32:19,636 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm_1        | 2021-01-28 02:32:19,661 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1        | 2021-01-28 02:32:19,662 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm_1        | 2021-01-28 02:32:19,694 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1        | 2021-01-28 02:32:19,700 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm_1        | 2021-01-28 02:32:19,728 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm_1        | 2021-01-28 02:32:19,728 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
scm_1        | 2021-01-28 02:32:19,730 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
scm_1        | 2021-01-28 02:32:19,752 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @14424ms to org.eclipse.jetty.util.log.Slf4jLog
scm_1        | 2021-01-28 02:32:19,879 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm_1        | 2021-01-28 02:32:19,883 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm_1        | 2021-01-28 02:32:19,884 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
scm_1        | 2021-01-28 02:32:19,885 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
scm_1        | 2021-01-28 02:32:19,885 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
scm_1        | 2021-01-28 02:32:19,886 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
scm_1        | 2021-01-28 02:32:19,989 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm_1        | 2021-01-28 02:32:20,092 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm_1        | 2021-01-28 02:32:20,104 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm_1        | 2021-01-28 02:32:20,104 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm_1        | 2021-01-28 02:32:20,289 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm_1        | 2021-01-28 02:32:20,294 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1        | 2021-01-28 02:32:20,295 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm_1        | 2021-01-28 02:32:20,356 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm_1        | 2021-01-28 02:32:20,360 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm_1        | 2021-01-28 02:32:20,361 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1        | 2021-01-28 02:32:20,366 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm_1        | 2021-01-28 02:32:20,443 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmDatanodeProtocl RPC server is listening at /0.0.0.0:9861
scm_1        | 2021-01-28 02:32:20,443 [Listener at 0.0.0.0/9860] INFO server.SCMDatanodeProtocolServer: RPC server for DataNodes is listening at /0.0.0.0:9861
scm_1        | 2021-01-28 02:32:20,451 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1        | 2021-01-28 02:32:20,452 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm_1        | 2021-01-28 02:32:20,522 [Listener at 0.0.0.0/9860] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
scm_1        | 2021-01-28 02:32:20,534 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1        | 2021-01-28 02:32:20,535 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
scm_1        | 2021-01-28 02:32:20,536 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
scm_1        | 2021-01-28 02:32:20,541 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.34.v20201102; built: 2020-11-02T14:15:39.302Z; git: e46af88704a893fc12cb0e3bf46e2c7b48a009e7; jvm 11.0.7+10-LTS
scm_1        | 2021-01-28 02:32:20,954 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm_1        | 2021-01-28 02:32:20,954 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm_1        | 2021-01-28 02:32:20,993 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 600000ms
scm_1        | 2021-01-28 02:32:21,181 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm_1        | 2021-01-28 02:32:21,174 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:43115
scm_1        | 2021-01-28 02:32:21,200 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1d5048d1{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm_1        | 2021-01-28 02:32:21,202 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@35d88a54{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-1.1.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm_1        | 2021-01-28 02:32:21,214 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/d20fde691356@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:40827
scm_1        | 2021-01-28 02:32:21,229 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1        | 2021-01-28 02:32:21,231 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/d5a2d8142681@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:38709
om1_1        | 2021-01-28 02:33:29,619 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-01-28 02:33:33,313 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44061
om1_1        | 2021-01-28 02:33:33,329 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-01-28 02:33:44,262 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40819
om1_1        | 2021-01-28 02:33:44,275 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-01-28 02:33:44,680 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:79087-source for user:testuser/scm@EXAMPLE.COM
om1_1        | 2021-01-28 02:33:47,161 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44173
om1_1        | 2021-01-28 02:33:47,177 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-01-28 02:33:47,598 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:79087-target for user:testuser/scm@EXAMPLE.COM
om1_1        | 2021-01-28 02:33:49,135 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:44709
om1_1        | 2021-01-28 02:33:49,144 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-01-28 02:33:49,711 [qtp1280441498-43] INFO om.OMDBCheckpointServlet: Received request to obtain OM DB checkpoint snapshot
om1_1        | 2021-01-28 02:33:49,731 [qtp1280441498-43] INFO db.RDBCheckpointManager: Created checkpoint at /data/metadata/db.checkpoints/rdb_rdb_checkpoint_1611801229711 in 19 milliseconds
om1_1        | 2021-01-28 02:33:49,762 [qtp1280441498-43] INFO om.OMDBCheckpointServlet: Time taken to write the checkpoint to response output stream: 29 milliseconds
om1_1        | 2021-01-28 02:33:49,762 [qtp1280441498-43] INFO db.RocksDBCheckpoint: Cleaning up RocksDB checkpoint at /data/metadata/db.checkpoints/rdb_rdb_checkpoint_1611801229711
om1_1        | 2021-01-28 02:33:50,959 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45033
om1_1        | 2021-01-28 02:33:50,975 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-01-28 02:33:53,918 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38309
om1_1        | 2021-01-28 02:33:53,934 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-01-28 02:33:59,032 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43467
om1_1        | 2021-01-28 02:33:59,052 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-01-28 02:34:02,030 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39677
om1_1        | 2021-01-28 02:34:02,055 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-01-28 02:34:04,934 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35283
om1_1        | 2021-01-28 02:34:04,951 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-01-28 02:34:07,831 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45739
om1_1        | 2021-01-28 02:34:07,841 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-01-28 02:34:10,737 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38749
om1_1        | 2021-01-28 02:34:10,779 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-01-28 02:34:13,950 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44587
om1_1        | 2021-01-28 02:34:13,969 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-01-28 02:34:16,745 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40645
om1_1        | 2021-01-28 02:34:16,756 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-01-28 02:34:19,711 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44777
om1_1        | 2021-01-28 02:34:19,724 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-01-28 02:34:22,562 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42393
om1_1        | 2021-01-28 02:34:22,580 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-01-28 02:34:25,494 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39045
om1_1        | 2021-01-28 02:34:25,507 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1        | 2021-01-28 02:32:21,243 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/db0158eeb642@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:42209
scm_1        | 2021-01-28 02:32:21,252 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/d20fde691356@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1        | 2021-01-28 02:32:21,270 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/d5a2d8142681@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1        | 2021-01-28 02:32:21,272 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/db0158eeb642@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1        | 2021-01-28 02:32:21,292 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40173
scm_1        | 2021-01-28 02:32:21,331 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1        | 2021-01-28 02:32:21,433 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm_1        | 2021-01-28 02:32:21,445 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@5ebfe7fa{scm,/,file:///tmp/jetty-0_0_0_0-9876-hadoop-hdds-server-scm-1_1_0-SNAPSHOT_jar-_-any-5933373062747761762/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-1.1.0-SNAPSHOT.jar!/webapps/scm}
scm_1        | 2021-01-28 02:32:21,471 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@1ac3a6f{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
scm_1        | 2021-01-28 02:32:21,471 [Listener at 0.0.0.0/9860] INFO server.Server: Started @16144ms
scm_1        | 2021-01-28 02:32:21,478 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm_1        | 2021-01-28 02:32:21,478 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm_1        | 2021-01-28 02:32:21,491 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm_1        | 2021-01-28 02:32:21,522 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2befb16f] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm_1        | 2021-01-28 02:32:21,526 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn d5a2d8142681, UUID: feb6bea5-edd2-410b-8ad4-c920818f117a
scm_1        | 2021-01-28 02:32:21,526 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn d20fde691356, UUID: bb31b8e2-b35d-4b3b-ae90-43363de8a349
scm_1        | 2021-01-28 02:32:21,691 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn db0158eeb642, UUID: 6bab7c5a-f782-4236-88e0-70f071e2bf9c
scm_1        | 2021-01-28 02:32:22,130 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om1@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:38437
scm_1        | 2021-01-28 02:32:22,173 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om1@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1        | 2021-01-28 02:32:22,979 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42473
scm_1        | 2021-01-28 02:32:23,008 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1        | 2021-01-28 02:32:24,521 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om3@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:43999
scm_1        | 2021-01-28 02:32:24,563 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om3@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1        | 2021-01-28 02:32:24,707 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om2@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:34963
om1_1        | 2021-01-28 02:34:28,769 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36591
om1_1        | 2021-01-28 02:34:28,781 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-01-28 02:34:31,916 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34329
om1_1        | 2021-01-28 02:34:31,924 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-01-28 02:34:34,950 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37059
om1_1        | 2021-01-28 02:34:34,967 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-01-28 02:34:38,037 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33083
om1_1        | 2021-01-28 02:34:38,056 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-01-28 02:34:43,252 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39971
om1_1        | 2021-01-28 02:34:43,262 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-01-28 02:34:47,698 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33685
om1_1        | 2021-01-28 02:34:47,712 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-01-28 02:34:50,521 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:33097
om1_1        | 2021-01-28 02:34:50,536 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-01-28 02:34:52,785 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45595
om1_1        | 2021-01-28 02:34:52,808 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-01-28 02:34:57,289 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43801
om1_1        | 2021-01-28 02:34:57,298 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-01-28 02:35:00,581 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40189
om1_1        | 2021-01-28 02:35:00,594 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-01-28 02:35:03,855 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40401
om1_1        | 2021-01-28 02:35:03,869 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-01-28 02:35:07,094 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35467
om1_1        | 2021-01-28 02:35:07,113 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-01-28 02:35:10,207 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42717
scm_1        | 2021-01-28 02:32:24,729 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om2@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1        | 2021-01-28 02:32:30,528 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om1@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:37061
scm_1        | 2021-01-28 02:32:30,548 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om1@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1        | 2021-01-28 02:32:30,598 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for om om1, UUID: 9632b218-a8d1-4a14-a6c3-48823ea795ba
scm_1        | 2021-01-28 02:32:32,775 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om3@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:39941
scm_1        | 2021-01-28 02:32:32,800 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om3@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1        | 2021-01-28 02:32:32,803 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for om om3, UUID: 6cdb9e9f-e5b7-49ad-89d4-6f3b02b1a091
scm_1        | 2021-01-28 02:32:33,040 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om2@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:33223
scm_1        | 2021-01-28 02:32:33,099 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om2@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1        | 2021-01-28 02:32:33,100 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for om om2, UUID: 0b91d617-455f-4a5f-adf5-fb0b5a373275
scm_1        | 2021-01-28 02:32:39,763 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/d20fde691356@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45727
scm_1        | 2021-01-28 02:32:39,764 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/db0158eeb642@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:40175
scm_1        | 2021-01-28 02:32:39,800 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/db0158eeb642@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1        | 2021-01-28 02:32:39,840 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/d20fde691356@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1        | 2021-01-28 02:32:40,963 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/d5a2d8142681@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44513
scm_1        | 2021-01-28 02:32:41,187 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/d5a2d8142681@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2021-01-28 02:35:10,232 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-01-28 02:35:13,632 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45129
om1_1        | 2021-01-28 02:35:13,652 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-01-28 02:35:16,724 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44629
om1_1        | 2021-01-28 02:35:16,736 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-01-28 02:35:19,960 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46717
om1_1        | 2021-01-28 02:35:19,975 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-01-28 02:35:23,027 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44569
om1_1        | 2021-01-28 02:35:23,038 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-01-28 02:35:25,865 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41339
om1_1        | 2021-01-28 02:35:25,880 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-01-28 02:35:28,602 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41821
scm_1        | 2021-01-28 02:32:41,776 [IPC Server handler 12 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/6bab7c5a-f782-4236-88e0-70f071e2bf9c
scm_1        | 2021-01-28 02:32:41,792 [IPC Server handler 13 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/bb31b8e2-b35d-4b3b-ae90-43363de8a349
scm_1        | 2021-01-28 02:32:41,830 [IPC Server handler 13 on default port 9861] INFO node.SCMNodeManager: Registered Data node : bb31b8e2-b35d-4b3b-ae90-43363de8a349{ip: 172.25.0.102, host: ozonesecure-om-ha_datanode1_1.ozonesecure-om-ha_ozone_net, networkLocation: /default-rack, certSerialId: 2411674243301, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
scm_1        | 2021-01-28 02:32:41,828 [IPC Server handler 12 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 6bab7c5a-f782-4236-88e0-70f071e2bf9c{ip: 172.25.0.103, host: ozonesecure-om-ha_datanode2_1.ozonesecure-om-ha_ozone_net, networkLocation: /default-rack, certSerialId: 2411778267491, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
scm_1        | 2021-01-28 02:32:41,887 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1        | 2021-01-28 02:32:42,045 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1        | 2021-01-28 02:32:42,097 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1        | 2021-01-28 02:32:42,079 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
scm_1        | 2021-01-28 02:32:42,097 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
scm_1        | 2021-01-28 02:32:42,105 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1        | 2021-01-28 02:32:42,134 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=f85be9de-7cd2-4361-be7a-1f92667e218d to datanode:bb31b8e2-b35d-4b3b-ae90-43363de8a349
scm_1        | 2021-01-28 02:32:42,248 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: f85be9de-7cd2-4361-be7a-1f92667e218d, Nodes: bb31b8e2-b35d-4b3b-ae90-43363de8a349{ip: 172.25.0.102, host: ozonesecure-om-ha_datanode1_1.ozonesecure-om-ha_ozone_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2021-01-28T02:32:42.119692Z]
scm_1        | 2021-01-28 02:32:42,302 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=f3928597-5304-49a3-b7ac-b28675baafbc to datanode:6bab7c5a-f782-4236-88e0-70f071e2bf9c
scm_1        | 2021-01-28 02:32:42,308 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: f3928597-5304-49a3-b7ac-b28675baafbc, Nodes: 6bab7c5a-f782-4236-88e0-70f071e2bf9c{ip: 172.25.0.103, host: ozonesecure-om-ha_datanode2_1.ozonesecure-om-ha_ozone_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2021-01-28T02:32:42.302603Z]
scm_1        | 2021-01-28 02:32:42,857 [IPC Server handler 13 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/feb6bea5-edd2-410b-8ad4-c920818f117a
scm_1        | 2021-01-28 02:32:42,857 [IPC Server handler 13 on default port 9861] INFO node.SCMNodeManager: Registered Data node : feb6bea5-edd2-410b-8ad4-c920818f117a{ip: 172.25.0.104, host: ozonesecure-om-ha_datanode3_1.ozonesecure-om-ha_ozone_net, networkLocation: /default-rack, certSerialId: 2411677671379, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
scm_1        | 2021-01-28 02:32:42,857 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
scm_1        | 2021-01-28 02:32:42,857 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm_1        | 2021-01-28 02:32:42,857 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm_1        | 2021-01-28 02:32:42,858 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1        | 2021-01-28 02:32:42,858 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1        | 2021-01-28 02:32:42,862 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=39c789b6-0c46-456e-8a71-97a240718454 to datanode:feb6bea5-edd2-410b-8ad4-c920818f117a
scm_1        | 2021-01-28 02:32:42,864 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 39c789b6-0c46-456e-8a71-97a240718454, Nodes: feb6bea5-edd2-410b-8ad4-c920818f117a{ip: 172.25.0.104, host: ozonesecure-om-ha_datanode3_1.ozonesecure-om-ha_ozone_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2021-01-28T02:32:42.862664Z]
scm_1        | 2021-01-28 02:32:42,878 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=45d6c387-0d5e-4ec1-887d-a71b52063026 to datanode:feb6bea5-edd2-410b-8ad4-c920818f117a
scm_1        | 2021-01-28 02:32:42,885 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=45d6c387-0d5e-4ec1-887d-a71b52063026 to datanode:6bab7c5a-f782-4236-88e0-70f071e2bf9c
scm_1        | 2021-01-28 02:32:42,887 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=45d6c387-0d5e-4ec1-887d-a71b52063026 to datanode:bb31b8e2-b35d-4b3b-ae90-43363de8a349
scm_1        | 2021-01-28 02:32:42,891 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 45d6c387-0d5e-4ec1-887d-a71b52063026, Nodes: feb6bea5-edd2-410b-8ad4-c920818f117a{ip: 172.25.0.104, host: ozonesecure-om-ha_datanode3_1.ozonesecure-om-ha_ozone_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}6bab7c5a-f782-4236-88e0-70f071e2bf9c{ip: 172.25.0.103, host: ozonesecure-om-ha_datanode2_1.ozonesecure-om-ha_ozone_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}bb31b8e2-b35d-4b3b-ae90-43363de8a349{ip: 172.25.0.102, host: ozonesecure-om-ha_datanode1_1.ozonesecure-om-ha_ozone_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:, CreationTimestamp2021-01-28T02:32:42.878648Z]
scm_1        | 2021-01-28 02:32:42,902 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=4954273f-2502-40bd-89f2-8e19c9aa218c to datanode:feb6bea5-edd2-410b-8ad4-c920818f117a
om1_1        | 2021-01-28 02:35:28,613 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-01-28 02:35:31,845 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43567
om1_1        | 2021-01-28 02:35:31,857 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-01-28 02:35:34,977 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45425
om1_1        | 2021-01-28 02:35:34,988 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-01-28 02:35:37,873 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40183
om1_1        | 2021-01-28 02:35:37,884 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-01-28 02:35:38,330 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:link2 in volume:79087-target
om1_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om1_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:192)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:415)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:240)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1        | 2021-01-28 02:35:40,845 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41647
om1_1        | 2021-01-28 02:35:40,861 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-01-28 02:35:43,878 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43381
om1_1        | 2021-01-28 02:35:43,889 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-01-28 02:35:44,261 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket3 in volume:79087-target
om1_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om1_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:192)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:415)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:240)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1        | 2021-01-28 02:35:46,693 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34149
om1_1        | 2021-01-28 02:35:46,708 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-01-28 02:35:49,887 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41833
om1_1        | 2021-01-28 02:35:49,901 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-01-28 02:35:50,284 [IPC Server handler 7 on default port 9862] WARN om.OzoneManager: User testuser2/scm@EXAMPLE.COM doesn't have READ permission to access bucket /79087-target/unreadable-link/null
om1_1        | 2021-01-28 02:35:50,872 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:33109
om1_1        | 2021-01-28 02:35:50,885 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-01-28 02:35:52,926 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37761
om1_1        | 2021-01-28 02:35:52,939 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-01-28 02:35:55,857 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39815
om1_1        | 2021-01-28 02:35:55,865 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-01-28 02:35:56,368 [IPC Server handler 12 on default port 9862] WARN om.OzoneManager: User testuser2/scm@EXAMPLE.COM doesn't have LIST permission to access bucket /79087-source/unreadable-bucket/
om1_1        | 2021-01-28 02:35:59,185 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42569
om1_1        | 2021-01-28 02:35:59,200 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-01-28 02:36:02,262 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:32843
om1_1        | 2021-01-28 02:36:02,280 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1        | 2021-01-28 02:32:42,904 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=4954273f-2502-40bd-89f2-8e19c9aa218c to datanode:bb31b8e2-b35d-4b3b-ae90-43363de8a349
scm_1        | 2021-01-28 02:32:42,911 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=4954273f-2502-40bd-89f2-8e19c9aa218c to datanode:6bab7c5a-f782-4236-88e0-70f071e2bf9c
scm_1        | 2021-01-28 02:32:42,914 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 4954273f-2502-40bd-89f2-8e19c9aa218c, Nodes: feb6bea5-edd2-410b-8ad4-c920818f117a{ip: 172.25.0.104, host: ozonesecure-om-ha_datanode3_1.ozonesecure-om-ha_ozone_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}bb31b8e2-b35d-4b3b-ae90-43363de8a349{ip: 172.25.0.102, host: ozonesecure-om-ha_datanode1_1.ozonesecure-om-ha_ozone_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}6bab7c5a-f782-4236-88e0-70f071e2bf9c{ip: 172.25.0.103, host: ozonesecure-om-ha_datanode2_1.ozonesecure-om-ha_ozone_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:, CreationTimestamp2021-01-28T02:32:42.902884Z]
scm_1        | 2021-01-28 02:32:42,921 [RatisPipelineUtilsThread] INFO pipeline.SCMPipelineManager: Pipeline: PipelineID=4954273f-2502-40bd-89f2-8e19c9aa218c contains same datanodes as previous pipelines: PipelineID=45d6c387-0d5e-4ec1-887d-a71b52063026 nodeIds: feb6bea5-edd2-410b-8ad4-c920818f117a, bb31b8e2-b35d-4b3b-ae90-43363de8a349, 6bab7c5a-f782-4236-88e0-70f071e2bf9c
scm_1        | 2021-01-28 02:32:46,339 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1        | 2021-01-28 02:32:46,347 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 39c789b6-0c46-456e-8a71-97a240718454, Nodes: feb6bea5-edd2-410b-8ad4-c920818f117a{ip: 172.25.0.104, host: ozonesecure-om-ha_datanode3_1.ozonesecure-om-ha_ozone_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:feb6bea5-edd2-410b-8ad4-c920818f117a, CreationTimestamp2021-01-28T02:32:42.862664Z] moved to OPEN state
scm_1        | 2021-01-28 02:32:46,419 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1        | 2021-01-28 02:32:46,454 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:34869
scm_1        | 2021-01-28 02:32:46,524 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1        | 2021-01-28 02:32:46,999 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1        | 2021-01-28 02:32:46,999 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1        | 2021-01-28 02:32:48,709 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om1@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:33073
scm_1        | 2021-01-28 02:32:48,776 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om1@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1        | 2021-01-28 02:32:49,300 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1        | 2021-01-28 02:32:49,888 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om3@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:40105
scm_1        | 2021-01-28 02:32:49,969 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om3@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1        | 2021-01-28 02:32:50,413 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41405
scm_1        | 2021-01-28 02:32:50,657 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1        | 2021-01-28 02:32:51,057 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om2@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:33061
scm_1        | 2021-01-28 02:32:51,119 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om2@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1        | 2021-01-28 02:32:51,560 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38779
scm_1        | 2021-01-28 02:32:51,569 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1        | 2021-01-28 02:32:51,631 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1        | 2021-01-28 02:32:51,993 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1        | 2021-01-28 02:32:51,993 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1        | 2021-01-28 02:32:52,290 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1        | 2021-01-28 02:32:52,291 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1        | 2021-01-28 02:32:52,568 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1        | 2021-01-28 02:32:52,823 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1        | 2021-01-28 02:32:57,594 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1        | 2021-01-28 02:32:57,597 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 4954273f-2502-40bd-89f2-8e19c9aa218c, Nodes: feb6bea5-edd2-410b-8ad4-c920818f117a{ip: 172.25.0.104, host: ozonesecure-om-ha_datanode3_1.ozonesecure-om-ha_ozone_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}bb31b8e2-b35d-4b3b-ae90-43363de8a349{ip: 172.25.0.102, host: ozonesecure-om-ha_datanode1_1.ozonesecure-om-ha_ozone_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}6bab7c5a-f782-4236-88e0-70f071e2bf9c{ip: 172.25.0.103, host: ozonesecure-om-ha_datanode2_1.ozonesecure-om-ha_ozone_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:feb6bea5-edd2-410b-8ad4-c920818f117a, CreationTimestamp2021-01-28T02:32:42.902884Z] moved to OPEN state
scm_1        | 2021-01-28 02:32:57,598 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
scm_1        | 2021-01-28 02:32:57,599 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm_1        | 2021-01-28 02:32:57,599 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm_1        | 2021-01-28 02:32:57,599 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
scm_1        | 2021-01-28 02:32:57,839 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 45d6c387-0d5e-4ec1-887d-a71b52063026, Nodes: feb6bea5-edd2-410b-8ad4-c920818f117a{ip: 172.25.0.104, host: ozonesecure-om-ha_datanode3_1.ozonesecure-om-ha_ozone_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}6bab7c5a-f782-4236-88e0-70f071e2bf9c{ip: 172.25.0.103, host: ozonesecure-om-ha_datanode2_1.ozonesecure-om-ha_ozone_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}bb31b8e2-b35d-4b3b-ae90-43363de8a349{ip: 172.25.0.102, host: ozonesecure-om-ha_datanode1_1.ozonesecure-om-ha_ozone_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:bb31b8e2-b35d-4b3b-ae90-43363de8a349, CreationTimestamp2021-01-28T02:32:42.878648Z] moved to OPEN state
scm_1        | 2021-01-28 02:33:03,648 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36955
scm_1        | 2021-01-28 02:33:03,658 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1        | 2021-01-28 02:33:03,808 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38103
scm_1        | 2021-01-28 02:33:03,812 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1        | 2021-01-28 02:33:14,642 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:35547
scm_1        | 2021-01-28 02:33:14,653 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1        | 2021-01-28 02:33:14,674 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/d20fde691356@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:42147
scm_1        | 2021-01-28 02:33:14,677 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/db0158eeb642@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:35353
scm_1        | 2021-01-28 02:33:14,686 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/db0158eeb642@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1        | 2021-01-28 02:33:14,686 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/d20fde691356@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1        | 2021-01-28 02:33:14,687 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: f3928597-5304-49a3-b7ac-b28675baafbc, Nodes: 6bab7c5a-f782-4236-88e0-70f071e2bf9c{ip: 172.25.0.103, host: ozonesecure-om-ha_datanode2_1.ozonesecure-om-ha_ozone_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:6bab7c5a-f782-4236-88e0-70f071e2bf9c, CreationTimestamp2021-01-28T02:32:42.302603Z] moved to OPEN state
scm_1        | 2021-01-28 02:33:14,727 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: f85be9de-7cd2-4361-be7a-1f92667e218d, Nodes: bb31b8e2-b35d-4b3b-ae90-43363de8a349{ip: 172.25.0.102, host: ozonesecure-om-ha_datanode1_1.ozonesecure-om-ha_ozone_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:bb31b8e2-b35d-4b3b-ae90-43363de8a349, CreationTimestamp2021-01-28T02:32:42.119692Z] moved to OPEN state
scm_1        | 2021-01-28 02:33:15,404 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om1@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:35105
scm_1        | 2021-01-28 02:33:15,412 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om1@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1        | 2021-01-28 02:33:19,196 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/d5a2d8142681@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43087
scm_1        | 2021-01-28 02:33:19,201 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/d5a2d8142681@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1        | 2021-01-28 02:33:19,451 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/d5a2d8142681@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33113
scm_1        | 2021-01-28 02:33:19,480 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/d5a2d8142681@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1        | 2021-01-28 02:33:20,081 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/d20fde691356@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38659
scm_1        | 2021-01-28 02:33:20,090 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/d20fde691356@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1        | 2021-01-28 02:33:20,130 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/db0158eeb642@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:46781
scm_1        | 2021-01-28 02:33:20,143 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/db0158eeb642@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1        | 2021-01-28 02:33:33,805 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om1@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:37893
scm_1        | 2021-01-28 02:33:33,814 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om1@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1        | 2021-01-28 02:33:49,477 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/d5a2d8142681@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44137
scm_1        | 2021-01-28 02:33:49,486 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/d5a2d8142681@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1        | 2021-01-28 02:33:50,591 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/d20fde691356@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35823
scm_1        | 2021-01-28 02:33:50,602 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/d20fde691356@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1        | 2021-01-28 02:33:50,662 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/db0158eeb642@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:41035
scm_1        | 2021-01-28 02:33:50,676 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/db0158eeb642@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1        | 2021-01-28 02:33:54,432 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om1@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:42843
scm_1        | 2021-01-28 02:33:54,439 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om1@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1        | 2021-01-28 02:34:19,462 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/d5a2d8142681@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:36373
scm_1        | 2021-01-28 02:34:19,469 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/d5a2d8142681@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1        | 2021-01-28 02:34:20,594 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/d20fde691356@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33997
scm_1        | 2021-01-28 02:34:20,600 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/d20fde691356@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1        | 2021-01-28 02:34:20,663 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/db0158eeb642@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36945
scm_1        | 2021-01-28 02:34:20,665 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/db0158eeb642@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1        | 2021-01-28 02:34:38,512 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om1@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:44747
scm_1        | 2021-01-28 02:34:38,514 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om1@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1        | 2021-01-28 02:34:43,705 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om1@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:42605
scm_1        | 2021-01-28 02:34:43,710 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om1@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1        | 2021-01-28 02:34:49,450 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/d5a2d8142681@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43869
scm_1        | 2021-01-28 02:34:49,463 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/d5a2d8142681@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1        | 2021-01-28 02:34:50,609 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/d20fde691356@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:40913
scm_1        | 2021-01-28 02:34:50,616 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/d20fde691356@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1        | 2021-01-28 02:34:50,683 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/db0158eeb642@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:43237
scm_1        | 2021-01-28 02:34:50,689 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/db0158eeb642@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1        | 2021-01-28 02:35:19,459 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/d5a2d8142681@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:37683
scm_1        | 2021-01-28 02:35:19,483 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/d5a2d8142681@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1        | 2021-01-28 02:35:20,591 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/d20fde691356@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34355
scm_1        | 2021-01-28 02:35:20,601 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/d20fde691356@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1        | 2021-01-28 02:35:20,654 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/db0158eeb642@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:34313
scm_1        | 2021-01-28 02:35:20,666 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/db0158eeb642@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1        | 2021-01-28 02:35:49,466 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/d5a2d8142681@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:42191
scm_1        | 2021-01-28 02:35:49,476 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/d5a2d8142681@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1        | 2021-01-28 02:35:50,572 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/d20fde691356@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41461
scm_1        | 2021-01-28 02:35:50,580 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/d20fde691356@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1        | 2021-01-28 02:35:50,642 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/db0158eeb642@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:46683
om1_1        | 2021-01-28 02:36:05,356 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37849
om1_1        | 2021-01-28 02:36:05,367 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-01-28 02:36:08,209 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37745
om1_1        | 2021-01-28 02:36:08,219 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-01-28 02:36:11,015 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37969
om1_1        | 2021-01-28 02:36:11,034 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-01-28 02:36:13,866 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36011
om1_1        | 2021-01-28 02:36:13,879 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-01-28 02:36:18,704 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37031
om1_1        | 2021-01-28 02:36:18,720 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-01-28 02:36:23,331 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37033
om1_1        | 2021-01-28 02:36:23,344 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-01-28 02:36:26,417 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39831
om1_1        | 2021-01-28 02:36:26,439 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-01-28 02:36:29,468 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46847
om1_1        | 2021-01-28 02:36:29,477 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1        | 2021-01-28 02:35:50,673 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/db0158eeb642@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1        | 2021-01-28 02:35:56,614 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om1@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:44931
scm_1        | 2021-01-28 02:35:56,631 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om1@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1        | 2021-01-28 02:36:14,384 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om1@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:37137
scm_1        | 2021-01-28 02:36:14,389 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om1@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1        | 2021-01-28 02:36:15,846 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/d5a2d8142681@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:37391
scm_1        | 2021-01-28 02:36:15,861 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/db0158eeb642@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:42227
scm_1        | 2021-01-28 02:36:15,879 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:45419
scm_1        | 2021-01-28 02:36:15,884 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/db0158eeb642@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1        | 2021-01-28 02:36:15,891 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1        | 2021-01-28 02:36:15,906 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/d5a2d8142681@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1        | 2021-01-28 02:36:15,907 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/d20fde691356@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38021
scm_1        | 2021-01-28 02:36:15,926 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/d20fde691356@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1        | 2021-01-28 02:36:19,172 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om1@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:45601
scm_1        | 2021-01-28 02:36:19,179 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om1@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
