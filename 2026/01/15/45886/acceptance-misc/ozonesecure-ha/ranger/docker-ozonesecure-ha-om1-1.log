Waiting for the service scm3.org:9894
No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8' to the OZONE_OPTS
Ozone Manager classpath extended by /opt/ranger/ozone-plugin/lib/libext/*:/opt/ozone/conf
2026-01-15 05:54:24,292 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting OzoneManager
STARTUP_MSG:        host = om1/172.25.0.111
STARTUP_MSG:     version = 2.2.0-SNAPSHOT
STARTUP_MSG:       build = https://github.com/apache/ozone/cd2e68c502e7271e18e87a3fdd104a8bd89109ca
STARTUP_MSG:        java = 21.0.2
STARTUP_MSG:        args = [--init]
STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/jackson-annotations-2.16.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.16.2.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.16.2.jar:/opt/hadoop/share/ozone/lib/guava-33.5.0-jre.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.3.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jspecify-1.0.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.29.2.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-3.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-3.25.8.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.18.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.18.0.jar:/opt/hadoop/share/ozone/lib/picocli-4.7.5.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.77.0.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.77.0.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.24.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.128.Final.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.128.Final.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.77.0.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.77.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.128.Final.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.128.Final.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.27.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.128.Final.jar:/opt/hadoop/share/ozone/lib/grpc-util-1.77.0.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.77.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.128.Final.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.128.Final.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.128.Final.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.128.Final.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.128.Final.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.128.Final.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-2.1.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.27.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.18.0.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.12.1.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.4.2.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.14.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-10.4.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.6.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.4.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.4.2.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_25-1.4.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.4.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.8.0.jar:/opt/hadoop/share/ozone/lib/commons-net-3.11.1.jar:/opt/hadoop/share/ozone/lib/commons-collections4-4.4.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.58.v20250814.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.58.v20250814.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.58.v20250814.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.58.v20250814.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.58.v20250814.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.58.v20250814.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.5.4.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.12.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.13.1.jar:/opt/hadoop/share/ozone/lib/re2j-1.7.jar:/opt/hadoop/share/ozone/lib/gson-2.13.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.55.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-epoll-4.1.128.Final.jar:/opt/hadoop/share/ozone/lib/netty-transport-classes-epoll-4.1.128.Final.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk18on-1.83.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-3.6.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.4.2.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.16.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.25.3.jar:/opt/hadoop/share/ozone/lib/hdds-client-2.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-2.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-2.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.16.2.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.10.0.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.11.0.jar:/opt/hadoop/share/ozone/lib/commons-digester-2.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/opentelemetry-api-1.58.0.jar:/opt/hadoop/share/ozone/lib/opentelemetry-context-1.58.0.jar:/opt/hadoop/share/ozone/lib/opentelemetry-common-1.58.0.jar:/opt/hadoop/share/ozone/lib/opentelemetry-exporter-otlp-1.58.0.jar:/opt/hadoop/share/ozone/lib/opentelemetry-sdk-metrics-1.58.0.jar:/opt/hadoop/share/ozone/lib/opentelemetry-sdk-logs-1.58.0.jar:/opt/hadoop/share/ozone/lib/opentelemetry-exporter-otlp-common-1.58.0.jar:/opt/hadoop/share/ozone/lib/opentelemetry-exporter-common-1.58.0.jar:/opt/hadoop/share/ozone/lib/opentelemetry-exporter-sender-okhttp-1.58.0.jar:/opt/hadoop/share/ozone/lib/okhttp-jvm-5.3.2.jar:/opt/hadoop/share/ozone/lib/okio-jvm-3.16.4.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.9.25.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/opentelemetry-sdk-extension-autoconfigure-spi-1.58.0.jar:/opt/hadoop/share/ozone/lib/opentelemetry-sdk-1.58.0.jar:/opt/hadoop/share/ozone/lib/opentelemetry-sdk-common-1.58.0.jar:/opt/hadoop/share/ozone/lib/opentelemetry-sdk-trace-1.58.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk18on-1.83.jar:/opt/hadoop/share/ozone/lib/bcutil-jdk18on-1.83.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-dropwizard3-3.2.1.jar:/opt/hadoop/share/ozone/lib/jcl-over-slf4j-2.0.17.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-2.0.17.jar:/opt/hadoop/share/ozone/lib/hdds-config-2.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-2.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-2.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-managed-rocksdb-2.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-rocks-native-2.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-2.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.26.jar:/opt/hadoop/share/ozone/lib/jnr-constants-0.10.4.jar:/opt/hadoop/share/ozone/lib/jnr-posix-3.1.21.jar:/opt/hadoop/share/ozone/lib/jnr-ffi-2.2.18.jar:/opt/hadoop/share/ozone/lib/jffi-1.3.14.jar:/opt/hadoop/share/ozone/lib/jffi-1.3.14-native.jar:/opt/hadoop/share/ozone/lib/asm-commons-9.7.1.jar:/opt/hadoop/share/ozone/lib/asm-analysis-9.7.1.jar:/opt/hadoop/share/ozone/lib/asm-tree-9.7.1.jar:/opt/hadoop/share/ozone/lib/asm-util-9.7.1.jar:/opt/hadoop/share/ozone/lib/jnr-a64asm-1.0.0.jar:/opt/hadoop/share/ozone/lib/jnr-x86asm-1.0.2.jar:/opt/hadoop/share/ozone/lib/commons-fileupload-1.6.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.16.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.16.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.16.0.jar:/opt/hadoop/share/ozone/lib/jakarta.ws.rs-api-2.1.6.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-2.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-api-3.2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.58.v20250814.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.47.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.6.1.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.47.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.3.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.47.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.47.jar:/opt/hadoop/share/ozone/lib/jakarta.validation-api-2.0.2.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.4.jar:/opt/hadoop/share/ozone/lib/apache-log4j-extras-1.2.17.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.25.3.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.10.8.jar:/opt/hadoop/share/ozone/lib/ozone-common-2.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-2.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.77.0.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.59.2.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.77.0.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-2.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/rocksdb-checkpoint-differ-2.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-3.2.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-3.2.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-3.2.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-3.2.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-3.2.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.10.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.24.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.58.v20250814.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.58.v20250814.jar:/opt/hadoop/share/ozone/lib/reflections-0.10.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.30.2-GA.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/slf4j-api-2.0.17.jar:/opt/hadoop/share/ozone/lib/snakeyaml-2.5.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.74.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.74.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.74.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.74.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.74.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.74.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.74.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/asm-9.8.jar:/opt/hadoop/share/ozone/lib/ozone-manager-2.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/web:/opt/ranger/ozone-plugin/lib/libext/ranger-ozone-plugin-impl:/opt/ranger/ozone-plugin/lib/libext/ranger-ozone-plugin-shim-2.6.0.jar:/opt/ranger/ozone-plugin/lib/libext/ranger-plugin-classloader-2.6.0.jar:/opt/ozone/conf:/opt/hadoop/share/ozone/lib/jersey-client-1.19.4.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.4.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/ranger-intg-2.6.0.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-base-2.16.2.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-json-provider-2.16.2.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.16.2.jar:/opt/hadoop/share/ozone/lib/gethostname4j-1.0.0.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-2.6.0.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-2.6.0.jar:/opt/hadoop/share/ozone/lib/aws-java-sdk-logs-1.12.765.jar:/opt/hadoop/share/ozone/lib/aws-java-sdk-core-1.12.788.jar:/opt/hadoop/share/ozone/lib/jackson-dataformat-cbor-2.16.2.jar:/opt/hadoop/share/ozone/lib/jmespath-java-1.12.765.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/aircompressor-0.27.jar:/opt/hadoop/share/ozone/lib/joda-time-2.12.7.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.4.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.16.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.13.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/orc-shims-1.5.8.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.58.v20250814.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-2.6.0.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.3.jar:/opt/hadoop/share/ozone/lib/ozone-multitenancy-ranger-2.2.0-SNAPSHOT.jar
STARTUP_MSG:        conf = {hadoop.hdds.db.rocksdb.WAL_size_limit_MB=0MB, hadoop.hdds.db.rocksdb.WAL_ttl_seconds=1200, hadoop.hdds.db.rocksdb.keep.log.file.num=10, hadoop.hdds.db.rocksdb.logging.enabled=false, hadoop.hdds.db.rocksdb.logging.level=INFO, hadoop.hdds.db.rocksdb.max.log.file.size=100MB, hadoop.hdds.db.rocksdb.writeoption.sync=false, hdds.block.token.enabled=true, hdds.block.token.expiry.time=1d, hdds.command.status.report.interval=30s, hdds.container.action.max.limit=20, hdds.container.balancer.balancing.iteration.interval=70m, hdds.container.balancer.datanodes.involved.max.percentage.per.iteration=20, hdds.container.balancer.iterations=10, hdds.container.balancer.move.networkTopology.enable=false, hdds.container.balancer.move.replication.timeout=50m, hdds.container.balancer.move.timeout=65m, hdds.container.balancer.size.entering.target.max=26GB, hdds.container.balancer.size.leaving.source.max=26GB, hdds.container.balancer.size.moved.max.per.iteration=500GB, hdds.container.balancer.trigger.du.before.move.enable=false, hdds.container.balancer.utilization.threshold=10, hdds.container.checksum.verification.enabled=true, hdds.container.chunk.write.sync=false, hdds.container.close.threshold=0.9f, hdds.container.ipc.port=9859, hdds.container.ipc.random.port=false, hdds.container.ratis.admin.port=9857, hdds.container.ratis.datastream.enabled=true, hdds.container.ratis.datastream.port=9855, hdds.container.ratis.datastream.random.port=false, hdds.container.ratis.enabled=false, hdds.container.ratis.ipc.port=9858, hdds.container.ratis.ipc.random.port=false, hdds.container.ratis.leader.pending.bytes.limit=1GB, hdds.container.ratis.log.appender.queue.byte-limit=32MB, hdds.container.ratis.log.appender.queue.num-elements=1024, hdds.container.ratis.log.purge.gap=1000000, hdds.container.ratis.log.queue.byte-limit=4GB, hdds.container.ratis.log.queue.num-elements=1024, hdds.container.ratis.num.container.op.executors=10, hdds.container.ratis.num.write.chunk.threads.per.volume=10, hdds.container.ratis.rpc.type=GRPC, hdds.container.ratis.segment.preallocated.size=4MB, hdds.container.ratis.segment.size=64MB, hdds.container.ratis.server.port=9856, hdds.container.ratis.statemachine.max.pending.apply-transactions=100000, hdds.container.ratis.statemachine.write.wait.interval=10m, hdds.container.ratis.statemachinedata.sync.timeout=10s, hdds.container.replication.compression=NO_COMPRESSION, hdds.container.report.interval=60s, hdds.container.token.enabled=true, hdds.datanode.client.bind.host=0.0.0.0, hdds.datanode.client.port=19864, hdds.datanode.df.refresh.period=5m, hdds.datanode.dir=/data/hdds, hdds.datanode.disk.balancer.enabled=false, hdds.datanode.dns.interface=default, hdds.datanode.dns.nameserver=default, hdds.datanode.du.refresh.period=1h, hdds.datanode.handler.count=10, hdds.datanode.http-address=0.0.0.0:9882, hdds.datanode.http-bind-host=0.0.0.0, hdds.datanode.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.datanode.http.auth.kerberos.principal=HTTP/db@EXAMPLE.COM, hdds.datanode.http.auth.type=kerberos, hdds.datanode.http.enabled=true, hdds.datanode.https-address=0.0.0.0:9883, hdds.datanode.https-bind-host=0.0.0.0, hdds.datanode.kerberos.keytab.file=/etc/security/keytabs/dn.keytab, hdds.datanode.kerberos.principal=dn/dn@EXAMPLE.COM, hdds.datanode.metadata.rocksdb.cache.size=1GB, hdds.datanode.ratis.server.request.timeout=2m, hdds.datanode.read.threadpool=10, hdds.datanode.slow.op.warning.threshold=500ms, hdds.datanode.storage.utilization.critical.threshold=0.95, hdds.datanode.storage.utilization.warning.threshold=0.75, hdds.datanode.use.datanode.hostname=false, hdds.datanode.volume.choosing.policy=org.apache.hadoop.ozone.container.common.volume.CapacityVolumeChoosingPolicy, hdds.datanode.volume.min.free.space=100MB, hdds.datanode.volume.min.free.space.percent=0, hdds.db.profile=DISK, hdds.grpc.tls.enabled=true, hdds.grpc.tls.provider=OPENSSL, hdds.heartbeat.initial-interval=2s, hdds.heartbeat.interval=5s, hdds.heartbeat.recon.initial-interval=60s, hdds.heartbeat.recon.interval=60s, hdds.key.algo=RSA, hdds.key.dir.name=keys, hdds.key.len=2048, hdds.node.report.interval=60000ms, hdds.pipeline.action.max.limit=20, hdds.pipeline.report.interval=60000ms, hdds.priv.key.file.name=private.pem, hdds.profiler.endpoint.enabled=false, hdds.prometheus.endpoint.enabled=true, hdds.public.key.file.name=public.pem, hdds.ratis.client.exponential.backoff.base.sleep=4s, hdds.ratis.client.exponential.backoff.max.retries=2147483647, hdds.ratis.client.exponential.backoff.max.sleep=40s, hdds.ratis.client.multilinear.random.retry.policy=5s, 5, 10s, 5, 15s, 5, 20s, 5, 25s, 5, 60s, 10, hdds.ratis.client.request.watch.timeout=3m, hdds.ratis.client.request.watch.type=ALL_COMMITTED, hdds.ratis.client.request.write.timeout=5m, hdds.ratis.client.retry.policy=org.apache.hadoop.hdds.ratis.retrypolicy.RequestTypeDependentRetryPolicyCreator, hdds.ratis.client.retrylimited.max.retries=180, hdds.ratis.client.retrylimited.retry.interval=1s, hdds.ratis.leader.election.minimum.timeout.duration=5s, hdds.ratis.raft.client.async.outstanding-requests.max=32, hdds.ratis.raft.client.rpc.request.timeout=60s, hdds.ratis.raft.client.rpc.watch.request.timeout=180s, hdds.ratis.raft.grpc.flow.control.window=5MB, hdds.ratis.raft.server.datastream.client.pool.size=10, hdds.ratis.raft.server.datastream.request.threads=20, hdds.ratis.raft.server.delete.ratis.log.directory=true, hdds.ratis.raft.server.leaderelection.pre-vote=true, hdds.ratis.raft.server.log.appender.wait-time.min=0us, hdds.ratis.raft.server.notification.no-leader.timeout=300s, hdds.ratis.raft.server.rpc.request.timeout=60s, hdds.ratis.raft.server.rpc.slowness.timeout=300s, hdds.ratis.raft.server.watch.timeout=30s, hdds.ratis.raft.server.write.element-limit=1024, hdds.ratis.server.retry-cache.timeout.duration=600000ms, hdds.ratis.snapshot.threshold=100000, hdds.scm.block.deleting.service.interval=60s, hdds.scm.block.deletion.per-interval.max=500000, hdds.scm.block.deletion.txn.dn.commit.map.limit=5000000, hdds.scm.ec.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.scm.http.auth.kerberos.principal=HTTP/scm@EXAMPLE.COM, hdds.scm.http.auth.type=kerberos, hdds.scm.kerberos.keytab.file=/etc/security/keytabs/scm.keytab, hdds.scm.kerberos.principal=scm/scm@EXAMPLE.COM, hdds.scm.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.safemode.atleast.one.node.reported.pipeline.pct=0.90, hdds.scm.safemode.enabled=true, hdds.scm.safemode.healthy.pipeline.pct=0.10, hdds.scm.safemode.log.interval=1m, hdds.scm.safemode.min.datanode=3, hdds.scm.safemode.pipeline.creation=true, hdds.scm.safemode.threshold.pct=0.99, hdds.scm.unknown-container.action=WARN, hdds.scm.wait.time.after.safemode.exit=5m, hdds.scmclient.failover.max.retry=15, hdds.scmclient.failover.retry.interval=2s, hdds.scmclient.max.retry.timeout=30s, hdds.scmclient.rpc.timeout=15m, hdds.secret.key.algorithm=HmacSHA256, hdds.secret.key.expiry.duration=1h, hdds.secret.key.file.name=secret_keys.json, hdds.secret.key.rotate.check.duration=1m, hdds.secret.key.rotate.duration=5m, hdds.security.client.datanode.container.protocol.acl=*, hdds.security.client.datanode.disk.balancer.protocol.acl=*, hdds.security.client.scm.block.protocol.acl=*, hdds.security.client.scm.certificate.protocol.acl=*, hdds.security.client.scm.container.protocol.acl=*, hdds.security.client.scm.secretkey.datanode.protocol.acl=*, hdds.security.client.scm.secretkey.om.protocol.acl=*, hdds.security.client.scm.secretkey.scm.protocol.acl=*, hdds.security.provider=BC, hdds.tracing.enabled=false, hdds.x509.ca.rotation.ack.timeout=PT15M, hdds.x509.ca.rotation.check.interval=P1D, hdds.x509.ca.rotation.enabled=false, hdds.x509.ca.rotation.time-of-day=02:00:00, hdds.x509.default.duration=P365D, hdds.x509.dir.name=certs, hdds.x509.expired.certificate.check.interval=P1D, hdds.x509.file.name=certificate.crt, hdds.x509.max.duration=P1865D, hdds.x509.renew.grace.duration=P28D, hdds.x509.rootca.certificate.polling.interval=PT2h, hdds.x509.signature.algorithm=SHA256withRSA, hdds.xframe.enabled=true, hdds.xframe.value=SAMEORIGIN, ozone.UnsafeByteOperations.enabled=true, ozone.acl.authorizer.class=org.apache.ranger.authorization.ozone.authorizer.RangerOzoneAuthorizer, ozone.acl.enabled=true, ozone.administrators=testuser,recon,om,hdfs, ozone.block.deleting.service.interval=1m, ozone.block.deleting.service.timeout=300000ms, ozone.block.deleting.service.workers=10, ozone.chunk.read.buffer.default.size=1MB, ozone.chunk.read.mapped.buffer.max.count=0, ozone.chunk.read.mapped.buffer.threshold=32KB, ozone.client.bucket.replication.config.refresh.time.ms=30000, ozone.client.bytes.per.checksum=16KB, ozone.client.checksum.combine.mode=COMPOSITE_CRC, ozone.client.checksum.type=CRC32, ozone.client.connection.timeout=5000ms, ozone.client.datastream.buffer.flush.size=16MB, ozone.client.datastream.min.packet.size=1MB, ozone.client.datastream.pipeline.mode=true, ozone.client.datastream.sync.size=0B, ozone.client.datastream.window.size=64MB, ozone.client.ec.grpc.retries.enabled=true, ozone.client.ec.grpc.retries.max=3, ozone.client.ec.grpc.write.timeout=30s, ozone.client.ec.reconstruct.stripe.read.pool.limit=30, ozone.client.ec.reconstruct.stripe.write.pool.limit=30, ozone.client.ec.stripe.queue.size=2, ozone.client.elastic.byte.buffer.pool.max.size=16GB, ozone.client.exclude.nodes.expiry.time=600000, ozone.client.failover.max.attempts=500, ozone.client.fs.default.bucket.layout=FILE_SYSTEM_OPTIMIZED, ozone.client.hbase.enhancements.allowed=false, ozone.client.incremental.chunk.list=false, ozone.client.key.latest.version.location=true, ozone.client.key.provider.cache.expiry=10d, ozone.client.key.write.concurrency=1, ozone.client.list.cache=1000, ozone.client.max.ec.stripe.write.retries=10, ozone.client.max.retries=5, ozone.client.read.max.retries=3, ozone.client.read.retry.interval=1, ozone.client.read.timeout=30s, ozone.client.retry.interval=0, ozone.client.server-defaults.validity.period.ms=3600000, ozone.client.socket.timeout=5000ms, ozone.client.stream.buffer.flush.delay=true, ozone.client.stream.buffer.flush.size=16MB, ozone.client.stream.buffer.increment=0B, ozone.client.stream.buffer.max.size=32MB, ozone.client.stream.buffer.size=4MB, ozone.client.stream.putblock.piggybacking=false, ozone.client.stream.read.pre-read-size=33554432, ozone.client.stream.read.response-data-size=1048576, ozone.client.stream.read.timeout=10s, ozone.client.stream.readblock.enable=false, ozone.client.verify.checksum=true, ozone.client.wait.between.retries.millis=2000, ozone.container.cache.lock.stripes=1024, ozone.container.cache.size=1024, ozone.directory.deleting.service.interval=1m, ozone.filesystem.snapshot.enabled=true, ozone.freon.http-address=0.0.0.0:9884, ozone.freon.http-bind-host=0.0.0.0, ozone.freon.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.freon.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.freon.http.auth.type=simple, ozone.freon.http.enabled=true, ozone.freon.https-address=0.0.0.0:9885, ozone.freon.https-bind-host=0.0.0.0, ozone.fs.datastream.auto.threshold=4MB, ozone.fs.datastream.enabled=false, ozone.fs.hsync.enabled=false, ozone.fs.iterate.batch-size=100, ozone.fs.listing.page.size=1024, ozone.fs.listing.page.size.max=5000, ozone.handler.type=distributed, ozone.hbase.enhancements.allowed=false, ozone.http.basedir=/tmp/ozone_http, ozone.http.filter.initializers=org.apache.hadoop.security.AuthenticationFilterInitializer, ozone.http.policy=HTTP_ONLY, ozone.httpfs.http.auth.kerberos.keytab=/etc/security/keytabs/httpfs.keytab, ozone.httpfs.http.auth.kerberos.principal=HTTP/httpfs@EXAMPLE.COM, ozone.httpfs.http.auth.type=kerberos, ozone.httpfs.kerberos.keytab.file=/etc/security/keytabs/httpfs.keytab, ozone.httpfs.kerberos.principal=httpfs/httpfs@EXAMPLE.COM, ozone.https.client.keystore.resource=ssl-client.xml, ozone.https.client.need-auth=false, ozone.https.server.keystore.resource=ssl-server.xml, ozone.key.deleting.limit.per.task=50000, ozone.key.preallocation.max.blocks=64, ozone.manager.delegation.remover.scan.interval=1m, ozone.manager.delegation.token.max-lifetime=30m, ozone.manager.delegation.token.renew-interval=5m, ozone.metadata.dirs=/data/metadata, ozone.metadata.dirs.permissions=750, ozone.metastore.rocksdb.cf.write.buffer.size=128MB, ozone.metastore.rocksdb.statistics=OFF, ozone.network.flexible.fqdn.resolution.enabled=false, ozone.network.jvm.address.cache.enabled=true, ozone.network.topology.aware.read=true, ozone.om.address=0.0.0.0:9862, ozone.om.address.omservice.om1=om1, ozone.om.address.omservice.om2=om2, ozone.om.address.omservice.om3=om3, ozone.om.admin.protocol.max.retries=20, ozone.om.admin.protocol.wait.between.retries=1000, ozone.om.allow.leader.skip.linearizable.read=false, ozone.om.client.rpc.timeout=15m, ozone.om.client.trash.core.pool.size=5, ozone.om.compaction.service.columnfamilies=keyTable,fileTable,directoryTable,deletedTable,deletedDirectoryTable,multipartInfoTable, ozone.om.compaction.service.enabled=false, ozone.om.compaction.service.run.interval=6h, ozone.om.compaction.service.timeout=10m, ozone.om.container.location.cache.size=100000, ozone.om.container.location.cache.ttl=360m, ozone.om.db.dirs.permissions=750, ozone.om.db.max.open.files=-1, ozone.om.delta.update.data.size.max.limit=1024MB, ozone.om.edekcacheloader.initial.delay.ms=3000, ozone.om.edekcacheloader.interval.ms=1000, ozone.om.edekcacheloader.max-retries=10, ozone.om.enable.filesystem.paths=false, ozone.om.enable.ofs.shared.tmp.dir=false, ozone.om.follower.read.local.lease.enabled=false, ozone.om.follower.read.local.lease.lag.limit=10000, ozone.om.follower.read.local.lease.time.ms=5000, ozone.om.fs.snapshot.max.limit=10000, ozone.om.group.rights=READ, LIST, ozone.om.grpc.bossgroup.size=8, ozone.om.grpc.maximum.response.length=134217728, ozone.om.grpc.port=8981, ozone.om.grpc.read.thread.num=32, ozone.om.grpc.workergroup.size=32, ozone.om.ha.raft.server.log.appender.wait-time.min=0ms, ozone.om.ha.raft.server.read.leader.lease.enabled=false, ozone.om.ha.raft.server.read.option=DEFAULT, ozone.om.ha.raft.server.retrycache.expirytime=300s, ozone.om.handler.count.key=100, ozone.om.hierarchical.resource.locks.hard.limit=10000, ozone.om.hierarchical.resource.locks.soft.limit=1024, ozone.om.http-address=0.0.0.0:9874, ozone.om.http-address.omservice.om1=om1, ozone.om.http-address.omservice.om2=om2, ozone.om.http-address.omservice.om3=om3, ozone.om.http-bind-host=0.0.0.0, ozone.om.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.om.http.auth.kerberos.principal=HTTP/om@EXAMPLE.COM, ozone.om.http.auth.type=kerberos, ozone.om.http.enabled=true, ozone.om.https-address=0.0.0.0:9875, ozone.om.https-bind-host=0.0.0.0, ozone.om.internal.service.id=omservice, ozone.om.kerberos.keytab.file=/etc/security/keytabs/om.keytab, ozone.om.kerberos.principal=om/om@EXAMPLE.COM, ozone.om.kerberos.principal.pattern=*, ozone.om.key.path.lock.enabled=false, ozone.om.keyname.character.check.enabled=false, ozone.om.leader.election.minimum.timeout.duration=5s, ozone.om.lease.hard.limit=7d, ozone.om.lease.soft.limit=60s, ozone.om.lock.fair=false, ozone.om.max.buckets=100000, ozone.om.multitenancy.enabled=true, ozone.om.multitenancy.ranger.sync.interval=10m, ozone.om.multitenancy.ranger.sync.timeout=10s, ozone.om.namespace.s3.strict=true, ozone.om.network.topology.refresh.duration=1h, ozone.om.nodes.omservice=om1,om2,om3, ozone.om.object.creation.ignore.client.acls=false, ozone.om.open.key.cleanup.limit.per.task=1000, ozone.om.open.key.cleanup.service.interval=24h, ozone.om.open.key.cleanup.service.timeout=300s, ozone.om.open.key.expire.threshold=7d, ozone.om.open.mpu.cleanup.service.interval=24h, ozone.om.open.mpu.cleanup.service.timeout=300s, ozone.om.open.mpu.expire.threshold=30d, ozone.om.open.mpu.parts.cleanup.limit.per.task=1000, ozone.om.ranger.https-address=http://ranger:6080, ozone.om.ranger.https.admin.api.passwd=rangerR0cks!, ozone.om.ranger.https.admin.api.user=admin, ozone.om.ranger.service=dev_ozone, ozone.om.ratis.log.appender.queue.byte-limit=32MB, ozone.om.ratis.log.appender.queue.num-elements=1024, ozone.om.ratis.log.purge.gap=1000000, ozone.om.ratis.log.purge.preservation.log.num=0, ozone.om.ratis.log.purge.upto.snapshot.index=true, ozone.om.ratis.minimum.timeout=5s, ozone.om.ratis.port=9872, ozone.om.ratis.rpc.type=GRPC, ozone.om.ratis.segment.preallocated.size=4MB, ozone.om.ratis.segment.size=64MB, ozone.om.ratis.server.close.threshold=60s, ozone.om.ratis.server.failure.timeout.duration=120s, ozone.om.ratis.server.leaderelection.pre-vote=true, ozone.om.ratis.server.pending.write.element-limit=4096, ozone.om.ratis.server.request.timeout=3s, ozone.om.ratis.server.retry.cache.timeout=600000ms, ozone.om.ratis.snapshot.max.total.sst.size=100000000, ozone.om.read.threadpool=10, ozone.om.s3.grpc.server_enabled=true, ozone.om.save.metrics.interval=5m, ozone.om.security.admin.protocol.acl=*, ozone.om.security.client.protocol.acl=*, ozone.om.server.list.max.size=1000, ozone.om.service.ids=omservice, ozone.om.snapshot.cache.cleanup.service.run.interval=1m, ozone.om.snapshot.cache.max.size=10, ozone.om.snapshot.checkpoint.dir.creation.poll.timeout=20s, ozone.om.snapshot.compact.non.snapshot.diff.tables=false, ozone.om.snapshot.compaction.dag.max.time.allowed=30d, ozone.om.snapshot.compaction.dag.prune.daemon.run.interval=10m, ozone.om.snapshot.db.max.open.files=100, ozone.om.snapshot.diff.cleanup.service.run.interval=1m, ozone.om.snapshot.diff.cleanup.service.timeout=5m, ozone.om.snapshot.diff.disable.native.libs=false, ozone.om.snapshot.diff.job.default.wait.time=1m, ozone.om.snapshot.diff.job.report.persistent.time=7d, ozone.om.snapshot.diff.max.allowed.keys.changed.per.job=10000000, ozone.om.snapshot.diff.max.jobs.purge.per.task=100, ozone.om.snapshot.diff.max.page.size=1000, ozone.om.snapshot.diff.thread.pool.size=10, ozone.om.snapshot.force.full.diff=false, ozone.om.snapshot.load.native.lib=true, ozone.om.snapshot.local.data.manager.service.interval=5m, ozone.om.snapshot.provider.connection.timeout=5000s, ozone.om.snapshot.provider.request.timeout=300000ms, ozone.om.snapshot.provider.socket.timeout=5000s, ozone.om.snapshot.prune.compaction.backup.batch.size=2000, ozone.om.snapshot.rocksdb.metrics.enabled=false, ozone.om.tenant.dev.skip.ranger=false, ozone.om.transport.class=org.apache.hadoop.ozone.om.protocolPB.Hadoop3OmTransportFactory, ozone.om.unflushed.transaction.max.count=10000, ozone.om.upgrade.finalization.ratis.based.timeout=30s, ozone.om.upgrade.quota.recalculate.enabled=true, ozone.om.user.max.volume=1024, ozone.om.user.rights=ALL, ozone.om.volume.listall.allowed=false, ozone.path.deleting.limit.per.task=20000, ozone.recon.address=recon:9891, ozone.recon.containerkey.flush.db.max.threshold=150000, ozone.recon.db.dir=/data/metadata/recon, ozone.recon.db.dirs.permissions=750, ozone.recon.dn.metrics.collection.minimum.api.delay=30s, ozone.recon.dn.metrics.collection.timeout=10m, ozone.recon.filesizecount.flush.db.max.threshold=200000, ozone.recon.heatmap.enable=false, ozone.recon.http-address=0.0.0.0:9888, ozone.recon.http-bind-host=0.0.0.0, ozone.recon.http.auth.kerberos.keytab=/etc/security/keytabs/recon.keytab, ozone.recon.http.auth.kerberos.principal=HTTP/recon@EXAMPLE.COM, ozone.recon.http.auth.type=kerberos, ozone.recon.http.enabled=true, ozone.recon.https-address=0.0.0.0:9889, ozone.recon.https-bind-host=0.0.0.0, ozone.recon.kerberos.keytab.file=/etc/security/keytabs/recon.keytab, ozone.recon.kerberos.principal=recon/recon@EXAMPLE.COM, ozone.recon.nssummary.flush.db.max.threshold=150000, ozone.recon.om.connection.request.timeout=5000, ozone.recon.om.connection.timeout=5s, ozone.recon.om.event.buffer.capacity=20000, ozone.recon.om.snapshot.task.flush.param=false, ozone.recon.om.snapshot.task.initial.delay=20s, ozone.recon.om.snapshot.task.interval.delay=1m, ozone.recon.om.socket.timeout=5s, ozone.recon.scm.connection.request.timeout=5s, ozone.recon.scm.connection.timeout=5s, ozone.recon.scm.container.threshold=100, ozone.recon.scm.snapshot.enabled=true, ozone.recon.scm.snapshot.task.initial.delay=1m, ozone.recon.scm.snapshot.task.interval.delay=24h, ozone.recon.scmclient.failover.max.retry=3, ozone.recon.scmclient.max.retry.timeout=6s, ozone.recon.scmclient.rpc.timeout=1m, ozone.recon.security.client.datanode.container.protocol.acl=*, ozone.recon.task.reprocess.max.iterators=5, ozone.recon.task.reprocess.max.keys.in.memory=2000, ozone.recon.task.reprocess.max.workers=20, ozone.recon.task.thread.count=1, ozone.replication.allowed-configs=^((STANDALONE|RATIS)/(ONE|THREE))|(EC/(3-2|6-3|10-4)-(512|1024|2048|4096)k)$, ozone.rest.client.http.connection.max=100, ozone.rest.client.http.connection.per-route.max=20, ozone.s3.administrators=testuser,s3g, ozone.s3g.client.buffer.size=4MB, ozone.s3g.default.bucket.layout=OBJECT_STORE, ozone.s3g.http-address=0.0.0.0:9878, ozone.s3g.http-bind-host=0.0.0.0, ozone.s3g.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.s3g.http.auth.kerberos.principal=HTTP/s3g@EXAMPLE.COM, ozone.s3g.http.auth.type=kerberos, ozone.s3g.http.enabled=true, ozone.s3g.https-address=0.0.0.0:9879, ozone.s3g.kerberos.keytab.file=/etc/security/keytabs/s3g.keytab, ozone.s3g.kerberos.principal=s3g/s3g@EXAMPLE.COM, ozone.s3g.list-keys.shallow.enabled=true, ozone.s3g.list.max.keys.limit=1000, ozone.s3g.metrics.percentiles.intervals.seconds=60, ozone.s3g.secret.http.auth.type=kerberos, ozone.s3g.secret.http.enabled=true, ozone.s3g.volume.name=s3v, ozone.s3g.webadmin.http-address=0.0.0.0:19878, ozone.s3g.webadmin.http-bind-host=0.0.0.0, ozone.s3g.webadmin.http.enabled=true, ozone.s3g.webadmin.https-address=0.0.0.0:19879, ozone.scm.address.scmservice.scm1=scm1.org, ozone.scm.address.scmservice.scm2=scm2.org, ozone.scm.address.scmservice.scm3=scm3.org, ozone.scm.block.client.address=scm, ozone.scm.block.client.bind.host=0.0.0.0, ozone.scm.block.client.port=9863, ozone.scm.block.deletion.per.dn.distribution.factor=8, ozone.scm.block.handler.count.key=100, ozone.scm.block.read.threadpool=10, ozone.scm.block.size=256MB, ozone.scm.ca.list.retry.interval=10s, ozone.scm.chunk.size=4MB, ozone.scm.client.address=scm, ozone.scm.client.bind.host=0.0.0.0, ozone.scm.client.handler.count.key=100, ozone.scm.client.port=9860, ozone.scm.client.read.threadpool=10, ozone.scm.close.container.wait.duration=5s, ozone.scm.container.layout=FILE_PER_BLOCK, ozone.scm.container.list.max.count=4096, ozone.scm.container.lock.stripes=512, ozone.scm.container.placement.ec.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter, ozone.scm.container.placement.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware, ozone.scm.container.size=1GB, ozone.scm.datanode.admin.monitor.interval=30s, ozone.scm.datanode.admin.monitor.logging.limit=1000, ozone.scm.datanode.disallow.same.peers=false, ozone.scm.datanode.handler.count.key=100, ozone.scm.datanode.id.dir=/data/metadata, ozone.scm.datanode.pipeline.limit=2, ozone.scm.datanode.port=9861, ozone.scm.datanode.ratis.volume.free-space.min=10MB, ozone.scm.datanode.read.threadpool=10, ozone.scm.db.dirs.permissions=750, ozone.scm.dead.node.interval=10m, ozone.scm.ec.pipeline.minimum=1, ozone.scm.event.ContainerReport.thread.pool.size=10, ozone.scm.expired.container.replica.op.scrub.interval=5m, ozone.scm.grpc.port=9895, ozone.scm.ha.dbtransactionbuffer.flush.interval=60s, ozone.scm.ha.grpc.deadline.interval=30m, ozone.scm.ha.raft.server.log.appender.wait-time.min=0ms, ozone.scm.ha.ratis.leader.election.timeout=5s, ozone.scm.ha.ratis.leader.ready.check.interval=2s, ozone.scm.ha.ratis.leader.ready.wait.timeout=60s, ozone.scm.ha.ratis.log.appender.queue.byte-limit=32MB, ozone.scm.ha.ratis.log.appender.queue.num-elements=1024, ozone.scm.ha.ratis.log.purge.enabled=false, ozone.scm.ha.ratis.log.purge.gap=1000000, ozone.scm.ha.ratis.request.timeout=30s, ozone.scm.ha.ratis.rpc.type=GRPC, ozone.scm.ha.ratis.segment.preallocated.size=4MB, ozone.scm.ha.ratis.segment.size=64MB, ozone.scm.ha.ratis.server.failure.timeout.duration=120s, ozone.scm.ha.ratis.server.leaderelection.pre-vote=true, ozone.scm.ha.ratis.server.retry.cache.timeout=60s, ozone.scm.ha.ratis.server.snapshot.creation.gap=1024, ozone.scm.ha.ratis.snapshot.threshold=1000, ozone.scm.handler.count.key=100, ozone.scm.heartbeat.log.warn.interval.count=10, ozone.scm.heartbeat.rpc-retry-count=15, ozone.scm.heartbeat.rpc-retry-interval=1s, ozone.scm.heartbeat.rpc-timeout=5s, ozone.scm.heartbeat.thread.interval=3s, ozone.scm.http-address=0.0.0.0:9876, ozone.scm.http-bind-host=0.0.0.0, ozone.scm.http.enabled=true, ozone.scm.https-address=0.0.0.0:9877, ozone.scm.https-bind-host=0.0.0.0, ozone.scm.info.wait.duration=10m, ozone.scm.keyvalue.container.deletion-choosing.policy=org.apache.hadoop.ozone.container.common.impl.TopNOrderedContainerDeletionChoosingPolicy, ozone.scm.network.topology.schema.file=network-topology-default.xml, ozone.scm.nodes.scmservice=scm1,scm2,scm3, ozone.scm.pipeline.allocated.timeout=5m, ozone.scm.pipeline.creation.auto.factor.one=true, ozone.scm.pipeline.creation.interval=30s, ozone.scm.pipeline.destroy.timeout=66s, ozone.scm.pipeline.leader-choose.policy=org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy, ozone.scm.pipeline.owner.container.count=1, ozone.scm.pipeline.per.metadata.disk=2, ozone.scm.pipeline.scrub.interval=5m, ozone.scm.primordial.node.id=scm1, ozone.scm.ratis.pipeline.limit=0, ozone.scm.ratis.port=9894, ozone.scm.security.handler.count.key=2, ozone.scm.security.read.threadpool=1, ozone.scm.security.service.bind.host=0.0.0.0, ozone.scm.security.service.port=9961, ozone.scm.sequence.id.batch.size=1000, ozone.scm.service.ids=scmservice, ozone.scm.skip.bootstrap.validation=false, ozone.scm.stale.node.interval=30s, ozone.security.crypto.compliance.mode=unrestricted, ozone.security.enabled=true, ozone.security.http.kerberos.enabled=true, ozone.security.reconfigure.protocol.acl=*, ozone.server.default.replication=3, ozone.server.default.replication.type=RATIS, ozone.service.shutdown.timeout=60s, ozone.snapshot.deep.cleaning.enabled=false, ozone.snapshot.defrag.limit.per.task=1, ozone.snapshot.defrag.service.interval=-1, ozone.snapshot.defrag.service.timeout=300s, ozone.snapshot.deleting.limit.per.task=10, ozone.snapshot.deleting.service.interval=30s, ozone.snapshot.deleting.service.timeout=300s, ozone.snapshot.directory.service.interval=24h, ozone.snapshot.directory.service.timeout=300s, ozone.snapshot.filtering.limit.per.task=2, ozone.snapshot.filtering.service.interval=1m, ozone.snapshot.key.deleting.limit.per.task=20000, ozone.sst.filtering.service.timeout=300000ms, ozone.volume.io.percentiles.intervals.seconds=60, ozone.xceiver.client.metrics.percentiles.intervals.seconds=60, recon.om.delta.update.lag.threshold=0, recon.om.delta.update.limit=50000, scm.container.client.idle.threshold=10s, scm.container.client.max.size=256}
************************************************************/
2026-01-15 05:54:24,419 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [SIGHUP, SIGINT, SIGTERM]
2026-01-15 05:54:26,124 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
2026-01-15 05:54:26,198 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMSystemAudit to [].
2026-01-15 05:54:26,496 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is omservice
2026-01-15 05:54:26,739 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: omservice, OMNodeId: om1, RPC Address: om1:9862 ,Ratis port: 9872 and isListener: false
2026-01-15 05:54:26,741 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.omservice.om1: om1
2026-01-15 05:54:26,742 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.omservice.om1: om1
2026-01-15 05:54:29,820 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
2026-01-15 05:54:29,820 [main] INFO om.OzoneManager: Ozone Manager login successful.
2026-01-15 05:54:29,829 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2026-01-15 05:54:30,152 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created fail-over proxy for protocol ScmBlockLocationProtocolPB with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-da209e7d-fe26-447b-88f4-e66ed4e4719a;layoutVersion=9
2026-01-15 05:54:30,851 [main] INFO om.OzoneManager: OM storage initialized. Initializing security
2026-01-15 05:54:30,851 [main] INFO om.OzoneManager: Initializing secure OzoneManager.
2026-01-15 05:54:31,012 [main] INFO om.OzoneManager: OzoneManager ports added:[name: "RPC"
value: 9862
]
2026-01-15 05:54:31,029 [main] INFO proxy.SCMSecurityProtocolFailoverProxyProvider: Created fail-over proxy for protocol SCMSecurityProtocolPB with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9961, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9961, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9961]
2026-01-15 05:54:31,080 [main] INFO security.OMCertificateClient: Certificate serial ID set to null
2026-01-15 05:54:31,080 [main] ERROR security.OMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
2026-01-15 05:54:31,081 [main] INFO security.OMCertificateClient: Certificate client init case: 0
2026-01-15 05:54:31,082 [main] INFO security.OMCertificateClient: Creating keypair for client as keypair and certificate not found.
2026-01-15 05:54:32,693 [main] INFO keys.KeyStorage: Storing public key to /data/metadata/om/keys/public.pem.
2026-01-15 05:54:32,703 [main] INFO keys.KeyStorage: Storing private key to /data/metadata/om/keys/private.pem.
2026-01-15 05:54:32,709 [main] INFO security.OMCertificateClient: Init response: GETCERT
2026-01-15 05:54:32,747 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.111,host:om1
2026-01-15 05:54:32,748 [main] INFO ozone.OzoneSecurityUtil: ip:0:0:0:0:0:0:0:1%lo not returned.
2026-01-15 05:54:32,748 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
2026-01-15 05:54:32,792 [main] ERROR utils.CertificateSignRequest: Invalid domain om1
2026-01-15 05:54:32,793 [main] INFO security.OMCertificateClient: Creating csr for OM->dns:om1,ip:172.25.0.111,scmId:08fda86b-ea1f-495c-a0b1-387cb09709b7,clusterId:CID-da209e7d-fe26-447b-88f4-e66ed4e4719a,subject:om1
2026-01-15 05:54:33,347 [main] INFO utils.CertificateCodec: Save certificate to /data/metadata/om/certs/9.crt
2026-01-15 05:54:33,348 [main] INFO utils.CertificateCodec: Certificate -----BEGIN CERTIFICATE-----
MIIDpDCCAoygAwIBAgIBCTANBgkqhkiG9w0BAQsFADCBiTEZMBcGA1UEAwwQc2Nt
LXN1YkBzY20xLm9yZzEtMCsGA1UECwwkMDhmZGE4NmItZWExZi00OTVjLWEwYjEt
Mzg3Y2IwOTcwOWI3MTEwLwYDVQQKDChDSUQtZGEyMDllN2QtZmUyNi00NDdiLTg4
ZjQtZTY2ZWQ0ZTQ3MTlhMQowCAYDVQQFEwEyMB4XDTI2MDExNTA1NTQzM1oXDTI3
MDExNTA1NTQzM1owfDEMMAoGA1UEAwwDb20xMS0wKwYDVQQLDCQwOGZkYTg2Yi1l
YTFmLTQ5NWMtYTBiMS0zODdjYjA5NzA5YjcxMTAvBgNVBAoMKENJRC1kYTIwOWU3
ZC1mZTI2LTQ0N2ItODhmNC1lNjZlZDRlNDcxOWExCjAIBgNVBAUTATkwggEiMA0G
CSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCWMwL0NjgvGKkiAN8NvgtgsYBiQL9o
PUAQAL8IB7U2J2uwb9qhHzBwpsTC5W5PepNQBWBPuSXMjH9yTrTUbWthIEoiSeQm
kmaf7A+FkNMeQ34qdAKC9LdZQ5DGdiy0YPGig80J6PUBuF2Aksb2C2u8N3tZ45+1
UEUeoIXd4rmORAtfY5b/BiPYQqO+cldp3R4fmxn63Jnbf8qVmQd4UtuhAFElwvvk
40VhZrE05ciPWoxp6nHEKijpRUhjazzWMgdSrRcIcHLbRaynmVv4pLF4JRqg+jT2
qrtO82ml/iWRjWvJjhPFwpV8gNcRtV2h06zWcRjUfmKxmzATMomJyCY/AgMBAAGj
IzAhMA4GA1UdDwEB/wQEAwIDuDAPBgNVHREECDAGhwSsGQBvMA0GCSqGSIb3DQEB
CwUAA4IBAQCEADucNzEeOzwhuGPpwDOEQYPfCn5R/07eO9VLSi9Y7GW65nUjm2Ej
CmvDNF0/PLmR9SJNuWmXFXMnM/JviFGFrmaxeeU0ahP7c2w9CoL0iUXxamDefCoP
mYLfEjTNO5KBbeWFOSCriQqyyXejpB39ndsuA3cwslSfD8ZWbxddBpQpJBC1gLhe
WCorwMeuFl1Avbvpdnsm0Hdk3W419zK1c5W9t3tF41eZoEGv1yxT+khF/SS72daJ
7AKhiwVcZKOeph+NqsydhVfLHcCWRetkE8n2HzjDCyJ5QskKTAWgyQ5Oc7gcwVU4
ZLCu8QTHbjldSgZy7wo/lkWJdUTUYCZ7
-----END CERTIFICATE-----

-----BEGIN CERTIFICATE-----
MIIDyTCCArGgAwIBAgIBAjANBgkqhkiG9w0BAQsFADCBhTEVMBMGA1UEAwwMc2Nt
QHNjbTEub3JnMS0wKwYDVQQLDCQwOGZkYTg2Yi1lYTFmLTQ5NWMtYTBiMS0zODdj
YjA5NzA5YjcxMTAvBgNVBAoMKENJRC1kYTIwOWU3ZC1mZTI2LTQ0N2ItODhmNC1l
NjZlZDRlNDcxOWExCjAIBgNVBAUTATEwHhcNMjYwMTE1MDU1MzA1WhcNMzEwMjIz
MDU1MzA1WjCBiTEZMBcGA1UEAwwQc2NtLXN1YkBzY20xLm9yZzEtMCsGA1UECwwk
MDhmZGE4NmItZWExZi00OTVjLWEwYjEtMzg3Y2IwOTcwOWI3MTEwLwYDVQQKDChD
SUQtZGEyMDllN2QtZmUyNi00NDdiLTg4ZjQtZTY2ZWQ0ZTQ3MTlhMQowCAYDVQQF
EwEyMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAposfEZYM8p5AKVYg
2/DBP2Rt71/6ULoQ+tcmwSHLAHNg3gmqDFLqBVRN+wrNwYG1Mj4/bJV6wJiGsvv9
yMwD83nWe0nELrGfB5pI+Ggxvv2CRPCPbBV+rSwNVpa+PUhoNS4I7kPG6SFplNmR
4eN5QeJi37TcRovf41c8yo0KEtO1XA69sBuwJTF9ZHOo1XPJpm/OuO6KReqXqLPL
xdToydjQocWK936wTBbzxnMbhd/18DDSA/Tsw5xGilWU4HilsOH8EGqfZ1Bybevh
lsheP2Q8nUI4a25q4lWVw931A7ZHmdBbINC6fcYfw3k+Mavte9rm2TctNyfxkbXx
e1BczwIDAQABoz4wPDAOBgNVHQ8BAf8EBAMCAb4wGQYDVR0RBBIwEIcErBkAdIII
c2NtMS5vcmcwDwYDVR0TAQH/BAUwAwEB/zANBgkqhkiG9w0BAQsFAAOCAQEAWOPy
1SfRgBvGcI/9zsSMcm/5tY5dHZqpDiUTX4idaB8IZE4NTIdJs1jr87Uzo8KHf6uy
/lbCpdXAnFg57uiEz7PcMTMCvi1JSdhh2TLYFDDcnfziD79eJRUAkGJi2Xtqr2hW
7DqB6pO/1REYs0xmBJcQySnPb5uWDlVxO7SXKD0FnteapQTRpZYGVfuhYPt8BFDv
3szzMMbftvv3BlKQ/xuC1IqVSoTlVwYT/CXdSewBBJModQvYzrc5TM60nIgE+LdX
/qk9VDtE1EaITQZXfFPHI4aipoLJyjsuQ98mkfk2YkAQWTEwDjohiHBHy3VmezUX
CesVe4OreLmZbKstew==
-----END CERTIFICATE-----

-----BEGIN CERTIFICATE-----
MIIDxTCCAq2gAwIBAgIBATANBgkqhkiG9w0BAQsFADCBhTEVMBMGA1UEAwwMc2Nt
QHNjbTEub3JnMS0wKwYDVQQLDCQwOGZkYTg2Yi1lYTFmLTQ5NWMtYTBiMS0zODdj
YjA5NzA5YjcxMTAvBgNVBAoMKENJRC1kYTIwOWU3ZC1mZTI2LTQ0N2ItODhmNC1l
NjZlZDRlNDcxOWExCjAIBgNVBAUTATEwHhcNMjYwMTE1MDU1MzA0WhcNMzEwMjIz
MDU1MzA0WjCBhTEVMBMGA1UEAwwMc2NtQHNjbTEub3JnMS0wKwYDVQQLDCQwOGZk
YTg2Yi1lYTFmLTQ5NWMtYTBiMS0zODdjYjA5NzA5YjcxMTAvBgNVBAoMKENJRC1k
YTIwOWU3ZC1mZTI2LTQ0N2ItODhmNC1lNjZlZDRlNDcxOWExCjAIBgNVBAUTATEw
ggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCpfpNQJIDnPl8kpkwQJTNp
tBZhDkI9gCc4l/OocLTYKhoAwUSB0qmCEnr3l8psGmD9Vgx0vcvxqpxv86wRTadS
WUGf4sGhLu2sz3i1CBaB+pg/RZz5qNs96h9p21k8HmjUCYfHuYpYQodlhMOATPYy
IFvbyiC+H88ho34grt06vFBPaighKq5bAGgPyvkjstQMdwYhbfSJhPc7rK4fkKnL
tvwy5BCcg2E5vxHsJ0SztczLUfn0zb9Ct9cBhuFMtCD83UcHv7c1Rh0KsH26alc0
Jp2jlFbXZYXHdy1fUONGLuZbvLVpXeQw4BuCtACnsLuZe1TlE/TmYlGQ2hS5Ku7V
AgMBAAGjPjA8MA8GA1UdEwEB/wQFMAMBAf8wDgYDVR0PAQH/BAQDAgEGMBkGA1Ud
EQQSMBCHBKwZAHSCCHNjbTEub3JnMA0GCSqGSIb3DQEBCwUAA4IBAQA2tmdn1JkR
XjmJ2mOg3vG68iZLOi9JEGXmvlOLWnfj/1nxIhfuQLxKN6HXgb1rkc2T0n8XGvol
srukj0C8pnohbr4lkG2gcP+Cipzq+nYiTKusLU0agrEN6r28eUttJaSEhYPQ07Rm
AQzm/ccPJ8BgJu5/w4JTK9xp/fgxISG6EAfB059dPJQuaHVEomkE+OLljZVwy0v7
QEaVvMD69aD6SZPa0EgOyYoa3eDomnIFiK6GrRsoe+KubSTIRv8gFzX3FKOZF8qZ
ULYiWm6W7Xhrg8L1552HPd3tPTBSdoWdYwJ18NOdThgiy3wYRaKLuBoApAMlFmef
KgVYZsQMjGOV
-----END CERTIFICATE-----

2026-01-15 05:54:33,355 [main] INFO utils.CertificateCodec: Save certificate to /data/metadata/om/certs/CA-2.crt
2026-01-15 05:54:33,355 [main] INFO utils.CertificateCodec: Certificate -----BEGIN CERTIFICATE-----
MIIDyTCCArGgAwIBAgIBAjANBgkqhkiG9w0BAQsFADCBhTEVMBMGA1UEAwwMc2Nt
QHNjbTEub3JnMS0wKwYDVQQLDCQwOGZkYTg2Yi1lYTFmLTQ5NWMtYTBiMS0zODdj
YjA5NzA5YjcxMTAvBgNVBAoMKENJRC1kYTIwOWU3ZC1mZTI2LTQ0N2ItODhmNC1l
NjZlZDRlNDcxOWExCjAIBgNVBAUTATEwHhcNMjYwMTE1MDU1MzA1WhcNMzEwMjIz
MDU1MzA1WjCBiTEZMBcGA1UEAwwQc2NtLXN1YkBzY20xLm9yZzEtMCsGA1UECwwk
MDhmZGE4NmItZWExZi00OTVjLWEwYjEtMzg3Y2IwOTcwOWI3MTEwLwYDVQQKDChD
SUQtZGEyMDllN2QtZmUyNi00NDdiLTg4ZjQtZTY2ZWQ0ZTQ3MTlhMQowCAYDVQQF
EwEyMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAposfEZYM8p5AKVYg
2/DBP2Rt71/6ULoQ+tcmwSHLAHNg3gmqDFLqBVRN+wrNwYG1Mj4/bJV6wJiGsvv9
yMwD83nWe0nELrGfB5pI+Ggxvv2CRPCPbBV+rSwNVpa+PUhoNS4I7kPG6SFplNmR
4eN5QeJi37TcRovf41c8yo0KEtO1XA69sBuwJTF9ZHOo1XPJpm/OuO6KReqXqLPL
xdToydjQocWK936wTBbzxnMbhd/18DDSA/Tsw5xGilWU4HilsOH8EGqfZ1Bybevh
lsheP2Q8nUI4a25q4lWVw931A7ZHmdBbINC6fcYfw3k+Mavte9rm2TctNyfxkbXx
e1BczwIDAQABoz4wPDAOBgNVHQ8BAf8EBAMCAb4wGQYDVR0RBBIwEIcErBkAdIII
c2NtMS5vcmcwDwYDVR0TAQH/BAUwAwEB/zANBgkqhkiG9w0BAQsFAAOCAQEAWOPy
1SfRgBvGcI/9zsSMcm/5tY5dHZqpDiUTX4idaB8IZE4NTIdJs1jr87Uzo8KHf6uy
/lbCpdXAnFg57uiEz7PcMTMCvi1JSdhh2TLYFDDcnfziD79eJRUAkGJi2Xtqr2hW
7DqB6pO/1REYs0xmBJcQySnPb5uWDlVxO7SXKD0FnteapQTRpZYGVfuhYPt8BFDv
3szzMMbftvv3BlKQ/xuC1IqVSoTlVwYT/CXdSewBBJModQvYzrc5TM60nIgE+LdX
/qk9VDtE1EaITQZXfFPHI4aipoLJyjsuQ98mkfk2YkAQWTEwDjohiHBHy3VmezUX
CesVe4OreLmZbKstew==
-----END CERTIFICATE-----

-----BEGIN CERTIFICATE-----
MIIDxTCCAq2gAwIBAgIBATANBgkqhkiG9w0BAQsFADCBhTEVMBMGA1UEAwwMc2Nt
QHNjbTEub3JnMS0wKwYDVQQLDCQwOGZkYTg2Yi1lYTFmLTQ5NWMtYTBiMS0zODdj
YjA5NzA5YjcxMTAvBgNVBAoMKENJRC1kYTIwOWU3ZC1mZTI2LTQ0N2ItODhmNC1l
NjZlZDRlNDcxOWExCjAIBgNVBAUTATEwHhcNMjYwMTE1MDU1MzA0WhcNMzEwMjIz
MDU1MzA0WjCBhTEVMBMGA1UEAwwMc2NtQHNjbTEub3JnMS0wKwYDVQQLDCQwOGZk
YTg2Yi1lYTFmLTQ5NWMtYTBiMS0zODdjYjA5NzA5YjcxMTAvBgNVBAoMKENJRC1k
YTIwOWU3ZC1mZTI2LTQ0N2ItODhmNC1lNjZlZDRlNDcxOWExCjAIBgNVBAUTATEw
ggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCpfpNQJIDnPl8kpkwQJTNp
tBZhDkI9gCc4l/OocLTYKhoAwUSB0qmCEnr3l8psGmD9Vgx0vcvxqpxv86wRTadS
WUGf4sGhLu2sz3i1CBaB+pg/RZz5qNs96h9p21k8HmjUCYfHuYpYQodlhMOATPYy
IFvbyiC+H88ho34grt06vFBPaighKq5bAGgPyvkjstQMdwYhbfSJhPc7rK4fkKnL
tvwy5BCcg2E5vxHsJ0SztczLUfn0zb9Ct9cBhuFMtCD83UcHv7c1Rh0KsH26alc0
Jp2jlFbXZYXHdy1fUONGLuZbvLVpXeQw4BuCtACnsLuZe1TlE/TmYlGQ2hS5Ku7V
AgMBAAGjPjA8MA8GA1UdEwEB/wQFMAMBAf8wDgYDVR0PAQH/BAQDAgEGMBkGA1Ud
EQQSMBCHBKwZAHSCCHNjbTEub3JnMA0GCSqGSIb3DQEBCwUAA4IBAQA2tmdn1JkR
XjmJ2mOg3vG68iZLOi9JEGXmvlOLWnfj/1nxIhfuQLxKN6HXgb1rkc2T0n8XGvol
srukj0C8pnohbr4lkG2gcP+Cipzq+nYiTKusLU0agrEN6r28eUttJaSEhYPQ07Rm
AQzm/ccPJ8BgJu5/w4JTK9xp/fgxISG6EAfB059dPJQuaHVEomkE+OLljZVwy0v7
QEaVvMD69aD6SZPa0EgOyYoa3eDomnIFiK6GrRsoe+KubSTIRv8gFzX3FKOZF8qZ
ULYiWm6W7Xhrg8L1552HPd3tPTBSdoWdYwJ18NOdThgiy3wYRaKLuBoApAMlFmef
KgVYZsQMjGOV
-----END CERTIFICATE-----

2026-01-15 05:54:33,372 [main] INFO utils.CertificateCodec: Save certificate to /data/metadata/om/certs/ROOTCA-1.crt
2026-01-15 05:54:33,373 [main] INFO utils.CertificateCodec: Certificate -----BEGIN CERTIFICATE-----
MIIDxTCCAq2gAwIBAgIBATANBgkqhkiG9w0BAQsFADCBhTEVMBMGA1UEAwwMc2Nt
QHNjbTEub3JnMS0wKwYDVQQLDCQwOGZkYTg2Yi1lYTFmLTQ5NWMtYTBiMS0zODdj
YjA5NzA5YjcxMTAvBgNVBAoMKENJRC1kYTIwOWU3ZC1mZTI2LTQ0N2ItODhmNC1l
NjZlZDRlNDcxOWExCjAIBgNVBAUTATEwHhcNMjYwMTE1MDU1MzA0WhcNMzEwMjIz
MDU1MzA0WjCBhTEVMBMGA1UEAwwMc2NtQHNjbTEub3JnMS0wKwYDVQQLDCQwOGZk
YTg2Yi1lYTFmLTQ5NWMtYTBiMS0zODdjYjA5NzA5YjcxMTAvBgNVBAoMKENJRC1k
YTIwOWU3ZC1mZTI2LTQ0N2ItODhmNC1lNjZlZDRlNDcxOWExCjAIBgNVBAUTATEw
ggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCpfpNQJIDnPl8kpkwQJTNp
tBZhDkI9gCc4l/OocLTYKhoAwUSB0qmCEnr3l8psGmD9Vgx0vcvxqpxv86wRTadS
WUGf4sGhLu2sz3i1CBaB+pg/RZz5qNs96h9p21k8HmjUCYfHuYpYQodlhMOATPYy
IFvbyiC+H88ho34grt06vFBPaighKq5bAGgPyvkjstQMdwYhbfSJhPc7rK4fkKnL
tvwy5BCcg2E5vxHsJ0SztczLUfn0zb9Ct9cBhuFMtCD83UcHv7c1Rh0KsH26alc0
Jp2jlFbXZYXHdy1fUONGLuZbvLVpXeQw4BuCtACnsLuZe1TlE/TmYlGQ2hS5Ku7V
AgMBAAGjPjA8MA8GA1UdEwEB/wQFMAMBAf8wDgYDVR0PAQH/BAQDAgEGMBkGA1Ud
EQQSMBCHBKwZAHSCCHNjbTEub3JnMA0GCSqGSIb3DQEBCwUAA4IBAQA2tmdn1JkR
XjmJ2mOg3vG68iZLOi9JEGXmvlOLWnfj/1nxIhfuQLxKN6HXgb1rkc2T0n8XGvol
srukj0C8pnohbr4lkG2gcP+Cipzq+nYiTKusLU0agrEN6r28eUttJaSEhYPQ07Rm
AQzm/ccPJ8BgJu5/w4JTK9xp/fgxISG6EAfB059dPJQuaHVEomkE+OLljZVwy0v7
QEaVvMD69aD6SZPa0EgOyYoa3eDomnIFiK6GrRsoe+KubSTIRv8gFzX3FKOZF8qZ
ULYiWm6W7Xhrg8L1552HPd3tPTBSdoWdYwJ18NOdThgiy3wYRaKLuBoApAMlFmef
KgVYZsQMjGOV
-----END CERTIFICATE-----

2026-01-15 05:54:33,377 [main] INFO security.OMCertificateClient: Certificate serial ID set to 9
2026-01-15 05:54:33,387 [main] INFO security.OMCertificateClient: Added certificate 1 from file: /data/metadata/om/certs/ROOTCA-1.crt.
2026-01-15 05:54:33,399 [main] INFO security.OMCertificateClient: Added certificate 9 from file: /data/metadata/om/certs/9.crt.
2026-01-15 05:54:33,408 [main] INFO security.OMCertificateClient: Added certificate 2 from file: /data/metadata/om/certs/CA-2.crt.
2026-01-15 05:54:33,418 [main] INFO security.OMCertificateClient: CertificateRenewerService for om is started with first delay 29116799585 ms and interval 86400000 ms.
2026-01-15 05:54:33,419 [main] INFO security.OMCertificateClient: Successfully stored OM signed certificate, case:GETCERT.
2026-01-15 05:54:33,431 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down OzoneManager at om1/172.25.0.111
************************************************************/
Custom user and group is available, using custom user and group.
+ Thu Jan 15 05:54:33 UTC 2026 : ozone: lib folder=/opt/ozone/lib conf folder=/opt/ozone/conf
+ Thu Jan 15 05:54:33 UTC 2026 : Saving current config file: /opt/ozone/conf/ranger-ozone-audit.xml to /opt/ozone/conf/.ranger-ozone-audit.xml.20260115-055433 ...
+ Thu Jan 15 05:54:34 UTC 2026 : Saving current config file: /opt/ozone/conf/ranger-ozone-security.xml to /opt/ozone/conf/.ranger-ozone-security.xml.20260115-055433 ...
+ Thu Jan 15 05:54:35 UTC 2026 : Saving current config file: /opt/ozone/conf/ranger-policymgr-ssl.xml to /opt/ozone/conf/.ranger-policymgr-ssl.xml.20260115-055433 ...
+ Thu Jan 15 05:54:37 UTC 2026 : Saving current JCE file: /etc/ranger/dev_ozone/cred.jceks to /etc/ranger/dev_ozone/.cred.jceks.20260115055437 ...
Ranger Plugin for ozone has been enabled. Please restart ozone to ensure that changes are effective.
No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8' to the OZONE_OPTS
Ozone Manager classpath extended by /opt/ranger/ozone-plugin/lib/libext/*:/opt/ozone/conf
2026-01-15 05:54:42,499 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting OzoneManager
STARTUP_MSG:        host = om1/172.25.0.111
STARTUP_MSG:     version = 2.2.0-SNAPSHOT
STARTUP_MSG:       build = https://github.com/apache/ozone/cd2e68c502e7271e18e87a3fdd104a8bd89109ca
STARTUP_MSG:        java = 21.0.2
STARTUP_MSG:        args = []
STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/jackson-annotations-2.16.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.16.2.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.16.2.jar:/opt/hadoop/share/ozone/lib/guava-33.5.0-jre.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.3.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jspecify-1.0.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.29.2.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-3.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-3.25.8.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.18.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.18.0.jar:/opt/hadoop/share/ozone/lib/picocli-4.7.5.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.77.0.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.77.0.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.24.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.128.Final.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.128.Final.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.77.0.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.77.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.128.Final.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.128.Final.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.27.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.128.Final.jar:/opt/hadoop/share/ozone/lib/grpc-util-1.77.0.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.77.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.128.Final.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.128.Final.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.128.Final.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.128.Final.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.128.Final.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.128.Final.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-2.1.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.27.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.18.0.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.12.1.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.4.2.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.14.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-10.4.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.6.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.4.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.4.2.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_25-1.4.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.4.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.8.0.jar:/opt/hadoop/share/ozone/lib/commons-net-3.11.1.jar:/opt/hadoop/share/ozone/lib/commons-collections4-4.4.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.58.v20250814.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.58.v20250814.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.58.v20250814.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.58.v20250814.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.58.v20250814.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.58.v20250814.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.5.4.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.12.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.13.1.jar:/opt/hadoop/share/ozone/lib/re2j-1.7.jar:/opt/hadoop/share/ozone/lib/gson-2.13.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.55.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-epoll-4.1.128.Final.jar:/opt/hadoop/share/ozone/lib/netty-transport-classes-epoll-4.1.128.Final.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk18on-1.83.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-3.6.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.4.2.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.16.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.25.3.jar:/opt/hadoop/share/ozone/lib/hdds-client-2.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-2.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-2.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.16.2.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.10.0.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.11.0.jar:/opt/hadoop/share/ozone/lib/commons-digester-2.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/opentelemetry-api-1.58.0.jar:/opt/hadoop/share/ozone/lib/opentelemetry-context-1.58.0.jar:/opt/hadoop/share/ozone/lib/opentelemetry-common-1.58.0.jar:/opt/hadoop/share/ozone/lib/opentelemetry-exporter-otlp-1.58.0.jar:/opt/hadoop/share/ozone/lib/opentelemetry-sdk-metrics-1.58.0.jar:/opt/hadoop/share/ozone/lib/opentelemetry-sdk-logs-1.58.0.jar:/opt/hadoop/share/ozone/lib/opentelemetry-exporter-otlp-common-1.58.0.jar:/opt/hadoop/share/ozone/lib/opentelemetry-exporter-common-1.58.0.jar:/opt/hadoop/share/ozone/lib/opentelemetry-exporter-sender-okhttp-1.58.0.jar:/opt/hadoop/share/ozone/lib/okhttp-jvm-5.3.2.jar:/opt/hadoop/share/ozone/lib/okio-jvm-3.16.4.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.9.25.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/opentelemetry-sdk-extension-autoconfigure-spi-1.58.0.jar:/opt/hadoop/share/ozone/lib/opentelemetry-sdk-1.58.0.jar:/opt/hadoop/share/ozone/lib/opentelemetry-sdk-common-1.58.0.jar:/opt/hadoop/share/ozone/lib/opentelemetry-sdk-trace-1.58.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk18on-1.83.jar:/opt/hadoop/share/ozone/lib/bcutil-jdk18on-1.83.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-dropwizard3-3.2.1.jar:/opt/hadoop/share/ozone/lib/jcl-over-slf4j-2.0.17.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-2.0.17.jar:/opt/hadoop/share/ozone/lib/hdds-config-2.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-2.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-2.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-managed-rocksdb-2.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-rocks-native-2.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-2.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.26.jar:/opt/hadoop/share/ozone/lib/jnr-constants-0.10.4.jar:/opt/hadoop/share/ozone/lib/jnr-posix-3.1.21.jar:/opt/hadoop/share/ozone/lib/jnr-ffi-2.2.18.jar:/opt/hadoop/share/ozone/lib/jffi-1.3.14.jar:/opt/hadoop/share/ozone/lib/jffi-1.3.14-native.jar:/opt/hadoop/share/ozone/lib/asm-commons-9.7.1.jar:/opt/hadoop/share/ozone/lib/asm-analysis-9.7.1.jar:/opt/hadoop/share/ozone/lib/asm-tree-9.7.1.jar:/opt/hadoop/share/ozone/lib/asm-util-9.7.1.jar:/opt/hadoop/share/ozone/lib/jnr-a64asm-1.0.0.jar:/opt/hadoop/share/ozone/lib/jnr-x86asm-1.0.2.jar:/opt/hadoop/share/ozone/lib/commons-fileupload-1.6.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.16.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.16.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.16.0.jar:/opt/hadoop/share/ozone/lib/jakarta.ws.rs-api-2.1.6.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-2.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-api-3.2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.58.v20250814.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.47.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.6.1.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.47.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.3.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.47.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.47.jar:/opt/hadoop/share/ozone/lib/jakarta.validation-api-2.0.2.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.4.jar:/opt/hadoop/share/ozone/lib/apache-log4j-extras-1.2.17.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.25.3.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.10.8.jar:/opt/hadoop/share/ozone/lib/ozone-common-2.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-2.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.77.0.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.59.2.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.77.0.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-2.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/rocksdb-checkpoint-differ-2.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-3.2.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-3.2.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-3.2.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-3.2.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-3.2.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.10.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.24.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.58.v20250814.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.58.v20250814.jar:/opt/hadoop/share/ozone/lib/reflections-0.10.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.30.2-GA.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/slf4j-api-2.0.17.jar:/opt/hadoop/share/ozone/lib/snakeyaml-2.5.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.74.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.74.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.74.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.74.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.74.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.74.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.74.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/asm-9.8.jar:/opt/hadoop/share/ozone/lib/ozone-manager-2.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/web:/opt/ranger/ozone-plugin/lib/libext/ranger-ozone-plugin-impl:/opt/ranger/ozone-plugin/lib/libext/ranger-ozone-plugin-shim-2.6.0.jar:/opt/ranger/ozone-plugin/lib/libext/ranger-plugin-classloader-2.6.0.jar:/opt/ozone/conf:/opt/hadoop/share/ozone/lib/jersey-client-1.19.4.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.4.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/ranger-intg-2.6.0.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-base-2.16.2.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-json-provider-2.16.2.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.16.2.jar:/opt/hadoop/share/ozone/lib/gethostname4j-1.0.0.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-2.6.0.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-2.6.0.jar:/opt/hadoop/share/ozone/lib/aws-java-sdk-logs-1.12.765.jar:/opt/hadoop/share/ozone/lib/aws-java-sdk-core-1.12.788.jar:/opt/hadoop/share/ozone/lib/jackson-dataformat-cbor-2.16.2.jar:/opt/hadoop/share/ozone/lib/jmespath-java-1.12.765.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/aircompressor-0.27.jar:/opt/hadoop/share/ozone/lib/joda-time-2.12.7.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.4.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.16.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.13.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/orc-shims-1.5.8.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.58.v20250814.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-2.6.0.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.3.jar:/opt/hadoop/share/ozone/lib/ozone-multitenancy-ranger-2.2.0-SNAPSHOT.jar
STARTUP_MSG:        conf = {hadoop.hdds.db.rocksdb.WAL_size_limit_MB=0MB, hadoop.hdds.db.rocksdb.WAL_ttl_seconds=1200, hadoop.hdds.db.rocksdb.keep.log.file.num=10, hadoop.hdds.db.rocksdb.logging.enabled=false, hadoop.hdds.db.rocksdb.logging.level=INFO, hadoop.hdds.db.rocksdb.max.log.file.size=100MB, hadoop.hdds.db.rocksdb.writeoption.sync=false, hdds.block.token.enabled=true, hdds.block.token.expiry.time=1d, hdds.command.status.report.interval=30s, hdds.container.action.max.limit=20, hdds.container.balancer.balancing.iteration.interval=70m, hdds.container.balancer.datanodes.involved.max.percentage.per.iteration=20, hdds.container.balancer.iterations=10, hdds.container.balancer.move.networkTopology.enable=false, hdds.container.balancer.move.replication.timeout=50m, hdds.container.balancer.move.timeout=65m, hdds.container.balancer.size.entering.target.max=26GB, hdds.container.balancer.size.leaving.source.max=26GB, hdds.container.balancer.size.moved.max.per.iteration=500GB, hdds.container.balancer.trigger.du.before.move.enable=false, hdds.container.balancer.utilization.threshold=10, hdds.container.checksum.verification.enabled=true, hdds.container.chunk.write.sync=false, hdds.container.close.threshold=0.9f, hdds.container.ipc.port=9859, hdds.container.ipc.random.port=false, hdds.container.ratis.admin.port=9857, hdds.container.ratis.datastream.enabled=true, hdds.container.ratis.datastream.port=9855, hdds.container.ratis.datastream.random.port=false, hdds.container.ratis.enabled=false, hdds.container.ratis.ipc.port=9858, hdds.container.ratis.ipc.random.port=false, hdds.container.ratis.leader.pending.bytes.limit=1GB, hdds.container.ratis.log.appender.queue.byte-limit=32MB, hdds.container.ratis.log.appender.queue.num-elements=1024, hdds.container.ratis.log.purge.gap=1000000, hdds.container.ratis.log.queue.byte-limit=4GB, hdds.container.ratis.log.queue.num-elements=1024, hdds.container.ratis.num.container.op.executors=10, hdds.container.ratis.num.write.chunk.threads.per.volume=10, hdds.container.ratis.rpc.type=GRPC, hdds.container.ratis.segment.preallocated.size=4MB, hdds.container.ratis.segment.size=64MB, hdds.container.ratis.server.port=9856, hdds.container.ratis.statemachine.max.pending.apply-transactions=100000, hdds.container.ratis.statemachine.write.wait.interval=10m, hdds.container.ratis.statemachinedata.sync.timeout=10s, hdds.container.replication.compression=NO_COMPRESSION, hdds.container.report.interval=60s, hdds.container.token.enabled=true, hdds.datanode.client.bind.host=0.0.0.0, hdds.datanode.client.port=19864, hdds.datanode.df.refresh.period=5m, hdds.datanode.dir=/data/hdds, hdds.datanode.disk.balancer.enabled=false, hdds.datanode.dns.interface=default, hdds.datanode.dns.nameserver=default, hdds.datanode.du.refresh.period=1h, hdds.datanode.handler.count=10, hdds.datanode.http-address=0.0.0.0:9882, hdds.datanode.http-bind-host=0.0.0.0, hdds.datanode.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.datanode.http.auth.kerberos.principal=HTTP/db@EXAMPLE.COM, hdds.datanode.http.auth.type=kerberos, hdds.datanode.http.enabled=true, hdds.datanode.https-address=0.0.0.0:9883, hdds.datanode.https-bind-host=0.0.0.0, hdds.datanode.kerberos.keytab.file=/etc/security/keytabs/dn.keytab, hdds.datanode.kerberos.principal=dn/dn@EXAMPLE.COM, hdds.datanode.metadata.rocksdb.cache.size=1GB, hdds.datanode.ratis.server.request.timeout=2m, hdds.datanode.read.threadpool=10, hdds.datanode.slow.op.warning.threshold=500ms, hdds.datanode.storage.utilization.critical.threshold=0.95, hdds.datanode.storage.utilization.warning.threshold=0.75, hdds.datanode.use.datanode.hostname=false, hdds.datanode.volume.choosing.policy=org.apache.hadoop.ozone.container.common.volume.CapacityVolumeChoosingPolicy, hdds.datanode.volume.min.free.space=100MB, hdds.datanode.volume.min.free.space.percent=0, hdds.db.profile=DISK, hdds.grpc.tls.enabled=true, hdds.grpc.tls.provider=OPENSSL, hdds.heartbeat.initial-interval=2s, hdds.heartbeat.interval=5s, hdds.heartbeat.recon.initial-interval=60s, hdds.heartbeat.recon.interval=60s, hdds.key.algo=RSA, hdds.key.dir.name=keys, hdds.key.len=2048, hdds.node.report.interval=60000ms, hdds.pipeline.action.max.limit=20, hdds.pipeline.report.interval=60000ms, hdds.priv.key.file.name=private.pem, hdds.profiler.endpoint.enabled=false, hdds.prometheus.endpoint.enabled=true, hdds.public.key.file.name=public.pem, hdds.ratis.client.exponential.backoff.base.sleep=4s, hdds.ratis.client.exponential.backoff.max.retries=2147483647, hdds.ratis.client.exponential.backoff.max.sleep=40s, hdds.ratis.client.multilinear.random.retry.policy=5s, 5, 10s, 5, 15s, 5, 20s, 5, 25s, 5, 60s, 10, hdds.ratis.client.request.watch.timeout=3m, hdds.ratis.client.request.watch.type=ALL_COMMITTED, hdds.ratis.client.request.write.timeout=5m, hdds.ratis.client.retry.policy=org.apache.hadoop.hdds.ratis.retrypolicy.RequestTypeDependentRetryPolicyCreator, hdds.ratis.client.retrylimited.max.retries=180, hdds.ratis.client.retrylimited.retry.interval=1s, hdds.ratis.leader.election.minimum.timeout.duration=5s, hdds.ratis.raft.client.async.outstanding-requests.max=32, hdds.ratis.raft.client.rpc.request.timeout=60s, hdds.ratis.raft.client.rpc.watch.request.timeout=180s, hdds.ratis.raft.grpc.flow.control.window=5MB, hdds.ratis.raft.server.datastream.client.pool.size=10, hdds.ratis.raft.server.datastream.request.threads=20, hdds.ratis.raft.server.delete.ratis.log.directory=true, hdds.ratis.raft.server.leaderelection.pre-vote=true, hdds.ratis.raft.server.log.appender.wait-time.min=0us, hdds.ratis.raft.server.notification.no-leader.timeout=300s, hdds.ratis.raft.server.rpc.request.timeout=60s, hdds.ratis.raft.server.rpc.slowness.timeout=300s, hdds.ratis.raft.server.watch.timeout=30s, hdds.ratis.raft.server.write.element-limit=1024, hdds.ratis.server.retry-cache.timeout.duration=600000ms, hdds.ratis.snapshot.threshold=100000, hdds.scm.block.deleting.service.interval=60s, hdds.scm.block.deletion.per-interval.max=500000, hdds.scm.block.deletion.txn.dn.commit.map.limit=5000000, hdds.scm.ec.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.scm.http.auth.kerberos.principal=HTTP/scm@EXAMPLE.COM, hdds.scm.http.auth.type=kerberos, hdds.scm.kerberos.keytab.file=/etc/security/keytabs/scm.keytab, hdds.scm.kerberos.principal=scm/scm@EXAMPLE.COM, hdds.scm.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.safemode.atleast.one.node.reported.pipeline.pct=0.90, hdds.scm.safemode.enabled=true, hdds.scm.safemode.healthy.pipeline.pct=0.10, hdds.scm.safemode.log.interval=1m, hdds.scm.safemode.min.datanode=3, hdds.scm.safemode.pipeline.creation=true, hdds.scm.safemode.threshold.pct=0.99, hdds.scm.unknown-container.action=WARN, hdds.scm.wait.time.after.safemode.exit=5m, hdds.scmclient.failover.max.retry=15, hdds.scmclient.failover.retry.interval=2s, hdds.scmclient.max.retry.timeout=30s, hdds.scmclient.rpc.timeout=15m, hdds.secret.key.algorithm=HmacSHA256, hdds.secret.key.expiry.duration=1h, hdds.secret.key.file.name=secret_keys.json, hdds.secret.key.rotate.check.duration=1m, hdds.secret.key.rotate.duration=5m, hdds.security.client.datanode.container.protocol.acl=*, hdds.security.client.datanode.disk.balancer.protocol.acl=*, hdds.security.client.scm.block.protocol.acl=*, hdds.security.client.scm.certificate.protocol.acl=*, hdds.security.client.scm.container.protocol.acl=*, hdds.security.client.scm.secretkey.datanode.protocol.acl=*, hdds.security.client.scm.secretkey.om.protocol.acl=*, hdds.security.client.scm.secretkey.scm.protocol.acl=*, hdds.security.provider=BC, hdds.tracing.enabled=false, hdds.x509.ca.rotation.ack.timeout=PT15M, hdds.x509.ca.rotation.check.interval=P1D, hdds.x509.ca.rotation.enabled=false, hdds.x509.ca.rotation.time-of-day=02:00:00, hdds.x509.default.duration=P365D, hdds.x509.dir.name=certs, hdds.x509.expired.certificate.check.interval=P1D, hdds.x509.file.name=certificate.crt, hdds.x509.max.duration=P1865D, hdds.x509.renew.grace.duration=P28D, hdds.x509.rootca.certificate.polling.interval=PT2h, hdds.x509.signature.algorithm=SHA256withRSA, hdds.xframe.enabled=true, hdds.xframe.value=SAMEORIGIN, ozone.UnsafeByteOperations.enabled=true, ozone.acl.authorizer.class=org.apache.ranger.authorization.ozone.authorizer.RangerOzoneAuthorizer, ozone.acl.enabled=true, ozone.administrators=testuser,recon,om,hdfs, ozone.block.deleting.service.interval=1m, ozone.block.deleting.service.timeout=300000ms, ozone.block.deleting.service.workers=10, ozone.chunk.read.buffer.default.size=1MB, ozone.chunk.read.mapped.buffer.max.count=0, ozone.chunk.read.mapped.buffer.threshold=32KB, ozone.client.bucket.replication.config.refresh.time.ms=30000, ozone.client.bytes.per.checksum=16KB, ozone.client.checksum.combine.mode=COMPOSITE_CRC, ozone.client.checksum.type=CRC32, ozone.client.connection.timeout=5000ms, ozone.client.datastream.buffer.flush.size=16MB, ozone.client.datastream.min.packet.size=1MB, ozone.client.datastream.pipeline.mode=true, ozone.client.datastream.sync.size=0B, ozone.client.datastream.window.size=64MB, ozone.client.ec.grpc.retries.enabled=true, ozone.client.ec.grpc.retries.max=3, ozone.client.ec.grpc.write.timeout=30s, ozone.client.ec.reconstruct.stripe.read.pool.limit=30, ozone.client.ec.reconstruct.stripe.write.pool.limit=30, ozone.client.ec.stripe.queue.size=2, ozone.client.elastic.byte.buffer.pool.max.size=16GB, ozone.client.exclude.nodes.expiry.time=600000, ozone.client.failover.max.attempts=500, ozone.client.fs.default.bucket.layout=FILE_SYSTEM_OPTIMIZED, ozone.client.hbase.enhancements.allowed=false, ozone.client.incremental.chunk.list=false, ozone.client.key.latest.version.location=true, ozone.client.key.provider.cache.expiry=10d, ozone.client.key.write.concurrency=1, ozone.client.list.cache=1000, ozone.client.max.ec.stripe.write.retries=10, ozone.client.max.retries=5, ozone.client.read.max.retries=3, ozone.client.read.retry.interval=1, ozone.client.read.timeout=30s, ozone.client.retry.interval=0, ozone.client.server-defaults.validity.period.ms=3600000, ozone.client.socket.timeout=5000ms, ozone.client.stream.buffer.flush.delay=true, ozone.client.stream.buffer.flush.size=16MB, ozone.client.stream.buffer.increment=0B, ozone.client.stream.buffer.max.size=32MB, ozone.client.stream.buffer.size=4MB, ozone.client.stream.putblock.piggybacking=false, ozone.client.stream.read.pre-read-size=33554432, ozone.client.stream.read.response-data-size=1048576, ozone.client.stream.read.timeout=10s, ozone.client.stream.readblock.enable=false, ozone.client.verify.checksum=true, ozone.client.wait.between.retries.millis=2000, ozone.container.cache.lock.stripes=1024, ozone.container.cache.size=1024, ozone.directory.deleting.service.interval=1m, ozone.filesystem.snapshot.enabled=true, ozone.freon.http-address=0.0.0.0:9884, ozone.freon.http-bind-host=0.0.0.0, ozone.freon.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.freon.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.freon.http.auth.type=simple, ozone.freon.http.enabled=true, ozone.freon.https-address=0.0.0.0:9885, ozone.freon.https-bind-host=0.0.0.0, ozone.fs.datastream.auto.threshold=4MB, ozone.fs.datastream.enabled=false, ozone.fs.hsync.enabled=false, ozone.fs.iterate.batch-size=100, ozone.fs.listing.page.size=1024, ozone.fs.listing.page.size.max=5000, ozone.handler.type=distributed, ozone.hbase.enhancements.allowed=false, ozone.http.basedir=/tmp/ozone_http, ozone.http.filter.initializers=org.apache.hadoop.security.AuthenticationFilterInitializer, ozone.http.policy=HTTP_ONLY, ozone.httpfs.http.auth.kerberos.keytab=/etc/security/keytabs/httpfs.keytab, ozone.httpfs.http.auth.kerberos.principal=HTTP/httpfs@EXAMPLE.COM, ozone.httpfs.http.auth.type=kerberos, ozone.httpfs.kerberos.keytab.file=/etc/security/keytabs/httpfs.keytab, ozone.httpfs.kerberos.principal=httpfs/httpfs@EXAMPLE.COM, ozone.https.client.keystore.resource=ssl-client.xml, ozone.https.client.need-auth=false, ozone.https.server.keystore.resource=ssl-server.xml, ozone.key.deleting.limit.per.task=50000, ozone.key.preallocation.max.blocks=64, ozone.manager.delegation.remover.scan.interval=1m, ozone.manager.delegation.token.max-lifetime=30m, ozone.manager.delegation.token.renew-interval=5m, ozone.metadata.dirs=/data/metadata, ozone.metadata.dirs.permissions=750, ozone.metastore.rocksdb.cf.write.buffer.size=128MB, ozone.metastore.rocksdb.statistics=OFF, ozone.network.flexible.fqdn.resolution.enabled=false, ozone.network.jvm.address.cache.enabled=true, ozone.network.topology.aware.read=true, ozone.om.address=0.0.0.0:9862, ozone.om.address.omservice.om1=om1, ozone.om.address.omservice.om2=om2, ozone.om.address.omservice.om3=om3, ozone.om.admin.protocol.max.retries=20, ozone.om.admin.protocol.wait.between.retries=1000, ozone.om.allow.leader.skip.linearizable.read=false, ozone.om.client.rpc.timeout=15m, ozone.om.client.trash.core.pool.size=5, ozone.om.compaction.service.columnfamilies=keyTable,fileTable,directoryTable,deletedTable,deletedDirectoryTable,multipartInfoTable, ozone.om.compaction.service.enabled=false, ozone.om.compaction.service.run.interval=6h, ozone.om.compaction.service.timeout=10m, ozone.om.container.location.cache.size=100000, ozone.om.container.location.cache.ttl=360m, ozone.om.db.dirs.permissions=750, ozone.om.db.max.open.files=-1, ozone.om.delta.update.data.size.max.limit=1024MB, ozone.om.edekcacheloader.initial.delay.ms=3000, ozone.om.edekcacheloader.interval.ms=1000, ozone.om.edekcacheloader.max-retries=10, ozone.om.enable.filesystem.paths=false, ozone.om.enable.ofs.shared.tmp.dir=false, ozone.om.follower.read.local.lease.enabled=false, ozone.om.follower.read.local.lease.lag.limit=10000, ozone.om.follower.read.local.lease.time.ms=5000, ozone.om.fs.snapshot.max.limit=10000, ozone.om.group.rights=READ, LIST, ozone.om.grpc.bossgroup.size=8, ozone.om.grpc.maximum.response.length=134217728, ozone.om.grpc.port=8981, ozone.om.grpc.read.thread.num=32, ozone.om.grpc.workergroup.size=32, ozone.om.ha.raft.server.log.appender.wait-time.min=0ms, ozone.om.ha.raft.server.read.leader.lease.enabled=false, ozone.om.ha.raft.server.read.option=DEFAULT, ozone.om.ha.raft.server.retrycache.expirytime=300s, ozone.om.handler.count.key=100, ozone.om.hierarchical.resource.locks.hard.limit=10000, ozone.om.hierarchical.resource.locks.soft.limit=1024, ozone.om.http-address=0.0.0.0:9874, ozone.om.http-address.omservice.om1=om1, ozone.om.http-address.omservice.om2=om2, ozone.om.http-address.omservice.om3=om3, ozone.om.http-bind-host=0.0.0.0, ozone.om.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.om.http.auth.kerberos.principal=HTTP/om@EXAMPLE.COM, ozone.om.http.auth.type=kerberos, ozone.om.http.enabled=true, ozone.om.https-address=0.0.0.0:9875, ozone.om.https-bind-host=0.0.0.0, ozone.om.internal.service.id=omservice, ozone.om.kerberos.keytab.file=/etc/security/keytabs/om.keytab, ozone.om.kerberos.principal=om/om@EXAMPLE.COM, ozone.om.kerberos.principal.pattern=*, ozone.om.key.path.lock.enabled=false, ozone.om.keyname.character.check.enabled=false, ozone.om.leader.election.minimum.timeout.duration=5s, ozone.om.lease.hard.limit=7d, ozone.om.lease.soft.limit=60s, ozone.om.lock.fair=false, ozone.om.max.buckets=100000, ozone.om.multitenancy.enabled=true, ozone.om.multitenancy.ranger.sync.interval=10m, ozone.om.multitenancy.ranger.sync.timeout=10s, ozone.om.namespace.s3.strict=true, ozone.om.network.topology.refresh.duration=1h, ozone.om.nodes.omservice=om1,om2,om3, ozone.om.object.creation.ignore.client.acls=false, ozone.om.open.key.cleanup.limit.per.task=1000, ozone.om.open.key.cleanup.service.interval=24h, ozone.om.open.key.cleanup.service.timeout=300s, ozone.om.open.key.expire.threshold=7d, ozone.om.open.mpu.cleanup.service.interval=24h, ozone.om.open.mpu.cleanup.service.timeout=300s, ozone.om.open.mpu.expire.threshold=30d, ozone.om.open.mpu.parts.cleanup.limit.per.task=1000, ozone.om.ranger.https-address=http://ranger:6080, ozone.om.ranger.https.admin.api.passwd=rangerR0cks!, ozone.om.ranger.https.admin.api.user=admin, ozone.om.ranger.service=dev_ozone, ozone.om.ratis.log.appender.queue.byte-limit=32MB, ozone.om.ratis.log.appender.queue.num-elements=1024, ozone.om.ratis.log.purge.gap=1000000, ozone.om.ratis.log.purge.preservation.log.num=0, ozone.om.ratis.log.purge.upto.snapshot.index=true, ozone.om.ratis.minimum.timeout=5s, ozone.om.ratis.port=9872, ozone.om.ratis.rpc.type=GRPC, ozone.om.ratis.segment.preallocated.size=4MB, ozone.om.ratis.segment.size=64MB, ozone.om.ratis.server.close.threshold=60s, ozone.om.ratis.server.failure.timeout.duration=120s, ozone.om.ratis.server.leaderelection.pre-vote=true, ozone.om.ratis.server.pending.write.element-limit=4096, ozone.om.ratis.server.request.timeout=3s, ozone.om.ratis.server.retry.cache.timeout=600000ms, ozone.om.ratis.snapshot.max.total.sst.size=100000000, ozone.om.read.threadpool=10, ozone.om.s3.grpc.server_enabled=true, ozone.om.save.metrics.interval=5m, ozone.om.security.admin.protocol.acl=*, ozone.om.security.client.protocol.acl=*, ozone.om.server.list.max.size=1000, ozone.om.service.ids=omservice, ozone.om.snapshot.cache.cleanup.service.run.interval=1m, ozone.om.snapshot.cache.max.size=10, ozone.om.snapshot.checkpoint.dir.creation.poll.timeout=20s, ozone.om.snapshot.compact.non.snapshot.diff.tables=false, ozone.om.snapshot.compaction.dag.max.time.allowed=30d, ozone.om.snapshot.compaction.dag.prune.daemon.run.interval=10m, ozone.om.snapshot.db.max.open.files=100, ozone.om.snapshot.diff.cleanup.service.run.interval=1m, ozone.om.snapshot.diff.cleanup.service.timeout=5m, ozone.om.snapshot.diff.disable.native.libs=false, ozone.om.snapshot.diff.job.default.wait.time=1m, ozone.om.snapshot.diff.job.report.persistent.time=7d, ozone.om.snapshot.diff.max.allowed.keys.changed.per.job=10000000, ozone.om.snapshot.diff.max.jobs.purge.per.task=100, ozone.om.snapshot.diff.max.page.size=1000, ozone.om.snapshot.diff.thread.pool.size=10, ozone.om.snapshot.force.full.diff=false, ozone.om.snapshot.load.native.lib=true, ozone.om.snapshot.local.data.manager.service.interval=5m, ozone.om.snapshot.provider.connection.timeout=5000s, ozone.om.snapshot.provider.request.timeout=300000ms, ozone.om.snapshot.provider.socket.timeout=5000s, ozone.om.snapshot.prune.compaction.backup.batch.size=2000, ozone.om.snapshot.rocksdb.metrics.enabled=false, ozone.om.tenant.dev.skip.ranger=false, ozone.om.transport.class=org.apache.hadoop.ozone.om.protocolPB.Hadoop3OmTransportFactory, ozone.om.unflushed.transaction.max.count=10000, ozone.om.upgrade.finalization.ratis.based.timeout=30s, ozone.om.upgrade.quota.recalculate.enabled=true, ozone.om.user.max.volume=1024, ozone.om.user.rights=ALL, ozone.om.volume.listall.allowed=false, ozone.path.deleting.limit.per.task=20000, ozone.recon.address=recon:9891, ozone.recon.containerkey.flush.db.max.threshold=150000, ozone.recon.db.dir=/data/metadata/recon, ozone.recon.db.dirs.permissions=750, ozone.recon.dn.metrics.collection.minimum.api.delay=30s, ozone.recon.dn.metrics.collection.timeout=10m, ozone.recon.filesizecount.flush.db.max.threshold=200000, ozone.recon.heatmap.enable=false, ozone.recon.http-address=0.0.0.0:9888, ozone.recon.http-bind-host=0.0.0.0, ozone.recon.http.auth.kerberos.keytab=/etc/security/keytabs/recon.keytab, ozone.recon.http.auth.kerberos.principal=HTTP/recon@EXAMPLE.COM, ozone.recon.http.auth.type=kerberos, ozone.recon.http.enabled=true, ozone.recon.https-address=0.0.0.0:9889, ozone.recon.https-bind-host=0.0.0.0, ozone.recon.kerberos.keytab.file=/etc/security/keytabs/recon.keytab, ozone.recon.kerberos.principal=recon/recon@EXAMPLE.COM, ozone.recon.nssummary.flush.db.max.threshold=150000, ozone.recon.om.connection.request.timeout=5000, ozone.recon.om.connection.timeout=5s, ozone.recon.om.event.buffer.capacity=20000, ozone.recon.om.snapshot.task.flush.param=false, ozone.recon.om.snapshot.task.initial.delay=20s, ozone.recon.om.snapshot.task.interval.delay=1m, ozone.recon.om.socket.timeout=5s, ozone.recon.scm.connection.request.timeout=5s, ozone.recon.scm.connection.timeout=5s, ozone.recon.scm.container.threshold=100, ozone.recon.scm.snapshot.enabled=true, ozone.recon.scm.snapshot.task.initial.delay=1m, ozone.recon.scm.snapshot.task.interval.delay=24h, ozone.recon.scmclient.failover.max.retry=3, ozone.recon.scmclient.max.retry.timeout=6s, ozone.recon.scmclient.rpc.timeout=1m, ozone.recon.security.client.datanode.container.protocol.acl=*, ozone.recon.task.reprocess.max.iterators=5, ozone.recon.task.reprocess.max.keys.in.memory=2000, ozone.recon.task.reprocess.max.workers=20, ozone.recon.task.thread.count=1, ozone.replication.allowed-configs=^((STANDALONE|RATIS)/(ONE|THREE))|(EC/(3-2|6-3|10-4)-(512|1024|2048|4096)k)$, ozone.rest.client.http.connection.max=100, ozone.rest.client.http.connection.per-route.max=20, ozone.s3.administrators=testuser,s3g, ozone.s3g.client.buffer.size=4MB, ozone.s3g.default.bucket.layout=OBJECT_STORE, ozone.s3g.http-address=0.0.0.0:9878, ozone.s3g.http-bind-host=0.0.0.0, ozone.s3g.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.s3g.http.auth.kerberos.principal=HTTP/s3g@EXAMPLE.COM, ozone.s3g.http.auth.type=kerberos, ozone.s3g.http.enabled=true, ozone.s3g.https-address=0.0.0.0:9879, ozone.s3g.kerberos.keytab.file=/etc/security/keytabs/s3g.keytab, ozone.s3g.kerberos.principal=s3g/s3g@EXAMPLE.COM, ozone.s3g.list-keys.shallow.enabled=true, ozone.s3g.list.max.keys.limit=1000, ozone.s3g.metrics.percentiles.intervals.seconds=60, ozone.s3g.secret.http.auth.type=kerberos, ozone.s3g.secret.http.enabled=true, ozone.s3g.volume.name=s3v, ozone.s3g.webadmin.http-address=0.0.0.0:19878, ozone.s3g.webadmin.http-bind-host=0.0.0.0, ozone.s3g.webadmin.http.enabled=true, ozone.s3g.webadmin.https-address=0.0.0.0:19879, ozone.scm.address.scmservice.scm1=scm1.org, ozone.scm.address.scmservice.scm2=scm2.org, ozone.scm.address.scmservice.scm3=scm3.org, ozone.scm.block.client.address=scm, ozone.scm.block.client.bind.host=0.0.0.0, ozone.scm.block.client.port=9863, ozone.scm.block.deletion.per.dn.distribution.factor=8, ozone.scm.block.handler.count.key=100, ozone.scm.block.read.threadpool=10, ozone.scm.block.size=256MB, ozone.scm.ca.list.retry.interval=10s, ozone.scm.chunk.size=4MB, ozone.scm.client.address=scm, ozone.scm.client.bind.host=0.0.0.0, ozone.scm.client.handler.count.key=100, ozone.scm.client.port=9860, ozone.scm.client.read.threadpool=10, ozone.scm.close.container.wait.duration=5s, ozone.scm.container.layout=FILE_PER_BLOCK, ozone.scm.container.list.max.count=4096, ozone.scm.container.lock.stripes=512, ozone.scm.container.placement.ec.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter, ozone.scm.container.placement.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware, ozone.scm.container.size=1GB, ozone.scm.datanode.admin.monitor.interval=30s, ozone.scm.datanode.admin.monitor.logging.limit=1000, ozone.scm.datanode.disallow.same.peers=false, ozone.scm.datanode.handler.count.key=100, ozone.scm.datanode.id.dir=/data/metadata, ozone.scm.datanode.pipeline.limit=2, ozone.scm.datanode.port=9861, ozone.scm.datanode.ratis.volume.free-space.min=10MB, ozone.scm.datanode.read.threadpool=10, ozone.scm.db.dirs.permissions=750, ozone.scm.dead.node.interval=10m, ozone.scm.ec.pipeline.minimum=1, ozone.scm.event.ContainerReport.thread.pool.size=10, ozone.scm.expired.container.replica.op.scrub.interval=5m, ozone.scm.grpc.port=9895, ozone.scm.ha.dbtransactionbuffer.flush.interval=60s, ozone.scm.ha.grpc.deadline.interval=30m, ozone.scm.ha.raft.server.log.appender.wait-time.min=0ms, ozone.scm.ha.ratis.leader.election.timeout=5s, ozone.scm.ha.ratis.leader.ready.check.interval=2s, ozone.scm.ha.ratis.leader.ready.wait.timeout=60s, ozone.scm.ha.ratis.log.appender.queue.byte-limit=32MB, ozone.scm.ha.ratis.log.appender.queue.num-elements=1024, ozone.scm.ha.ratis.log.purge.enabled=false, ozone.scm.ha.ratis.log.purge.gap=1000000, ozone.scm.ha.ratis.request.timeout=30s, ozone.scm.ha.ratis.rpc.type=GRPC, ozone.scm.ha.ratis.segment.preallocated.size=4MB, ozone.scm.ha.ratis.segment.size=64MB, ozone.scm.ha.ratis.server.failure.timeout.duration=120s, ozone.scm.ha.ratis.server.leaderelection.pre-vote=true, ozone.scm.ha.ratis.server.retry.cache.timeout=60s, ozone.scm.ha.ratis.server.snapshot.creation.gap=1024, ozone.scm.ha.ratis.snapshot.threshold=1000, ozone.scm.handler.count.key=100, ozone.scm.heartbeat.log.warn.interval.count=10, ozone.scm.heartbeat.rpc-retry-count=15, ozone.scm.heartbeat.rpc-retry-interval=1s, ozone.scm.heartbeat.rpc-timeout=5s, ozone.scm.heartbeat.thread.interval=3s, ozone.scm.http-address=0.0.0.0:9876, ozone.scm.http-bind-host=0.0.0.0, ozone.scm.http.enabled=true, ozone.scm.https-address=0.0.0.0:9877, ozone.scm.https-bind-host=0.0.0.0, ozone.scm.info.wait.duration=10m, ozone.scm.keyvalue.container.deletion-choosing.policy=org.apache.hadoop.ozone.container.common.impl.TopNOrderedContainerDeletionChoosingPolicy, ozone.scm.network.topology.schema.file=network-topology-default.xml, ozone.scm.nodes.scmservice=scm1,scm2,scm3, ozone.scm.pipeline.allocated.timeout=5m, ozone.scm.pipeline.creation.auto.factor.one=true, ozone.scm.pipeline.creation.interval=30s, ozone.scm.pipeline.destroy.timeout=66s, ozone.scm.pipeline.leader-choose.policy=org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy, ozone.scm.pipeline.owner.container.count=1, ozone.scm.pipeline.per.metadata.disk=2, ozone.scm.pipeline.scrub.interval=5m, ozone.scm.primordial.node.id=scm1, ozone.scm.ratis.pipeline.limit=0, ozone.scm.ratis.port=9894, ozone.scm.security.handler.count.key=2, ozone.scm.security.read.threadpool=1, ozone.scm.security.service.bind.host=0.0.0.0, ozone.scm.security.service.port=9961, ozone.scm.sequence.id.batch.size=1000, ozone.scm.service.ids=scmservice, ozone.scm.skip.bootstrap.validation=false, ozone.scm.stale.node.interval=30s, ozone.security.crypto.compliance.mode=unrestricted, ozone.security.enabled=true, ozone.security.http.kerberos.enabled=true, ozone.security.reconfigure.protocol.acl=*, ozone.server.default.replication=3, ozone.server.default.replication.type=RATIS, ozone.service.shutdown.timeout=60s, ozone.snapshot.deep.cleaning.enabled=false, ozone.snapshot.defrag.limit.per.task=1, ozone.snapshot.defrag.service.interval=-1, ozone.snapshot.defrag.service.timeout=300s, ozone.snapshot.deleting.limit.per.task=10, ozone.snapshot.deleting.service.interval=30s, ozone.snapshot.deleting.service.timeout=300s, ozone.snapshot.directory.service.interval=24h, ozone.snapshot.directory.service.timeout=300s, ozone.snapshot.filtering.limit.per.task=2, ozone.snapshot.filtering.service.interval=1m, ozone.snapshot.key.deleting.limit.per.task=20000, ozone.sst.filtering.service.timeout=300000ms, ozone.volume.io.percentiles.intervals.seconds=60, ozone.xceiver.client.metrics.percentiles.intervals.seconds=60, recon.om.delta.update.lag.threshold=0, recon.om.delta.update.limit=50000, scm.container.client.idle.threshold=10s, scm.container.client.max.size=256}
************************************************************/
2026-01-15 05:54:42,591 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [SIGHUP, SIGINT, SIGTERM]
2026-01-15 05:54:43,810 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
2026-01-15 05:54:43,857 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMSystemAudit to [].
2026-01-15 05:54:44,428 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is omservice
2026-01-15 05:54:44,692 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: omservice, OMNodeId: om1, RPC Address: om1:9862 ,Ratis port: 9872 and isListener: false
2026-01-15 05:54:44,693 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.omservice.om1: om1
2026-01-15 05:54:44,693 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.omservice.om1: om1
2026-01-15 05:54:46,187 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2026-01-15 05:54:46,309 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = SNAPSHOT_DEFRAG (version = 9), software layout = SNAPSHOT_DEFRAG (version = 9)
2026-01-15 05:54:47,369 [main] INFO reflections.Reflections: Reflections took 637 ms to scan 1 urls, producing 164 keys and 492 values
2026-01-15 05:54:47,407 [main] INFO upgrade.OMLayoutVersionManager: Skipping Upgrade Action QuotaRepairUpgradeAction since it has been finalized.
2026-01-15 05:54:47,679 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
2026-01-15 05:54:47,679 [main] INFO om.OzoneManager: Ozone Manager login successful.
2026-01-15 05:54:47,679 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2026-01-15 05:54:47,758 [main] INFO om.OzoneManager: Set default replication in OM: RATIS/3 -> RATIS/THREE
2026-01-15 05:54:47,804 [main] INFO proxy.SCMContainerLocationFailoverProxyProvider: Created fail-over proxy for protocol StorageContainerLocationProtocolPB with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9860, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9860, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9860]
2026-01-15 05:54:48,012 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created fail-over proxy for protocol ScmBlockLocationProtocolPB with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
2026-01-15 05:54:48,093 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created fail-over proxy for protocol ScmBlockLocationProtocolPB with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
2026-01-15 05:54:49,150 [main] INFO om.OzoneManager: OzoneManager ports added:[name: "RPC"
value: 9862
]
2026-01-15 05:54:49,164 [main] INFO proxy.SCMSecurityProtocolFailoverProxyProvider: Created fail-over proxy for protocol SCMSecurityProtocolPB with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9961, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9961, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9961]
2026-01-15 05:54:49,218 [main] INFO security.OMCertificateClient: Certificate serial ID set to 9
2026-01-15 05:54:49,358 [main] INFO security.OMCertificateClient: Added certificate 1 from file: /data/metadata/om/certs/ROOTCA-1.crt.
2026-01-15 05:54:49,368 [main] INFO security.OMCertificateClient: Added certificate 9 from file: /data/metadata/om/certs/9.crt.
2026-01-15 05:54:49,378 [main] INFO security.OMCertificateClient: Added certificate 2 from file: /data/metadata/om/certs/CA-2.crt.
2026-01-15 05:54:49,396 [main] INFO security.OMCertificateClient: CertificateRenewerService for om is started with first delay 29116783614 ms and interval 86400000 ms.
2026-01-15 05:54:49,408 [main] INFO proxy.SecretKeyProtocolFailoverProxyProvider: Created fail-over proxy for protocol SecretKeyProtocolOmPB with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9961, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9961, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9961]
2026-01-15 05:54:49,445 [main] INFO symmetric.DefaultSecretKeyVerifierClient: Initializing secret key cache with size 26, TTL PT1H
2026-01-15 05:54:49,449 [main] INFO security.OMCertificateClient: om has 1 Root CA certificates
2026-01-15 05:54:49,593 [main] WARN om.OzoneManager: Detected clear text username and password override configs. These will be used to authenticate to Ranger Admin Server instead of using the recommended Kerberos principal and keytab authentication method. This is NOT recommended on a production cluster.
2026-01-15 05:54:49,727 [main] INFO om.OzoneManager: OM start with adminUsers: [testuser, recon, om, hdfs]
2026-01-15 05:54:49,897 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2026-01-15 05:54:50,397 [main] INFO utils.NativeLibraryLoader: Loading Library: ozone_rocksdb_tools
2026-01-15 05:54:50,399 [main] WARN utils.NativeLibraryLoader: Unable to load library: ozone_rocksdb_tools
java.nio.file.AccessDeniedException: /opt/hadoop/ozone_rocksdb_tools7063094149752862326
	at java.base/sun.nio.fs.UnixException.translateToIOException(UnixException.java:90)
	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:106)
	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:111)
	at java.base/sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:438)
	at java.base/java.nio.file.Files.createDirectory(Files.java:699)
	at java.base/java.nio.file.TempFileHelper.create(TempFileHelper.java:134)
	at java.base/java.nio.file.TempFileHelper.createTempDirectory(TempFileHelper.java:171)
	at java.base/java.nio.file.Files.createTempDirectory(Files.java:976)
	at org.apache.hadoop.hdds.utils.NativeLibraryLoader.copyResourceFromJarToTemp(NativeLibraryLoader.java:174)
	at org.apache.hadoop.hdds.utils.NativeLibraryLoader.loadLibrary(NativeLibraryLoader.java:131)
	at org.apache.hadoop.hdds.utils.db.ManagedRawSSTFileReader.loadLibrary(ManagedRawSSTFileReader.java:55)
	at org.apache.ozone.rocksdiff.RocksDBCheckpointDiffer.<init>(RocksDBCheckpointDiffer.java:252)
	at org.apache.ozone.rocksdiff.RocksDBCheckpointDiffer$RocksDBCheckpointDifferHolder.lambda$getInstance$0(RocksDBCheckpointDiffer.java:1420)
	at java.base/java.util.concurrent.ConcurrentHashMap.computeIfAbsent(ConcurrentHashMap.java:1708)
	at org.apache.ozone.rocksdiff.RocksDBCheckpointDiffer$RocksDBCheckpointDifferHolder.getInstance(RocksDBCheckpointDiffer.java:1419)
	at org.apache.hadoop.hdds.utils.db.RDBStore.<init>(RDBStore.java:105)
	at org.apache.hadoop.hdds.utils.db.DBStoreBuilder.build(DBStoreBuilder.java:230)
	at org.apache.hadoop.ozone.om.OmMetadataManagerImpl.loadDB(OmMetadataManagerImpl.java:442)
	at org.apache.hadoop.ozone.om.OmMetadataManagerImpl.start(OmMetadataManagerImpl.java:425)
	at org.apache.hadoop.ozone.om.OmMetadataManagerImpl.<init>(OmMetadataManagerImpl.java:221)
	at org.apache.hadoop.ozone.om.OzoneManager.instantiateServices(OzoneManager.java:917)
	at org.apache.hadoop.ozone.om.OzoneManager.<init>(OzoneManager.java:688)
	at org.apache.hadoop.ozone.om.OzoneManager.createOm(OzoneManager.java:882)
	at org.apache.hadoop.ozone.om.OzoneManagerStarter$OMStarterHelper.start(OzoneManagerStarter.java:188)
	at org.apache.hadoop.ozone.om.OzoneManagerStarter.startOm(OzoneManagerStarter.java:85)
	at org.apache.hadoop.ozone.om.OzoneManagerStarter.call(OzoneManagerStarter.java:73)
	at org.apache.hadoop.ozone.om.OzoneManagerStarter.call(OzoneManagerStarter.java:1)
	at picocli.CommandLine.executeUserObject(CommandLine.java:2041)
	at picocli.CommandLine.access$1500(CommandLine.java:148)
	at picocli.CommandLine$RunLast.executeUserObjectOfLastSubcommandWithSameParent(CommandLine.java:2461)
	at picocli.CommandLine$RunLast.handle(CommandLine.java:2453)
	at picocli.CommandLine$RunLast.handle(CommandLine.java:2415)
	at picocli.CommandLine$AbstractParseResultHandler.execute(CommandLine.java:2273)
	at picocli.CommandLine$RunLast.execute(CommandLine.java:2417)
	at picocli.CommandLine.execute(CommandLine.java:2170)
	at org.apache.hadoop.hdds.cli.GenericCli.execute(GenericCli.java:89)
	at org.apache.hadoop.hdds.cli.GenericCli.run(GenericCli.java:80)
	at org.apache.hadoop.ozone.om.OzoneManagerStarter.main(OzoneManagerStarter.java:57)
2026-01-15 05:54:50,401 [main] WARN rocksdiff.RocksDBCheckpointDiffer: Native Library for raw sst file reading loading failed. Cannot prune OMKeyInfo from SST files. Unable to load library ozone_rocksdb_tools from both java.library.path & resource file libozone_rocksdb_tools.so from jar.
2026-01-15 05:54:51,081 [main] INFO om.OzoneManager: S3 Multi-Tenancy is enabled
2026-01-15 05:54:51,098 [main] INFO om.OMMultiTenantManagerImpl: Loaded 0 tenants and 0 tenant users from the database
2026-01-15 05:54:51,117 [main] INFO multitenant.RangerClientMultiTenantAccessController: authType = SIMPLE, login user = admin
2026-01-15 05:54:51,184 [main] INFO config.RangerPluginConfig: PolicyEngineOptions: { evaluatorType: auto, evaluateDelegateAdminOnly: false, disableContextEnrichers: false, disableCustomConditions: false, disableTagPolicyEvaluation: false, disablePolicyRefresher: false, disableTagRetriever: false, disableUserStoreRetriever: false, enableTagEnricherWithLocalRefresher: false, enableUserStoreEnricherWithLocalRefresher: false, disableTrieLookupPrefilter: false, optimizeTrieForRetrieval: false, cacheAuditResult: false, disableRoleResolution: true, optimizeTrieForSpace: false, optimizeTagTrieForRetrieval: false, optimizeTagTrieForSpace: false, enableResourceMatcherReuse: true }
2026-01-15 05:54:51,296 [main] INFO utils.BackgroundService: Starting service OMRangerBGSyncService with interval 600 seconds
2026-01-15 05:54:51,311 [om1-OMRangerBGSyncService#0] WARN service.OMRangerBGSyncService: OzoneManagerRatisServer is not initialized yet
2026-01-15 05:54:51,327 [main] INFO security.OzoneSecretStore: Loaded 0 tokens
2026-01-15 05:54:51,327 [main] INFO security.OzoneDelegationTokenSecretManager: Loading token state into token manager.
2026-01-15 05:54:51,442 [main] INFO config.RangerPluginConfig: PolicyEngineOptions: { evaluatorType: auto, evaluateDelegateAdminOnly: false, disableContextEnrichers: false, disableCustomConditions: false, disableTagPolicyEvaluation: false, disablePolicyRefresher: false, disableTagRetriever: false, disableUserStoreRetriever: false, enableTagEnricherWithLocalRefresher: false, enableUserStoreEnricherWithLocalRefresher: false, disableTrieLookupPrefilter: false, optimizeTrieForRetrieval: false, cacheAuditResult: false, disableRoleResolution: true, optimizeTrieForSpace: false, optimizeTagTrieForRetrieval: false, optimizeTagTrieForSpace: false, enableResourceMatcherReuse: true }
2026-01-15 05:54:51,444 [main] INFO service.RangerBasePlugin: ranger.plugin.ozone.null_safe.supplier=v2
2026-01-15 05:54:51,463 [main] INFO provider.AuditProviderFactory: AuditProviderFactory: creating..
2026-01-15 05:54:51,464 [main] INFO provider.AuditProviderFactory: AuditProviderFactory: initializing..
2026-01-15 05:54:51,469 [main] INFO provider.AuditProviderFactory: AUDIT PROPERTY: xasecure.audit.solr.async.max.flush.interval.ms=1000
2026-01-15 05:54:51,470 [main] INFO provider.AuditProviderFactory: AUDIT PROPERTY: xasecure.audit.hdfs.config.local.buffer.file.buffer.size.bytes=8192
2026-01-15 05:54:51,470 [main] INFO provider.AuditProviderFactory: AUDIT PROPERTY: xasecure.audit.destination.elasticsearch.password=NONE
2026-01-15 05:54:51,471 [main] INFO provider.AuditProviderFactory: AUDIT PROPERTY: xasecure.audit.hdfs.config.destination.open.retry.interval.seconds=60
2026-01-15 05:54:51,471 [main] INFO provider.AuditProviderFactory: AUDIT PROPERTY: xasecure.audit.ozone.async.max.queue.size=1
2026-01-15 05:54:51,472 [main] INFO provider.AuditProviderFactory: AUDIT PROPERTY: ranger.plugin.ozone.service.name=dev_ozone
2026-01-15 05:54:51,472 [main] INFO provider.AuditProviderFactory: AUDIT PROPERTY: xasecure.audit.destination.elasticsearch.user=NONE
2026-01-15 05:54:51,472 [main] INFO provider.AuditProviderFactory: AUDIT PROPERTY: xasecure.audit.log4j.is.async=false
2026-01-15 05:54:51,472 [main] INFO provider.AuditProviderFactory: AUDIT PROPERTY: xasecure.audit.destination.solr=false
2026-01-15 05:54:51,472 [main] INFO provider.AuditProviderFactory: AUDIT PROPERTY: xasecure.audit.solr.solr_url=http://localhost:6083/solr/ranger_audits
2026-01-15 05:54:51,472 [main] INFO provider.AuditProviderFactory: AUDIT PROPERTY: xasecure.audit.hdfs.config.local.archive.directory=__REPLACE__LOG_DIR/ozone/audit/archive
2026-01-15 05:54:51,472 [main] INFO provider.AuditProviderFactory: AUDIT PROPERTY: xasecure.audit.destination.solr.zookeepers=NONE
2026-01-15 05:54:51,472 [main] INFO provider.AuditProviderFactory: AUDIT PROPERTY: xasecure.audit.destination.solr.urls=NONE
2026-01-15 05:54:51,472 [main] INFO provider.AuditProviderFactory: AUDIT PROPERTY: xasecure.audit.destination.elasticsearch.protocol=NONE
2026-01-15 05:54:51,472 [main] INFO provider.AuditProviderFactory: AUDIT PROPERTY: xasecure.audit.hdfs.is.enabled=false
2026-01-15 05:54:51,472 [main] INFO provider.AuditProviderFactory: AUDIT PROPERTY: xasecure.audit.destination.solr.user=NONE
2026-01-15 05:54:51,472 [main] INFO provider.AuditProviderFactory: AUDIT PROPERTY: xasecure.audit.hdfs.config.destination.directory=hdfs://__REPLACE__NAME_NODE_HOST:8020/ranger/audit/%app-type%/%time:yyyyMMdd%
2026-01-15 05:54:51,472 [main] INFO provider.AuditProviderFactory: AUDIT PROPERTY: xasecure.audit.hdfs.config.local.archive.max.file.count=10
2026-01-15 05:54:51,472 [main] INFO provider.AuditProviderFactory: AUDIT PROPERTY: xasecure.audit.destination.amazon_cloudwatch=false
2026-01-15 05:54:51,472 [main] INFO provider.AuditProviderFactory: AUDIT PROPERTY: xasecure.audit.destination.amazon_cloudwatch.region=NONE
2026-01-15 05:54:51,472 [main] INFO provider.AuditProviderFactory: AUDIT PROPERTY: xasecure.audit.destination.elasticsearch.index=NONE
2026-01-15 05:54:51,472 [main] INFO provider.AuditProviderFactory: AUDIT PROPERTY: xasecure.audit.ozone.topic_name=ranger_audits
2026-01-15 05:54:51,472 [main] INFO provider.AuditProviderFactory: AUDIT PROPERTY: xasecure.audit.hdfs.is.async=true
2026-01-15 05:54:51,472 [main] INFO provider.AuditProviderFactory: AUDIT PROPERTY: xasecure.audit.destination.hdfs.config.fs.azure.account.keyprovider.__REPLACE_AZURE_ACCOUNT_NAME.blob.core.windows.net=__REPLACE_AZURE_ACCOUNT_KEY_PROVIDER
2026-01-15 05:54:51,472 [main] INFO provider.AuditProviderFactory: AUDIT PROPERTY: xasecure.audit.ozone.is.enabled=false
2026-01-15 05:54:51,472 [main] INFO provider.AuditProviderFactory: AUDIT PROPERTY: xasecure.audit.hdfs.config.destination.rollover.interval.seconds=86400
2026-01-15 05:54:51,474 [main] INFO provider.AuditProviderFactory: AUDIT PROPERTY: xasecure.audit.ozone.async.max.flush.interval.ms=1000
2026-01-15 05:54:51,474 [main] INFO provider.AuditProviderFactory: AUDIT PROPERTY: xasecure.audit.provider.summary.enabled=true
2026-01-15 05:54:51,474 [main] INFO provider.AuditProviderFactory: AUDIT PROPERTY: xasecure.audit.destination.elasticsearch=false
2026-01-15 05:54:51,474 [main] INFO provider.AuditProviderFactory: AUDIT PROPERTY: ranger.plugin.ozone.policy.rest.client.password=hdfs
2026-01-15 05:54:51,474 [main] INFO provider.AuditProviderFactory: AUDIT PROPERTY: xasecure.audit.hdfs.config.local.buffer.directory=__REPLACE__LOG_DIR/ozone/audit
2026-01-15 05:54:51,475 [main] INFO provider.AuditProviderFactory: AUDIT PROPERTY: xasecure.audit.ozone.broker_list=localhost:9092
2026-01-15 05:54:51,475 [main] INFO provider.AuditProviderFactory: AUDIT PROPERTY: xasecure.audit.solr.is.enabled=false
2026-01-15 05:54:51,475 [main] INFO provider.AuditProviderFactory: AUDIT PROPERTY: xasecure.audit.is.enabled=true
2026-01-15 05:54:51,475 [main] INFO provider.AuditProviderFactory: AUDIT PROPERTY: xasecure.audit.destination.elasticsearch.port=NONE
2026-01-15 05:54:51,475 [main] INFO provider.AuditProviderFactory: AUDIT PROPERTY: xasecure.audit.log4j.async.max.flush.interval.ms=30000
2026-01-15 05:54:51,476 [main] INFO provider.AuditProviderFactory: AUDIT PROPERTY: xasecure.audit.destination.solr.batch.filespool.dir=/var/log/ozone/audit/solr/spool
2026-01-15 05:54:51,476 [main] INFO provider.AuditProviderFactory: AUDIT PROPERTY: xasecure.audit.destination.amazon_cloudwatch.batch.filespool.dir=NONE
2026-01-15 05:54:51,476 [main] INFO provider.AuditProviderFactory: AUDIT PROPERTY: xasecure.audit.destination.hdfs.dir=hdfs://__REPLACE__NAME_NODE_HOST:8020/ranger/audit
2026-01-15 05:54:51,476 [main] INFO provider.AuditProviderFactory: AUDIT PROPERTY: xasecure.audit.hdfs.config.local.buffer.rollover.interval.seconds=600
2026-01-15 05:54:51,476 [main] INFO provider.AuditProviderFactory: AUDIT PROPERTY: xasecure.audit.destination.hdfs.config.fs.azure.shellkeyprovider.script=__REPLACE_AZURE_SHELL_KEY_PROVIDER
2026-01-15 05:54:51,476 [main] INFO provider.AuditProviderFactory: AUDIT PROPERTY: xasecure.audit.destination.amazon_cloudwatch.log_stream_prefix=NONE
2026-01-15 05:54:51,476 [main] INFO provider.AuditProviderFactory: AUDIT PROPERTY: xasecure.audit.log4j.is.enabled=false
2026-01-15 05:54:51,476 [main] INFO provider.AuditProviderFactory: AUDIT PROPERTY: ranger.plugin.ozone.policy.rest.url=http://ranger:6080
2026-01-15 05:54:51,478 [main] INFO provider.AuditProviderFactory: AUDIT PROPERTY: xasecure.audit.hdfs.config.destination.flush.interval.seconds=900
2026-01-15 05:54:51,478 [main] INFO provider.AuditProviderFactory: AUDIT PROPERTY: ranger.plugin.ozone.policy.rest.client.username=hdfs
2026-01-15 05:54:51,478 [main] INFO provider.AuditProviderFactory: AUDIT PROPERTY: xasecure.audit.hdfs.async.max.flush.interval.ms=30000
2026-01-15 05:54:51,478 [main] INFO provider.AuditProviderFactory: AUDIT PROPERTY: xasecure.audit.hdfs.config.local.buffer.flush.interval.seconds=60
2026-01-15 05:54:51,478 [main] INFO provider.AuditProviderFactory: AUDIT PROPERTY: xasecure.audit.solr.async.max.queue.size=1
2026-01-15 05:54:51,478 [main] INFO provider.AuditProviderFactory: AUDIT PROPERTY: xasecure.audit.destination.amazon_cloudwatch.log_group=NONE
2026-01-15 05:54:51,478 [main] INFO provider.AuditProviderFactory: AUDIT PROPERTY: xasecure.audit.destination.hdfs.batch.filespool.dir=/var/log/ozone/audit/hdfs/spool
2026-01-15 05:54:51,478 [main] INFO provider.AuditProviderFactory: AUDIT PROPERTY: xasecure.audit.destination.hdfs=false
2026-01-15 05:54:51,478 [main] INFO provider.AuditProviderFactory: AUDIT PROPERTY: xasecure.audit.hdfs.async.max.queue.size=1048576
2026-01-15 05:54:51,478 [main] INFO provider.AuditProviderFactory: AUDIT PROPERTY: xasecure.audit.destination.solr.password=NONE
2026-01-15 05:54:51,478 [main] INFO provider.AuditProviderFactory: AUDIT PROPERTY: xasecure.audit.destination.elasticsearch.urls=NONE
2026-01-15 05:54:51,478 [main] INFO provider.AuditProviderFactory: AUDIT PROPERTY: xasecure.audit.destination.log4j=true
2026-01-15 05:54:51,478 [main] INFO provider.AuditProviderFactory: AUDIT PROPERTY: xasecure.audit.destination.hdfs.config.fs.azure.account.key.__REPLACE_AZURE_ACCOUNT_NAME.blob.core.windows.net=__REPLACE_AZURE_ACCOUNT_KEY
2026-01-15 05:54:51,478 [main] INFO provider.AuditProviderFactory: AUDIT PROPERTY: xasecure.audit.hdfs.config.destination.file=%hostname%-audit.log
2026-01-15 05:54:51,478 [main] INFO provider.AuditProviderFactory: AUDIT PROPERTY: xasecure.audit.destination.log4j.logger=xaaudit
2026-01-15 05:54:51,478 [main] INFO provider.AuditProviderFactory: AUDIT PROPERTY: xasecure.audit.hdfs.config.local.buffer.file=%time:yyyyMMdd-HHmm.ss%.log
2026-01-15 05:54:51,478 [main] INFO provider.AuditProviderFactory: AUDIT PROPERTY: xasecure.audit.log4j.async.max.queue.size=10240
2026-01-15 05:54:51,478 [main] INFO provider.AuditProviderFactory: AUDIT PROPERTY: ranger.plugin.ozone.forceNonKerberos=true
2026-01-15 05:54:51,478 [main] INFO provider.AuditProviderFactory: Audit destination xasecure.audit.destination.log4j is set to true
2026-01-15 05:54:51,483 [main] INFO destination.AuditDestination: AuditDestination() enter
2026-01-15 05:54:51,483 [main] INFO destination.Log4JAuditDestination: Log4JAuditDestination() called.
2026-01-15 05:54:51,485 [main] INFO provider.BaseAuditHandler: BaseAuditProvider.init()
2026-01-15 05:54:51,485 [main] INFO provider.BaseAuditHandler: propPrefix=xasecure.audit.destination.log4j
2026-01-15 05:54:51,485 [main] INFO provider.BaseAuditHandler: Using providerName from property prefix. providerName=log4j
2026-01-15 05:54:51,485 [main] INFO provider.BaseAuditHandler: providerName=log4j
2026-01-15 05:54:51,486 [main] INFO provider.BaseAuditHandler: xasecure.audit.log.status.log.enabled=false
2026-01-15 05:54:51,487 [main] INFO provider.BaseAuditHandler: xasecure.audit.log.status.log.interval.sec=300
2026-01-15 05:54:51,487 [main] INFO provider.BaseAuditHandler: xasecure.audit.destination.log4j.status.log.enabled=false
2026-01-15 05:54:51,487 [main] INFO provider.BaseAuditHandler: xasecure.audit.destination.log4j.status.log.interval.sec=300
2026-01-15 05:54:51,487 [main] INFO destination.Log4JAuditDestination: Logger name for log4j is xaaudit
2026-01-15 05:54:51,487 [main] INFO destination.Log4JAuditDestination: Done initializing logger for audit. name=log4j, loggerName=xaaudit
2026-01-15 05:54:51,487 [main] INFO provider.AuditProviderFactory: xasecure.audit.destination.log4j.queue is not set. Setting queue to batch for log4j
2026-01-15 05:54:51,487 [main] INFO provider.AuditProviderFactory: queue for log4j is batch
2026-01-15 05:54:51,488 [main] INFO queue.AuditQueue: BaseAuditProvider.init()
2026-01-15 05:54:51,488 [main] INFO provider.BaseAuditHandler: BaseAuditProvider.init()
2026-01-15 05:54:51,492 [main] INFO provider.BaseAuditHandler: propPrefix=xasecure.audit.destination.log4j.batch
2026-01-15 05:54:51,492 [main] INFO provider.BaseAuditHandler: providerName=batch
2026-01-15 05:54:51,492 [main] INFO provider.BaseAuditHandler: xasecure.audit.log.status.log.enabled=false
2026-01-15 05:54:51,492 [main] INFO provider.BaseAuditHandler: xasecure.audit.log.status.log.interval.sec=300
2026-01-15 05:54:51,492 [main] INFO provider.BaseAuditHandler: xasecure.audit.destination.log4j.batch.status.log.enabled=false
2026-01-15 05:54:51,492 [main] INFO provider.BaseAuditHandler: xasecure.audit.destination.log4j.batch.status.log.interval.sec=300
2026-01-15 05:54:51,492 [main] INFO queue.AuditQueue: File spool is disabled for batch
2026-01-15 05:54:51,492 [main] INFO provider.AuditProviderFactory: Using v3 audit configuration
2026-01-15 05:54:51,492 [main] INFO provider.AuditProviderFactory: AuditSummaryQueue is enabled
2026-01-15 05:54:51,495 [main] INFO queue.AuditQueue: BaseAuditProvider.init()
2026-01-15 05:54:51,495 [main] INFO provider.BaseAuditHandler: BaseAuditProvider.init()
2026-01-15 05:54:51,495 [main] INFO provider.BaseAuditHandler: propPrefix=xasecure.audit.provider
2026-01-15 05:54:51,495 [main] INFO provider.BaseAuditHandler: providerName=summary
2026-01-15 05:54:51,495 [main] INFO provider.BaseAuditHandler: xasecure.audit.log.status.log.enabled=false
2026-01-15 05:54:51,496 [main] INFO provider.BaseAuditHandler: xasecure.audit.log.status.log.interval.sec=300
2026-01-15 05:54:51,496 [main] INFO provider.BaseAuditHandler: xasecure.audit.provider.status.log.enabled=false
2026-01-15 05:54:51,496 [main] INFO provider.BaseAuditHandler: xasecure.audit.provider.status.log.interval.sec=300
2026-01-15 05:54:51,496 [main] INFO queue.AuditQueue: File spool is disabled for summary
2026-01-15 05:54:51,496 [main] INFO queue.AuditSummaryQueue: maxSummaryInterval=5000, name=summary
2026-01-15 05:54:51,498 [main] INFO queue.AuditQueue: BaseAuditProvider.init()
2026-01-15 05:54:51,499 [main] INFO provider.BaseAuditHandler: BaseAuditProvider.init()
2026-01-15 05:54:51,499 [main] INFO provider.BaseAuditHandler: propPrefix=xasecure.audit.provider.async
2026-01-15 05:54:51,499 [main] INFO provider.BaseAuditHandler: providerName=async
2026-01-15 05:54:51,499 [main] INFO provider.BaseAuditHandler: xasecure.audit.log.status.log.enabled=false
2026-01-15 05:54:51,499 [main] INFO provider.BaseAuditHandler: xasecure.audit.log.status.log.interval.sec=300
2026-01-15 05:54:51,499 [main] INFO provider.BaseAuditHandler: xasecure.audit.provider.async.status.log.enabled=false
2026-01-15 05:54:51,499 [main] INFO provider.BaseAuditHandler: xasecure.audit.provider.async.status.log.interval.sec=300
2026-01-15 05:54:51,499 [main] INFO queue.AuditQueue: File spool is disabled for async
2026-01-15 05:54:51,500 [main] INFO provider.AuditProviderFactory: Starting audit queue ozone.async
2026-01-15 05:54:51,501 [main] INFO queue.AuditBatchQueue: Creating ArrayBlockingQueue with maxSize=1048576
2026-01-15 05:54:51,511 [Ranger async Audit cleanup] INFO provider.AuditProviderFactory: RangerAsyncAuditCleanup: Waiting to audit cleanup start signal
2026-01-15 05:54:51,731 [main] INFO service.RangerBasePlugin: Created PolicyRefresher Thread(PolicyRefresher(serviceName=dev_ozone)-48)
2026-01-15 05:54:52,858 [main] INFO util.RangerRolesProvider: RangerRolesProvider(serviceName=dev_ozone): found updated version. lastKnownRoleVersion=-1; newVersion=1
2026-01-15 05:54:53,303 [main] INFO util.PolicyRefresher: PolicyRefresher(serviceName=dev_ozone): found updated version. lastKnownVersion=-1; newVersion=5
2026-01-15 05:54:53,337 [main] INFO policyengine.PolicyEngine: Policy engine will not perform in place update while processing policies.
2026-01-15 05:54:53,382 [main] INFO policyengine.RangerPolicyRepository: This policy engine contains 3 policy evaluators
2026-01-15 05:54:53,468 [main] WARN conditionevaluator.RangerScriptConditionEvaluator: initScriptEngineCreator(): failed to create engine using plugin-class-loader by creator org.apache.ranger.plugin.util.GraalScriptEngineCreator
2026-01-15 05:54:53,469 [main] WARN conditionevaluator.RangerScriptConditionEvaluator: initScriptEngineCreator(): failed to create engine using plugin-class-loader by creator org.apache.ranger.plugin.util.JavaScriptEngineCreator
2026-01-15 05:54:53,470 [main] INFO conditionevaluator.RangerScriptConditionEvaluator: createScriptEngine(serviceType=tag): no engine creator found
2026-01-15 05:54:53,470 [main] WARN conditionevaluator.RangerScriptConditionEvaluator: createScriptEngine(serviceType=tag): failed to create script engine
2026-01-15 05:54:53,470 [main] ERROR conditionevaluator.RangerScriptConditionEvaluator: failed to initialize condition 'accessed-after-expiry': script engine 'JavaScript' was not created
2026-01-15 05:54:53,470 [main] INFO policyengine.RangerPolicyRepository: This policy engine contains 1 policy evaluators
2026-01-15 05:54:53,476 [main] INFO contextenricher.RangerTagEnricher: Policy-Engine will not use read-write locking to update tags in place when tag-deltas are provided
2026-01-15 05:54:53,477 [main] INFO contextenricher.RangerTagEnricher: Created RangerTagRefresher Thread(RangerTagRefresher(serviceName=dev_ozone)-50)
2026-01-15 05:54:53,683 [main] INFO contextenricher.RangerTagEnricher: Number of duplicate tags removed from the received serviceTags:[0]. Number of tags in the de-duplicated serviceTags :[0].
2026-01-15 05:54:53,684 [main] INFO contextenricher.RangerTagEnricher: There are no tagged resources for service dev_ozone
2026-01-15 05:54:53,684 [main] INFO contextenricher.RangerTagEnricher$RangerTagRefresher: RangerTagRefresher(serviceName=dev_ozone).populateTags() - Updated tags-cache to new version of tags, lastKnownVersion=-1; newVersion=1
2026-01-15 05:54:53,703 [main] INFO service.RangerBasePlugin: Switching policy engine from [-1]
2026-01-15 05:54:53,703 [main] INFO service.RangerBasePlugin: Switched policy engine to [5]
2026-01-15 05:54:53,719 [main] INFO acl.OzoneAuthorizerFactory: om1: Authorizer for OM is class org.apache.ranger.authorization.ozone.authorizer.RangerOzoneAuthorizer
2026-01-15 05:54:53,787 [main] INFO om.OmSnapshotManager: Ozone filesystem snapshot feature is enabled.
2026-01-15 05:54:53,831 [main] WARN server.ServerUtils: ozone.om.snapshot.diff.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2026-01-15 05:54:53,897 [main] INFO utils.NativeLibraryLoader: Loading Library: ozone_rocksdb_tools
2026-01-15 05:54:53,898 [main] WARN utils.NativeLibraryLoader: Unable to load library: ozone_rocksdb_tools
java.nio.file.AccessDeniedException: /opt/hadoop/ozone_rocksdb_tools7528231282424682191
	at java.base/sun.nio.fs.UnixException.translateToIOException(UnixException.java:90)
	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:106)
	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:111)
	at java.base/sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:438)
	at java.base/java.nio.file.Files.createDirectory(Files.java:699)
	at java.base/java.nio.file.TempFileHelper.create(TempFileHelper.java:134)
	at java.base/java.nio.file.TempFileHelper.createTempDirectory(TempFileHelper.java:171)
	at java.base/java.nio.file.Files.createTempDirectory(Files.java:976)
	at org.apache.hadoop.hdds.utils.NativeLibraryLoader.copyResourceFromJarToTemp(NativeLibraryLoader.java:174)
	at org.apache.hadoop.hdds.utils.NativeLibraryLoader.loadLibrary(NativeLibraryLoader.java:131)
	at org.apache.hadoop.hdds.utils.db.ManagedRawSSTFileReader.loadLibrary(ManagedRawSSTFileReader.java:55)
	at org.apache.hadoop.ozone.om.snapshot.SnapshotDiffManager.initNativeLibraryForEfficientDiff(SnapshotDiffManager.java:288)
	at org.apache.hadoop.ozone.om.snapshot.SnapshotDiffManager.<init>(SnapshotDiffManager.java:262)
	at org.apache.hadoop.ozone.om.OmSnapshotManager.<init>(OmSnapshotManager.java:256)
	at org.apache.hadoop.ozone.om.OzoneManager.instantiateServices(OzoneManager.java:999)
	at org.apache.hadoop.ozone.om.OzoneManager.<init>(OzoneManager.java:688)
	at org.apache.hadoop.ozone.om.OzoneManager.createOm(OzoneManager.java:882)
	at org.apache.hadoop.ozone.om.OzoneManagerStarter$OMStarterHelper.start(OzoneManagerStarter.java:188)
	at org.apache.hadoop.ozone.om.OzoneManagerStarter.startOm(OzoneManagerStarter.java:85)
	at org.apache.hadoop.ozone.om.OzoneManagerStarter.call(OzoneManagerStarter.java:73)
	at org.apache.hadoop.ozone.om.OzoneManagerStarter.call(OzoneManagerStarter.java:1)
	at picocli.CommandLine.executeUserObject(CommandLine.java:2041)
	at picocli.CommandLine.access$1500(CommandLine.java:148)
	at picocli.CommandLine$RunLast.executeUserObjectOfLastSubcommandWithSameParent(CommandLine.java:2461)
	at picocli.CommandLine$RunLast.handle(CommandLine.java:2453)
	at picocli.CommandLine$RunLast.handle(CommandLine.java:2415)
	at picocli.CommandLine$AbstractParseResultHandler.execute(CommandLine.java:2273)
	at picocli.CommandLine$RunLast.execute(CommandLine.java:2417)
	at picocli.CommandLine.execute(CommandLine.java:2170)
	at org.apache.hadoop.hdds.cli.GenericCli.execute(GenericCli.java:89)
	at org.apache.hadoop.hdds.cli.GenericCli.run(GenericCli.java:80)
	at org.apache.hadoop.ozone.om.OzoneManagerStarter.main(OzoneManagerStarter.java:57)
2026-01-15 05:54:53,899 [main] WARN snapshot.SnapshotDiffManager: Native Library for raw sst file reading loading failed. Fallback to performing a full diff instead. Unable to load library ozone_rocksdb_tools from both java.library.path & resource file libozone_rocksdb_tools.so from jar.
2026-01-15 05:54:53,907 [main] INFO utils.BackgroundService: Starting service SnapshotDiffCleanupService with interval 60000 milliseconds
2026-01-15 05:54:54,230 [main] INFO om.OzoneManager: Created Volume s3v With Owner om required for S3Gateway operations.
2026-01-15 05:54:54,434 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2026-01-15 05:54:54,436 [main] WARN server.ServerUtils: Snapshot directory for Ratis is not configured. Falling back to ozone.metadata.dirs
2026-01-15 05:54:54,565 [main] INFO utils.RDBSnapshotProvider: Cleaning up the candidate dir: /data/metadata/om.ratis.snapshot/om.db.candidate
2026-01-15 05:54:54,565 [main] INFO ratis_snapshot.OmRatisSnapshotProvider: Initializing OM Snapshot Provider
2026-01-15 05:54:54,850 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2026-01-15 05:54:54,890 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2026-01-15 05:54:54,911 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with groupID: omservice and peers: om1:9872, om3:9872, om2:9872
2026-01-15 05:54:54,968 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMSystemAudit to [].
2026-01-15 05:54:54,974 [main] INFO ratis.OzoneManagerStateMachine: TransactionInfo not found in OM DB.
2026-01-15 05:54:55,138 [main] INFO server.RaftServerConfigKeys: raft.server.read.option = DEFAULT (default)
2026-01-15 05:54:55,185 [main] INFO keys.KeyStorage: Reading private key from /data/metadata/om/keys/private.pem.
2026-01-15 05:54:55,532 [main] INFO ssl.ReloadingX509KeyManager: Key manager is loaded with certificate chain
2026-01-15 05:54:55,588 [main] INFO ssl.ReloadingX509KeyManager:   [0]         Version: 3
         SerialNumber: 9
             IssuerDN: CN=scm-sub@scm1.org,OU=08fda86b-ea1f-495c-a0b1-387cb09709b7,O=CID-da209e7d-fe26-447b-88f4-e66ed4e4719a,SERIALNUMBER=2
           Start Date: Thu Jan 15 05:54:33 UTC 2026
           Final Date: Fri Jan 15 05:54:33 UTC 2027
            SubjectDN: CN=om1,OU=08fda86b-ea1f-495c-a0b1-387cb09709b7,O=CID-da209e7d-fe26-447b-88f4-e66ed4e4719a,SERIALNUMBER=9
           Public Key: RSA Public Key [c1:65:b3:cf:27:f8:7f:76:1a:ef:c9:f1:b5:9b:23:43:09:be:af:04],[56:66:d1:a4]
        modulus: 963302f436382f18a92200df0dbe0b60b1806240bf683d401000bf0807b536276bb06fdaa11f3070a6c4c2e56e4f7a935005604fb925cc8c7f724eb4d46d6b61204a2249e42692669fec0f8590d31e437e2a740282f4b7594390c6762cb460f1a283cd09e8f501b85d8092c6f60b6bbc377b59e39fb550451ea085dde2b98e440b5f6396ff0623d842a3be725769dd1e1f9b19fadc99db7fca9599077852dba1005125c2fbe4e3456166b134e5c88f5a8c69ea71c42a28e94548636b3cd6320752ad17087072db45aca7995bf8a4b178251aa0fa34f6aabb4ef369a5fe25918d6bc98e13c5c2957c80d711b55da1d3acd67118d47e62b19b3013328989c8263f
public exponent: 10001

  Signature Algorithm: SHA256WITHRSA
            Signature: 84003b9c37311e3b3c21b863e9c033844183df0a
                       7e51ff4ede3bd54b4a2f58ec65bae675239b6123
                       0a6bc3345d3f3cb991f5224db9699715732733f2
                       6f885185ae66b179e5346a13fb736c3d0a82f489
                       45f16a60de7c2a0f9982df1234cd3b92816de585
                       3920ab890ab2c977a3a41dfd9ddb2e037730b254
                       9f0fc6566f175d0694292410b580b85e582a2bc0
                       c7ae165d40bdbbe9767b26d07764dd6e35f732b5
                       7395bdb77b45e35799a041afd72c53fa4845fd24
                       bbd9d689ec02a18b055c64a39ea61f8daacc9d85
                       57cb1dc09645eb6413c9f61f38c30b227942c90a
                       4c05a0c90e4e73b81cc1553864b0aef104c76e39
                       5d4a0672ef0a3f9645897544d460267b
       Extensions: 
                       critical(true) KeyUsage: 0xb8
                       critical(false) 2.5.29.17 value = Sequence
    Tagged [CONTEXT 7] IMPLICIT
        DER Octet String[4]


2026-01-15 05:54:55,627 [main] INFO ssl.ReloadingX509KeyManager:   [0]         Version: 3
         SerialNumber: 2
             IssuerDN: CN=scm@scm1.org,OU=08fda86b-ea1f-495c-a0b1-387cb09709b7,O=CID-da209e7d-fe26-447b-88f4-e66ed4e4719a,SERIALNUMBER=1
           Start Date: Thu Jan 15 05:53:05 UTC 2026
           Final Date: Sun Feb 23 05:53:05 UTC 2031
            SubjectDN: CN=scm-sub@scm1.org,OU=08fda86b-ea1f-495c-a0b1-387cb09709b7,O=CID-da209e7d-fe26-447b-88f4-e66ed4e4719a,SERIALNUMBER=2
           Public Key: RSA Public Key [09:23:14:52:32:1d:a9:8c:47:28:b0:e9:c0:9d:bf:c5:ac:55:1c:c2],[56:66:d1:a4]
        modulus: a68b1f11960cf29e40295620dbf0c13f646def5ffa50ba10fad726c121cb007360de09aa0c52ea05544dfb0acdc181b5323e3f6c957ac09886b2fbfdc8cc03f379d67b49c42eb19f079a48f86831befd8244f08f6c157ead2c0d5696be3d4868352e08ee43c6e9216994d991e1e37941e262dfb4dc468bdfe3573cca8d0a12d3b55c0ebdb01bb025317d6473a8d573c9a66fceb8ee8a45ea97a8b3cbc5d4e8c9d8d0a1c58af77eb04c16f3c6731b85dff5f030d203f4ecc39c468a5594e078a5b0e1fc106a9f6750726debe196c85e3f643c9d42386b6e6ae25595c3ddf503b64799d05b20d0ba7dc61fc3793e31abed7bdae6d9372d3727f191b5f17b505ccf
public exponent: 10001

  Signature Algorithm: SHA256WITHRSA
            Signature: 58e3f2d527d1801bc6708ffdcec48c726ff9b58e
                       5d1d9aa90e25135f889d681f08644e0d4c8749b3
                       58ebf3b533a3c2877fabb2fe56c2a5d5c09c5839
                       eee884cfb3dc313302be2d4949d861d932d81430
                       dc9dfce20fbf5e251500906262d97b6aaf6856ec
                       3a81ea93bfd51118b34c66049710c929cf6f9b96
                       0e55713bb497283d059ed79aa504d1a5960655fb
                       a160fb7c0450efdeccf330c6dfb6fbf7065290ff
                       1b82d48a954a84e5570613fc25dd49ec01049328
                       750bd8ceb7394cceb49c8804f8b757fea93d543b
                       44d446884d06577c53c72386a2a682c9ca3b2e43
                       df2691f9366240105931300e3a21887047cb7566
                       7b351709eb157b83ab78b9996cab2d7b
       Extensions: 
                       critical(true) KeyUsage: 0xbe
                       critical(false) 2.5.29.17 value = Sequence
    Tagged [CONTEXT 7] IMPLICIT
        DER Octet String[4]
    Tagged [CONTEXT 2] IMPLICIT
        DER Octet String[8]

                       critical(true) BasicConstraints: isCa(true)

2026-01-15 05:54:55,700 [main] INFO ssl.ReloadingX509KeyManager:   [0]         Version: 3
         SerialNumber: 1
             IssuerDN: CN=scm@scm1.org,OU=08fda86b-ea1f-495c-a0b1-387cb09709b7,O=CID-da209e7d-fe26-447b-88f4-e66ed4e4719a,SERIALNUMBER=1
           Start Date: Thu Jan 15 05:53:04 UTC 2026
           Final Date: Sun Feb 23 05:53:04 UTC 2031
            SubjectDN: CN=scm@scm1.org,OU=08fda86b-ea1f-495c-a0b1-387cb09709b7,O=CID-da209e7d-fe26-447b-88f4-e66ed4e4719a,SERIALNUMBER=1
           Public Key: RSA Public Key [14:34:be:85:a6:92:05:12:38:b7:7d:0c:a9:8c:d9:4e:66:35:e6:3a],[56:66:d1:a4]
        modulus: a97e93502480e73e5f24a64c10253369b416610e423d80273897f3a870b4d82a1a00c14481d2a982127af797ca6c1a60fd560c74bdcbf1aa9c6ff3ac114da75259419fe2c1a12eedaccf78b5081681fa983f459cf9a8db3dea1f69db593c1e68d40987c7b98a5842876584c3804cf632205bdbca20be1fcf21a37e20aedd3abc504f6a28212aae5b00680fcaf923b2d40c7706216df48984f73bacae1f90a9cbb6fc32e4109c836139bf11ec2744b3b5cccb51f9f4cdbf42b7d70186e14cb420fcdd4707bfb735461d0ab07dba6a5734269da39456d76585c7772d5f50e3462ee65bbcb5695de430e01b82b400a7b0bb997b54e513f4e6625190da14b92aeed5
public exponent: 10001

  Signature Algorithm: SHA256WITHRSA
            Signature: 36b66767d499115e3989da63a0def1baf2264b3a
                       2f491065e6be538b5a77e3ff59f12217ee40bc4a
                       37a1d781bd6b91cd93d27f171afa25b2bba48f40
                       bca67a216ebe25906da070ff828a9ceafa76224c
                       abac2d4d1a82b10deabdbc794b6d25a4848583d0
                       d3b466010ce6fdc70f27c06026ee7fc382532bdc
                       69fdf8312121ba1007c1d39f5d3c942e687544a2
                       6904f8e2e58d9570cb4bfb404695bcc0faf5a0fa
                       4993dad0480ec98a1adde0e89a720588ae86ad1b
                       287be2ae6d24c846ff201735f714a39917ca9950
                       b6225a6e96ed786b83c2f5e79d873ddded3d3052
                       76859d630275f0d39d4e1822cb7c1845a28bb81a
                       00a4032516679f2a055866c40c8c6395
       Extensions: 
                       critical(true) BasicConstraints: isCa(true)
                       critical(true) KeyUsage: 0x6
                       critical(false) 2.5.29.17 value = Sequence
    Tagged [CONTEXT 7] IMPLICIT
        DER Octet String[4]
    Tagged [CONTEXT 2] IMPLICIT
        DER Octet String[8]


2026-01-15 05:54:55,781 [main] INFO ssl.ReloadingX509TrustManager: Trust manager is loaded with certificates
2026-01-15 05:54:55,783 [main] INFO ssl.ReloadingX509TrustManager:   [0]         Version: 3
         SerialNumber: 1
             IssuerDN: CN=scm@scm1.org,OU=08fda86b-ea1f-495c-a0b1-387cb09709b7,O=CID-da209e7d-fe26-447b-88f4-e66ed4e4719a,SERIALNUMBER=1
           Start Date: Thu Jan 15 05:53:04 UTC 2026
           Final Date: Sun Feb 23 05:53:04 UTC 2031
            SubjectDN: CN=scm@scm1.org,OU=08fda86b-ea1f-495c-a0b1-387cb09709b7,O=CID-da209e7d-fe26-447b-88f4-e66ed4e4719a,SERIALNUMBER=1
           Public Key: RSA Public Key [14:34:be:85:a6:92:05:12:38:b7:7d:0c:a9:8c:d9:4e:66:35:e6:3a],[56:66:d1:a4]
        modulus: a97e93502480e73e5f24a64c10253369b416610e423d80273897f3a870b4d82a1a00c14481d2a982127af797ca6c1a60fd560c74bdcbf1aa9c6ff3ac114da75259419fe2c1a12eedaccf78b5081681fa983f459cf9a8db3dea1f69db593c1e68d40987c7b98a5842876584c3804cf632205bdbca20be1fcf21a37e20aedd3abc504f6a28212aae5b00680fcaf923b2d40c7706216df48984f73bacae1f90a9cbb6fc32e4109c836139bf11ec2744b3b5cccb51f9f4cdbf42b7d70186e14cb420fcdd4707bfb735461d0ab07dba6a5734269da39456d76585c7772d5f50e3462ee65bbcb5695de430e01b82b400a7b0bb997b54e513f4e6625190da14b92aeed5
public exponent: 10001

  Signature Algorithm: SHA256WITHRSA
            Signature: 36b66767d499115e3989da63a0def1baf2264b3a
                       2f491065e6be538b5a77e3ff59f12217ee40bc4a
                       37a1d781bd6b91cd93d27f171afa25b2bba48f40
                       bca67a216ebe25906da070ff828a9ceafa76224c
                       abac2d4d1a82b10deabdbc794b6d25a4848583d0
                       d3b466010ce6fdc70f27c06026ee7fc382532bdc
                       69fdf8312121ba1007c1d39f5d3c942e687544a2
                       6904f8e2e58d9570cb4bfb404695bcc0faf5a0fa
                       4993dad0480ec98a1adde0e89a720588ae86ad1b
                       287be2ae6d24c846ff201735f714a39917ca9950
                       b6225a6e96ed786b83c2f5e79d873ddded3d3052
                       76859d630275f0d39d4e1822cb7c1845a28bb81a
                       00a4032516679f2a055866c40c8c6395
       Extensions: 
                       critical(true) BasicConstraints: isCa(true)
                       critical(true) KeyUsage: 0x6
                       critical(false) 2.5.29.17 value = Sequence
    Tagged [CONTEXT 7] IMPLICIT
        DER Octet String[4]
    Tagged [CONTEXT 2] IMPLICIT
        DER Octet String[8]


2026-01-15 05:54:55,790 [main] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
2026-01-15 05:54:55,791 [main] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
2026-01-15 05:54:55,812 [main] INFO server.RaftServer: Starting Apache Ratis Client -- RaftServerProxy om1
2026-01-15 05:54:55,812 [main] INFO server.RaftServer:                version: 3.2.1
2026-01-15 05:54:55,812 [main] INFO server.RaftServer:                    url: git@github.com:onesizefitsquorum/ratis.git
2026-01-15 05:54:55,812 [main] INFO server.RaftServer:               revision: 07a340e37662b1f0c9fd2dfde79fccb728060d34
2026-01-15 05:54:55,812 [main] INFO server.RaftServer:                   java: OpenJDK 64-Bit Server VM 21.0.2+13-58
2026-01-15 05:54:55,812 [main] INFO server.RaftServer:                   user: hadoop
2026-01-15 05:54:55,813 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
2026-01-15 05:54:55,950 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2026-01-15 05:54:55,951 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9872 (fallback to raft.grpc.server.port)
2026-01-15 05:54:55,951 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2026-01-15 05:54:55,952 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9872 (fallback to raft.grpc.server.port)
2026-01-15 05:54:55,952 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
2026-01-15 05:54:55,952 [main] INFO server.GrpcServicesImpl: raft.grpc.message.size.max = 34603008 (custom)
2026-01-15 05:54:55,955 [main] INFO server.GrpcServicesImpl: raft.grpc.flow.control.window = 1MB (=1048576) (default)
2026-01-15 05:54:55,956 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
2026-01-15 05:54:55,964 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
2026-01-15 05:54:55,969 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
2026-01-15 05:54:55,970 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
2026-01-15 05:54:56,081 [main] INFO server.GrpcServicesImpl: Setting TLS for 0.0.0.0/0.0.0.0:9872
2026-01-15 05:54:56,184 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
2026-01-15 05:54:56,186 [main] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
2026-01-15 05:54:56,186 [main] INFO server.RaftServerConfigKeys: raft.server.close.threshold = 60s (default)
2026-01-15 05:54:56,186 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2026-01-15 05:54:56,189 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/om.ratis] (custom)
2026-01-15 05:54:56,190 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
2026-01-15 05:54:56,190 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
2026-01-15 05:54:56,207 [main] INFO server.RaftServer: om1: addNew group-D66704EFC61C:[om1|om1:9872, om3|om3:9872, om2|om2:9872] returns group-D66704EFC61C:java.util.concurrent.CompletableFuture@38950d4b[Not completed]
2026-01-15 05:54:56,207 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
2026-01-15 05:54:56,227 [om1-groupManagement] INFO server.RaftServer$Division: om1: new RaftServerImpl for group-D66704EFC61C:[om1|om1:9872, om3|om3:9872, om2|om2:9872] with OzoneManagerStateMachine-1:uninitialized
2026-01-15 05:54:56,232 [om1-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
2026-01-15 05:54:56,232 [om1-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
2026-01-15 05:54:56,232 [om1-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
2026-01-15 05:54:56,232 [om1-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
2026-01-15 05:54:56,233 [om1-groupManagement] INFO server.RaftServerConfigKeys: raft.server.leaderelection.member.majority-add = false (default)
2026-01-15 05:54:56,236 [main] INFO om.OzoneManager: Creating RPC Server
2026-01-15 05:54:56,246 [om1-groupManagement] INFO server.RaftServer$Division: om1@group-D66704EFC61C: ConfigurationManager, init=conf: {index: -1, cur=peers:[om1|om1:9872, om3|om3:9872, om2|om2:9872]|listeners:[], old=null}, confs=<EMPTY_MAP>
2026-01-15 05:54:56,262 [om1-groupManagement] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
2026-01-15 05:54:56,266 [om1-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.timeout = 10s (default)
2026-01-15 05:54:56,275 [om1-groupManagement] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
2026-01-15 05:54:56,275 [om1-groupManagement] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100ms (default)
2026-01-15 05:54:56,317 [om1-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2026-01-15 05:54:56,502 [om1-groupManagement] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
2026-01-15 05:54:56,505 [om1-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
2026-01-15 05:54:56,506 [om1-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
2026-01-15 05:54:56,507 [om1-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
2026-01-15 05:54:56,508 [om1-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
2026-01-15 05:54:57,816 [main] INFO reflections.Reflections: Reflections took 1460 ms to scan 8 urls, producing 24 keys and 938 values
2026-01-15 05:54:58,339 [main] INFO ipc_.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc_.DefaultRpcScheduler, ipcBackoff: false.
2026-01-15 05:54:58,347 [main] INFO ipc_.Server: Listener at om1:9862
2026-01-15 05:54:58,348 [Socket Reader #1 for port 9862] INFO ipc_.Server: Starting Socket Reader #1 for port 9862
2026-01-15 05:54:58,349 [Socket Reader #2 for port 9862] INFO ipc_.Server: Starting Socket Reader #2 for port 9862
2026-01-15 05:54:58,349 [Socket Reader #3 for port 9862] INFO ipc_.Server: Starting Socket Reader #3 for port 9862
2026-01-15 05:54:58,351 [Socket Reader #4 for port 9862] INFO ipc_.Server: Starting Socket Reader #4 for port 9862
2026-01-15 05:54:58,352 [Socket Reader #5 for port 9862] INFO ipc_.Server: Starting Socket Reader #5 for port 9862
2026-01-15 05:54:58,356 [Socket Reader #6 for port 9862] INFO ipc_.Server: Starting Socket Reader #6 for port 9862
2026-01-15 05:54:58,357 [Socket Reader #7 for port 9862] INFO ipc_.Server: Starting Socket Reader #7 for port 9862
2026-01-15 05:54:58,358 [Socket Reader #8 for port 9862] INFO ipc_.Server: Starting Socket Reader #8 for port 9862
2026-01-15 05:54:58,358 [Socket Reader #9 for port 9862] INFO ipc_.Server: Starting Socket Reader #9 for port 9862
2026-01-15 05:54:58,361 [Socket Reader #10 for port 9862] INFO ipc_.Server: Starting Socket Reader #10 for port 9862
2026-01-15 05:54:59,459 [main] INFO om.OzoneManager: OzoneManager RPC server is listening at om1/172.25.0.111:9862
2026-01-15 05:54:59,461 [main] INFO keys.KeyStorage: Reading public key from /data/metadata/om/keys/public.pem.
2026-01-15 05:54:59,463 [main] INFO om.OzoneManager: Starting secret key client.
2026-01-15 05:54:59,602 [main] INFO symmetric.DefaultSecretKeySignerClient: Initial secret key fetched from SCM: SecretKey(id = a8bf5bbb-563b-4536-8bba-4b90220db084, creation at: 2026-01-15T05:53:25.771Z, expire at: 2026-01-15T06:53:25.771Z).
2026-01-15 05:54:59,603 [main] INFO symmetric.DefaultSecretKeySignerClient: Scheduling SecretKeyPoller with initial delay of PT3M26.16781281S and interval of PT1M
2026-01-15 05:54:59,604 [main] INFO om.OzoneManager: Starting OM delegation token secret manager
2026-01-15 05:54:59,606 [main] INFO security.OzoneDelegationTokenSecretManager: Updated current master key for generating tokens. Cert id 9, Master key id 1
2026-01-15 05:54:59,609 [main] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om1 at port 9872
2026-01-15 05:54:59,609 [om1-ExpiredTokenRemover] INFO security.OzoneDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=1 min(s)
2026-01-15 05:54:59,616 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
2026-01-15 05:54:59,617 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
2026-01-15 05:54:59,634 [om1-impl-thread1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/om.ratis/5cb24680-b9e7-3c90-a862-d66704efc61c does not exist. Creating ...
2026-01-15 05:54:59,643 [om1-impl-thread1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/om.ratis/5cb24680-b9e7-3c90-a862-d66704efc61c/in_use.lock acquired by nodename 7@om1
2026-01-15 05:54:59,653 [om1-impl-thread1] INFO storage.RaftStorage: Storage directory /data/metadata/om.ratis/5cb24680-b9e7-3c90-a862-d66704efc61c has been successfully formatted.
2026-01-15 05:54:59,660 [om1-impl-thread1] INFO ratis.OzoneManagerStateMachine: om1: initialize group-D66704EFC61C with <INITIAL_VALUE>
2026-01-15 05:54:59,664 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
2026-01-15 05:54:59,675 [om1-impl-thread1] INFO server.RaftServer$Division: om1@group-D66704EFC61C: getLatestSnapshot(OzoneManagerStateMachine-1:om1:group-D66704EFC61C) returns 0#-1
2026-01-15 05:54:59,675 [om1-impl-thread1] INFO raftlog.RaftLog: om1@group-D66704EFC61C-SegmentedRaftLog: snapshotIndexFromStateMachine = -1
2026-01-15 05:54:59,676 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
2026-01-15 05:54:59,677 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2026-01-15 05:54:59,678 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
2026-01-15 05:54:59,681 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 67108864 (custom)
2026-01-15 05:54:59,687 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
2026-01-15 05:54:59,687 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2026-01-15 05:54:59,690 [om1-impl-thread1] INFO util.AwaitToRun: Thread[#84,om1@group-D66704EFC61C-cacheEviction-AwaitToRun,5,main] started
2026-01-15 05:54:59,696 [om1-impl-thread1] INFO segmented.SegmentedRaftLogWorker: new om1@group-D66704EFC61C-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/om.ratis/5cb24680-b9e7-3c90-a862-d66704efc61c
2026-01-15 05:54:59,696 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2026-01-15 05:54:59,696 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
2026-01-15 05:54:59,698 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (default)
2026-01-15 05:54:59,698 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
2026-01-15 05:54:59,699 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
2026-01-15 05:54:59,699 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
2026-01-15 05:54:59,700 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2026-01-15 05:54:59,702 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554440 (custom)
2026-01-15 05:54:59,723 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
2026-01-15 05:54:59,724 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
2026-01-15 05:54:59,724 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
2026-01-15 05:54:59,734 [om1-impl-thread1] INFO segmented.SegmentedRaftLogWorker: om1@group-D66704EFC61C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2026-01-15 05:54:59,735 [om1-impl-thread1] INFO segmented.SegmentedRaftLogWorker: om1@group-D66704EFC61C-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2026-01-15 05:54:59,737 [om1-impl-thread1] INFO server.RaftServer$Division: om1@group-D66704EFC61C: start as a follower, conf=conf: {index: -1, cur=peers:[om1|om1:9872, om3|om3:9872, om2|om2:9872]|listeners:[], old=null}
2026-01-15 05:54:59,740 [om1-impl-thread1] INFO server.RaftServer$Division: om1@group-D66704EFC61C: changes role from      null to FOLLOWER at term 0 for startAsFollower
2026-01-15 05:54:59,742 [om1-impl-thread1] INFO impl.RoleInfo: om1: start om1@group-D66704EFC61C-FollowerState
2026-01-15 05:54:59,743 [om1@group-D66704EFC61C-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2026-01-15 05:54:59,743 [om1@group-D66704EFC61C-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2026-01-15 05:54:59,745 [om1-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D66704EFC61C,id=om1
2026-01-15 05:54:59,745 [om1-impl-thread1] INFO util.JmxRegister: register mxBean class org.apache.ratis.server.impl.RaftServerJmxAdapter as Ratis:service=RaftServer,group=group-D66704EFC61C,id=om1
2026-01-15 05:54:59,749 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.trigger-when-stop.enabled = true (default)
2026-01-15 05:54:59,749 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.trigger-when-remove.enabled = true (default)
2026-01-15 05:54:59,749 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
2026-01-15 05:54:59,751 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
2026-01-15 05:54:59,752 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
2026-01-15 05:54:59,752 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
2026-01-15 05:54:59,763 [om1-impl-thread1] INFO server.RaftServer$Division: om1@group-D66704EFC61C: Successfully started.
2026-01-15 05:54:59,763 [main] INFO server.RaftServer: om1: start RPC server
2026-01-15 05:54:59,886 [main] INFO server.GrpcServicesImpl: om1: GrpcServicesImpl started, listening on 9872
2026-01-15 05:54:59,890 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-om1: Started
2026-01-15 05:54:59,895 [main] INFO om.OzoneManager: Version File has different layout version (9) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
2026-01-15 05:55:00,061 [main] INFO client.ScmTopologyClient: Initial network topology fetched from SCM: /.
2026-01-15 05:55:00,074 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-2.2.0-SNAPSHOT.jar!/network-topology-default.xml]
2026-01-15 05:55:00,075 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
2026-01-15 05:55:00,164 [main] INFO utils.BackgroundService: Starting service KeyDeletingService with interval 60000 milliseconds
2026-01-15 05:55:00,173 [main] INFO utils.BackgroundService: Starting service DirectoryDeletingService with interval 60000 milliseconds
2026-01-15 05:55:00,178 [main] INFO utils.BackgroundService: Starting service OpenKeyCleanupService with interval 86400000 milliseconds
2026-01-15 05:55:00,182 [main] INFO om.KeyManagerImpl: SstFilteringService is enabled. Note SstFilteringService is deprecated in favor of SnapshotDefragService and may be removed in a future release.
2026-01-15 05:55:00,184 [main] INFO utils.BackgroundService: Starting service SstFilteringService with interval 60000 milliseconds
2026-01-15 05:55:00,186 [main] INFO om.KeyManagerImpl: SnapshotDefragService is disabled. Snapshot defragmentation will not run periodically.
2026-01-15 05:55:00,192 [main] INFO utils.BackgroundService: Starting service SnapshotDeletingService with interval 30000 milliseconds
2026-01-15 05:55:00,197 [main] INFO utils.BackgroundService: Starting service MultipartUploadCleanupService with interval 86400000 milliseconds
2026-01-15 05:55:00,233 [main] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
2026-01-15 05:55:00,234 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
2026-01-15 05:55:00,234 [main] INFO http.BaseHttpServer: HttpAuthType: ozone.om.http.auth.type = kerberos
2026-01-15 05:55:00,328 [main] INFO util.log: Logging initialized @20716ms to org.eclipse.jetty.util.log.Slf4jLog
2026-01-15 05:55:00,607 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2026-01-15 05:55:00,611 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context ozoneManager
2026-01-15 05:55:00,614 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
2026-01-15 05:55:00,614 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
2026-01-15 05:55:00,620 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.om.http.auth.kerberos.principal keytabKey: ozone.om.http.auth.kerberos.keytab
2026-01-15 05:55:00,680 [main] INFO http.BaseHttpServer: HTTP server of ozoneManager uses base directory /tmp/ozone_http
2026-01-15 05:55:00,697 [main] INFO http.HttpServer2: Jetty bound to port 9874
2026-01-15 05:55:00,698 [main] INFO server.Server: jetty-9.4.58.v20250814; built: 2025-08-14T02:28:49.637Z; git: 8f1440587e9e4ae7db3d74cf205643f3d707148d; jvm 21.0.2+13-58
2026-01-15 05:55:00,753 [main] INFO server.session: DefaultSessionIdManager workerName=node0
2026-01-15 05:55:00,754 [main] INFO server.session: No SessionScavenger set, using defaults
2026-01-15 05:55:00,755 [main] INFO server.session: node0 Scavenging every 660000ms
2026-01-15 05:55:00,780 [main] WARN server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /etc/security/http_secret
2026-01-15 05:55:00,794 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
2026-01-15 05:55:00,802 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@26b78c2{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
2026-01-15 05:55:00,807 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@8108420{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-2.2.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2026-01-15 05:55:01,011 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
2026-01-15 05:55:01,031 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@622b91dc{ozoneManager,/,file:///tmp/ozone_http/jetty-0_0_0_0-9874-ozone-manager-2_2_0-SNAPSHOT_jar-_-any-16016390548705765111/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-2.2.0-SNAPSHOT.jar!/webapps/ozoneManager}
2026-01-15 05:55:01,044 [main] INFO server.AbstractConnector: Started ServerConnector@20bc4c09{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
2026-01-15 05:55:01,046 [main] INFO server.Server: Started @21432ms
2026-01-15 05:55:01,047 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
2026-01-15 05:55:01,048 [main] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://om1:9874
2026-01-15 05:55:01,048 [IPC Server Responder] INFO ipc_.Server: IPC Server Responder: starting
2026-01-15 05:55:01,048 [IPC Server listener on 9862] INFO ipc_.Server: IPC Server listener on 9862: starting
2026-01-15 05:55:01,184 [Socket Reader #3 for port 9862] INFO ipc_.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:37029
2026-01-15 05:55:01,188 [Socket Reader #3 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
2026-01-15 05:55:01,235 [main] INFO om.TrashPolicyOzone: The configured checkpoint interval is 0 minutes. Using an interval of 1 minutes that is used for deletion instead
2026-01-15 05:55:01,237 [main] INFO om.TrashPolicyOzone: Ozone Manager trash configuration: Deletion interval = 1 minutes, Emptier interval = 1 minutes.
2026-01-15 05:55:01,282 [Socket Reader #2 for port 9862] INFO ipc_.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55974
2026-01-15 05:55:01,302 [main] INFO om.GrpcOzoneManagerServer: GrpcOzoneManagerServer is started using port 8981
2026-01-15 05:55:01,305 [Socket Reader #2 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
2026-01-15 05:55:04,892 [om1@group-D66704EFC61C-FollowerState] INFO impl.FollowerState: om1@group-D66704EFC61C-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5149962507ns, electionTimeout:5148ms
2026-01-15 05:55:04,892 [om1@group-D66704EFC61C-FollowerState] INFO impl.RoleInfo: om1: shutdown om1@group-D66704EFC61C-FollowerState
2026-01-15 05:55:04,892 [om1@group-D66704EFC61C-FollowerState] INFO server.RaftServer$Division: om1@group-D66704EFC61C: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2026-01-15 05:55:04,895 [om1@group-D66704EFC61C-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = true (default)
2026-01-15 05:55:04,895 [om1@group-D66704EFC61C-FollowerState] INFO impl.RoleInfo: om1: start om1@group-D66704EFC61C-LeaderElection1
2026-01-15 05:55:04,898 [om1@group-D66704EFC61C-LeaderElection1] INFO impl.LeaderElection: om1@group-D66704EFC61C-LeaderElection1 PRE_VOTE round 0: submit vote requests at term 0 for conf: {index: -1, cur=peers:[om1|om1:9872, om3|om3:9872, om2|om2:9872]|listeners:[], old=null}
2026-01-15 05:55:04,915 [om1@group-D66704EFC61C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2026-01-15 05:55:04,916 [om1@group-D66704EFC61C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2026-01-15 05:55:04,917 [om1@group-D66704EFC61C-LeaderElection1-1] INFO server.GrpcServerProtocolClient: Build channel for om3|om3:9872
2026-01-15 05:55:04,917 [om1@group-D66704EFC61C-LeaderElection1-2] INFO server.GrpcServerProtocolClient: Build channel for om2|om2:9872
2026-01-15 05:55:05,541 [om1@group-D66704EFC61C-LeaderElection1] INFO impl.LeaderElection: om1@group-D66704EFC61C-LeaderElection1: PRE_VOTE PASSED received 1 response(s) and 0 exception(s):
2026-01-15 05:55:05,542 [om1@group-D66704EFC61C-LeaderElection1] INFO impl.LeaderElection:   Response 0: om1<-om2#0:OK-t0-last:<INITIAL_VALUE>
2026-01-15 05:55:05,542 [om1@group-D66704EFC61C-LeaderElection1] INFO impl.LeaderElection: om1@group-D66704EFC61C-LeaderElection1 PRE_VOTE round 0: result PASSED
2026-01-15 05:55:05,546 [om1@group-D66704EFC61C-LeaderElection1] INFO impl.LeaderElection: om1@group-D66704EFC61C-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for conf: {index: -1, cur=peers:[om1|om1:9872, om3|om3:9872, om2|om2:9872]|listeners:[], old=null}
2026-01-15 05:55:05,549 [om1@group-D66704EFC61C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2026-01-15 05:55:05,549 [om1@group-D66704EFC61C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2026-01-15 05:55:05,567 [om1@group-D66704EFC61C-LeaderElection1] INFO impl.LeaderElection: om1@group-D66704EFC61C-LeaderElection1: ELECTION PASSED received 1 response(s) and 0 exception(s):
2026-01-15 05:55:05,568 [om1@group-D66704EFC61C-LeaderElection1] INFO impl.LeaderElection:   Response 0: om1<-om2#0:OK-t1-last:<INITIAL_VALUE>
2026-01-15 05:55:05,572 [om1@group-D66704EFC61C-LeaderElection1] INFO impl.LeaderElection: om1@group-D66704EFC61C-LeaderElection1 ELECTION round 0: result PASSED
2026-01-15 05:55:05,572 [om1@group-D66704EFC61C-LeaderElection1] INFO impl.RoleInfo: om1: shutdown om1@group-D66704EFC61C-LeaderElection1
2026-01-15 05:55:05,573 [om1@group-D66704EFC61C-LeaderElection1] INFO server.RaftServer$Division: om1@group-D66704EFC61C: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2026-01-15 05:55:05,580 [om1@group-D66704EFC61C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
2026-01-15 05:55:05,580 [om1@group-D66704EFC61C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.timeout = 15600ms (fallback to raft.server.rpc.timeout.max)
2026-01-15 05:55:05,584 [om1@group-D66704EFC61C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
2026-01-15 05:55:05,584 [om1@group-D66704EFC61C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
2026-01-15 05:55:05,590 [om1@group-D66704EFC61C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
2026-01-15 05:55:05,590 [om1@group-D66704EFC61C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
2026-01-15 05:55:05,591 [om1@group-D66704EFC61C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
2026-01-15 05:55:05,598 [om1@group-D66704EFC61C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.read.leader.lease.enabled = false (default)
2026-01-15 05:55:05,601 [om1@group-D66704EFC61C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2026-01-15 05:55:05,602 [om1@group-D66704EFC61C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.log-metadata.enabled = false (custom)
2026-01-15 05:55:05,602 [om1@group-D66704EFC61C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
2026-01-15 05:55:05,615 [om1@group-D66704EFC61C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2026-01-15 05:55:05,615 [om1@group-D66704EFC61C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
2026-01-15 05:55:05,617 [om1@group-D66704EFC61C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.wait-time.min = 0ms (custom)
2026-01-15 05:55:05,619 [om1@group-D66704EFC61C-LeaderElection1] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 8 (default)
2026-01-15 05:55:05,619 [om1@group-D66704EFC61C-LeaderElection1] INFO grpc.GrpcConfigKeys: raft.grpc.server.install_snapshot.request.element-limit = 8 (default)
2026-01-15 05:55:05,619 [om1@group-D66704EFC61C-LeaderElection1] INFO grpc.GrpcConfigKeys: raft.grpc.server.install_snapshot.request.timeout = 3000ms (default)
2026-01-15 05:55:05,619 [om1@group-D66704EFC61C-LeaderElection1] INFO grpc.GrpcConfigKeys: raft.grpc.server.log-message.batch.duration = 5s (default)
2026-01-15 05:55:05,628 [om1@group-D66704EFC61C-LeaderElection1] INFO impl.RoleInfo: om1: start om1@group-D66704EFC61C-LeaderStateImpl
2026-01-15 05:55:05,628 [om1@group-D66704EFC61C-LeaderElection1] INFO server.RaftServer$Division: om1@group-D66704EFC61C: set firstElectionSinceStartup to false for becomeLeader
2026-01-15 05:55:05,630 [Warm Up EDEK Cache Thread #0] INFO om.OzoneManager: Warming up 0 EDEKs... (initialDelay=3000, retryInterval=1000, maxRetries=10)
2026-01-15 05:55:05,635 [om1@group-D66704EFC61C-LeaderElection1] INFO ratis.OzoneManagerStateMachine: om1@group-D66704EFC61C: leader changed to om1
2026-01-15 05:55:05,635 [om1@group-D66704EFC61C-LeaderElection1] INFO server.RaftServer$Division: om1@group-D66704EFC61C: change Leader from null to om1 at term 1 for becomeLeader, leader elected after 9366ms
2026-01-15 05:55:05,655 [om1@group-D66704EFC61C-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: om1@group-D66704EFC61C-SegmentedRaftLogWorker: Starting segment from index:0
2026-01-15 05:55:05,676 [om1@group-D66704EFC61C-LeaderElection1] INFO server.RaftServer$Division: om1@group-D66704EFC61C: set configuration conf: {index: 0, cur=peers:[om1|om1:9872, om3|om3:9872, om2|om2:9872]|listeners:[], old=null}
2026-01-15 05:55:05,750 [om1@group-D66704EFC61C-SegmentedRaftLogWorker] INFO segmented.BufferedWriteChannel: open log_inprogress_0 at position 0
2026-01-15 05:55:05,760 [om1@group-D66704EFC61C-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om1@group-D66704EFC61C-SegmentedRaftLogWorker: created new log segment /data/metadata/om.ratis/5cb24680-b9e7-3c90-a862-d66704efc61c/current/log_inprogress_0
2026-01-15 05:55:05,881 [om1@group-D66704EFC61C-StateMachineUpdater] INFO ratis.OzoneManagerStateMachine: notifyConfigurationChanged from Ratis: term=1, index=0, New Peer list: om1(om1:9872), om3(om3:9872), om2(om2:9872), New Listener list
2026-01-15 05:55:05,883 [om1@group-D66704EFC61C-StateMachineUpdater] INFO server.RaftServer$Division: Leader om1@group-D66704EFC61C-LeaderStateImpl is ready since appliedIndex == startIndex == 0
2026-01-15 05:55:08,630 [Warm Up EDEK Cache Thread #0] INFO om.OzoneManager: Successfully warmed up 0 EDEKs.
2026-01-15 05:55:09,775 [Socket Reader #4 for port 9862] INFO ipc_.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39246
2026-01-15 05:55:09,778 [Socket Reader #4 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
2026-01-15 05:55:14,742 [Socket Reader #5 for port 9862] INFO ipc_.Server: Auth successful for hdfs/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.120:35339
2026-01-15 05:55:14,748 [Socket Reader #5 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for hdfs/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
2026-01-15 05:55:15,483 [om1-OMStateMachineApplyTransactionThread - 0] WARN helpers.OzoneAclUtil: Failed to get primary group from user hdfs (auth:SIMPLE)
2026-01-15 05:55:15,486 [om1-OMStateMachineApplyTransactionThread - 0] INFO volume.OMVolumeCreateRequest: created volume:vol1 for user:hdfs
2026-01-15 05:55:15,567 [om1-OMStateMachineApplyTransactionThread - 0] WARN helpers.OzoneAclUtil: Failed to get primary group from user hdfs/s3g@EXAMPLE.COM (auth:SIMPLE)
2026-01-15 05:55:15,578 [om1-OMStateMachineApplyTransactionThread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket1 of layout FILE_SYSTEM_OPTIMIZED in volume: vol1
2026-01-15 05:55:16,091 [om1-OMStateMachineApplyTransactionThread - 0] WARN helpers.OzoneAclUtil: Failed to get primary group from user hdfs/s3g@EXAMPLE.COM (auth:SIMPLE)
2026-01-15 05:55:16,094 [om1-OMStateMachineApplyTransactionThread - 0] WARN helpers.OzoneAclUtil: Failed to get primary group from user hdfs/s3g@EXAMPLE.COM (auth:SIMPLE)
2026-01-15 05:55:18,542 [org.apache.ranger.audit.queue.AuditBatchQueue0] INFO xaaudit: {"repoType":201,"repo":"dev_ozone","reqUser":"hdfs","evtTime":"2026-01-15 05:55:16.038","access":"create","resource":"vol1/bucket1/ockg/0","resType":"key","action":"create","result":1,"agent":"ozone","policy":36,"reason":null,"enforcer":"ranger-acl","sess":null,"cliType":null,"cliIP":"172.25.0.120","reqData":"/vol1/bucket1/ockg/0","agentHost":"om1","logType":"RangerAudit","id":"25b3cf5a-ee66-4ab4-8194-6aefbace5864-6","seq_num":13,"event_count":1,"event_dur_ms":1,"tags":[],"datasets":null,"projects":null,"additional_info":"{\"forwarded-ip-addresses\":\"[]\",\"remote-ip-address\":\"172.25.0.120\"}","cluster_name":"","zone_name":null,"policy_version":1}
2026-01-15 05:55:18,542 [org.apache.ranger.audit.queue.AuditBatchQueue0] INFO xaaudit: {"repoType":201,"repo":"dev_ozone","reqUser":"hdfs","evtTime":"2026-01-15 05:55:15.602","access":"read","resource":"vol1/bucket1","resType":"bucket","action":"read","result":1,"agent":"ozone","policy":36,"reason":null,"enforcer":"ranger-acl","sess":null,"cliType":null,"cliIP":"172.25.0.120","reqData":"/vol1/bucket1","agentHost":"om1","logType":"RangerAudit","id":"25b3cf5a-ee66-4ab4-8194-6aefbace5864-4","seq_num":9,"event_count":2,"event_dur_ms":89,"tags":[],"datasets":null,"projects":null,"additional_info":"{\"forwarded-ip-addresses\":\"[]\",\"remote-ip-address\":\"172.25.0.120\"}","cluster_name":"","zone_name":null,"policy_version":1}
2026-01-15 05:55:18,542 [org.apache.ranger.audit.queue.AuditBatchQueue0] INFO xaaudit: {"repoType":201,"repo":"dev_ozone","reqUser":"hdfs","evtTime":"2026-01-15 05:55:15.505","access":"read","resource":"vol1","resType":"volume","action":"read","result":1,"agent":"ozone","policy":36,"reason":null,"enforcer":"ranger-acl","sess":null,"cliType":null,"cliIP":"172.25.0.120","reqData":"/vol1","agentHost":"om1","logType":"RangerAudit","id":"25b3cf5a-ee66-4ab4-8194-6aefbace5864-1","seq_num":3,"event_count":2,"event_dur_ms":88,"tags":[],"datasets":null,"projects":null,"additional_info":"{\"forwarded-ip-addresses\":\"[]\",\"remote-ip-address\":\"172.25.0.120\"}","cluster_name":"","zone_name":null,"policy_version":1}
2026-01-15 05:55:18,542 [org.apache.ranger.audit.queue.AuditBatchQueue0] INFO xaaudit: {"repoType":201,"repo":"dev_ozone","reqUser":"hdfs","evtTime":"2026-01-15 05:55:15.548","access":"create","resource":"vol1/bucket1","resType":"bucket","action":"create","result":1,"agent":"ozone","policy":36,"reason":null,"enforcer":"ranger-acl","sess":null,"cliType":null,"cliIP":"172.25.0.120","reqData":"/vol1/bucket1","agentHost":"om1","logType":"RangerAudit","id":"25b3cf5a-ee66-4ab4-8194-6aefbace5864-2","seq_num":5,"event_count":1,"event_dur_ms":1,"tags":[],"datasets":null,"projects":null,"additional_info":"{\"forwarded-ip-addresses\":\"[]\",\"remote-ip-address\":\"172.25.0.120\"}","cluster_name":"","zone_name":null,"policy_version":1}
2026-01-15 05:55:18,543 [org.apache.ranger.audit.queue.AuditBatchQueue0] INFO xaaudit: {"repoType":201,"repo":"dev_ozone","reqUser":"hdfs","evtTime":"2026-01-15 05:55:15.421","access":"create","resource":"vol1","resType":"volume","action":"create","result":1,"agent":"ozone","policy":36,"reason":null,"enforcer":"ranger-acl","sess":null,"cliType":null,"cliIP":"172.25.0.120","reqData":"/vol1","agentHost":"om1","logType":"RangerAudit","id":"25b3cf5a-ee66-4ab4-8194-6aefbace5864-0","seq_num":1,"event_count":1,"event_dur_ms":1,"tags":[],"datasets":null,"projects":null,"additional_info":"{\"forwarded-ip-addresses\":\"[]\",\"remote-ip-address\":\"172.25.0.120\"}","cluster_name":"","zone_name":null,"policy_version":1}
2026-01-15 05:55:20,357 [Socket Reader #6 for port 9862] INFO ipc_.Server: Auth successful for hdfs/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.120:38287
2026-01-15 05:55:20,358 [Socket Reader #6 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for hdfs/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
2026-01-15 05:55:21,218 [Socket Reader #7 for port 9862] INFO ipc_.Server: Auth successful for hdfs/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.120:43091
2026-01-15 05:55:21,220 [Socket Reader #7 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for hdfs/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
2026-01-15 05:55:21,240 [om1-OMStateMachineApplyTransactionThread - 0] WARN helpers.OzoneAclUtil: Failed to get primary group from user hdfs/s3g@EXAMPLE.COM (auth:SIMPLE)
2026-01-15 05:55:21,240 [om1-OMStateMachineApplyTransactionThread - 0] WARN helpers.OzoneAclUtil: Failed to get primary group from user hdfs/s3g@EXAMPLE.COM (auth:SIMPLE)
2026-01-15 05:55:21,521 [org.apache.ranger.audit.queue.AuditBatchQueue0] INFO xaaudit: {"repoType":201,"repo":"dev_ozone","reqUser":"hdfs","evtTime":"2026-01-15 05:55:21.156","access":"read","resource":"vol1/bucket1","resType":"bucket","action":"read","result":1,"agent":"ozone","policy":36,"reason":null,"enforcer":"ranger-acl","sess":null,"cliType":null,"cliIP":"172.25.0.120","reqData":"/vol1/bucket1","agentHost":"om1","logType":"RangerAudit","id":"25b3cf5a-ee66-4ab4-8194-6aefbace5864-10","seq_num":21,"event_count":2,"event_dur_ms":65,"tags":[],"datasets":null,"projects":null,"additional_info":"{\"forwarded-ip-addresses\":\"[]\",\"remote-ip-address\":\"172.25.0.120\"}","cluster_name":"","zone_name":null,"policy_version":1}
2026-01-15 05:55:21,521 [org.apache.ranger.audit.queue.AuditBatchQueue0] INFO xaaudit: {"repoType":201,"repo":"dev_ozone","reqUser":"hdfs","evtTime":"2026-01-15 05:55:21.125","access":"read","resource":"vol1","resType":"volume","action":"read","result":1,"agent":"ozone","policy":36,"reason":null,"enforcer":"ranger-acl","sess":null,"cliType":null,"cliIP":"172.25.0.120","reqData":"/vol1","agentHost":"om1","logType":"RangerAudit","id":"25b3cf5a-ee66-4ab4-8194-6aefbace5864-8","seq_num":17,"event_count":2,"event_dur_ms":26,"tags":[],"datasets":null,"projects":null,"additional_info":"{\"forwarded-ip-addresses\":\"[]\",\"remote-ip-address\":\"172.25.0.120\"}","cluster_name":"","zone_name":null,"policy_version":1}
2026-01-15 05:55:21,522 [org.apache.ranger.audit.queue.AuditBatchQueue0] INFO xaaudit: {"repoType":201,"repo":"dev_ozone","reqUser":"hdfs","evtTime":"2026-01-15 05:55:21.293","access":"write","resource":"vol1/bucket1/omkg/0","resType":"key","action":"write","result":1,"agent":"ozone","policy":36,"reason":null,"enforcer":"ranger-acl","sess":null,"cliType":null,"cliIP":"172.25.0.120","reqData":"/vol1/bucket1/omkg/0","agentHost":"om1","logType":"RangerAudit","id":"25b3cf5a-ee66-4ab4-8194-6aefbace5864-13","seq_num":27,"event_count":1,"event_dur_ms":1,"tags":[],"datasets":null,"projects":null,"additional_info":"{\"forwarded-ip-addresses\":\"[]\",\"remote-ip-address\":\"172.25.0.120\"}","cluster_name":"","zone_name":null,"policy_version":1}
2026-01-15 05:55:21,522 [org.apache.ranger.audit.queue.AuditBatchQueue0] INFO xaaudit: {"repoType":201,"repo":"dev_ozone","reqUser":"hdfs","evtTime":"2026-01-15 05:55:17.898","access":"write","resource":"vol1/bucket1/ockg/0","resType":"key","action":"write","result":1,"agent":"ozone","policy":36,"reason":null,"enforcer":"ranger-acl","sess":null,"cliType":null,"cliIP":"172.25.0.120","reqData":"/vol1/bucket1/ockg/0","agentHost":"om1","logType":"RangerAudit","id":"25b3cf5a-ee66-4ab4-8194-6aefbace5864-7","seq_num":15,"event_count":1,"event_dur_ms":1,"tags":[],"datasets":null,"projects":null,"additional_info":"{\"forwarded-ip-addresses\":\"[]\",\"remote-ip-address\":\"172.25.0.120\"}","cluster_name":"","zone_name":null,"policy_version":1}
2026-01-15 05:55:21,522 [org.apache.ranger.audit.queue.AuditBatchQueue0] INFO xaaudit: {"repoType":201,"repo":"dev_ozone","reqUser":"hdfs","evtTime":"2026-01-15 05:55:21.229","access":"create","resource":"vol1/bucket1/omkg/0","resType":"key","action":"create","result":1,"agent":"ozone","policy":36,"reason":null,"enforcer":"ranger-acl","sess":null,"cliType":null,"cliIP":"172.25.0.120","reqData":"/vol1/bucket1/omkg/0","agentHost":"om1","logType":"RangerAudit","id":"25b3cf5a-ee66-4ab4-8194-6aefbace5864-12","seq_num":25,"event_count":1,"event_dur_ms":1,"tags":[],"datasets":null,"projects":null,"additional_info":"{\"forwarded-ip-addresses\":\"[]\",\"remote-ip-address\":\"172.25.0.120\"}","cluster_name":"","zone_name":null,"policy_version":1}
2026-01-15 05:55:23,785 [Socket Reader #8 for port 9862] INFO ipc_.Server: Auth successful for hdfs/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.120:36895
2026-01-15 05:55:23,788 [Socket Reader #8 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for hdfs/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
2026-01-15 05:55:24,613 [Socket Reader #9 for port 9862] INFO ipc_.Server: Auth successful for hdfs/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.120:40791
2026-01-15 05:55:24,614 [Socket Reader #9 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for hdfs/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
2026-01-15 05:55:24,623 [om1-OMStateMachineApplyTransactionThread - 0] WARN helpers.OzoneAclUtil: Failed to get primary group from user hdfs/s3g@EXAMPLE.COM (auth:SIMPLE)
2026-01-15 05:55:24,623 [om1-OMStateMachineApplyTransactionThread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ombg0 of layout LEGACY in volume: vol1
2026-01-15 05:55:27,521 [org.apache.ranger.audit.queue.AuditBatchQueue0] INFO xaaudit: {"repoType":201,"repo":"dev_ozone","reqUser":"hdfs","evtTime":"2026-01-15 05:55:24.537","access":"read","resource":"vol1","resType":"volume","action":"read","result":1,"agent":"ozone","policy":36,"reason":null,"enforcer":"ranger-acl","sess":null,"cliType":null,"cliIP":"172.25.0.120","reqData":"/vol1","agentHost":"om1","logType":"RangerAudit","id":"25b3cf5a-ee66-4ab4-8194-6aefbace5864-14","seq_num":29,"event_count":1,"event_dur_ms":1,"tags":[],"datasets":null,"projects":null,"additional_info":"{\"forwarded-ip-addresses\":\"[]\",\"remote-ip-address\":\"172.25.0.120\"}","cluster_name":"","zone_name":null,"policy_version":1}
2026-01-15 05:55:27,522 [org.apache.ranger.audit.queue.AuditBatchQueue0] INFO xaaudit: {"repoType":201,"repo":"dev_ozone","reqUser":"hdfs","evtTime":"2026-01-15 05:55:24.615","access":"create","resource":"vol1/ombg0","resType":"bucket","action":"create","result":1,"agent":"ozone","policy":36,"reason":null,"enforcer":"ranger-acl","sess":null,"cliType":null,"cliIP":"172.25.0.120","reqData":"/vol1/ombg0","agentHost":"om1","logType":"RangerAudit","id":"25b3cf5a-ee66-4ab4-8194-6aefbace5864-15","seq_num":31,"event_count":1,"event_dur_ms":1,"tags":[],"datasets":null,"projects":null,"additional_info":"{\"forwarded-ip-addresses\":\"[]\",\"remote-ip-address\":\"172.25.0.120\"}","cluster_name":"","zone_name":null,"policy_version":1}
2026-01-15 05:55:27,771 [Socket Reader #10 for port 9862] INFO ipc_.Server: Auth successful for hdfs/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.120:40431
2026-01-15 05:55:27,774 [Socket Reader #10 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for hdfs/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
2026-01-15 05:55:33,522 [org.apache.ranger.audit.queue.AuditBatchQueue0] INFO xaaudit: {"repoType":201,"repo":"dev_ozone","reqUser":"hdfs","evtTime":"2026-01-15 05:55:28.502","access":"read","resource":"vol1/bucket1","resType":"bucket","action":"read","result":1,"agent":"ozone","policy":36,"reason":null,"enforcer":"ranger-acl","sess":null,"cliType":null,"cliIP":"172.25.0.120","reqData":"/vol1/bucket1","agentHost":"om1","logType":"RangerAudit","id":"25b3cf5a-ee66-4ab4-8194-6aefbace5864-17","seq_num":35,"event_count":3,"event_dur_ms":1183,"tags":[],"datasets":null,"projects":null,"additional_info":"{\"forwarded-ip-addresses\":\"[]\",\"remote-ip-address\":\"172.25.0.120\"}","cluster_name":"","zone_name":null,"policy_version":1}
2026-01-15 05:55:33,523 [org.apache.ranger.audit.queue.AuditBatchQueue0] INFO xaaudit: {"repoType":201,"repo":"dev_ozone","reqUser":"hdfs","evtTime":"2026-01-15 05:55:28.532","access":"read","resource":"vol1/bucket1/ockg/0","resType":"key","action":"read","result":1,"agent":"ozone","policy":36,"reason":null,"enforcer":"ranger-acl","sess":null,"cliType":null,"cliIP":"172.25.0.120","reqData":"/vol1/bucket1/ockg/0","agentHost":"om1","logType":"RangerAudit","id":"25b3cf5a-ee66-4ab4-8194-6aefbace5864-18","seq_num":37,"event_count":3,"event_dur_ms":1156,"tags":[],"datasets":null,"projects":null,"additional_info":"{\"forwarded-ip-addresses\":\"[]\",\"remote-ip-address\":\"172.25.0.120\"}","cluster_name":"","zone_name":null,"policy_version":1}
2026-01-15 05:55:33,524 [org.apache.ranger.audit.queue.AuditBatchQueue0] INFO xaaudit: {"repoType":201,"repo":"dev_ozone","reqUser":"hdfs","evtTime":"2026-01-15 05:55:28.480","access":"read","resource":"vol1","resType":"volume","action":"read","result":1,"agent":"ozone","policy":36,"reason":null,"enforcer":"ranger-acl","sess":null,"cliType":null,"cliIP":"172.25.0.120","reqData":"/vol1","agentHost":"om1","logType":"RangerAudit","id":"25b3cf5a-ee66-4ab4-8194-6aefbace5864-16","seq_num":33,"event_count":3,"event_dur_ms":1202,"tags":[],"datasets":null,"projects":null,"additional_info":"{\"forwarded-ip-addresses\":\"[]\",\"remote-ip-address\":\"172.25.0.120\"}","cluster_name":"","zone_name":null,"policy_version":1}
2026-01-15 05:55:33,528 [Socket Reader #1 for port 9862] INFO ipc_.Server: Auth successful for hdfs/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.120:41885
2026-01-15 05:55:33,530 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for hdfs/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
2026-01-15 05:55:34,729 [om1-OMStateMachineApplyTransactionThread - 0] INFO tenant.OMTenantCreateRequest: Created tenant 'tenantone' and volume 'tenantone'
2026-01-15 05:55:36,208 [Socket Reader #2 for port 9862] INFO ipc_.Server: Auth successful for hdfs/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.120:42553
2026-01-15 05:55:36,209 [Socket Reader #2 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for hdfs/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
2026-01-15 05:55:36,522 [org.apache.ranger.audit.queue.AuditBatchQueue0] INFO xaaudit: {"repoType":201,"repo":"dev_ozone","reqUser":"hdfs","evtTime":"2026-01-15 05:55:34.292","access":"create","resource":"tenantone","resType":"volume","action":"create","result":1,"agent":"ozone","policy":36,"reason":null,"enforcer":"ranger-acl","sess":null,"cliType":null,"cliIP":"172.25.0.120","reqData":"/tenantone","agentHost":"om1","logType":"RangerAudit","id":"25b3cf5a-ee66-4ab4-8194-6aefbace5864-25","seq_num":51,"event_count":1,"event_dur_ms":1,"tags":[],"datasets":null,"projects":null,"additional_info":"{\"forwarded-ip-addresses\":\"[]\",\"remote-ip-address\":\"172.25.0.120\"}","cluster_name":"","zone_name":null,"policy_version":1}
2026-01-15 05:55:37,105 [om1-OMStateMachineApplyTransactionThread - 0] INFO om.S3SecretManager: Updating cache for accessId/user: tenantone$hdfs.
2026-01-15 05:55:37,106 [om1-OMStateMachineApplyTransactionThread - 0] INFO om.OMMultiTenantManagerImpl: Adding to cache: user 'hdfs' accessId 'tenantone$hdfs' in tenant 'tenantone'
2026-01-15 05:55:37,111 [om1-OMStateMachineApplyTransactionThread - 0] INFO tenant.OMTenantAssignUserAccessIdRequest: Assigned user 'hdfs' to tenant 'tenantone' with accessId 'tenantone$hdfs'
2026-01-15 05:55:38,489 [Socket Reader #3 for port 9862] INFO ipc_.Server: Auth successful for hdfs/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.120:36579
2026-01-15 05:55:38,496 [Socket Reader #3 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for hdfs/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
2026-01-15 05:55:40,570 [Socket Reader #4 for port 9862] INFO ipc_.Server: Auth successful for hdfs/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.120:44701
2026-01-15 05:55:40,572 [Socket Reader #4 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for hdfs/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
2026-01-15 05:55:42,471 [Socket Reader #5 for port 9862] INFO ipc_.Server: Auth successful for hdfs/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.120:33711
2026-01-15 05:55:42,473 [Socket Reader #5 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for hdfs/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
2026-01-15 05:55:44,753 [Socket Reader #6 for port 9862] INFO ipc_.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.120:38229
2026-01-15 05:55:44,754 [Socket Reader #6 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
2026-01-15 05:55:44,926 [IPC Server handler 12 on default port 9862] INFO om.S3SecretManager: Updating cache for accessId/user: tenantone$hdfs.
2026-01-15 05:55:44,970 [om1-OMStateMachineApplyTransactionThread - 0] WARN helpers.OzoneAclUtil: Failed to get primary group from user hdfs (auth:SIMPLE)
2026-01-15 05:55:44,970 [om1-OMStateMachineApplyTransactionThread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-test1 of layout OBJECT_STORE in volume: tenantone
2026-01-15 05:55:46,925 [Socket Reader #7 for port 9862] INFO ipc_.Server: Auth successful for hdfs/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.120:43279
2026-01-15 05:55:46,927 [Socket Reader #7 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for hdfs/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
2026-01-15 05:55:48,414 [om1-OMStateMachineApplyTransactionThread - 0] WARN helpers.OzoneAclUtil: Failed to get primary group from user hdfs (auth:SIMPLE)
2026-01-15 05:55:48,524 [org.apache.ranger.audit.queue.AuditBatchQueue0] INFO xaaudit: {"repoType":201,"repo":"dev_ozone","reqUser":"hdfs","evtTime":"2026-01-15 05:55:44.930","access":"read","resource":"tenantone","resType":"volume","action":"read","result":1,"agent":"ozone","policy":36,"reason":null,"enforcer":"ranger-acl","sess":null,"cliType":null,"cliIP":"172.25.0.120","reqData":"/tenantone","agentHost":"om1","logType":"RangerAudit","id":"25b3cf5a-ee66-4ab4-8194-6aefbace5864-26","seq_num":53,"event_count":2,"event_dur_ms":566,"tags":[],"datasets":null,"projects":null,"additional_info":"{\"forwarded-ip-addresses\":\"[]\",\"remote-ip-address\":\"172.25.0.120\"}","cluster_name":"","zone_name":null,"policy_version":1}
2026-01-15 05:55:48,524 [org.apache.ranger.audit.queue.AuditBatchQueue0] INFO xaaudit: {"repoType":201,"repo":"dev_ozone","reqUser":"hdfs","evtTime":"2026-01-15 05:55:45.510","access":"list","resource":"tenantone","resType":"volume","action":"list","result":1,"agent":"ozone","policy":36,"reason":null,"enforcer":"ranger-acl","sess":null,"cliType":null,"cliIP":"172.25.0.120","reqData":"/tenantone","agentHost":"om1","logType":"RangerAudit","id":"25b3cf5a-ee66-4ab4-8194-6aefbace5864-29","seq_num":59,"event_count":2,"event_dur_ms":8,"tags":[],"datasets":null,"projects":null,"additional_info":"{\"forwarded-ip-addresses\":\"[]\",\"remote-ip-address\":\"172.25.0.120\"}","cluster_name":"","zone_name":null,"policy_version":1}
2026-01-15 05:55:48,525 [org.apache.ranger.audit.queue.AuditBatchQueue0] INFO xaaudit: {"repoType":201,"repo":"dev_ozone","reqUser":"hdfs","evtTime":"2026-01-15 05:55:44.962","access":"create","resource":"tenantone/bucket-test1","resType":"bucket","action":"create","result":1,"agent":"ozone","policy":36,"reason":null,"enforcer":"ranger-acl","sess":null,"cliType":null,"cliIP":"172.25.0.120","reqData":"/tenantone/bucket-test1","agentHost":"om1","logType":"RangerAudit","id":"25b3cf5a-ee66-4ab4-8194-6aefbace5864-27","seq_num":55,"event_count":1,"event_dur_ms":1,"tags":[],"datasets":null,"projects":null,"additional_info":"{\"forwarded-ip-addresses\":\"[]\",\"remote-ip-address\":\"172.25.0.120\"}","cluster_name":"","zone_name":null,"policy_version":1}
2026-01-15 05:55:50,979 [Socket Reader #8 for port 9862] INFO ipc_.Server: Auth successful for hdfs/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.120:36799
2026-01-15 05:55:50,985 [Socket Reader #8 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for hdfs/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
2026-01-15 05:55:51,524 [org.apache.ranger.audit.queue.AuditBatchQueue0] INFO xaaudit: {"repoType":201,"repo":"dev_ozone","reqUser":"hdfs","evtTime":"2026-01-15 05:55:48.403","access":"create","resource":"tenantone/bucket-test1/mykey","resType":"key","action":"create","result":1,"agent":"ozone","policy":36,"reason":null,"enforcer":"ranger-acl","sess":null,"cliType":null,"cliIP":"172.25.0.120","reqData":"/tenantone/bucket-test1/mykey","agentHost":"om1","logType":"RangerAudit","id":"25b3cf5a-ee66-4ab4-8194-6aefbace5864-36","seq_num":73,"event_count":1,"event_dur_ms":1,"tags":[],"datasets":null,"projects":null,"additional_info":"{\"forwarded-ip-addresses\":\"[]\",\"remote-ip-address\":\"172.25.0.120\"}","cluster_name":"","zone_name":null,"policy_version":1}
2026-01-15 05:55:51,525 [org.apache.ranger.audit.queue.AuditBatchQueue0] INFO xaaudit: {"repoType":201,"repo":"dev_ozone","reqUser":"hdfs","evtTime":"2026-01-15 05:55:47.713","access":"read","resource":"tenantone","resType":"volume","action":"read","result":1,"agent":"ozone","policy":36,"reason":null,"enforcer":"ranger-acl","sess":null,"cliType":null,"cliIP":"172.25.0.120","reqData":"/tenantone","agentHost":"om1","logType":"RangerAudit","id":"25b3cf5a-ee66-4ab4-8194-6aefbace5864-31","seq_num":63,"event_count":2,"event_dur_ms":640,"tags":[],"datasets":null,"projects":null,"additional_info":"{\"forwarded-ip-addresses\":\"[]\",\"remote-ip-address\":\"172.25.0.120\"}","cluster_name":"","zone_name":null,"policy_version":1}
2026-01-15 05:55:51,525 [org.apache.ranger.audit.queue.AuditBatchQueue0] INFO xaaudit: {"repoType":201,"repo":"dev_ozone","reqUser":"hdfs","evtTime":"2026-01-15 05:55:49.478","access":"write","resource":"tenantone/bucket-test1/mykey","resType":"key","action":"write","result":1,"agent":"ozone","policy":36,"reason":null,"enforcer":"ranger-acl","sess":null,"cliType":null,"cliIP":"172.25.0.120","reqData":"/tenantone/bucket-test1/mykey","agentHost":"om1","logType":"RangerAudit","id":"25b3cf5a-ee66-4ab4-8194-6aefbace5864-37","seq_num":75,"event_count":1,"event_dur_ms":1,"tags":[],"datasets":null,"projects":null,"additional_info":"{\"forwarded-ip-addresses\":\"[]\",\"remote-ip-address\":\"172.25.0.120\"}","cluster_name":"","zone_name":null,"policy_version":1}
2026-01-15 05:55:51,525 [org.apache.ranger.audit.queue.AuditBatchQueue0] INFO xaaudit: {"repoType":201,"repo":"dev_ozone","reqUser":"hdfs","evtTime":"2026-01-15 05:55:47.735","access":"read","resource":"tenantone/bucket-test1","resType":"bucket","action":"read","result":1,"agent":"ozone","policy":36,"reason":null,"enforcer":"ranger-acl","sess":null,"cliType":null,"cliIP":"172.25.0.120","reqData":"/tenantone/bucket-test1","agentHost":"om1","logType":"RangerAudit","id":"25b3cf5a-ee66-4ab4-8194-6aefbace5864-32","seq_num":65,"event_count":3,"event_dur_ms":636,"tags":[],"datasets":null,"projects":null,"additional_info":"{\"forwarded-ip-addresses\":\"[]\",\"remote-ip-address\":\"172.25.0.120\"}","cluster_name":"","zone_name":null,"policy_version":1}
2026-01-15 05:55:53,736 [PolicyRefresher(serviceName=dev_ozone)-48] INFO util.RangerRolesProvider: RangerRolesProvider(serviceName=dev_ozone): found updated version. lastKnownRoleVersion=1; newVersion=4
2026-01-15 05:55:53,934 [PolicyRefresher(serviceName=dev_ozone)-48] INFO util.PolicyRefresher: PolicyRefresher(serviceName=dev_ozone): found updated version. lastKnownVersion=5; newVersion=8
2026-01-15 05:55:53,934 [PolicyRefresher(serviceName=dev_ozone)-48] INFO policyengine.PolicyEngine: Policy engine will not perform in place update while processing policies.
2026-01-15 05:55:53,936 [PolicyRefresher(serviceName=dev_ozone)-48] INFO policyengine.RangerPolicyRepository: This policy engine contains 5 policy evaluators
2026-01-15 05:55:53,940 [PolicyRefresher(serviceName=dev_ozone)-48] INFO conditionevaluator.RangerScriptConditionEvaluator: createScriptEngine(serviceType=tag): no engine creator found
2026-01-15 05:55:53,940 [PolicyRefresher(serviceName=dev_ozone)-48] WARN conditionevaluator.RangerScriptConditionEvaluator: createScriptEngine(serviceType=tag): failed to create script engine
2026-01-15 05:55:53,940 [PolicyRefresher(serviceName=dev_ozone)-48] ERROR conditionevaluator.RangerScriptConditionEvaluator: failed to initialize condition 'accessed-after-expiry': script engine 'JavaScript' was not created
2026-01-15 05:55:53,940 [PolicyRefresher(serviceName=dev_ozone)-48] INFO policyengine.RangerPolicyRepository: This policy engine contains 1 policy evaluators
2026-01-15 05:55:53,941 [PolicyRefresher(serviceName=dev_ozone)-48] INFO contextenricher.RangerTagEnricher: Policy-Engine will not use read-write locking to update tags in place when tag-deltas are provided
2026-01-15 05:55:53,941 [PolicyRefresher(serviceName=dev_ozone)-48] INFO contextenricher.RangerTagEnricher: Created RangerTagRefresher Thread(RangerTagRefresher(serviceName=dev_ozone)-265)
2026-01-15 05:55:53,956 [PolicyRefresher(serviceName=dev_ozone)-48] INFO contextenricher.RangerTagEnricher: Number of duplicate tags removed from the received serviceTags:[0]. Number of tags in the de-duplicated serviceTags :[0].
2026-01-15 05:55:53,956 [PolicyRefresher(serviceName=dev_ozone)-48] INFO contextenricher.RangerTagEnricher: There are no tagged resources for service dev_ozone
2026-01-15 05:55:53,956 [PolicyRefresher(serviceName=dev_ozone)-48] INFO contextenricher.RangerTagEnricher$RangerTagRefresher: RangerTagRefresher(serviceName=dev_ozone).populateTags() - Updated tags-cache to new version of tags, lastKnownVersion=-1; newVersion=1
2026-01-15 05:55:53,956 [PolicyRefresher(serviceName=dev_ozone)-48] INFO service.RangerBasePlugin: Switching policy engine from [5]
2026-01-15 05:55:53,956 [PolicyRefresher(serviceName=dev_ozone)-48] INFO service.RangerBasePlugin: Switched policy engine to [8]
2026-01-15 05:55:53,957 [RangerTagRefresher(serviceName=dev_ozone)-50] INFO contextenricher.RangerTagEnricher$RangerTagRefresher: RangerTagRefresher(RangerTagRefresher(serviceName=dev_ozone)-50).run(): Interrupted! Exiting thread
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1722)
	at java.base/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
	at org.apache.ranger.plugin.contextenricher.RangerTagEnricher$RangerTagRefresher.run(RangerTagEnricher.java:926)
2026-01-15 05:55:54,417 [Socket Reader #9 for port 9862] INFO ipc_.Server: Auth successful for hdfs/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.120:42293
2026-01-15 05:55:54,418 [Socket Reader #9 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for hdfs/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
2026-01-15 05:55:55,110 [om1-OMStateMachineApplyTransactionThread - 0] INFO om.S3SecretManager: Updating cache for accessId/user: tenantone$hdfs.
2026-01-15 05:55:56,549 [Socket Reader #10 for port 9862] INFO ipc_.Server: Auth successful for hdfs/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.120:36367
2026-01-15 05:55:56,550 [Socket Reader #10 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for hdfs/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
2026-01-15 05:55:57,526 [org.apache.ranger.audit.queue.AuditBatchQueue0] INFO xaaudit: {"repoType":201,"repo":"dev_ozone","reqUser":"hdfs","evtTime":"2026-01-15 05:55:52.934","access":"delete","resource":"tenantone/bucket-test1/mykey","resType":"key","action":"delete","result":1,"agent":"ozone","policy":36,"reason":null,"enforcer":"ranger-acl","sess":null,"cliType":null,"cliIP":"172.25.0.120","reqData":"/tenantone/bucket-test1/mykey","agentHost":"om1","logType":"RangerAudit","id":"25b3cf5a-ee66-4ab4-8194-6aefbace5864-43","seq_num":87,"event_count":1,"event_dur_ms":1,"tags":[],"datasets":null,"projects":null,"additional_info":"{\"forwarded-ip-addresses\":\"[]\",\"remote-ip-address\":\"172.25.0.120\"}","cluster_name":"","zone_name":null,"policy_version":1}
2026-01-15 05:55:57,526 [org.apache.ranger.audit.queue.AuditBatchQueue0] INFO xaaudit: {"repoType":201,"repo":"dev_ozone","reqUser":"hdfs","evtTime":"2026-01-15 05:55:51.703","access":"read","resource":"tenantone","resType":"volume","action":"read","result":1,"agent":"ozone","policy":36,"reason":null,"enforcer":"ranger-acl","sess":null,"cliType":null,"cliIP":"172.25.0.120","reqData":"/tenantone","agentHost":"om1","logType":"RangerAudit","id":"25b3cf5a-ee66-4ab4-8194-6aefbace5864-38","seq_num":77,"event_count":2,"event_dur_ms":1222,"tags":[],"datasets":null,"projects":null,"additional_info":"{\"forwarded-ip-addresses\":\"[]\",\"remote-ip-address\":\"172.25.0.120\"}","cluster_name":"","zone_name":null,"policy_version":1}
2026-01-15 05:55:57,526 [org.apache.ranger.audit.queue.AuditBatchQueue0] INFO xaaudit: {"repoType":201,"repo":"dev_ozone","reqUser":"hdfs","evtTime":"2026-01-15 05:55:51.725","access":"read","resource":"tenantone/bucket-test1","resType":"bucket","action":"read","result":1,"agent":"ozone","policy":36,"reason":null,"enforcer":"ranger-acl","sess":null,"cliType":null,"cliIP":"172.25.0.120","reqData":"/tenantone/bucket-test1","agentHost":"om1","logType":"RangerAudit","id":"25b3cf5a-ee66-4ab4-8194-6aefbace5864-39","seq_num":79,"event_count":1,"event_dur_ms":1,"tags":[],"datasets":null,"projects":null,"additional_info":"{\"forwarded-ip-addresses\":\"[]\",\"remote-ip-address\":\"172.25.0.120\"}","cluster_name":"","zone_name":null,"policy_version":1}
2026-01-15 05:55:57,526 [org.apache.ranger.audit.queue.AuditBatchQueue0] INFO xaaudit: {"repoType":201,"repo":"dev_ozone","reqUser":"hdfs","evtTime":"2026-01-15 05:55:51.753","access":"read","resource":"tenantone/bucket-test1/mykey","resType":"key","action":"read","result":1,"agent":"ozone","policy":36,"reason":null,"enforcer":"ranger-acl","sess":null,"cliType":null,"cliIP":"172.25.0.120","reqData":"/tenantone/bucket-test1/mykey","agentHost":"om1","logType":"RangerAudit","id":"25b3cf5a-ee66-4ab4-8194-6aefbace5864-40","seq_num":81,"event_count":2,"event_dur_ms":735,"tags":[],"datasets":null,"projects":null,"additional_info":"{\"forwarded-ip-addresses\":\"[]\",\"remote-ip-address\":\"172.25.0.120\"}","cluster_name":"","zone_name":null,"policy_version":1}
2026-01-15 05:55:58,629 [Socket Reader #1 for port 9862] INFO ipc_.Server: Auth successful for hdfs/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.120:39843
2026-01-15 05:55:58,631 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for hdfs/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
2026-01-15 05:56:00,200 [om1-KeyDeletingService#2] INFO service.KeyDeletingService: Send 2 key(s) to SCM, first 2 keys: [PurgedKey{blockGroup=BlockGroup[groupID='/vol1/bucket1/0/-9223372036854774272/0', deletedBlocks=[ localID: 117883640217600002 containerID: 1 size: 268435456 replicatedSize: 805306368]], volume='vol1', bucket='bucket1', bucketId=-9223372036854775296, purgedBytes=805306368, isCommittedKey=false, deleteKeyName='/vol1/bucket1/0/-9223372036854774272'}, PurgedKey{blockGroup=BlockGroup[groupID='/tenantone/bucket-test1/mykey/-9223372036854772992/0', deletedBlocks=[ localID: 117883640217600003 containerID: 2 size: 11 replicatedSize: 33]], volume='tenantone', bucket='bucket-test1', bucketId=-9223372036854773248, purgedBytes=33, isCommittedKey=true, deleteKeyName='/tenantone/bucket-test1/mykey/-9223372036854772992'}]
2026-01-15 05:56:00,345 [om1-KeyDeletingService#2] INFO service.KeyDeletingService: 2 BlockGroup deletion are acked by SCM in 145 ms
2026-01-15 05:56:00,395 [om1-OMStateMachineApplyTransactionThread - 0] INFO audit.AuditLogger: Refresh DebugCmdSet for OMSystemAudit to [].
2026-01-15 05:56:00,397 [om1-KeyDeletingService#2] INFO service.KeyDeletingService: Blocks for 2 (out of 2) keys are deleted from DB in 53 ms. Limit per task is 50000.
2026-01-15 05:56:00,780 [Socket Reader #2 for port 9862] INFO ipc_.Server: Auth successful for hdfs/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.120:39041
2026-01-15 05:56:00,788 [Socket Reader #2 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for hdfs/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
2026-01-15 05:56:01,533 [om1-OMStateMachineApplyTransactionThread - 0] INFO om.S3SecretManager: Updating cache for accessId/user: tenantone$hdfs.
2026-01-15 05:56:02,002 [IPC Server handler 20 on default port 9862] ERROR protocolPB.OzoneManagerProtocolServerSideTranslatorPB: signatures do NOT match for S3 identifier:OzoneToken owner=tenantone$hdfs, renewer=, realUser=, issueDate=1970-01-01T00:00:00Z, maxDate=1970-01-01T00:00:00Z, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
20260115T055601Z
20260115/us-east-1/s3/aws4_request
f5100ec5d9de0d438741cb83724357efde13ce71e6f3f814ced798d0cbfd2556, signature=c0fed921bde6d0935955be817d8548bb31677110d6e2c07e93d486d8640423e8, awsAccessKeyId=tenantone$hdfs, omServiceId=null, omCertSerialId=null, secretKeyId=null
org.apache.hadoop.security.token.SecretManager$InvalidToken: Invalid S3 identifier:OzoneToken owner=tenantone$hdfs, renewer=, realUser=, issueDate=1970-01-01T00:00:00Z, maxDate=1970-01-01T00:00:00Z, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
20260115T055601Z
20260115/us-east-1/s3/aws4_request
f5100ec5d9de0d438741cb83724357efde13ce71e6f3f814ced798d0cbfd2556, signature=c0fed921bde6d0935955be817d8548bb31677110d6e2c07e93d486d8640423e8, awsAccessKeyId=tenantone$hdfs, omServiceId=null, omCertSerialId=null, secretKeyId=null
	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3AuthInfo(OzoneDelegationTokenSecretManager.java:502)
	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:375)
	at org.apache.hadoop.ozone.security.S3SecurityUtil.validateS3Credential(S3SecurityUtil.java:61)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.internalProcessRequest(OzoneManagerProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:136)
	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:89)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:125)
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
	at org.apache.hadoop.ipc_.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:539)
	at org.apache.hadoop.ipc_.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:508)
	at org.apache.hadoop.ipc_.RPC$Server.call(RPC.java:1164)
	at org.apache.hadoop.ipc_.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc_.Server$RpcCall.run(Server.java:948)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:714)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:525)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.hadoop.ipc_.Server$Handler.run(Server.java:2951)
2026-01-15 05:56:04,156 [Socket Reader #3 for port 9862] INFO ipc_.Server: Auth successful for hdfs/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.120:40729
2026-01-15 05:56:04,157 [Socket Reader #3 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for hdfs/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
2026-01-15 05:56:04,831 [IPC Server handler 17 on default port 9862] WARN tenant.OMTenantDeleteRequest: tenant: 'tenantone' is not empty. Unable to delete the tenant
2026-01-15 05:56:06,515 [Socket Reader #4 for port 9862] INFO ipc_.Server: Auth successful for hdfs/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.120:40283
2026-01-15 05:56:06,517 [Socket Reader #4 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for hdfs/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
2026-01-15 05:56:06,520 [IPC Server handler 4 on default port 9862] INFO om.OzoneManager: User 'hdfs/s3g@EXAMPLE.COM (auth:KERBEROS)' manually triggered Multi-Tenancy Ranger Sync
2026-01-15 05:56:06,526 [org.apache.ranger.audit.queue.AuditBatchQueue0] INFO xaaudit: {"repoType":201,"repo":"dev_ozone","reqUser":"hdfs","evtTime":"2026-01-15 05:56:02.771","access":"read","resource":"tenantone","resType":"volume","action":"read","result":1,"agent":"ozone","policy":36,"reason":null,"enforcer":"ranger-acl","sess":null,"cliType":null,"cliIP":"172.25.0.120","reqData":"/tenantone","agentHost":"om1","logType":"RangerAudit","id":"25b3cf5a-ee66-4ab4-8194-6aefbace5864-44","seq_num":89,"event_count":1,"event_dur_ms":1,"tags":[],"datasets":null,"projects":null,"additional_info":"{\"forwarded-ip-addresses\":\"[]\",\"remote-ip-address\":\"172.25.0.120\"}","cluster_name":"","zone_name":null,"policy_version":1}
2026-01-15 05:56:06,527 [org.apache.ranger.audit.queue.AuditBatchQueue0] INFO xaaudit: {"repoType":201,"repo":"dev_ozone","reqUser":"hdfs","evtTime":"2026-01-15 05:56:02.786","access":"delete","resource":"tenantone/bucket-test1","resType":"bucket","action":"delete","result":1,"agent":"ozone","policy":36,"reason":null,"enforcer":"ranger-acl","sess":null,"cliType":null,"cliIP":"172.25.0.120","reqData":"/tenantone/bucket-test1","agentHost":"om1","logType":"RangerAudit","id":"25b3cf5a-ee66-4ab4-8194-6aefbace5864-45","seq_num":91,"event_count":1,"event_dur_ms":1,"tags":[],"datasets":null,"projects":null,"additional_info":"{\"forwarded-ip-addresses\":\"[]\",\"remote-ip-address\":\"172.25.0.120\"}","cluster_name":"","zone_name":null,"policy_version":1}
2026-01-15 05:56:06,542 [IPC Server handler 4 on default port 9862] INFO service.OMRangerBGSyncService: Executing Multi-Tenancy Ranger Sync: run # 0, attempt # 1. Ranger service version: 8, DB service version: -1
2026-01-15 05:56:06,665 [IPC Server handler 4 on default port 9862] INFO service.OMRangerBGSyncService: Finished executing Multi-Tenancy Ranger Sync run # 0 after1 attempts.
2026-01-15 05:56:07,012 [Socket Reader #5 for port 9862] INFO ipc_.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:46297
2026-01-15 05:56:07,014 [Socket Reader #5 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
2026-01-15 05:56:08,158 [Socket Reader #6 for port 9862] INFO ipc_.Server: Auth successful for testuser2/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.120:40801
2026-01-15 05:56:08,167 [Socket Reader #6 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
2026-01-15 05:56:10,286 [Socket Reader #7 for port 9862] INFO ipc_.Server: Auth successful for testuser2/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.120:44857
2026-01-15 05:56:10,293 [Socket Reader #7 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
2026-01-15 05:56:11,435 [om1-OMStateMachineApplyTransactionThread - 0] WARN helpers.OzoneAclUtil: Failed to get primary group from user hdfs (auth:SIMPLE)
2026-01-15 05:56:11,435 [om1-OMStateMachineApplyTransactionThread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-test2 of layout OBJECT_STORE in volume: tenantone
2026-01-15 05:56:12,156 [IPC Server handler 76 on default port 9862] ERROR protocolPB.OzoneManagerProtocolServerSideTranslatorPB: signatures do NOT match for S3 identifier:OzoneToken owner=tenantone$hdfs, renewer=, realUser=, issueDate=1970-01-01T00:00:00Z, maxDate=1970-01-01T00:00:00Z, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
20260115T055612Z
20260115/us-east-1/s3/aws4_request
675aad79ad73c83713827479e6a678bd70d02d85319ec7cf1bda86fa5860741b, signature=a60f646304fda9f7860f4da7126609ac56d470b794b4175bc885af9cedd6ad97, awsAccessKeyId=tenantone$hdfs, omServiceId=null, omCertSerialId=null, secretKeyId=null
org.apache.hadoop.security.token.SecretManager$InvalidToken: Invalid S3 identifier:OzoneToken owner=tenantone$hdfs, renewer=, realUser=, issueDate=1970-01-01T00:00:00Z, maxDate=1970-01-01T00:00:00Z, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
20260115T055612Z
20260115/us-east-1/s3/aws4_request
675aad79ad73c83713827479e6a678bd70d02d85319ec7cf1bda86fa5860741b, signature=a60f646304fda9f7860f4da7126609ac56d470b794b4175bc885af9cedd6ad97, awsAccessKeyId=tenantone$hdfs, omServiceId=null, omCertSerialId=null, secretKeyId=null
	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3AuthInfo(OzoneDelegationTokenSecretManager.java:502)
	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:375)
	at org.apache.hadoop.ozone.security.S3SecurityUtil.validateS3Credential(S3SecurityUtil.java:61)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.internalProcessRequest(OzoneManagerProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:136)
	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:89)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:125)
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
	at org.apache.hadoop.ipc_.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:539)
	at org.apache.hadoop.ipc_.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:508)
	at org.apache.hadoop.ipc_.RPC$Server.call(RPC.java:1164)
	at org.apache.hadoop.ipc_.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc_.Server$RpcCall.run(Server.java:948)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:714)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:525)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.hadoop.ipc_.Server$Handler.run(Server.java:2951)
2026-01-15 05:56:12,525 [org.apache.ranger.audit.queue.AuditBatchQueue0] INFO xaaudit: {"repoType":201,"repo":"dev_ozone","reqUser":"hdfs","evtTime":"2026-01-15 05:56:11.427","access":"create","resource":"tenantone/bucket-test2","resType":"bucket","action":"create","result":1,"agent":"ozone","policy":36,"reason":null,"enforcer":"ranger-acl","sess":null,"cliType":null,"cliIP":"172.25.0.120","reqData":"/tenantone/bucket-test2","agentHost":"om1","logType":"RangerAudit","id":"25b3cf5a-ee66-4ab4-8194-6aefbace5864-47","seq_num":95,"event_count":1,"event_dur_ms":1,"tags":[],"datasets":null,"projects":null,"additional_info":"{\"forwarded-ip-addresses\":\"[]\",\"remote-ip-address\":\"172.25.0.120\"}","cluster_name":"","zone_name":null,"policy_version":1}
2026-01-15 05:56:12,526 [org.apache.ranger.audit.queue.AuditBatchQueue0] INFO xaaudit: {"repoType":201,"repo":"dev_ozone","reqUser":"hdfs","evtTime":"2026-01-15 05:56:11.424","access":"read","resource":"tenantone","resType":"volume","action":"read","result":1,"agent":"ozone","policy":36,"reason":null,"enforcer":"ranger-acl","sess":null,"cliType":null,"cliIP":"172.25.0.120","reqData":"/tenantone","agentHost":"om1","logType":"RangerAudit","id":"25b3cf5a-ee66-4ab4-8194-6aefbace5864-46","seq_num":93,"event_count":1,"event_dur_ms":1,"tags":[],"datasets":null,"projects":null,"additional_info":"{\"forwarded-ip-addresses\":\"[]\",\"remote-ip-address\":\"172.25.0.120\"}","cluster_name":"","zone_name":null,"policy_version":1}
2026-01-15 05:56:14,358 [Socket Reader #8 for port 9862] INFO ipc_.Server: Auth successful for hdfs/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.120:34719
2026-01-15 05:56:14,360 [Socket Reader #8 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for hdfs/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
2026-01-15 05:56:15,098 [om1-OMStateMachineApplyTransactionThread - 0] INFO om.OMMultiTenantManagerImpl: Removing from cache: accessId 'tenantone$hdfs' in tenant 'tenantone'
2026-01-15 05:56:15,100 [om1-OMStateMachineApplyTransactionThread - 0] INFO tenant.OMTenantRevokeUserAccessIdRequest: Revoked user 'hdfs' accessId 'tenantone$hdfs' to tenant 'tenantone'
2026-01-15 05:56:15,513 [IPC Server handler 4 on default port 9862] ERROR protocolPB.OzoneManagerProtocolServerSideTranslatorPB: signatures do NOT match for S3 identifier:OzoneToken owner=tenantone$hdfs, renewer=, realUser=, issueDate=1970-01-01T00:00:00Z, maxDate=1970-01-01T00:00:00Z, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
20260115T055615Z
20260115/us-east-1/s3/aws4_request
b94f0b6c3f7ab0f7ef80e800393675ac1c31770b508efd41eae0291ec7333adb, signature=399df0315593b48e7f78bf896c09575364a7c30a44d33585bd7b0981b431e889, awsAccessKeyId=tenantone$hdfs, omServiceId=null, omCertSerialId=null, secretKeyId=null
org.apache.hadoop.security.token.SecretManager$InvalidToken: Invalid S3 identifier:OzoneToken owner=tenantone$hdfs, renewer=, realUser=, issueDate=1970-01-01T00:00:00Z, maxDate=1970-01-01T00:00:00Z, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
20260115T055615Z
20260115/us-east-1/s3/aws4_request
b94f0b6c3f7ab0f7ef80e800393675ac1c31770b508efd41eae0291ec7333adb, signature=399df0315593b48e7f78bf896c09575364a7c30a44d33585bd7b0981b431e889, awsAccessKeyId=tenantone$hdfs, omServiceId=null, omCertSerialId=null, secretKeyId=null
	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3AuthInfo(OzoneDelegationTokenSecretManager.java:502)
	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:375)
	at org.apache.hadoop.ozone.security.S3SecurityUtil.validateS3Credential(S3SecurityUtil.java:61)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.internalProcessRequest(OzoneManagerProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:136)
	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:89)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:125)
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
	at org.apache.hadoop.ipc_.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:539)
	at org.apache.hadoop.ipc_.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:508)
	at org.apache.hadoop.ipc_.RPC$Server.call(RPC.java:1164)
	at org.apache.hadoop.ipc_.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc_.Server$RpcCall.run(Server.java:948)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:714)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:525)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.hadoop.ipc_.Server$Handler.run(Server.java:2951)
2026-01-15 05:56:16,835 [Socket Reader #9 for port 9862] INFO ipc_.Server: Auth successful for hdfs/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.120:35587
2026-01-15 05:56:16,842 [Socket Reader #9 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for hdfs/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
2026-01-15 05:56:17,509 [IPC Server handler 4 on default port 9862] INFO om.OMMultiTenantManagerImpl: Deleting tenant policies and roles from Ranger: OzoneTenant{tenantId='tenantone', tenantRoleNames=[tenantone-UserRole, tenantone-AdminRole], accessPolicies=[tenantone-VolumeAccess, tenantone-BucketAccess], accountNameSpace=org.apache.hadoop.ozone.om.multitenant.impl.AccountNameSpaceImpl@2db5c947, bucketNameSpace=org.apache.hadoop.ozone.om.multitenant.impl.SingleVolumeTenantNamespace@43e47abb}
2026-01-15 05:56:17,690 [om1-OMStateMachineApplyTransactionThread - 0] INFO om.OMMultiTenantManagerImpl: Removing tenant from in-memory cache: tenantone
2026-01-15 05:56:17,697 [om1-OMStateMachineApplyTransactionThread - 0] INFO tenant.OMTenantDeleteRequest: Deleted tenant 'tenantone' and volume 'tenantone'
2026-01-15 05:56:18,525 [org.apache.ranger.audit.queue.AuditBatchQueue0] INFO xaaudit: {"repoType":201,"repo":"dev_ozone","reqUser":"hdfs","evtTime":"2026-01-15 05:56:12.870","access":"read","resource":"tenantone","resType":"volume","action":"read","result":1,"agent":"ozone","policy":36,"reason":null,"enforcer":"ranger-acl","sess":null,"cliType":null,"cliIP":"172.25.0.120","reqData":"/tenantone","agentHost":"om1","logType":"RangerAudit","id":"25b3cf5a-ee66-4ab4-8194-6aefbace5864-48","seq_num":97,"event_count":1,"event_dur_ms":1,"tags":[],"datasets":null,"projects":null,"additional_info":"{\"forwarded-ip-addresses\":\"[]\",\"remote-ip-address\":\"172.25.0.120\"}","cluster_name":"","zone_name":null,"policy_version":1}
2026-01-15 05:56:18,525 [org.apache.ranger.audit.queue.AuditBatchQueue0] INFO xaaudit: {"repoType":201,"repo":"dev_ozone","reqUser":"hdfs","evtTime":"2026-01-15 05:56:12.882","access":"delete","resource":"tenantone/bucket-test2","resType":"bucket","action":"delete","result":1,"agent":"ozone","policy":36,"reason":null,"enforcer":"ranger-acl","sess":null,"cliType":null,"cliIP":"172.25.0.120","reqData":"/tenantone/bucket-test2","agentHost":"om1","logType":"RangerAudit","id":"25b3cf5a-ee66-4ab4-8194-6aefbace5864-49","seq_num":99,"event_count":1,"event_dur_ms":1,"tags":[],"datasets":null,"projects":null,"additional_info":"{\"forwarded-ip-addresses\":\"[]\",\"remote-ip-address\":\"172.25.0.120\"}","cluster_name":"","zone_name":null,"policy_version":1}
2026-01-15 05:56:19,037 [Socket Reader #10 for port 9862] INFO ipc_.Server: Auth successful for hdfs/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.120:34949
2026-01-15 05:56:19,038 [Socket Reader #10 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for hdfs/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
2026-01-15 05:56:21,105 [Socket Reader #1 for port 9862] INFO ipc_.Server: Auth successful for hdfs/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.120:39971
2026-01-15 05:56:21,113 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for hdfs/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
2026-01-15 05:56:21,525 [org.apache.ranger.audit.queue.AuditBatchQueue0] INFO xaaudit: {"repoType":201,"repo":"dev_ozone","reqUser":"hdfs","evtTime":"2026-01-15 05:56:17.508","access":"write_acl","resource":"tenantone","resType":"volume","action":"write_acl","result":1,"agent":"ozone","policy":36,"reason":null,"enforcer":"ranger-acl","sess":null,"cliType":null,"cliIP":"172.25.0.120","reqData":"/tenantone","agentHost":"om1","logType":"RangerAudit","id":"25b3cf5a-ee66-4ab4-8194-6aefbace5864-50","seq_num":101,"event_count":1,"event_dur_ms":1,"tags":[],"datasets":null,"projects":null,"additional_info":"{\"forwarded-ip-addresses\":\"[]\",\"remote-ip-address\":\"172.25.0.120\"}","cluster_name":"","zone_name":null,"policy_version":1}
2026-01-15 05:56:21,526 [org.apache.ranger.audit.queue.AuditBatchQueue0] INFO xaaudit: {"repoType":201,"repo":"dev_ozone","reqUser":"hdfs","evtTime":"2026-01-15 05:56:19.777","access":"delete","resource":"tenantone","resType":"volume","action":"delete","result":1,"agent":"ozone","policy":36,"reason":null,"enforcer":"ranger-acl","sess":null,"cliType":null,"cliIP":"172.25.0.120","reqData":"/tenantone","agentHost":"om1","logType":"RangerAudit","id":"25b3cf5a-ee66-4ab4-8194-6aefbace5864-51","seq_num":103,"event_count":1,"event_dur_ms":1,"tags":[],"datasets":null,"projects":null,"additional_info":"{\"forwarded-ip-addresses\":\"[]\",\"remote-ip-address\":\"172.25.0.120\"}","cluster_name":"","zone_name":null,"policy_version":1}
