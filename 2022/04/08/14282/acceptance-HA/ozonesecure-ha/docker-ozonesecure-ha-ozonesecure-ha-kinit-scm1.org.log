Attaching to ozonesecure-ha_datanode2_1, ozonesecure-ha_kms_1, ozonesecure-ha_recon_1, ozonesecure-ha_scm3.org_1, ozonesecure-ha_datanode1_1, ozonesecure-ha_om3_1, ozonesecure-ha_om2_1, ozonesecure-ha_scm1.org_1, ozonesecure-ha_scm2.org_1, ozonesecure-ha_om1_1, ozonesecure-ha_datanode3_1, ozonesecure-ha_s3g_1, ozonesecure-ha_kdc_1
datanode2_1  | Sleeping for 5 seconds
datanode2_1  | Waiting for the service scm3.org:9894
datanode2_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode2_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode2_1  | 2022-04-08 11:48:10,376 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode2_1  | /************************************************************
datanode2_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode2_1  | STARTUP_MSG:   host = 19c25d99ddaf/172.25.0.103
datanode2_1  | STARTUP_MSG:   args = []
datanode2_1  | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
datanode2_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.0.4.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.3.0-SNAPSHOT.jar
datanode2_1  | STARTUP_MSG:   build = https://github.com/apache/ozone/805b5e1d3b8eaf7ab8aef1c57e2bb17b73dea398 ; compiled by 'runner' on 2022-04-08T11:25Z
datanode2_1  | STARTUP_MSG:   java = 11.0.14.1
datanode2_1  | ************************************************************/
datanode2_1  | 2022-04-08 11:48:10,435 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode2_1  | 2022-04-08 11:48:12,031 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode2_1  | 2022-04-08 11:48:12,795 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode2_1  | 2022-04-08 11:48:13,699 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode2_1  | 2022-04-08 11:48:13,699 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode2_1  | 2022-04-08 11:48:14,667 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:19c25d99ddaf ip:172.25.0.103
datanode2_1  | 2022-04-08 11:48:17,561 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/dn@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode2_1  | 2022-04-08 11:48:18,458 [main] INFO security.UserGroupInformation: Login successful for user dn/dn@EXAMPLE.COM using keytab file dn.keytab. Keytab auto renewal enabled : false
datanode2_1  | 2022-04-08 11:48:18,487 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
datanode2_1  | 2022-04-08 11:48:20,517 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
datanode2_1  | 2022-04-08 11:48:20,539 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode2_1  | 2022-04-08 11:48:20,543 [main] INFO client.DNCertificateClient: Certificate client init case: 0
datanode2_1  | 2022-04-08 11:48:20,544 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode2_1  | 2022-04-08 11:48:24,527 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
datanode2_1  | 2022-04-08 11:48:24,589 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.103,host:19c25d99ddaf
datanode2_1  | 2022-04-08 11:48:24,589 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode2_1  | 2022-04-08 11:48:24,604 [main] ERROR client.DNCertificateClient: Invalid domain 19c25d99ddaf
datanode2_1  | 2022-04-08 11:48:24,608 [main] INFO ozone.HddsDatanodeService: Creating csr for DN-> subject:root@19c25d99ddaf
datanode2_1  | 2022-04-08 11:48:29,121 [main] INFO client.DNCertificateClient: Loading certificate from location:/data/metadata/dn/certs.
datanode2_1  | 2022-04-08 11:48:29,231 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/ROOTCA-1.crt.
datanode2_1  | 2022-04-08 11:48:29,258 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/932981906868.crt.
datanode2_1  | 2022-04-08 11:48:29,278 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/CA-848180596473.crt.
datanode2_1  | 2022-04-08 11:48:29,291 [main] INFO ozone.HddsDatanodeService: Successfully stored SCM signed certificate, case:GETCERT.
datanode2_1  | 2022-04-08 11:48:29,384 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = SCM_HA (version = 2), software layout = SCM_HA (version = 2)
datanode2_1  | 2022-04-08 11:48:30,315 [main] INFO reflections.Reflections: Reflections took 734 ms to scan 2 urls, producing 87 keys and 176 values 
datanode2_1  | 2022-04-08 11:48:30,700 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 4
datanode2_1  | 2022-04-08 11:48:31,718 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode2_1  | 2022-04-08 11:48:31,804 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89311358976
datanode2_1  | 2022-04-08 11:48:31,837 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode2_1  | 2022-04-08 11:48:31,852 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode2_1  | 2022-04-08 11:48:32,149 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode2_1  | 2022-04-08 11:48:32,288 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode2_1  | 2022-04-08 11:48:32,297 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode2_1  | 2022-04-08 11:48:32,306 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode2_1  | 2022-04-08 11:48:32,308 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
datanode2_1  | 2022-04-08 11:48:32,332 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
datanode2_1  | 2022-04-08 11:48:32,508 [Thread-8] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode2_1  | 2022-04-08 11:48:32,549 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode2_1  | 2022-04-08 11:48:38,373 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode2_1  | 2022-04-08 11:48:38,638 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode2_1  | 2022-04-08 11:48:39,439 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode2_1  | 2022-04-08 11:48:39,472 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode2_1  | 2022-04-08 11:48:39,492 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode2_1  | 2022-04-08 11:48:39,497 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode1_1  | Sleeping for 5 seconds
datanode1_1  | Waiting for the service scm3.org:9894
datanode1_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode1_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode1_1  | 2022-04-08 11:48:10,146 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode1_1  | /************************************************************
datanode1_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode1_1  | STARTUP_MSG:   host = e7d6b6474bc4/172.25.0.102
datanode1_1  | STARTUP_MSG:   args = []
datanode1_1  | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
datanode1_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.0.4.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.3.0-SNAPSHOT.jar
datanode1_1  | STARTUP_MSG:   build = https://github.com/apache/ozone/805b5e1d3b8eaf7ab8aef1c57e2bb17b73dea398 ; compiled by 'runner' on 2022-04-08T11:25Z
datanode1_1  | STARTUP_MSG:   java = 11.0.14.1
datanode1_1  | ************************************************************/
datanode1_1  | 2022-04-08 11:48:10,229 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode1_1  | 2022-04-08 11:48:11,816 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode1_1  | 2022-04-08 11:48:12,507 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode1_1  | 2022-04-08 11:48:13,422 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode1_1  | 2022-04-08 11:48:13,423 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode1_1  | 2022-04-08 11:48:14,358 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:e7d6b6474bc4 ip:172.25.0.102
datanode1_1  | 2022-04-08 11:48:17,146 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/dn@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode1_1  | 2022-04-08 11:48:18,248 [main] INFO security.UserGroupInformation: Login successful for user dn/dn@EXAMPLE.COM using keytab file dn.keytab. Keytab auto renewal enabled : false
datanode1_1  | 2022-04-08 11:48:18,248 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
datanode1_1  | 2022-04-08 11:48:20,649 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
datanode1_1  | 2022-04-08 11:48:20,652 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode1_1  | 2022-04-08 11:48:20,659 [main] INFO client.DNCertificateClient: Certificate client init case: 0
datanode1_1  | 2022-04-08 11:48:20,660 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode1_1  | 2022-04-08 11:48:24,950 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
datanode1_1  | 2022-04-08 11:48:25,027 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.102,host:e7d6b6474bc4
datanode1_1  | 2022-04-08 11:48:25,066 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode1_1  | 2022-04-08 11:48:25,070 [main] ERROR client.DNCertificateClient: Invalid domain e7d6b6474bc4
datanode1_1  | 2022-04-08 11:48:25,108 [main] INFO ozone.HddsDatanodeService: Creating csr for DN-> subject:root@e7d6b6474bc4
datanode1_1  | 2022-04-08 11:48:29,791 [main] INFO client.DNCertificateClient: Loading certificate from location:/data/metadata/dn/certs.
datanode1_1  | 2022-04-08 11:48:29,881 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/ROOTCA-1.crt.
datanode1_1  | 2022-04-08 11:48:29,901 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/933750048452.crt.
datanode1_1  | 2022-04-08 11:48:29,925 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/CA-848180596473.crt.
datanode1_1  | 2022-04-08 11:48:29,929 [main] INFO ozone.HddsDatanodeService: Successfully stored SCM signed certificate, case:GETCERT.
datanode1_1  | 2022-04-08 11:48:30,064 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = SCM_HA (version = 2), software layout = SCM_HA (version = 2)
datanode1_1  | 2022-04-08 11:48:30,852 [main] INFO reflections.Reflections: Reflections took 598 ms to scan 2 urls, producing 87 keys and 176 values 
datanode1_1  | 2022-04-08 11:48:31,304 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 4
datanode1_1  | 2022-04-08 11:48:32,547 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode1_1  | 2022-04-08 11:48:32,626 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89311358976
datanode1_1  | 2022-04-08 11:48:32,647 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode1_1  | 2022-04-08 11:48:32,655 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode1_1  | 2022-04-08 11:48:32,862 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode1_1  | 2022-04-08 11:48:32,972 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode1_1  | 2022-04-08 11:48:32,981 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode1_1  | 2022-04-08 11:48:32,982 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode1_1  | 2022-04-08 11:48:32,982 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
datanode1_1  | 2022-04-08 11:48:32,994 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
datanode1_1  | 2022-04-08 11:48:33,193 [Thread-8] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode1_1  | 2022-04-08 11:48:33,205 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode1_1  | 2022-04-08 11:48:38,927 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode1_1  | 2022-04-08 11:48:39,642 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode1_1  | 2022-04-08 11:48:41,019 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode1_1  | 2022-04-08 11:48:41,024 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode1_1  | 2022-04-08 11:48:41,027 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode1_1  | 2022-04-08 11:48:41,032 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode1_1  | 2022-04-08 11:48:41,035 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2022-04-08 11:48:41,038 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode1_1  | 2022-04-08 11:48:41,052 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode1_1  | 2022-04-08 11:48:47,120 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode1_1  | 2022-04-08 11:48:47,128 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode1_1  | 2022-04-08 11:48:47,131 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode1_1  | 2022-04-08 11:48:47,202 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode1_1  | 2022-04-08 11:48:47,742 [main] INFO server.XceiverServerGrpc: GrpcServer channel type EpollServerSocketChannel
datanode1_1  | 2022-04-08 11:48:48,701 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode1_1  | 2022-04-08 11:48:48,702 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode1_1  | 2022-04-08 11:48:48,702 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.datanode.http.auth.type = kerberos
datanode1_1  | 2022-04-08 11:48:48,865 [main] INFO util.log: Logging initialized @46862ms to org.eclipse.jetty.util.log.Slf4jLog
datanode1_1  | 2022-04-08 11:48:49,587 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode1_1  | 2022-04-08 11:48:49,636 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode1_1  | 2022-04-08 11:48:49,652 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode1_1  | 2022-04-08 11:48:49,656 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode1_1  | 2022-04-08 11:48:49,657 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode1_1  | 2022-04-08 11:48:49,685 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.datanode.http.auth.kerberos.principal keytabKey: hdds.datanode.http.auth.kerberos.keytab
datanode1_1  | 2022-04-08 11:48:49,963 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode1_1  | 2022-04-08 11:48:50,000 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
datanode1_1  | 2022-04-08 11:48:50,252 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode1_1  | 2022-04-08 11:48:50,255 [main] INFO server.session: No SessionScavenger set, using defaults
datanode1_1  | 2022-04-08 11:48:50,273 [main] INFO server.session: node0 Scavenging every 660000ms
datanode1_1  | 2022-04-08 11:48:50,524 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode1_1  | 2022-04-08 11:48:50,557 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@264c9994{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode1_1  | 2022-04-08 11:48:50,563 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@64c79b69{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode1_1  | 2022-04-08 11:48:51,211 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode1_1  | 2022-04-08 11:48:51,317 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@690113f0{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-8519549660565324873/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode1_1  | 2022-04-08 11:48:51,378 [main] INFO server.AbstractConnector: Started ServerConnector@2df40273{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode1_1  | 2022-04-08 11:48:51,383 [main] INFO server.Server: Started @49380ms
datanode1_1  | 2022-04-08 11:48:51,403 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode1_1  | 2022-04-08 11:48:51,410 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode1_1  | 2022-04-08 11:48:51,417 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode1_1  | 2022-04-08 11:48:51,449 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
datanode1_1  | 2022-04-08 11:48:51,718 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@136e202] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode1_1  | 2022-04-08 11:48:52,242 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.25.0.115:9891
datanode1_1  | 2022-04-08 11:48:54,389 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode1_1  | 2022-04-08 11:48:54,400 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode1_1  | 2022-04-08 11:48:54,923 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 0005597f-3053-4b02-96b8-efe2de95313b
datanode1_1  | 2022-04-08 11:48:54,990 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO server.RaftServer: 0005597f-3053-4b02-96b8-efe2de95313b: start RPC server
datanode1_1  | 2022-04-08 11:48:54,992 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO server.GrpcService: 0005597f-3053-4b02-96b8-efe2de95313b: GrpcService started, listening on 9856
datanode1_1  | 2022-04-08 11:48:55,015 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO server.GrpcService: 0005597f-3053-4b02-96b8-efe2de95313b: GrpcService started, listening on 9857
datanode1_1  | 2022-04-08 11:48:55,016 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO server.GrpcService: 0005597f-3053-4b02-96b8-efe2de95313b: GrpcService started, listening on 9858
datanode1_1  | 2022-04-08 11:48:55,021 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 0005597f-3053-4b02-96b8-efe2de95313b is started using port 9858 for RATIS
datanode1_1  | 2022-04-08 11:48:55,021 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 0005597f-3053-4b02-96b8-efe2de95313b is started using port 9857 for RATIS_ADMIN
datanode1_1  | 2022-04-08 11:48:55,023 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 0005597f-3053-4b02-96b8-efe2de95313b is started using port 9856 for RATIS_SERVER
datanode1_1  | 2022-04-08 11:48:55,028 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$351/0x00000008405b6840@2e479a24] INFO util.JvmPauseMonitor: JvmPauseMonitor-0005597f-3053-4b02-96b8-efe2de95313b: Started
datanode1_1  | 2022-04-08 11:48:55,122 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode1_1  | 2022-04-08 11:48:55,122 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode1_1  | 2022-04-08 11:49:09,599 [grpc-default-executor-1] WARN server.GrpcServerProtocolService: 0005597f-3053-4b02-96b8-efe2de95313b: Failed requestVote 4cf3df89-7b36-4576-a18a-5d0c57ddb620->0005597f-3053-4b02-96b8-efe2de95313b#0
datanode1_1  | org.apache.ratis.protocol.exceptions.GroupMismatchException: 0005597f-3053-4b02-96b8-efe2de95313b: group-0543FC7274B5 not found.
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:147)
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:339)
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:348)
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:343)
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.requestVote(RaftServerProxy.java:548)
datanode1_1  | 	at org.apache.ratis.grpc.server.GrpcServerProtocolService.requestVote(GrpcServerProtocolService.java:172)
datanode1_1  | 	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$MethodHandlers.invoke(RaftServerProtocolServiceGrpc.java:394)
datanode2_1  | 2022-04-08 11:48:39,544 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2022-04-08 11:48:39,589 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode2_1  | 2022-04-08 11:48:39,590 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode2_1  | 2022-04-08 11:48:45,352 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode2_1  | 2022-04-08 11:48:45,384 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode2_1  | 2022-04-08 11:48:45,384 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode2_1  | 2022-04-08 11:48:45,461 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2022-04-08 11:48:45,812 [main] INFO server.XceiverServerGrpc: GrpcServer channel type EpollServerSocketChannel
datanode2_1  | 2022-04-08 11:48:46,651 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode2_1  | 2022-04-08 11:48:46,654 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode2_1  | 2022-04-08 11:48:46,655 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.datanode.http.auth.type = kerberos
datanode2_1  | 2022-04-08 11:48:46,794 [main] INFO util.log: Logging initialized @44721ms to org.eclipse.jetty.util.log.Slf4jLog
datanode2_1  | 2022-04-08 11:48:47,369 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode2_1  | 2022-04-08 11:48:47,390 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode2_1  | 2022-04-08 11:48:47,396 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode2_1  | 2022-04-08 11:48:47,396 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode2_1  | 2022-04-08 11:48:47,402 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode2_1  | 2022-04-08 11:48:47,420 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.datanode.http.auth.kerberos.principal keytabKey: hdds.datanode.http.auth.kerberos.keytab
datanode2_1  | 2022-04-08 11:48:47,621 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode2_1  | 2022-04-08 11:48:47,643 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
datanode2_1  | 2022-04-08 11:48:47,907 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode2_1  | 2022-04-08 11:48:47,908 [main] INFO server.session: No SessionScavenger set, using defaults
datanode2_1  | 2022-04-08 11:48:47,938 [main] INFO server.session: node0 Scavenging every 600000ms
datanode2_1  | 2022-04-08 11:48:48,074 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode2_1  | 2022-04-08 11:48:48,077 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@8a0a1d1{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode2_1  | 2022-04-08 11:48:48,092 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@18d8da77{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode2_1  | 2022-04-08 11:48:48,598 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode2_1  | 2022-04-08 11:48:48,654 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@fffb4a8{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-14612002499226631005/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode2_1  | 2022-04-08 11:48:48,693 [main] INFO server.AbstractConnector: Started ServerConnector@5ab7e997{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode2_1  | 2022-04-08 11:48:48,694 [main] INFO server.Server: Started @46621ms
datanode2_1  | 2022-04-08 11:48:48,695 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode2_1  | 2022-04-08 11:48:48,696 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode2_1  | 2022-04-08 11:48:48,704 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode2_1  | 2022-04-08 11:48:48,715 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
datanode2_1  | 2022-04-08 11:48:48,990 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@280bb55e] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode2_1  | 2022-04-08 11:48:49,409 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.25.0.115:9891
datanode2_1  | 2022-04-08 11:48:53,062 [Datanode State Machine Daemon Thread] ERROR datanode.RunningDatanodeState: Error in executing end point task.
datanode2_1  | java.util.concurrent.ExecutionException: java.util.concurrent.TimeoutException
datanode2_1  | 	at java.base/java.util.concurrent.FutureTask.report(FutureTask.java:122)
datanode2_1  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:191)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:193)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:233)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:50)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:658)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:283)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:471)
datanode2_1  | 	at java.base/java.lang.Thread.run(Thread.java:829)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:182)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.PartialForwardingServerCallListener.onHalfClose(PartialForwardingServerCallListener.java:35)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onHalfClose(ForwardingServerCallListener.java:23)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode1_1  | 	at java.base/java.lang.Thread.run(Thread.java:829)
datanode1_1  | 2022-04-08 11:49:09,985 [grpc-default-executor-0] INFO server.RaftServer: 0005597f-3053-4b02-96b8-efe2de95313b: addNew group-0543FC7274B5:[0005597f-3053-4b02-96b8-efe2de95313b|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 8b7f16e2-5fb9-442f-a717-cc893c5795e0|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 4cf3df89-7b36-4576-a18a-5d0c57ddb620|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1] returns group-0543FC7274B5:java.util.concurrent.CompletableFuture@1d26c0ae[Not completed]
datanode1_1  | 2022-04-08 11:49:10,139 [pool-23-thread-1] INFO server.RaftServer$Division: 0005597f-3053-4b02-96b8-efe2de95313b: new RaftServerImpl for group-0543FC7274B5:[0005597f-3053-4b02-96b8-efe2de95313b|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 8b7f16e2-5fb9-442f-a717-cc893c5795e0|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 4cf3df89-7b36-4576-a18a-5d0c57ddb620|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1] with ContainerStateMachine:uninitialized
datanode1_1  | 2022-04-08 11:49:10,171 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode1_1  | 2022-04-08 11:49:10,183 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode1_1  | 2022-04-08 11:49:10,184 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode1_1  | 2022-04-08 11:49:10,184 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode1_1  | 2022-04-08 11:49:10,184 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode1_1  | 2022-04-08 11:49:10,184 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode1_1  | 2022-04-08 11:49:10,185 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode1_1  | 2022-04-08 11:49:10,228 [pool-23-thread-1] INFO server.RaftServer$Division: 0005597f-3053-4b02-96b8-efe2de95313b@group-0543FC7274B5: ConfigurationManager, init=-1: [0005597f-3053-4b02-96b8-efe2de95313b|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 8b7f16e2-5fb9-442f-a717-cc893c5795e0|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 4cf3df89-7b36-4576-a18a-5d0c57ddb620|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1], old=null, confs=<EMPTY_MAP>
datanode1_1  | 2022-04-08 11:49:10,238 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode1_1  | 2022-04-08 11:49:10,253 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode1_1  | 2022-04-08 11:49:10,264 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode1_1  | 2022-04-08 11:49:10,279 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/a6f33c92-47f3-4bcf-8c55-0543fc7274b5 does not exist. Creating ...
datanode1_1  | 2022-04-08 11:49:10,343 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/a6f33c92-47f3-4bcf-8c55-0543fc7274b5/in_use.lock acquired by nodename 7@e7d6b6474bc4
datanode1_1  | 2022-04-08 11:49:10,362 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/a6f33c92-47f3-4bcf-8c55-0543fc7274b5 has been successfully formatted.
datanode1_1  | 2022-04-08 11:49:10,497 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-0543FC7274B5: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode1_1  | 2022-04-08 11:49:10,501 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode1_1  | 2022-04-08 11:49:10,520 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode1_1  | 2022-04-08 11:49:10,643 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode1_1  | 2022-04-08 11:49:10,663 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2022-04-08 11:49:10,760 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2022-04-08 11:49:10,808 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode1_1  | 2022-04-08 11:49:10,832 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode1_1  | 2022-04-08 11:49:10,912 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 0005597f-3053-4b02-96b8-efe2de95313b@group-0543FC7274B5-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/a6f33c92-47f3-4bcf-8c55-0543fc7274b5
datanode1_1  | 2022-04-08 11:49:10,918 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode1_1  | 2022-04-08 11:49:10,921 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode1_1  | 2022-04-08 11:49:10,922 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2022-04-08 11:49:10,930 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode1_1  | 2022-04-08 11:49:10,931 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode1_1  | 2022-04-08 11:49:10,949 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode1_1  | 2022-04-08 11:49:10,950 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode1_1  | 2022-04-08 11:49:10,952 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode1_1  | 2022-04-08 11:49:10,970 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode1_1  | 2022-04-08 11:49:10,988 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode2_1  | Caused by: java.util.concurrent.TimeoutException
datanode2_1  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:204)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.lambda$execute$0(RunningDatanodeState.java:151)
datanode2_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode2_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode2_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode2_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode2_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode2_1  | 	... 1 more
datanode2_1  | 2022-04-08 11:48:53,369 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode2_1  | 2022-04-08 11:48:53,382 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode2_1  | 2022-04-08 11:48:54,090 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 8b7f16e2-5fb9-442f-a717-cc893c5795e0
datanode2_1  | 2022-04-08 11:48:54,154 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO server.RaftServer: 8b7f16e2-5fb9-442f-a717-cc893c5795e0: start RPC server
datanode2_1  | 2022-04-08 11:48:54,206 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO server.GrpcService: 8b7f16e2-5fb9-442f-a717-cc893c5795e0: GrpcService started, listening on 9856
datanode2_1  | 2022-04-08 11:48:54,223 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO server.GrpcService: 8b7f16e2-5fb9-442f-a717-cc893c5795e0: GrpcService started, listening on 9857
datanode2_1  | 2022-04-08 11:48:54,231 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO server.GrpcService: 8b7f16e2-5fb9-442f-a717-cc893c5795e0: GrpcService started, listening on 9858
datanode2_1  | 2022-04-08 11:48:54,244 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 8b7f16e2-5fb9-442f-a717-cc893c5795e0 is started using port 9858 for RATIS
datanode2_1  | 2022-04-08 11:48:54,247 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 8b7f16e2-5fb9-442f-a717-cc893c5795e0 is started using port 9857 for RATIS_ADMIN
datanode2_1  | 2022-04-08 11:48:54,251 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 8b7f16e2-5fb9-442f-a717-cc893c5795e0 is started using port 9856 for RATIS_SERVER
datanode2_1  | 2022-04-08 11:48:54,247 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$352/0x00000008405b6c40@293aa1a7] INFO util.JvmPauseMonitor: JvmPauseMonitor-8b7f16e2-5fb9-442f-a717-cc893c5795e0: Started
datanode2_1  | 2022-04-08 11:48:54,336 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode2_1  | 2022-04-08 11:48:54,339 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode2_1  | 2022-04-08 11:49:06,108 [grpc-default-executor-0] INFO server.RaftServer: 8b7f16e2-5fb9-442f-a717-cc893c5795e0: addNew group-0543FC7274B5:[0005597f-3053-4b02-96b8-efe2de95313b|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 8b7f16e2-5fb9-442f-a717-cc893c5795e0|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 4cf3df89-7b36-4576-a18a-5d0c57ddb620|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1] returns group-0543FC7274B5:java.util.concurrent.CompletableFuture@1e2f390[Not completed]
datanode2_1  | 2022-04-08 11:49:06,231 [pool-23-thread-1] INFO server.RaftServer$Division: 8b7f16e2-5fb9-442f-a717-cc893c5795e0: new RaftServerImpl for group-0543FC7274B5:[0005597f-3053-4b02-96b8-efe2de95313b|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 8b7f16e2-5fb9-442f-a717-cc893c5795e0|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 4cf3df89-7b36-4576-a18a-5d0c57ddb620|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1] with ContainerStateMachine:uninitialized
datanode2_1  | 2022-04-08 11:49:06,239 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode2_1  | 2022-04-08 11:49:06,241 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode2_1  | 2022-04-08 11:49:06,243 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode2_1  | 2022-04-08 11:49:06,243 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode2_1  | 2022-04-08 11:49:06,244 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode2_1  | 2022-04-08 11:49:06,244 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode2_1  | 2022-04-08 11:49:06,255 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | 2022-04-08 11:49:06,271 [pool-23-thread-1] INFO server.RaftServer$Division: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-0543FC7274B5: ConfigurationManager, init=-1: [0005597f-3053-4b02-96b8-efe2de95313b|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 8b7f16e2-5fb9-442f-a717-cc893c5795e0|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 4cf3df89-7b36-4576-a18a-5d0c57ddb620|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1], old=null, confs=<EMPTY_MAP>
datanode2_1  | 2022-04-08 11:49:06,282 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2022-04-08 11:49:06,306 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode2_1  | 2022-04-08 11:49:06,326 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode2_1  | 2022-04-08 11:49:06,331 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/a6f33c92-47f3-4bcf-8c55-0543fc7274b5 does not exist. Creating ...
datanode2_1  | 2022-04-08 11:49:06,368 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/a6f33c92-47f3-4bcf-8c55-0543fc7274b5/in_use.lock acquired by nodename 8@19c25d99ddaf
datanode2_1  | 2022-04-08 11:49:06,411 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/a6f33c92-47f3-4bcf-8c55-0543fc7274b5 has been successfully formatted.
datanode2_1  | 2022-04-08 11:49:06,488 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-0543FC7274B5: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode2_1  | 2022-04-08 11:49:06,489 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode2_1  | 2022-04-08 11:49:06,494 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode2_1  | 2022-04-08 11:49:06,595 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode2_1  | 2022-04-08 11:49:06,597 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2022-04-08 11:49:06,628 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2022-04-08 11:49:06,675 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode2_1  | 2022-04-08 11:49:06,676 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode2_1  | 2022-04-08 11:49:06,690 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-0543FC7274B5-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/a6f33c92-47f3-4bcf-8c55-0543fc7274b5
datanode2_1  | 2022-04-08 11:49:06,693 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode2_1  | 2022-04-08 11:49:06,694 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode2_1  | 2022-04-08 11:49:06,700 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2022-04-08 11:49:06,707 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode2_1  | 2022-04-08 11:49:06,707 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode2_1  | 2022-04-08 11:49:06,714 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode2_1  | 2022-04-08 11:49:06,714 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode2_1  | 2022-04-08 11:49:06,717 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode2_1  | 2022-04-08 11:49:06,749 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode2_1  | 2022-04-08 11:49:06,754 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode2_1  | 2022-04-08 11:49:06,777 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-0543FC7274B5-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode2_1  | 2022-04-08 11:49:06,777 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-0543FC7274B5-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode2_1  | 2022-04-08 11:49:06,793 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
kdc_1        | Apr 08 11:46:41 kdc krb5kdc[7](info): Loaded
kdc_1        | Apr 08 11:46:41 kdc krb5kdc[7](Error): preauth spake failed to initialize: No SPAKE preauth groups configured
kdc_1        | Apr 08 11:46:41 kdc krb5kdc[7](info): setting up network...
kdc_1        | Apr 08 11:46:41 kdc krb5kdc[7](info): setsockopt(8,IPV6_V6ONLY,1) worked
kdc_1        | Apr 08 11:46:41 kdc krb5kdc[7](info): setsockopt(10,IPV6_V6ONLY,1) worked
kdc_1        | Apr 08 11:46:41 kdc krb5kdc[7](info): set up 4 sockets
kdc_1        | Apr 08 11:46:41 kdc krb5kdc[7](info): commencing operation
kdc_1        | krb5kdc: starting...
kdc_1        | Apr 08 11:46:46 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1649418406, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 08 11:46:51 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.114: ISSUE: authtime 1649418411, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, s3g/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 08 11:46:57 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.115: ISSUE: authtime 1649418417, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, recon/recon@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 08 11:46:57 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1649418417, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 08 11:47:06 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.117: ISSUE: authtime 1649418426, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 08 11:47:13 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.116: ISSUE: authtime 1649418433, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 08 11:47:17 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418417, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Apr 08 11:47:19 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1649418426, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Apr 08 11:47:20 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: ISSUE: authtime 1649418417, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, recon/recon@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Apr 08 11:47:27 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1649418447, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 08 11:47:36 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.117: ISSUE: authtime 1649418456, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 08 11:47:37 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418447, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Apr 08 11:47:41 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1649418461, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 08 11:47:44 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1649418456, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Apr 08 11:47:47 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.118: ISSUE: authtime 1649418467, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 08 11:47:48 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.118: ISSUE: authtime 1649418467, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Apr 08 11:47:50 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418461, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Apr 08 11:47:54 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1649418474, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 08 11:47:55 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.118: ISSUE: authtime 1649418475, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 08 11:47:59 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418474, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Apr 08 11:48:01 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.118: ISSUE: authtime 1649418475, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Apr 08 11:48:03 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1649418483, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 08 11:48:17 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.104: ISSUE: authtime 1649418497, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 08 11:48:17 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.102: ISSUE: authtime 1649418497, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 08 11:48:18 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.103: ISSUE: authtime 1649418498, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 08 11:48:20 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.113: ISSUE: authtime 1649418500, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 08 11:48:21 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.111: ISSUE: authtime 1649418501, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 08 11:48:21 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.112: ISSUE: authtime 1649418501, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 08 11:48:23 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.113: ISSUE: authtime 1649418500, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Apr 08 11:48:24 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.111: ISSUE: authtime 1649418501, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Apr 08 11:48:25 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.112: ISSUE: authtime 1649418501, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Apr 08 11:48:27 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.103: ISSUE: authtime 1649418498, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Apr 08 11:48:28 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.102: ISSUE: authtime 1649418497, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Apr 08 11:48:31 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.104: ISSUE: authtime 1649418497, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Apr 08 11:48:33 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418483, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Apr 08 11:48:40 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1649418520, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 08 11:48:51 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.103: ISSUE: authtime 1649418498, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for recon/recon@EXAMPLE.COM
datanode2_1  | 2022-04-08 11:49:06,799 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode2_1  | 2022-04-08 11:49:06,801 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode2_1  | 2022-04-08 11:49:06,802 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode2_1  | 2022-04-08 11:49:06,804 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode2_1  | 2022-04-08 11:49:06,809 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode2_1  | 2022-04-08 11:49:06,940 [pool-23-thread-1] INFO server.RaftServer$Division: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-0543FC7274B5: start as a follower, conf=-1: [0005597f-3053-4b02-96b8-efe2de95313b|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 8b7f16e2-5fb9-442f-a717-cc893c5795e0|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 4cf3df89-7b36-4576-a18a-5d0c57ddb620|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1], old=null
datanode2_1  | 2022-04-08 11:49:06,945 [pool-23-thread-1] INFO server.RaftServer$Division: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-0543FC7274B5: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode2_1  | 2022-04-08 11:49:06,951 [pool-23-thread-1] INFO impl.RoleInfo: 8b7f16e2-5fb9-442f-a717-cc893c5795e0: start 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-0543FC7274B5-FollowerState
datanode2_1  | 2022-04-08 11:49:06,973 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-0543FC7274B5,id=8b7f16e2-5fb9-442f-a717-cc893c5795e0
datanode2_1  | 2022-04-08 11:49:09,065 [grpc-default-executor-0] INFO server.RaftServer$Division: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-0543FC7274B5: receive requestVote(ELECTION, 4cf3df89-7b36-4576-a18a-5d0c57ddb620, group-0543FC7274B5, 1, (t:0, i:0))
datanode2_1  | 2022-04-08 11:49:09,077 [grpc-default-executor-0] INFO impl.VoteContext: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-0543FC7274B5-FOLLOWER: accept ELECTION from 4cf3df89-7b36-4576-a18a-5d0c57ddb620: our priority 0 <= candidate's priority 1
datanode2_1  | 2022-04-08 11:49:09,078 [grpc-default-executor-0] INFO server.RaftServer$Division: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-0543FC7274B5: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:4cf3df89-7b36-4576-a18a-5d0c57ddb620
datanode2_1  | 2022-04-08 11:49:09,079 [grpc-default-executor-0] INFO impl.RoleInfo: 8b7f16e2-5fb9-442f-a717-cc893c5795e0: shutdown 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-0543FC7274B5-FollowerState
datanode2_1  | 2022-04-08 11:49:09,080 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-0543FC7274B5-FollowerState] INFO impl.FollowerState: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-0543FC7274B5-FollowerState was interrupted: {}
datanode2_1  | java.lang.InterruptedException: sleep interrupted
datanode2_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode2_1  | 	at java.base/java.lang.Thread.sleep(Thread.java:334)
datanode2_1  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode2_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
datanode2_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode2_1  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
datanode2_1  | 2022-04-08 11:49:09,107 [grpc-default-executor-0] INFO impl.RoleInfo: 8b7f16e2-5fb9-442f-a717-cc893c5795e0: start 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-0543FC7274B5-FollowerState
datanode2_1  | 2022-04-08 11:49:09,153 [grpc-default-executor-0] INFO server.RaftServer$Division: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-0543FC7274B5 replies to ELECTION vote request: 4cf3df89-7b36-4576-a18a-5d0c57ddb620<-8b7f16e2-5fb9-442f-a717-cc893c5795e0#0:OK-t1. Peer's state: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-0543FC7274B5:t1, leader=null, voted=4cf3df89-7b36-4576-a18a-5d0c57ddb620, raftlog=8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-0543FC7274B5-SegmentedRaftLog:OPENED:c-1, conf=-1: [0005597f-3053-4b02-96b8-efe2de95313b|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 8b7f16e2-5fb9-442f-a717-cc893c5795e0|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 4cf3df89-7b36-4576-a18a-5d0c57ddb620|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1], old=null
datanode2_1  | 2022-04-08 11:49:09,737 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-0543FC7274B5 with new leaderId: 4cf3df89-7b36-4576-a18a-5d0c57ddb620
datanode2_1  | 2022-04-08 11:49:09,740 [grpc-default-executor-0] INFO server.RaftServer$Division: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-0543FC7274B5: change Leader from null to 4cf3df89-7b36-4576-a18a-5d0c57ddb620 at term 1 for appendEntries, leader elected after 3248ms
datanode2_1  | 2022-04-08 11:49:09,849 [grpc-default-executor-0] INFO server.RaftServer$Division: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-0543FC7274B5: set configuration 0: [0005597f-3053-4b02-96b8-efe2de95313b|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 8b7f16e2-5fb9-442f-a717-cc893c5795e0|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 4cf3df89-7b36-4576-a18a-5d0c57ddb620|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1], old=null
datanode2_1  | 2022-04-08 11:49:09,887 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-0543FC7274B5-SegmentedRaftLogWorker: Starting segment from index:0
datanode1_1  | 2022-04-08 11:49:11,026 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 0005597f-3053-4b02-96b8-efe2de95313b@group-0543FC7274B5-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode1_1  | 2022-04-08 11:49:11,027 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 0005597f-3053-4b02-96b8-efe2de95313b@group-0543FC7274B5-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode1_1  | 2022-04-08 11:49:11,036 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode1_1  | 2022-04-08 11:49:11,050 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode1_1  | 2022-04-08 11:49:11,052 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode1_1  | 2022-04-08 11:49:11,054 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode1_1  | 2022-04-08 11:49:11,068 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode1_1  | 2022-04-08 11:49:11,068 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode1_1  | 2022-04-08 11:49:11,279 [pool-23-thread-1] INFO server.RaftServer$Division: 0005597f-3053-4b02-96b8-efe2de95313b@group-0543FC7274B5: start as a follower, conf=-1: [0005597f-3053-4b02-96b8-efe2de95313b|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 8b7f16e2-5fb9-442f-a717-cc893c5795e0|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 4cf3df89-7b36-4576-a18a-5d0c57ddb620|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1], old=null
datanode1_1  | 2022-04-08 11:49:11,281 [pool-23-thread-1] INFO server.RaftServer$Division: 0005597f-3053-4b02-96b8-efe2de95313b@group-0543FC7274B5: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode1_1  | 2022-04-08 11:49:11,284 [pool-23-thread-1] INFO impl.RoleInfo: 0005597f-3053-4b02-96b8-efe2de95313b: start 0005597f-3053-4b02-96b8-efe2de95313b@group-0543FC7274B5-FollowerState
datanode1_1  | 2022-04-08 11:49:11,311 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-0543FC7274B5,id=0005597f-3053-4b02-96b8-efe2de95313b
datanode1_1  | 2022-04-08 11:49:12,063 [grpc-default-executor-0] INFO server.RaftServer: 0005597f-3053-4b02-96b8-efe2de95313b: addNew group-BC074898D12A:[0005597f-3053-4b02-96b8-efe2de95313b|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 8b7f16e2-5fb9-442f-a717-cc893c5795e0|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, 4cf3df89-7b36-4576-a18a-5d0c57ddb620|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0] returns group-BC074898D12A:java.util.concurrent.CompletableFuture@3248ae13[Not completed]
datanode1_1  | 2022-04-08 11:49:12,065 [pool-23-thread-1] INFO server.RaftServer$Division: 0005597f-3053-4b02-96b8-efe2de95313b: new RaftServerImpl for group-BC074898D12A:[0005597f-3053-4b02-96b8-efe2de95313b|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 8b7f16e2-5fb9-442f-a717-cc893c5795e0|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, 4cf3df89-7b36-4576-a18a-5d0c57ddb620|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0] with ContainerStateMachine:uninitialized
datanode1_1  | 2022-04-08 11:49:12,067 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode1_1  | 2022-04-08 11:49:12,067 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode1_1  | 2022-04-08 11:49:12,068 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode1_1  | 2022-04-08 11:49:12,069 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode1_1  | 2022-04-08 11:49:12,069 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode1_1  | 2022-04-08 11:49:12,069 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode1_1  | 2022-04-08 11:49:12,070 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode1_1  | 2022-04-08 11:49:12,070 [pool-23-thread-1] INFO server.RaftServer$Division: 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A: ConfigurationManager, init=-1: [0005597f-3053-4b02-96b8-efe2de95313b|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 8b7f16e2-5fb9-442f-a717-cc893c5795e0|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, 4cf3df89-7b36-4576-a18a-5d0c57ddb620|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null, confs=<EMPTY_MAP>
datanode1_1  | 2022-04-08 11:49:12,071 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode1_1  | 2022-04-08 11:49:12,072 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode1_1  | 2022-04-08 11:49:12,082 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode1_1  | 2022-04-08 11:49:12,082 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/d7bff567-93ff-485c-a104-bc074898d12a does not exist. Creating ...
datanode1_1  | 2022-04-08 11:49:12,084 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/d7bff567-93ff-485c-a104-bc074898d12a/in_use.lock acquired by nodename 7@e7d6b6474bc4
datanode1_1  | 2022-04-08 11:49:12,089 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/d7bff567-93ff-485c-a104-bc074898d12a has been successfully formatted.
datanode1_1  | 2022-04-08 11:49:12,089 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-BC074898D12A: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode1_1  | 2022-04-08 11:49:12,090 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode1_1  | 2022-04-08 11:49:12,090 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode1_1  | 2022-04-08 11:49:12,090 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode1_1  | 2022-04-08 11:49:12,090 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2022-04-08 11:49:12,126 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2022-04-08 11:49:12,130 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode1_1  | 2022-04-08 11:49:12,131 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode1_1  | 2022-04-08 11:49:12,132 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/d7bff567-93ff-485c-a104-bc074898d12a
datanode1_1  | 2022-04-08 11:49:12,132 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode1_1  | 2022-04-08 11:49:12,132 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode1_1  | 2022-04-08 11:49:12,133 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2022-04-08 11:49:12,133 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode1_1  | 2022-04-08 11:49:12,134 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode1_1  | 2022-04-08 11:49:12,135 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode1_1  | 2022-04-08 11:49:12,137 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode1_1  | 2022-04-08 11:49:12,146 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode1_1  | 2022-04-08 11:49:12,147 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode1_1  | 2022-04-08 11:49:12,152 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode1_1  | 2022-04-08 11:49:12,158 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode1_1  | 2022-04-08 11:49:12,159 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode1_1  | 2022-04-08 11:49:12,161 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode1_1  | 2022-04-08 11:49:12,164 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode1_1  | 2022-04-08 11:49:12,165 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode1_1  | 2022-04-08 11:49:12,165 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode1_1  | 2022-04-08 11:49:12,165 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode1_1  | 2022-04-08 11:49:12,166 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode1_1  | 2022-04-08 11:49:12,167 [pool-23-thread-1] INFO server.RaftServer$Division: 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A: start as a follower, conf=-1: [0005597f-3053-4b02-96b8-efe2de95313b|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 8b7f16e2-5fb9-442f-a717-cc893c5795e0|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, 4cf3df89-7b36-4576-a18a-5d0c57ddb620|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-04-08 11:49:12,171 [pool-23-thread-1] INFO server.RaftServer$Division: 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode1_1  | 2022-04-08 11:49:12,174 [pool-23-thread-1] INFO impl.RoleInfo: 0005597f-3053-4b02-96b8-efe2de95313b: start 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A-FollowerState
datanode1_1  | 2022-04-08 11:49:12,181 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-BC074898D12A,id=0005597f-3053-4b02-96b8-efe2de95313b
datanode1_1  | 2022-04-08 11:49:12,769 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-0543FC7274B5 with new leaderId: 4cf3df89-7b36-4576-a18a-5d0c57ddb620
datanode1_1  | 2022-04-08 11:49:12,771 [grpc-default-executor-0] INFO server.RaftServer$Division: 0005597f-3053-4b02-96b8-efe2de95313b@group-0543FC7274B5: change Leader from null to 4cf3df89-7b36-4576-a18a-5d0c57ddb620 at term 1 for appendEntries, leader elected after 2268ms
datanode1_1  | 2022-04-08 11:49:12,789 [grpc-default-executor-0] INFO server.RaftServer$Division: 0005597f-3053-4b02-96b8-efe2de95313b@group-0543FC7274B5: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
datanode1_1  | 2022-04-08 11:49:12,810 [grpc-default-executor-0] INFO server.RaftServer$Division: 0005597f-3053-4b02-96b8-efe2de95313b@group-0543FC7274B5: inconsistency entries. Reply:4cf3df89-7b36-4576-a18a-5d0c57ddb620<-0005597f-3053-4b02-96b8-efe2de95313b#3:FAIL-t0,INCONSISTENCY,nextIndex=0,followerCommit=-1
datanode1_1  | 2022-04-08 11:49:12,860 [grpc-default-executor-0] INFO server.RaftServer$Division: 0005597f-3053-4b02-96b8-efe2de95313b@group-0543FC7274B5: set configuration 0: [0005597f-3053-4b02-96b8-efe2de95313b|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 8b7f16e2-5fb9-442f-a717-cc893c5795e0|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 4cf3df89-7b36-4576-a18a-5d0c57ddb620|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1], old=null
datanode1_1  | 2022-04-08 11:49:12,897 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 0005597f-3053-4b02-96b8-efe2de95313b@group-0543FC7274B5-SegmentedRaftLogWorker: Starting segment from index:0
datanode1_1  | 2022-04-08 11:49:13,128 [0005597f-3053-4b02-96b8-efe2de95313b@group-0543FC7274B5-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 0005597f-3053-4b02-96b8-efe2de95313b@group-0543FC7274B5-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/a6f33c92-47f3-4bcf-8c55-0543fc7274b5/current/log_inprogress_0
datanode1_1  | 2022-04-08 11:49:16,896 [grpc-default-executor-0] INFO server.RaftServer$Division: 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A: receive requestVote(ELECTION, 4cf3df89-7b36-4576-a18a-5d0c57ddb620, group-BC074898D12A, 1, (t:0, i:0))
datanode1_1  | 2022-04-08 11:49:16,902 [grpc-default-executor-0] INFO impl.VoteContext: 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A-FOLLOWER: accept ELECTION from 4cf3df89-7b36-4576-a18a-5d0c57ddb620: our priority 0 <= candidate's priority 0
datanode1_1  | 2022-04-08 11:49:16,903 [grpc-default-executor-0] INFO server.RaftServer$Division: 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:4cf3df89-7b36-4576-a18a-5d0c57ddb620
datanode1_1  | 2022-04-08 11:49:16,903 [grpc-default-executor-0] INFO impl.RoleInfo: 0005597f-3053-4b02-96b8-efe2de95313b: shutdown 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A-FollowerState
datanode1_1  | 2022-04-08 11:49:16,904 [grpc-default-executor-0] INFO impl.RoleInfo: 0005597f-3053-4b02-96b8-efe2de95313b: start 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A-FollowerState
kdc_1        | Apr 08 11:48:53 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.102: ISSUE: authtime 1649418497, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for recon/recon@EXAMPLE.COM
kdc_1        | Apr 08 11:48:57 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.104: ISSUE: authtime 1649418497, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for recon/recon@EXAMPLE.COM
kdc_1        | Apr 08 11:48:58 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.112: ISSUE: authtime 1649418538, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 08 11:48:58 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.111: ISSUE: authtime 1649418538, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 08 11:48:59 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.113: ISSUE: authtime 1649418539, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 08 11:49:01 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.112: ISSUE: authtime 1649418538, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Apr 08 11:49:01 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.113: ISSUE: authtime 1649418539, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Apr 08 11:49:02 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.111: ISSUE: authtime 1649418538, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Apr 08 11:49:09 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418520, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Apr 08 11:49:15 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1649418555, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 08 11:49:19 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: ISSUE: authtime 1649418417, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, recon/recon@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:49:22 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418555, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Apr 08 11:49:25 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1649418565, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 08 11:49:29 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418565, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:49:33 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Apr 08 11:49:33 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Apr 08 11:49:33 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Apr 08 11:49:33 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Apr 08 11:49:35 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1649418575, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om1_1        | Sleeping for 5 seconds
om1_1        | Waiting for the service scm3.org:9894
om1_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om1_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om1_1        | 2022-04-08 11:48:10,234 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om1_1        | /************************************************************
om1_1        | STARTUP_MSG: Starting OzoneManager
om1_1        | STARTUP_MSG:   host = om1/172.25.0.111
om1_1        | STARTUP_MSG:   args = [--init]
om1_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om1_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.0.4.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om1_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/805b5e1d3b8eaf7ab8aef1c57e2bb17b73dea398 ; compiled by 'runner' on 2022-04-08T11:25Z
om1_1        | STARTUP_MSG:   java = 11.0.14.1
om1_1        | ************************************************************/
om1_1        | 2022-04-08 11:48:10,303 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om1_1        | 2022-04-08 11:48:19,141 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om1_1        | 2022-04-08 11:48:19,624 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om1, RPC Address: om1:9862 and Ratis port: 9872
om1_1        | 2022-04-08 11:48:19,626 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om1: om1
om1_1        | 2022-04-08 11:48:19,628 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om1: om1
om1_1        | 2022-04-08 11:48:21,555 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om1_1        | 2022-04-08 11:48:21,560 [main] INFO om.OzoneManager: Ozone Manager login successful.
om1_1        | 2022-04-08 11:48:21,609 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2022-04-08 11:48:25,358 [main] INFO om.OzoneManager: Initializing secure OzoneManager.
om1_1        | 2022-04-08 11:48:28,368 [main] ERROR client.OMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
om1_1        | 2022-04-08 11:48:28,368 [main] INFO client.OMCertificateClient: Certificate client init case: 0
om1_1        | 2022-04-08 11:48:28,369 [main] INFO client.OMCertificateClient: Creating keypair for client as keypair and certificate not found.
om1_1        | 2022-04-08 11:48:34,267 [main] INFO om.OzoneManager: Init response: GETCERT
om1_1        | 2022-04-08 11:48:34,494 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.111,host:om1
om1_1        | 2022-04-08 11:48:34,498 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
om1_1        | 2022-04-08 11:48:34,506 [main] ERROR client.OMCertificateClient: Invalid domain om1
om1_1        | 2022-04-08 11:48:34,524 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om1_1        | 2022-04-08 11:48:34,531 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om1, RPC Address: om1:9862 and Ratis port: 9872
om1_1        | 2022-04-08 11:48:34,535 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om1: om1
om1_1        | 2022-04-08 11:48:34,538 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om1: om1
om1_1        | 2022-04-08 11:48:34,540 [main] INFO om.OzoneManager: Creating csr for OM->dns:om1,ip:172.25.0.111,scmId:088c2e91-0545-411d-8d31-8415832ed844,clusterId:CID-236d968d-b3de-4c14-8c61-a2ea220fd69f,subject:om1
om1_1        | 2022-04-08 11:48:35,470 [main] INFO om.OzoneManager: OzoneManager ports added:[name: "RPC"
om1_1        | value: 9862
om1_1        | ]
om1_1        | 2022-04-08 11:48:37,150 [main] INFO om.OzoneManager: Successfully stored SCM signed certificate.
om1_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-236d968d-b3de-4c14-8c61-a2ea220fd69f;layoutVersion=0
om1_1        | 2022-04-08 11:48:37,301 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om1_1        | /************************************************************
om1_1        | SHUTDOWN_MSG: Shutting down OzoneManager at om1/172.25.0.111
om1_1        | ************************************************************/
om1_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om1_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om1_1        | 2022-04-08 11:48:46,367 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om1_1        | /************************************************************
om1_1        | STARTUP_MSG: Starting OzoneManager
om1_1        | STARTUP_MSG:   host = om1/172.25.0.111
om1_1        | STARTUP_MSG:   args = []
om1_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
kms_1        | Sleeping for 5 seconds
kms_1        | WARNING: /opt/hadoop/temp does not exist. Creating.
datanode3_1  | Sleeping for 5 seconds
datanode3_1  | Waiting for the service scm3.org:9894
datanode3_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode3_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode3_1  | 2022-04-08 11:48:09,644 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode3_1  | /************************************************************
datanode3_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode3_1  | STARTUP_MSG:   host = 1e89468786a9/172.25.0.104
datanode3_1  | STARTUP_MSG:   args = []
datanode3_1  | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
datanode3_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.0.4.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.3.0-SNAPSHOT.jar
datanode3_1  | STARTUP_MSG:   build = https://github.com/apache/ozone/805b5e1d3b8eaf7ab8aef1c57e2bb17b73dea398 ; compiled by 'runner' on 2022-04-08T11:25Z
datanode3_1  | STARTUP_MSG:   java = 11.0.14.1
datanode3_1  | ************************************************************/
datanode3_1  | 2022-04-08 11:48:09,710 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode3_1  | 2022-04-08 11:48:11,414 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode3_1  | 2022-04-08 11:48:11,994 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode3_1  | 2022-04-08 11:48:12,927 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode3_1  | 2022-04-08 11:48:12,927 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode3_1  | 2022-04-08 11:48:13,984 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:1e89468786a9 ip:172.25.0.104
datanode3_1  | 2022-04-08 11:48:16,923 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/dn@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode3_1  | 2022-04-08 11:48:17,865 [main] INFO security.UserGroupInformation: Login successful for user dn/dn@EXAMPLE.COM using keytab file dn.keytab. Keytab auto renewal enabled : false
datanode3_1  | 2022-04-08 11:48:17,869 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
datanode3_1  | 2022-04-08 11:48:19,956 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
datanode3_1  | 2022-04-08 11:48:19,959 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode3_1  | 2022-04-08 11:48:19,963 [main] INFO client.DNCertificateClient: Certificate client init case: 0
datanode3_1  | 2022-04-08 11:48:19,966 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode3_1  | 2022-04-08 11:48:27,724 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
datanode3_1  | 2022-04-08 11:48:27,807 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.104,host:1e89468786a9
datanode3_1  | 2022-04-08 11:48:27,808 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode3_1  | 2022-04-08 11:48:27,817 [main] ERROR client.DNCertificateClient: Invalid domain 1e89468786a9
datanode3_1  | 2022-04-08 11:48:27,841 [main] INFO ozone.HddsDatanodeService: Creating csr for DN-> subject:root@1e89468786a9
datanode3_1  | 2022-04-08 11:48:32,876 [main] INFO client.DNCertificateClient: Loading certificate from location:/data/metadata/dn/certs.
datanode3_1  | 2022-04-08 11:48:32,975 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/936508841118.crt.
datanode3_1  | 2022-04-08 11:48:32,978 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/ROOTCA-1.crt.
datanode3_1  | 2022-04-08 11:48:33,012 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/CA-848180596473.crt.
datanode3_1  | 2022-04-08 11:48:33,012 [main] INFO ozone.HddsDatanodeService: Successfully stored SCM signed certificate, case:GETCERT.
datanode3_1  | 2022-04-08 11:48:33,153 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = SCM_HA (version = 2), software layout = SCM_HA (version = 2)
datanode3_1  | 2022-04-08 11:48:34,491 [main] INFO reflections.Reflections: Reflections took 1077 ms to scan 2 urls, producing 87 keys and 176 values 
datanode3_1  | 2022-04-08 11:48:34,963 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 4
datanode3_1  | 2022-04-08 11:48:36,044 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode3_1  | 2022-04-08 11:48:36,093 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89311358976
datanode3_1  | 2022-04-08 11:48:36,120 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode3_1  | 2022-04-08 11:48:36,126 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode3_1  | 2022-04-08 11:48:36,394 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode3_1  | 2022-04-08 11:48:36,494 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode3_1  | 2022-04-08 11:48:36,524 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode3_1  | 2022-04-08 11:48:36,554 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode3_1  | 2022-04-08 11:48:36,555 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
datanode3_1  | 2022-04-08 11:48:36,556 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
datanode3_1  | 2022-04-08 11:48:36,831 [Thread-8] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode3_1  | 2022-04-08 11:48:36,832 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode3_1  | 2022-04-08 11:48:42,957 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode3_1  | 2022-04-08 11:48:43,415 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode3_1  | 2022-04-08 11:48:44,245 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode3_1  | 2022-04-08 11:48:44,252 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode3_1  | 2022-04-08 11:48:44,262 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode3_1  | 2022-04-08 11:48:44,263 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode3_1  | 2022-04-08 11:48:44,267 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2022-04-08 11:48:44,267 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode3_1  | 2022-04-08 11:48:44,272 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode3_1  | 2022-04-08 11:48:49,576 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode3_1  | 2022-04-08 11:48:49,590 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode3_1  | 2022-04-08 11:48:49,603 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode3_1  | 2022-04-08 11:48:49,692 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode3_1  | 2022-04-08 11:48:50,207 [main] INFO server.XceiverServerGrpc: GrpcServer channel type EpollServerSocketChannel
kdc_1        | Apr 08 11:49:45 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418575, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:49:58 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418575, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:50:03 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418575, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:50:09 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418575, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:50:18 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418575, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:50:23 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418575, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:50:28 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418575, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:50:33 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418575, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:50:33 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Apr 08 11:50:33 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Apr 08 11:50:47 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418575, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:50:51 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418575, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:50:54 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418575, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:50:58 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418575, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:51:07 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418575, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:51:10 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418575, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:51:14 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418575, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:51:18 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418575, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode2_1  | 2022-04-08 11:49:10,153 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-0543FC7274B5-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-0543FC7274B5-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/a6f33c92-47f3-4bcf-8c55-0543fc7274b5/current/log_inprogress_0
datanode2_1  | 2022-04-08 11:49:12,507 [grpc-default-executor-0] INFO server.RaftServer: 8b7f16e2-5fb9-442f-a717-cc893c5795e0: addNew group-BC074898D12A:[0005597f-3053-4b02-96b8-efe2de95313b|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 8b7f16e2-5fb9-442f-a717-cc893c5795e0|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, 4cf3df89-7b36-4576-a18a-5d0c57ddb620|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0] returns group-BC074898D12A:java.util.concurrent.CompletableFuture@7232797f[Not completed]
datanode2_1  | 2022-04-08 11:49:12,509 [pool-23-thread-1] INFO server.RaftServer$Division: 8b7f16e2-5fb9-442f-a717-cc893c5795e0: new RaftServerImpl for group-BC074898D12A:[0005597f-3053-4b02-96b8-efe2de95313b|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 8b7f16e2-5fb9-442f-a717-cc893c5795e0|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, 4cf3df89-7b36-4576-a18a-5d0c57ddb620|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0] with ContainerStateMachine:uninitialized
datanode2_1  | 2022-04-08 11:49:12,510 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode2_1  | 2022-04-08 11:49:12,510 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode2_1  | 2022-04-08 11:49:12,510 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode2_1  | 2022-04-08 11:49:12,510 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode2_1  | 2022-04-08 11:49:12,510 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode2_1  | 2022-04-08 11:49:12,511 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode2_1  | 2022-04-08 11:49:12,511 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | 2022-04-08 11:49:12,511 [pool-23-thread-1] INFO server.RaftServer$Division: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A: ConfigurationManager, init=-1: [0005597f-3053-4b02-96b8-efe2de95313b|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 8b7f16e2-5fb9-442f-a717-cc893c5795e0|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, 4cf3df89-7b36-4576-a18a-5d0c57ddb620|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null, confs=<EMPTY_MAP>
datanode2_1  | 2022-04-08 11:49:12,511 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2022-04-08 11:49:12,512 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode2_1  | 2022-04-08 11:49:12,512 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode2_1  | 2022-04-08 11:49:12,512 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/d7bff567-93ff-485c-a104-bc074898d12a does not exist. Creating ...
datanode2_1  | 2022-04-08 11:49:12,527 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/d7bff567-93ff-485c-a104-bc074898d12a/in_use.lock acquired by nodename 8@19c25d99ddaf
datanode2_1  | 2022-04-08 11:49:12,530 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/d7bff567-93ff-485c-a104-bc074898d12a has been successfully formatted.
datanode2_1  | 2022-04-08 11:49:12,534 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-BC074898D12A: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode2_1  | 2022-04-08 11:49:12,545 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode2_1  | 2022-04-08 11:49:12,545 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode2_1  | 2022-04-08 11:49:12,545 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode2_1  | 2022-04-08 11:49:12,545 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2022-04-08 11:49:12,545 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2022-04-08 11:49:12,546 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode2_1  | 2022-04-08 11:49:12,559 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode2_1  | 2022-04-08 11:49:12,559 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/d7bff567-93ff-485c-a104-bc074898d12a
datanode2_1  | 2022-04-08 11:49:12,559 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode2_1  | 2022-04-08 11:49:12,560 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode2_1  | 2022-04-08 11:49:12,560 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2022-04-08 11:49:12,560 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode2_1  | 2022-04-08 11:49:12,560 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode2_1  | 2022-04-08 11:49:12,560 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode2_1  | 2022-04-08 11:49:12,560 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode2_1  | 2022-04-08 11:49:12,560 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode2_1  | 2022-04-08 11:49:12,562 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode2_1  | 2022-04-08 11:49:12,569 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode2_1  | 2022-04-08 11:49:12,576 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode2_1  | 2022-04-08 11:49:12,576 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode2_1  | 2022-04-08 11:49:12,577 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode2_1  | 2022-04-08 11:49:12,579 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode2_1  | 2022-04-08 11:49:12,579 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode2_1  | 2022-04-08 11:49:12,579 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode2_1  | 2022-04-08 11:49:12,580 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode2_1  | 2022-04-08 11:49:12,580 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode2_1  | 2022-04-08 11:49:12,581 [pool-23-thread-1] INFO server.RaftServer$Division: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A: start as a follower, conf=-1: [0005597f-3053-4b02-96b8-efe2de95313b|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 8b7f16e2-5fb9-442f-a717-cc893c5795e0|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, 4cf3df89-7b36-4576-a18a-5d0c57ddb620|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode2_1  | 2022-04-08 11:49:12,582 [pool-23-thread-1] INFO server.RaftServer$Division: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode2_1  | 2022-04-08 11:49:12,582 [pool-23-thread-1] INFO impl.RoleInfo: 8b7f16e2-5fb9-442f-a717-cc893c5795e0: start 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-FollowerState
datanode2_1  | 2022-04-08 11:49:12,599 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-BC074898D12A,id=8b7f16e2-5fb9-442f-a717-cc893c5795e0
datanode2_1  | 2022-04-08 11:49:16,897 [grpc-default-executor-0] INFO server.RaftServer$Division: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A: receive requestVote(ELECTION, 4cf3df89-7b36-4576-a18a-5d0c57ddb620, group-BC074898D12A, 1, (t:0, i:0))
datanode2_1  | 2022-04-08 11:49:16,897 [grpc-default-executor-0] INFO impl.VoteContext: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-FOLLOWER: reject ELECTION from 4cf3df89-7b36-4576-a18a-5d0c57ddb620: our priority 1 > candidate's priority 0
kdc_1        | Apr 08 11:51:22 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418575, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:51:26 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418575, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:51:30 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418575, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:51:33 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Apr 08 11:51:33 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Apr 08 11:51:33 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418575, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:51:37 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418575, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:51:38 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1649418698, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 08 11:51:41 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418698, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:51:45 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418698, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:51:46 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1649418706, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 08 11:51:49 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418706, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:51:53 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418706, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:51:57 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418706, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:52:06 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418706, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:52:08 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1649418728, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 08 11:52:12 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418728, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:52:21 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418728, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:52:24 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1649418744, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 08 11:52:27 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418744, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:52:31 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418744, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:52:32 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1649418752, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 08 11:52:33 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Apr 08 11:52:33 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Apr 08 11:52:35 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418752, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:52:39 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418752, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:52:40 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1649418760, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 08 11:52:43 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418760, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:52:44 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1649418764, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 08 11:52:47 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418764, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:52:48 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1649418768, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 08 11:52:51 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418768, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:52:55 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418768, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:52:59 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418768, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:53:02 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418768, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:53:06 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418768, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:53:10 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418768, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:53:11 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1649418791, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 08 11:53:14 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418791, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:53:18 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418791, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:53:22 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418791, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:53:25 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418791, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:53:26 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1649418806, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 08 11:53:26 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1649418806, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 08 11:53:29 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418806, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:53:30 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1649418810, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 08 11:53:30 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1649418810, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 08 11:53:33 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Apr 08 11:53:33 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Apr 08 11:53:34 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418810, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:53:34 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1649418814, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 08 11:53:34 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1649418814, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 08 11:53:38 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418814, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om2_1        | Sleeping for 5 seconds
om2_1        | Waiting for the service scm3.org:9894
om2_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om2_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om2_1        | 2022-04-08 11:48:10,346 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om2_1        | /************************************************************
om2_1        | STARTUP_MSG: Starting OzoneManager
om2_1        | STARTUP_MSG:   host = om2/172.25.0.112
om2_1        | STARTUP_MSG:   args = [--init]
om2_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om2_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.0.4.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om2_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/805b5e1d3b8eaf7ab8aef1c57e2bb17b73dea398 ; compiled by 'runner' on 2022-04-08T11:25Z
om2_1        | STARTUP_MSG:   java = 11.0.14.1
om2_1        | ************************************************************/
om2_1        | 2022-04-08 11:48:10,429 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om2_1        | 2022-04-08 11:48:19,645 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om2_1        | 2022-04-08 11:48:20,030 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om2, RPC Address: om2:9862 and Ratis port: 9872
om2_1        | 2022-04-08 11:48:20,031 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om2: om2
om2_1        | 2022-04-08 11:48:20,031 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om2: om2
om2_1        | 2022-04-08 11:48:22,030 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om2_1        | 2022-04-08 11:48:22,030 [main] INFO om.OzoneManager: Ozone Manager login successful.
om2_1        | 2022-04-08 11:48:22,075 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2022-04-08 11:48:25,936 [main] INFO om.OzoneManager: Initializing secure OzoneManager.
om2_1        | 2022-04-08 11:48:29,118 [main] ERROR client.OMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
om2_1        | 2022-04-08 11:48:29,133 [main] INFO client.OMCertificateClient: Certificate client init case: 0
om2_1        | 2022-04-08 11:48:29,135 [main] INFO client.OMCertificateClient: Creating keypair for client as keypair and certificate not found.
om2_1        | 2022-04-08 11:48:33,594 [main] INFO om.OzoneManager: Init response: GETCERT
om2_1        | 2022-04-08 11:48:33,869 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.112,host:om2
om2_1        | 2022-04-08 11:48:33,869 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
om2_1        | 2022-04-08 11:48:33,920 [main] ERROR client.OMCertificateClient: Invalid domain om2
om2_1        | 2022-04-08 11:48:33,924 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om2_1        | 2022-04-08 11:48:33,929 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om2, RPC Address: om2:9862 and Ratis port: 9872
om2_1        | 2022-04-08 11:48:33,929 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om2: om2
om2_1        | 2022-04-08 11:48:33,942 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om2: om2
om2_1        | 2022-04-08 11:48:33,956 [main] INFO om.OzoneManager: Creating csr for OM->dns:om2,ip:172.25.0.112,scmId:088c2e91-0545-411d-8d31-8415832ed844,clusterId:CID-236d968d-b3de-4c14-8c61-a2ea220fd69f,subject:om2
om2_1        | 2022-04-08 11:48:34,847 [main] INFO om.OzoneManager: OzoneManager ports added:[name: "RPC"
om2_1        | value: 9862
om2_1        | ]
om2_1        | 2022-04-08 11:48:36,563 [main] INFO om.OzoneManager: Successfully stored SCM signed certificate.
om2_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-236d968d-b3de-4c14-8c61-a2ea220fd69f;layoutVersion=0
om2_1        | 2022-04-08 11:48:36,714 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om2_1        | /************************************************************
om2_1        | SHUTDOWN_MSG: Shutting down OzoneManager at om2/172.25.0.112
om2_1        | ************************************************************/
om2_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om2_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om2_1        | 2022-04-08 11:48:45,744 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om2_1        | /************************************************************
om2_1        | STARTUP_MSG: Starting OzoneManager
om2_1        | STARTUP_MSG:   host = om2/172.25.0.112
om2_1        | STARTUP_MSG:   args = []
om2_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om2_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.0.4.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om2_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/805b5e1d3b8eaf7ab8aef1c57e2bb17b73dea398 ; compiled by 'runner' on 2022-04-08T11:25Z
om2_1        | STARTUP_MSG:   java = 11.0.14.1
om2_1        | ************************************************************/
om2_1        | 2022-04-08 11:48:45,795 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om2_1        | 2022-04-08 11:48:54,275 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om2_1        | 2022-04-08 11:48:54,748 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om2, RPC Address: om2:9862 and Ratis port: 9872
om2_1        | 2022-04-08 11:48:54,750 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om2: om2
om2_1        | 2022-04-08 11:48:54,750 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om2: om2
om2_1        | 2022-04-08 11:48:54,815 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2022-04-08 11:48:55,202 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = INITIAL_VERSION (version = 0), software layout = INITIAL_VERSION (version = 0)
om2_1        | 2022-04-08 11:48:57,030 [main] INFO reflections.Reflections: Reflections took 1125 ms to scan 1 urls, producing 101 keys and 277 values [using 2 cores]
om2_1        | 2022-04-08 11:48:58,929 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om2_1        | 2022-04-08 11:48:58,929 [main] INFO om.OzoneManager: Ozone Manager login successful.
om2_1        | 2022-04-08 11:48:58,933 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2022-04-08 11:49:04,899 [main] INFO client.OMCertificateClient: Loading certificate from location:/data/metadata/om/certs.
om2_1        | 2022-04-08 11:49:05,412 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/940919975869.crt.
om2_1        | 2022-04-08 11:49:05,441 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/ROOTCA-1.crt.
om2_1        | 2022-04-08 11:49:05,469 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/CA-848180596473.crt.
om2_1        | 2022-04-08 11:49:05,797 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2022-04-08 11:49:06,579 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om2_1        | 2022-04-08 11:49:06,594 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om2_1        | 2022-04-08 11:49:07,862 [main] INFO security.OzoneSecretStore: Loaded 0 tokens
om2_1        | 2022-04-08 11:49:07,862 [main] INFO security.OzoneDelegationTokenSecretManager: Loading token state into token manager.
om2_1        | 2022-04-08 11:49:08,388 [main] INFO om.OzoneManager: Created Volume s3v With Owner root required for S3Gateway operations.
datanode1_1  | 2022-04-08 11:49:16,904 [0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A-FollowerState] INFO impl.FollowerState: 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A-FollowerState was interrupted: {}
datanode1_1  | java.lang.InterruptedException: sleep interrupted
datanode1_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode1_1  | 	at java.base/java.lang.Thread.sleep(Thread.java:334)
datanode1_1  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode1_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
datanode1_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode1_1  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
datanode1_1  | 2022-04-08 11:49:16,947 [grpc-default-executor-0] INFO server.RaftServer$Division: 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A replies to ELECTION vote request: 4cf3df89-7b36-4576-a18a-5d0c57ddb620<-0005597f-3053-4b02-96b8-efe2de95313b#0:OK-t1. Peer's state: 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A:t1, leader=null, voted=4cf3df89-7b36-4576-a18a-5d0c57ddb620, raftlog=0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A-SegmentedRaftLog:OPENED:c-1, conf=-1: [0005597f-3053-4b02-96b8-efe2de95313b|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 8b7f16e2-5fb9-442f-a717-cc893c5795e0|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, 4cf3df89-7b36-4576-a18a-5d0c57ddb620|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-04-08 11:49:22,061 [grpc-default-executor-0] INFO server.RaftServer$Division: 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A: receive requestVote(ELECTION, 4cf3df89-7b36-4576-a18a-5d0c57ddb620, group-BC074898D12A, 2, (t:0, i:0))
datanode1_1  | 2022-04-08 11:49:22,061 [grpc-default-executor-0] INFO impl.VoteContext: 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A-FOLLOWER: accept ELECTION from 4cf3df89-7b36-4576-a18a-5d0c57ddb620: our priority 0 <= candidate's priority 0
datanode1_1  | 2022-04-08 11:49:22,061 [grpc-default-executor-0] INFO server.RaftServer$Division: 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:4cf3df89-7b36-4576-a18a-5d0c57ddb620
datanode1_1  | 2022-04-08 11:49:22,062 [grpc-default-executor-0] INFO impl.RoleInfo: 0005597f-3053-4b02-96b8-efe2de95313b: shutdown 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A-FollowerState
datanode1_1  | 2022-04-08 11:49:22,062 [grpc-default-executor-0] INFO impl.RoleInfo: 0005597f-3053-4b02-96b8-efe2de95313b: start 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A-FollowerState
datanode1_1  | 2022-04-08 11:49:22,062 [0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A-FollowerState] INFO impl.FollowerState: 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A-FollowerState was interrupted: {}
datanode1_1  | java.lang.InterruptedException: sleep interrupted
datanode1_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode1_1  | 	at java.base/java.lang.Thread.sleep(Thread.java:334)
datanode1_1  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode1_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
datanode1_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode1_1  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
datanode1_1  | 2022-04-08 11:49:22,077 [grpc-default-executor-0] INFO server.RaftServer$Division: 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A replies to ELECTION vote request: 4cf3df89-7b36-4576-a18a-5d0c57ddb620<-0005597f-3053-4b02-96b8-efe2de95313b#0:OK-t2. Peer's state: 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A:t2, leader=null, voted=4cf3df89-7b36-4576-a18a-5d0c57ddb620, raftlog=0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A-SegmentedRaftLog:OPENED:c-1, conf=-1: [0005597f-3053-4b02-96b8-efe2de95313b|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 8b7f16e2-5fb9-442f-a717-cc893c5795e0|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, 4cf3df89-7b36-4576-a18a-5d0c57ddb620|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-04-08 11:49:22,608 [grpc-default-executor-0] INFO server.RaftServer$Division: 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A: receive requestVote(ELECTION, 8b7f16e2-5fb9-442f-a717-cc893c5795e0, group-BC074898D12A, 2, (t:0, i:0))
datanode1_1  | 2022-04-08 11:49:22,608 [grpc-default-executor-0] INFO impl.VoteContext: 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A-FOLLOWER: reject ELECTION from 8b7f16e2-5fb9-442f-a717-cc893c5795e0: already has voted for 4cf3df89-7b36-4576-a18a-5d0c57ddb620 at current term 2
datanode1_1  | 2022-04-08 11:49:22,608 [grpc-default-executor-0] INFO server.RaftServer$Division: 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A replies to ELECTION vote request: 8b7f16e2-5fb9-442f-a717-cc893c5795e0<-0005597f-3053-4b02-96b8-efe2de95313b#0:FAIL-t2. Peer's state: 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A:t2, leader=null, voted=4cf3df89-7b36-4576-a18a-5d0c57ddb620, raftlog=0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A-SegmentedRaftLog:OPENED:c-1, conf=-1: [0005597f-3053-4b02-96b8-efe2de95313b|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 8b7f16e2-5fb9-442f-a717-cc893c5795e0|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, 4cf3df89-7b36-4576-a18a-5d0c57ddb620|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-04-08 11:49:27,187 [grpc-default-executor-0] INFO server.RaftServer$Division: 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A: receive requestVote(ELECTION, 4cf3df89-7b36-4576-a18a-5d0c57ddb620, group-BC074898D12A, 3, (t:0, i:0))
datanode1_1  | 2022-04-08 11:49:27,188 [grpc-default-executor-0] INFO impl.VoteContext: 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A-FOLLOWER: accept ELECTION from 4cf3df89-7b36-4576-a18a-5d0c57ddb620: our priority 0 <= candidate's priority 0
datanode1_1  | 2022-04-08 11:49:27,188 [grpc-default-executor-0] INFO server.RaftServer$Division: 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A: changes role from  FOLLOWER to FOLLOWER at term 3 for candidate:4cf3df89-7b36-4576-a18a-5d0c57ddb620
datanode1_1  | 2022-04-08 11:49:27,189 [grpc-default-executor-0] INFO impl.RoleInfo: 0005597f-3053-4b02-96b8-efe2de95313b: shutdown 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A-FollowerState
datanode1_1  | 2022-04-08 11:49:27,189 [0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A-FollowerState] INFO impl.FollowerState: 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A-FollowerState was interrupted: {}
datanode1_1  | java.lang.InterruptedException: sleep interrupted
datanode1_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode1_1  | 	at java.base/java.lang.Thread.sleep(Thread.java:334)
datanode1_1  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode1_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
datanode1_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode1_1  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
datanode1_1  | 2022-04-08 11:49:27,192 [grpc-default-executor-0] INFO impl.RoleInfo: 0005597f-3053-4b02-96b8-efe2de95313b: start 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A-FollowerState
datanode1_1  | 2022-04-08 11:49:27,198 [grpc-default-executor-0] INFO server.RaftServer$Division: 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A replies to ELECTION vote request: 4cf3df89-7b36-4576-a18a-5d0c57ddb620<-0005597f-3053-4b02-96b8-efe2de95313b#0:OK-t3. Peer's state: 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A:t3, leader=null, voted=4cf3df89-7b36-4576-a18a-5d0c57ddb620, raftlog=0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A-SegmentedRaftLog:OPENED:c-1, conf=-1: [0005597f-3053-4b02-96b8-efe2de95313b|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 8b7f16e2-5fb9-442f-a717-cc893c5795e0|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, 4cf3df89-7b36-4576-a18a-5d0c57ddb620|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-04-08 11:49:28,547 [Command processor thread] INFO server.RaftServer: 0005597f-3053-4b02-96b8-efe2de95313b: addNew group-E49E3DA5DF9C:[0005597f-3053-4b02-96b8-efe2de95313b|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1] returns group-E49E3DA5DF9C:java.util.concurrent.CompletableFuture@5b3700d8[Not completed]
datanode1_1  | 2022-04-08 11:49:28,549 [pool-23-thread-1] INFO server.RaftServer$Division: 0005597f-3053-4b02-96b8-efe2de95313b: new RaftServerImpl for group-E49E3DA5DF9C:[0005597f-3053-4b02-96b8-efe2de95313b|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1] with ContainerStateMachine:uninitialized
datanode1_1  | 2022-04-08 11:49:28,549 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode1_1  | 2022-04-08 11:49:28,550 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode1_1  | 2022-04-08 11:49:28,550 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode1_1  | 2022-04-08 11:49:28,550 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode1_1  | 2022-04-08 11:49:28,550 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode1_1  | 2022-04-08 11:49:28,550 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode1_1  | 2022-04-08 11:49:28,550 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode1_1  | 2022-04-08 11:49:28,550 [pool-23-thread-1] INFO server.RaftServer$Division: 0005597f-3053-4b02-96b8-efe2de95313b@group-E49E3DA5DF9C: ConfigurationManager, init=-1: [0005597f-3053-4b02-96b8-efe2de95313b|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode1_1  | 2022-04-08 11:49:28,550 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode1_1  | 2022-04-08 11:49:28,550 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode1_1  | 2022-04-08 11:49:28,550 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode1_1  | 2022-04-08 11:49:28,550 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/8c48fa47-1e15-404a-9159-e49e3da5df9c does not exist. Creating ...
datanode1_1  | 2022-04-08 11:49:28,553 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/8c48fa47-1e15-404a-9159-e49e3da5df9c/in_use.lock acquired by nodename 7@e7d6b6474bc4
datanode1_1  | 2022-04-08 11:49:28,555 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/8c48fa47-1e15-404a-9159-e49e3da5df9c has been successfully formatted.
datanode1_1  | 2022-04-08 11:49:28,556 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-E49E3DA5DF9C: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode1_1  | 2022-04-08 11:49:28,556 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode1_1  | 2022-04-08 11:49:28,556 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode1_1  | 2022-04-08 11:49:28,556 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode1_1  | 2022-04-08 11:49:28,556 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2022-04-08 11:49:28,557 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2022-04-08 11:49:28,557 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode1_1  | 2022-04-08 11:49:28,557 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode1_1  | 2022-04-08 11:49:28,557 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 0005597f-3053-4b02-96b8-efe2de95313b@group-E49E3DA5DF9C-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/8c48fa47-1e15-404a-9159-e49e3da5df9c
datanode1_1  | 2022-04-08 11:49:28,557 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode1_1  | 2022-04-08 11:49:28,557 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode1_1  | 2022-04-08 11:49:28,557 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2022-04-08 11:49:28,557 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode1_1  | 2022-04-08 11:49:28,557 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode1_1  | 2022-04-08 11:49:28,560 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode1_1  | 2022-04-08 11:49:28,596 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode1_1  | 2022-04-08 11:49:28,596 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode1_1  | 2022-04-08 11:49:28,597 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode1_1  | 2022-04-08 11:49:28,597 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode1_1  | 2022-04-08 11:49:28,598 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 0005597f-3053-4b02-96b8-efe2de95313b@group-E49E3DA5DF9C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode1_1  | 2022-04-08 11:49:28,598 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 0005597f-3053-4b02-96b8-efe2de95313b@group-E49E3DA5DF9C-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode1_1  | 2022-04-08 11:49:28,617 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode1_1  | 2022-04-08 11:49:28,620 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode1_1  | 2022-04-08 11:49:28,622 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode1_1  | 2022-04-08 11:49:28,622 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode1_1  | 2022-04-08 11:49:28,622 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode1_1  | 2022-04-08 11:49:28,622 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode1_1  | 2022-04-08 11:49:28,623 [pool-23-thread-1] INFO server.RaftServer$Division: 0005597f-3053-4b02-96b8-efe2de95313b@group-E49E3DA5DF9C: start as a follower, conf=-1: [0005597f-3053-4b02-96b8-efe2de95313b|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1], old=null
datanode1_1  | 2022-04-08 11:49:28,628 [pool-23-thread-1] INFO server.RaftServer$Division: 0005597f-3053-4b02-96b8-efe2de95313b@group-E49E3DA5DF9C: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode1_1  | 2022-04-08 11:49:28,631 [pool-23-thread-1] INFO impl.RoleInfo: 0005597f-3053-4b02-96b8-efe2de95313b: start 0005597f-3053-4b02-96b8-efe2de95313b@group-E49E3DA5DF9C-FollowerState
datanode1_1  | 2022-04-08 11:49:28,640 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-E49E3DA5DF9C,id=0005597f-3053-4b02-96b8-efe2de95313b
datanode1_1  | 2022-04-08 11:49:28,644 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=8c48fa47-1e15-404a-9159-e49e3da5df9c
datanode1_1  | 2022-04-08 11:49:28,645 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=8c48fa47-1e15-404a-9159-e49e3da5df9c.
om3_1        | Sleeping for 5 seconds
om3_1        | Waiting for the service scm3.org:9894
om3_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om3_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om3_1        | 2022-04-08 11:48:10,155 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om3_1        | /************************************************************
om3_1        | STARTUP_MSG: Starting OzoneManager
om3_1        | STARTUP_MSG:   host = om3/172.25.0.113
om3_1        | STARTUP_MSG:   args = [--init]
om3_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om3_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.0.4.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om3_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/805b5e1d3b8eaf7ab8aef1c57e2bb17b73dea398 ; compiled by 'runner' on 2022-04-08T11:25Z
om3_1        | STARTUP_MSG:   java = 11.0.14.1
om3_1        | ************************************************************/
om3_1        | 2022-04-08 11:48:10,231 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om3_1        | 2022-04-08 11:48:18,654 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om3_1        | 2022-04-08 11:48:19,108 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om3, RPC Address: om3:9862 and Ratis port: 9872
om3_1        | 2022-04-08 11:48:19,109 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om3: om3
om3_1        | 2022-04-08 11:48:19,116 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om3: om3
om3_1        | 2022-04-08 11:48:21,002 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om3_1        | 2022-04-08 11:48:21,014 [main] INFO om.OzoneManager: Ozone Manager login successful.
om3_1        | 2022-04-08 11:48:21,101 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2022-04-08 11:48:24,515 [main] INFO om.OzoneManager: Initializing secure OzoneManager.
om3_1        | 2022-04-08 11:48:27,400 [main] ERROR client.OMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
om3_1        | 2022-04-08 11:48:27,400 [main] INFO client.OMCertificateClient: Certificate client init case: 0
om3_1        | 2022-04-08 11:48:27,401 [main] INFO client.OMCertificateClient: Creating keypair for client as keypair and certificate not found.
om3_1        | 2022-04-08 11:48:35,159 [main] INFO om.OzoneManager: Init response: GETCERT
om3_1        | 2022-04-08 11:48:35,456 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.113,host:om3
om3_1        | 2022-04-08 11:48:35,456 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
om3_1        | 2022-04-08 11:48:35,483 [main] ERROR client.OMCertificateClient: Invalid domain om3
om3_1        | 2022-04-08 11:48:35,508 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om3_1        | 2022-04-08 11:48:35,523 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om3, RPC Address: om3:9862 and Ratis port: 9872
om3_1        | 2022-04-08 11:48:35,529 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om3: om3
om3_1        | 2022-04-08 11:48:35,531 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om3: om3
om3_1        | 2022-04-08 11:48:35,533 [main] INFO om.OzoneManager: Creating csr for OM->dns:om3,ip:172.25.0.113,scmId:088c2e91-0545-411d-8d31-8415832ed844,clusterId:CID-236d968d-b3de-4c14-8c61-a2ea220fd69f,subject:om3
om3_1        | 2022-04-08 11:48:36,612 [main] INFO om.OzoneManager: OzoneManager ports added:[name: "RPC"
om3_1        | value: 9862
om3_1        | ]
om3_1        | 2022-04-08 11:48:38,110 [main] INFO om.OzoneManager: Successfully stored SCM signed certificate.
om3_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-236d968d-b3de-4c14-8c61-a2ea220fd69f;layoutVersion=0
om3_1        | 2022-04-08 11:48:38,268 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om3_1        | /************************************************************
om3_1        | SHUTDOWN_MSG: Shutting down OzoneManager at om3/172.25.0.113
om3_1        | ************************************************************/
om3_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om3_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om3_1        | 2022-04-08 11:48:47,205 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om3_1        | /************************************************************
om3_1        | STARTUP_MSG: Starting OzoneManager
om3_1        | STARTUP_MSG:   host = om3/172.25.0.113
om3_1        | STARTUP_MSG:   args = []
om3_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
datanode3_1  | 2022-04-08 11:48:51,220 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode3_1  | 2022-04-08 11:48:51,221 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode3_1  | 2022-04-08 11:48:51,221 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.datanode.http.auth.type = kerberos
datanode3_1  | 2022-04-08 11:48:51,395 [main] INFO util.log: Logging initialized @49176ms to org.eclipse.jetty.util.log.Slf4jLog
datanode3_1  | 2022-04-08 11:48:52,404 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode3_1  | 2022-04-08 11:48:52,439 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode3_1  | 2022-04-08 11:48:52,468 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode3_1  | 2022-04-08 11:48:52,469 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode3_1  | 2022-04-08 11:48:52,508 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode3_1  | 2022-04-08 11:48:52,510 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.datanode.http.auth.kerberos.principal keytabKey: hdds.datanode.http.auth.kerberos.keytab
datanode3_1  | 2022-04-08 11:48:52,839 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode3_1  | 2022-04-08 11:48:52,854 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
datanode3_1  | 2022-04-08 11:48:53,060 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode3_1  | 2022-04-08 11:48:53,060 [main] INFO server.session: No SessionScavenger set, using defaults
datanode3_1  | 2022-04-08 11:48:53,083 [main] INFO server.session: node0 Scavenging every 660000ms
datanode3_1  | 2022-04-08 11:48:53,239 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode3_1  | 2022-04-08 11:48:53,286 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@46c7e6c0{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode3_1  | 2022-04-08 11:48:53,288 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@a94c8e3{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode3_1  | 2022-04-08 11:48:54,146 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode3_1  | 2022-04-08 11:48:54,273 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@509e4d53{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-17944479645001311682/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode3_1  | 2022-04-08 11:48:54,338 [main] INFO server.AbstractConnector: Started ServerConnector@49467fc6{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode3_1  | 2022-04-08 11:48:54,343 [main] INFO server.Server: Started @52125ms
datanode3_1  | 2022-04-08 11:48:54,367 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode3_1  | 2022-04-08 11:48:54,367 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode3_1  | 2022-04-08 11:48:54,372 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode3_1  | 2022-04-08 11:48:54,415 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
datanode3_1  | 2022-04-08 11:48:54,568 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2d3e5863] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode3_1  | 2022-04-08 11:48:55,148 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.25.0.115:9891
datanode3_1  | 2022-04-08 11:48:57,321 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode3_1  | 2022-04-08 11:48:57,400 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode3_1  | 2022-04-08 11:48:57,960 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 4cf3df89-7b36-4576-a18a-5d0c57ddb620
datanode3_1  | 2022-04-08 11:48:58,136 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.RaftServer: 4cf3df89-7b36-4576-a18a-5d0c57ddb620: start RPC server
datanode3_1  | 2022-04-08 11:48:58,164 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.GrpcService: 4cf3df89-7b36-4576-a18a-5d0c57ddb620: GrpcService started, listening on 9856
datanode3_1  | 2022-04-08 11:48:58,177 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.GrpcService: 4cf3df89-7b36-4576-a18a-5d0c57ddb620: GrpcService started, listening on 9857
datanode3_1  | 2022-04-08 11:48:58,186 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.GrpcService: 4cf3df89-7b36-4576-a18a-5d0c57ddb620: GrpcService started, listening on 9858
datanode3_1  | 2022-04-08 11:48:58,205 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 4cf3df89-7b36-4576-a18a-5d0c57ddb620 is started using port 9858 for RATIS
datanode3_1  | 2022-04-08 11:48:58,215 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 4cf3df89-7b36-4576-a18a-5d0c57ddb620 is started using port 9857 for RATIS_ADMIN
datanode3_1  | 2022-04-08 11:48:58,219 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 4cf3df89-7b36-4576-a18a-5d0c57ddb620 is started using port 9856 for RATIS_SERVER
datanode3_1  | 2022-04-08 11:48:58,220 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$351/0x00000008405ae840@4d920721] INFO util.JvmPauseMonitor: JvmPauseMonitor-4cf3df89-7b36-4576-a18a-5d0c57ddb620: Started
datanode3_1  | 2022-04-08 11:48:58,259 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode3_1  | 2022-04-08 11:48:58,275 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode3_1  | 2022-04-08 11:49:01,577 [Command processor thread] INFO server.RaftServer: 4cf3df89-7b36-4576-a18a-5d0c57ddb620: addNew group-7AF890CF2706:[4cf3df89-7b36-4576-a18a-5d0c57ddb620|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1] returns group-7AF890CF2706:java.util.concurrent.CompletableFuture@74e65b04[Not completed]
datanode3_1  | 2022-04-08 11:49:01,641 [pool-23-thread-1] INFO server.RaftServer$Division: 4cf3df89-7b36-4576-a18a-5d0c57ddb620: new RaftServerImpl for group-7AF890CF2706:[4cf3df89-7b36-4576-a18a-5d0c57ddb620|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1] with ContainerStateMachine:uninitialized
datanode3_1  | 2022-04-08 11:49:01,644 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode3_1  | 2022-04-08 11:49:01,650 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode3_1  | 2022-04-08 11:49:01,651 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om1_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.0.4.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om1_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/805b5e1d3b8eaf7ab8aef1c57e2bb17b73dea398 ; compiled by 'runner' on 2022-04-08T11:25Z
om1_1        | STARTUP_MSG:   java = 11.0.14.1
om1_1        | ************************************************************/
om1_1        | 2022-04-08 11:48:46,457 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om1_1        | 2022-04-08 11:48:54,925 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om1_1        | 2022-04-08 11:48:55,496 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om1, RPC Address: om1:9862 and Ratis port: 9872
om1_1        | 2022-04-08 11:48:55,499 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om1: om1
om1_1        | 2022-04-08 11:48:55,499 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om1: om1
om1_1        | 2022-04-08 11:48:55,595 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2022-04-08 11:48:56,299 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = INITIAL_VERSION (version = 0), software layout = INITIAL_VERSION (version = 0)
om1_1        | 2022-04-08 11:48:58,167 [main] INFO reflections.Reflections: Reflections took 1054 ms to scan 1 urls, producing 101 keys and 277 values [using 2 cores]
om1_1        | 2022-04-08 11:48:59,363 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om1_1        | 2022-04-08 11:48:59,363 [main] INFO om.OzoneManager: Ozone Manager login successful.
om1_1        | 2022-04-08 11:48:59,391 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2022-04-08 11:49:04,903 [main] INFO client.OMCertificateClient: Loading certificate from location:/data/metadata/om/certs.
om1_1        | 2022-04-08 11:49:05,336 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/ROOTCA-1.crt.
om1_1        | 2022-04-08 11:49:05,369 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/941464992973.crt.
om1_1        | 2022-04-08 11:49:05,377 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/CA-848180596473.crt.
om1_1        | 2022-04-08 11:49:05,593 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2022-04-08 11:49:06,384 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om1_1        | 2022-04-08 11:49:06,395 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om1_1        | 2022-04-08 11:49:07,497 [main] INFO security.OzoneSecretStore: Loaded 0 tokens
om1_1        | 2022-04-08 11:49:07,497 [main] INFO security.OzoneDelegationTokenSecretManager: Loading token state into token manager.
om1_1        | 2022-04-08 11:49:08,008 [main] INFO om.OzoneManager: Created Volume s3v With Owner root required for S3Gateway operations.
om1_1        | 2022-04-08 11:49:08,487 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om1_1        | 2022-04-08 11:49:08,504 [main] WARN utils.OzoneManagerRatisUtils: ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
om1_1        | 2022-04-08 11:49:08,582 [main] INFO snapshot.OzoneManagerSnapshotProvider: Initializing OM Snapshot Provider
om1_1        | 2022-04-08 11:49:09,414 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om1_1        | 2022-04-08 11:49:09,503 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om1_1        | 2022-04-08 11:49:09,866 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with groupID: id1 and peers: om1:9872, om3:9872, om2:9872
om1_1        | 2022-04-08 11:49:09,965 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
om1_1        | 2022-04-08 11:49:11,370 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
om1_1        | 2022-04-08 11:49:11,832 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
om1_1        | 2022-04-08 11:49:11,840 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om1_1        | 2022-04-08 11:49:11,843 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
om1_1        | 2022-04-08 11:49:11,845 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om1_1        | 2022-04-08 11:49:11,846 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om1_1        | 2022-04-08 11:49:11,849 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om1_1        | 2022-04-08 11:49:11,878 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om1_1        | 2022-04-08 11:49:11,902 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om1_1        | 2022-04-08 11:49:11,936 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om1_1        | 2022-04-08 11:49:13,734 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om1_1        | 2022-04-08 11:49:13,764 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om1_1        | 2022-04-08 11:49:13,764 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om1_1        | 2022-04-08 11:49:13,826 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om1_1        | 2022-04-08 11:49:13,878 [main] INFO server.RaftServer: om1: addNew group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] returns group-562213E44849:java.util.concurrent.CompletableFuture@785ba20d[Not completed]
om1_1        | 2022-04-08 11:49:13,879 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om1_1        | 2022-04-08 11:49:14,030 [pool-24-thread-1] INFO server.RaftServer$Division: om1: new RaftServerImpl for group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] with OzoneManagerStateMachine:uninitialized
om1_1        | 2022-04-08 11:49:14,042 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om1_1        | 2022-04-08 11:49:14,054 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om1_1        | 2022-04-08 11:49:14,055 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om1_1        | 2022-04-08 11:49:14,059 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om1_1        | 2022-04-08 11:49:14,067 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om1_1        | 2022-04-08 11:49:14,067 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om1_1        | 2022-04-08 11:49:14,068 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om1_1        | 2022-04-08 11:49:14,116 [pool-24-thread-1] INFO server.RaftServer$Division: om1@group-562213E44849: ConfigurationManager, init=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null, confs=<EMPTY_MAP>
om1_1        | 2022-04-08 11:49:14,120 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om1_1        | 2022-04-08 11:49:14,176 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om1_1        | 2022-04-08 11:49:14,183 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
om1_1        | 2022-04-08 11:49:14,197 [pool-24-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 does not exist. Creating ...
om1_1        | 2022-04-08 11:49:14,287 [pool-24-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/in_use.lock acquired by nodename 6@om1
om1_1        | 2022-04-08 11:49:14,438 [pool-24-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 has been successfully formatted.
om1_1        | 2022-04-08 11:49:14,456 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om1_1        | 2022-04-08 11:49:14,491 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om1_1        | 2022-04-08 11:49:14,719 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om1_1        | 2022-04-08 11:49:14,739 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om1_1        | 2022-04-08 11:49:15,277 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om1_1        | 2022-04-08 11:49:15,601 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om1_1        | 2022-04-08 11:49:15,604 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om1_1        | 2022-04-08 11:49:15,636 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: new om1@group-562213E44849-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849
om1_1        | 2022-04-08 11:49:15,644 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om1_1        | 2022-04-08 11:49:15,646 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om1_1        | 2022-04-08 11:49:15,647 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om1_1        | 2022-04-08 11:49:15,660 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om1_1        | 2022-04-08 11:49:15,662 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om1_1        | 2022-04-08 11:49:15,672 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om1_1        | 2022-04-08 11:49:15,679 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om1_1        | 2022-04-08 11:49:15,680 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om1_1        | 2022-04-08 11:49:15,789 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om1_1        | 2022-04-08 11:49:15,813 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om1_1        | 2022-04-08 11:49:15,893 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
om1_1        | 2022-04-08 11:49:15,903 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om1_1        | 2022-04-08 11:49:16,006 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om1_1        | 2022-04-08 11:49:16,007 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om1_1        | 2022-04-08 11:49:16,014 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om1_1        | 2022-04-08 11:49:16,015 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om1_1        | 2022-04-08 11:49:16,027 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
om1_1        | 2022-04-08 11:49:16,041 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om1_1        | 2022-04-08 11:49:16,612 [main] INFO reflections.Reflections: Reflections took 2229 ms to scan 7 urls, producing 19 keys and 316 values [using 2 cores]
om1_1        | 2022-04-08 11:49:16,708 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om1_1        | 2022-04-08 11:49:16,751 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om1_1        | 2022-04-08 11:49:17,459 [Listener at om1/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om1_1        | 2022-04-08 11:49:17,512 [Listener at om1/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om1_1        | 2022-04-08 11:49:17,513 [Listener at om1/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om1_1        | 2022-04-08 11:49:17,668 [Listener at om1/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om1/172.25.0.111:9862
om1_1        | 2022-04-08 11:49:17,668 [Listener at om1/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om1 at port 9872
om1_1        | 2022-04-08 11:49:17,672 [Listener at om1/9862] INFO server.RaftServer$Division: om1@group-562213E44849: start as a follower, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1        | 2022-04-08 11:49:17,679 [Listener at om1/9862] INFO server.RaftServer$Division: om1@group-562213E44849: changes role from      null to FOLLOWER at term 0 for startAsFollower
om1_1        | 2022-04-08 11:49:17,683 [Listener at om1/9862] INFO impl.RoleInfo: om1: start om1@group-562213E44849-FollowerState
om1_1        | 2022-04-08 11:49:17,692 [Listener at om1/9862] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-562213E44849,id=om1
om1_1        | 2022-04-08 11:49:17,721 [Listener at om1/9862] INFO server.RaftServer: om1: start RPC server
om1_1        | 2022-04-08 11:49:17,890 [Listener at om1/9862] INFO server.GrpcService: om1: GrpcService started, listening on 9872
om1_1        | 2022-04-08 11:49:17,898 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$411/0x00000008405cf040@586f1bef] INFO util.JvmPauseMonitor: JvmPauseMonitor-om1: Started
om1_1        | 2022-04-08 11:49:17,899 [Listener at om1/9862] INFO om.OzoneManager: Starting OM block token secret manager
om1_1        | 2022-04-08 11:49:17,900 [Listener at om1/9862] INFO security.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
om1_1        | 2022-04-08 11:49:17,901 [Listener at om1/9862] INFO om.OzoneManager: Starting OM delegation token secret manager
om1_1        | 2022-04-08 11:49:17,903 [Listener at om1/9862] INFO security.OzoneDelegationTokenSecretManager: Updating the current master key for generating tokens
om1_1        | 2022-04-08 11:49:17,907 [Listener at om1/9862] INFO om.OzoneManager: Version File has different layout version (0) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
om1_1        | 2022-04-08 11:49:17,920 [Thread[Thread-17,5,main]] INFO security.OzoneDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
om1_1        | 2022-04-08 11:49:18,033 [Listener at om1/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om1_1        | 2022-04-08 11:49:18,033 [Listener at om1/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
om1_1        | 2022-04-08 11:49:18,034 [Listener at om1/9862] INFO http.BaseHttpServer: HttpAuthType: ozone.om.http.auth.type = kerberos
om1_1        | 2022-04-08 11:49:18,080 [Listener at om1/9862] INFO util.log: Logging initialized @39786ms to org.eclipse.jetty.util.log.Slf4jLog
om1_1        | 2022-04-08 11:49:18,486 [Listener at om1/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om1_1        | 2022-04-08 11:49:18,491 [Listener at om1/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om1_1        | 2022-04-08 11:49:18,505 [Listener at om1/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context ozoneManager
om1_1        | 2022-04-08 11:49:18,513 [Listener at om1/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
om1_1        | 2022-04-08 11:49:18,513 [Listener at om1/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
om1_1        | 2022-04-08 11:49:18,517 [Listener at om1/9862] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.om.http.auth.kerberos.principal keytabKey: ozone.om.http.auth.kerberos.keytab
om1_1        | 2022-04-08 11:49:18,664 [Listener at om1/9862] INFO http.HttpServer2: Jetty bound to port 9874
om1_1        | 2022-04-08 11:49:18,678 [Listener at om1/9862] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
om1_1        | 2022-04-08 11:49:18,824 [Listener at om1/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om1_1        | 2022-04-08 11:49:18,824 [Listener at om1/9862] INFO server.session: No SessionScavenger set, using defaults
om1_1        | 2022-04-08 11:49:18,828 [Listener at om1/9862] INFO server.session: node0 Scavenging every 660000ms
om1_1        | 2022-04-08 11:49:18,891 [Listener at om1/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om1_1        | 2022-04-08 11:49:18,910 [Listener at om1/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@40977fab{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om1_1        | 2022-04-08 11:49:18,914 [Listener at om1/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@83b0d9f{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om1_1        | 2022-04-08 11:49:19,267 [Listener at om1/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
datanode2_1  | 2022-04-08 11:49:16,897 [grpc-default-executor-0] INFO server.RaftServer$Division: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:4cf3df89-7b36-4576-a18a-5d0c57ddb620
datanode2_1  | 2022-04-08 11:49:16,897 [grpc-default-executor-0] INFO impl.RoleInfo: 8b7f16e2-5fb9-442f-a717-cc893c5795e0: shutdown 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-FollowerState
datanode2_1  | 2022-04-08 11:49:16,898 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-FollowerState] INFO impl.FollowerState: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-FollowerState was interrupted: {}
datanode2_1  | java.lang.InterruptedException: sleep interrupted
datanode2_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode2_1  | 	at java.base/java.lang.Thread.sleep(Thread.java:334)
datanode2_1  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode2_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
datanode2_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode2_1  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
datanode2_1  | 2022-04-08 11:49:16,901 [grpc-default-executor-0] INFO impl.RoleInfo: 8b7f16e2-5fb9-442f-a717-cc893c5795e0: start 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-FollowerState
datanode2_1  | 2022-04-08 11:49:16,904 [grpc-default-executor-0] INFO server.RaftServer$Division: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A replies to ELECTION vote request: 4cf3df89-7b36-4576-a18a-5d0c57ddb620<-8b7f16e2-5fb9-442f-a717-cc893c5795e0#0:FAIL-t1. Peer's state: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A:t1, leader=null, voted=null, raftlog=8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-SegmentedRaftLog:OPENED:c-1, conf=-1: [0005597f-3053-4b02-96b8-efe2de95313b|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 8b7f16e2-5fb9-442f-a717-cc893c5795e0|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, 4cf3df89-7b36-4576-a18a-5d0c57ddb620|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode2_1  | 2022-04-08 11:49:21,992 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-FollowerState] INFO impl.FollowerState: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5091861000ns, electionTimeout:5090ms
datanode2_1  | 2022-04-08 11:49:21,993 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-FollowerState] INFO impl.RoleInfo: 8b7f16e2-5fb9-442f-a717-cc893c5795e0: shutdown 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-FollowerState
datanode2_1  | 2022-04-08 11:49:21,993 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-FollowerState] INFO server.RaftServer$Division: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
datanode2_1  | 2022-04-08 11:49:21,997 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode2_1  | 2022-04-08 11:49:21,997 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-FollowerState] INFO impl.RoleInfo: 8b7f16e2-5fb9-442f-a717-cc893c5795e0: start 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-LeaderElection1
datanode2_1  | 2022-04-08 11:49:22,002 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-LeaderElection1] INFO impl.LeaderElection: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-LeaderElection1 ELECTION round 0: submit vote requests at term 2 for -1: [0005597f-3053-4b02-96b8-efe2de95313b|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 8b7f16e2-5fb9-442f-a717-cc893c5795e0|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, 4cf3df89-7b36-4576-a18a-5d0c57ddb620|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode2_1  | 2022-04-08 11:49:22,076 [grpc-default-executor-0] INFO server.RaftServer$Division: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A: receive requestVote(ELECTION, 4cf3df89-7b36-4576-a18a-5d0c57ddb620, group-BC074898D12A, 2, (t:0, i:0))
datanode2_1  | 2022-04-08 11:49:22,076 [grpc-default-executor-0] INFO impl.VoteContext: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-CANDIDATE: reject ELECTION from 4cf3df89-7b36-4576-a18a-5d0c57ddb620: already has voted for 8b7f16e2-5fb9-442f-a717-cc893c5795e0 at current term 2
datanode2_1  | 2022-04-08 11:49:22,076 [grpc-default-executor-0] INFO server.RaftServer$Division: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A replies to ELECTION vote request: 4cf3df89-7b36-4576-a18a-5d0c57ddb620<-8b7f16e2-5fb9-442f-a717-cc893c5795e0#0:FAIL-t2. Peer's state: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A:t2, leader=null, voted=8b7f16e2-5fb9-442f-a717-cc893c5795e0, raftlog=8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-SegmentedRaftLog:OPENED:c-1, conf=-1: [0005597f-3053-4b02-96b8-efe2de95313b|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 8b7f16e2-5fb9-442f-a717-cc893c5795e0|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, 4cf3df89-7b36-4576-a18a-5d0c57ddb620|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode2_1  | 2022-04-08 11:49:22,666 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-LeaderElection1] INFO impl.LeaderElection: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-LeaderElection1: ELECTION REJECTED received 2 response(s) and 0 exception(s):
datanode2_1  | 2022-04-08 11:49:22,667 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-LeaderElection1] INFO impl.LeaderElection:   Response 0: 8b7f16e2-5fb9-442f-a717-cc893c5795e0<-0005597f-3053-4b02-96b8-efe2de95313b#0:FAIL-t2
datanode2_1  | 2022-04-08 11:49:22,671 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-LeaderElection1] INFO impl.LeaderElection:   Response 1: 8b7f16e2-5fb9-442f-a717-cc893c5795e0<-4cf3df89-7b36-4576-a18a-5d0c57ddb620#0:FAIL-t2
datanode2_1  | 2022-04-08 11:49:22,671 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-LeaderElection1] INFO impl.LeaderElection: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-LeaderElection1 ELECTION round 0: result REJECTED
datanode2_1  | 2022-04-08 11:49:22,672 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-LeaderElection1] INFO server.RaftServer$Division: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A: changes role from CANDIDATE to FOLLOWER at term 2 for REJECTED
datanode2_1  | 2022-04-08 11:49:22,672 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-LeaderElection1] INFO impl.RoleInfo: 8b7f16e2-5fb9-442f-a717-cc893c5795e0: shutdown 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-LeaderElection1
datanode2_1  | 2022-04-08 11:49:22,673 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-LeaderElection1] INFO impl.RoleInfo: 8b7f16e2-5fb9-442f-a717-cc893c5795e0: start 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-FollowerState
datanode2_1  | 2022-04-08 11:49:27,196 [grpc-default-executor-0] INFO server.RaftServer$Division: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A: receive requestVote(ELECTION, 4cf3df89-7b36-4576-a18a-5d0c57ddb620, group-BC074898D12A, 3, (t:0, i:0))
datanode2_1  | 2022-04-08 11:49:27,197 [grpc-default-executor-0] INFO impl.VoteContext: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-FOLLOWER: reject ELECTION from 4cf3df89-7b36-4576-a18a-5d0c57ddb620: our priority 1 > candidate's priority 0
datanode2_1  | 2022-04-08 11:49:27,197 [grpc-default-executor-0] INFO server.RaftServer$Division: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A: changes role from  FOLLOWER to FOLLOWER at term 3 for candidate:4cf3df89-7b36-4576-a18a-5d0c57ddb620
om1_1        | 2022-04-08 11:49:19,308 [Listener at om1/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@71ebc2e{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-ozone-manager-1_3_0-SNAPSHOT_jar-_-any-13650583871266605597/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/ozoneManager}
om1_1        | 2022-04-08 11:49:19,341 [Listener at om1/9862] INFO server.AbstractConnector: Started ServerConnector@6e92aadd{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
om1_1        | 2022-04-08 11:49:19,353 [Listener at om1/9862] INFO server.Server: Started @41059ms
om1_1        | 2022-04-08 11:49:19,359 [Listener at om1/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om1_1        | 2022-04-08 11:49:19,359 [Listener at om1/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om1_1        | 2022-04-08 11:49:19,363 [Listener at om1/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om1_1        | 2022-04-08 11:49:19,367 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om1_1        | 2022-04-08 11:49:19,386 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om1_1        | 2022-04-08 11:49:19,444 [Listener at om1/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted will not move to trash
om1_1        | 2022-04-08 11:49:19,524 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1a8d4a3c] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om1_1        | 2022-04-08 11:49:22,617 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:44277
om1_1        | 2022-04-08 11:49:22,640 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:49:22,854 [om1@group-562213E44849-FollowerState] INFO impl.FollowerState: om1@group-562213E44849-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5171533260ns, electionTimeout:5145ms
om1_1        | 2022-04-08 11:49:22,871 [om1@group-562213E44849-FollowerState] INFO impl.RoleInfo: om1: shutdown om1@group-562213E44849-FollowerState
om1_1        | 2022-04-08 11:49:22,874 [om1@group-562213E44849-FollowerState] INFO server.RaftServer$Division: om1@group-562213E44849: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
om1_1        | 2022-04-08 11:49:22,877 [om1@group-562213E44849-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om1_1        | 2022-04-08 11:49:22,879 [om1@group-562213E44849-FollowerState] INFO impl.RoleInfo: om1: start om1@group-562213E44849-LeaderElection1
om1_1        | 2022-04-08 11:49:22,909 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1        | 2022-04-08 11:49:25,572 [grpc-default-executor-1] INFO server.RaftServer$Division: om1@group-562213E44849: receive requestVote(ELECTION, om3, group-562213E44849, 1, (t:0, i:~))
om1_1        | 2022-04-08 11:49:25,575 [grpc-default-executor-1] INFO impl.VoteContext: om1@group-562213E44849-CANDIDATE: reject ELECTION from om3: already has voted for om1 at current term 1
om1_1        | 2022-04-08 11:49:25,596 [grpc-default-executor-1] INFO server.RaftServer$Division: om1@group-562213E44849 replies to ELECTION vote request: om3<-om1#0:FAIL-t1. Peer's state: om1@group-562213E44849:t1, leader=null, voted=om1, raftlog=om1@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1        | 2022-04-08 11:49:25,652 [grpc-default-executor-1] INFO server.RaftServer$Division: om1@group-562213E44849: receive requestVote(ELECTION, om2, group-562213E44849, 1, (t:0, i:~))
om1_1        | 2022-04-08 11:49:25,653 [grpc-default-executor-1] INFO impl.VoteContext: om1@group-562213E44849-CANDIDATE: reject ELECTION from om2: already has voted for om1 at current term 1
om1_1        | 2022-04-08 11:49:25,653 [grpc-default-executor-1] INFO server.RaftServer$Division: om1@group-562213E44849 replies to ELECTION vote request: om2<-om1#0:FAIL-t1. Peer's state: om1@group-562213E44849:t1, leader=null, voted=om1, raftlog=om1@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1        | 2022-04-08 11:49:25,769 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection1: ELECTION REJECTED received 2 response(s) and 0 exception(s):
om1_1        | 2022-04-08 11:49:25,771 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 0: om1<-om3#0:FAIL-t1
om1_1        | 2022-04-08 11:49:25,771 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 1: om1<-om2#0:FAIL-t1
om1_1        | 2022-04-08 11:49:25,771 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection1 ELECTION round 0: result REJECTED
om1_1        | 2022-04-08 11:49:25,778 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServer$Division: om1@group-562213E44849: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
om1_1        | 2022-04-08 11:49:25,779 [om1@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om1: shutdown om1@group-562213E44849-LeaderElection1
om1_1        | 2022-04-08 11:49:25,794 [om1@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om1: start om1@group-562213E44849-FollowerState
om1_1        | 2022-04-08 11:49:29,796 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41366
om1_1        | 2022-04-08 11:49:29,816 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:49:30,813 [om1@group-562213E44849-FollowerState] INFO impl.FollowerState: om1@group-562213E44849-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5018125751ns, electionTimeout:5003ms
om1_1        | 2022-04-08 11:49:30,814 [om1@group-562213E44849-FollowerState] INFO impl.RoleInfo: om1: shutdown om1@group-562213E44849-FollowerState
om1_1        | 2022-04-08 11:49:30,814 [om1@group-562213E44849-FollowerState] INFO server.RaftServer$Division: om1@group-562213E44849: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
om1_1        | 2022-04-08 11:49:30,814 [om1@group-562213E44849-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om1_1        | 2022-04-08 11:49:30,814 [om1@group-562213E44849-FollowerState] INFO impl.RoleInfo: om1: start om1@group-562213E44849-LeaderElection2
om1_1        | 2022-04-08 11:49:30,817 [om1@group-562213E44849-LeaderElection2] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection2 ELECTION round 0: submit vote requests at term 2 for -1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1        | 2022-04-08 11:49:30,842 [om1@group-562213E44849-LeaderElection2] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection2: ELECTION PASSED received 1 response(s) and 0 exception(s):
om1_1        | 2022-04-08 11:49:30,842 [om1@group-562213E44849-LeaderElection2] INFO impl.LeaderElection:   Response 0: om1<-om3#0:OK-t2
om1_1        | 2022-04-08 11:49:30,842 [om1@group-562213E44849-LeaderElection2] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection2 ELECTION round 0: result PASSED
om1_1        | 2022-04-08 11:49:30,843 [om1@group-562213E44849-LeaderElection2] INFO impl.RoleInfo: om1: shutdown om1@group-562213E44849-LeaderElection2
om2_1        | 2022-04-08 11:49:08,818 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om2_1        | 2022-04-08 11:49:08,835 [main] WARN utils.OzoneManagerRatisUtils: ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
om2_1        | 2022-04-08 11:49:08,978 [main] INFO snapshot.OzoneManagerSnapshotProvider: Initializing OM Snapshot Provider
om2_1        | 2022-04-08 11:49:09,656 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om2_1        | 2022-04-08 11:49:09,704 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om2_1        | 2022-04-08 11:49:10,034 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with groupID: id1 and peers: om2:9872, om1:9872, om3:9872
om2_1        | 2022-04-08 11:49:10,120 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
om2_1        | 2022-04-08 11:49:11,544 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
om2_1        | 2022-04-08 11:49:12,049 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
om2_1        | 2022-04-08 11:49:12,063 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om2_1        | 2022-04-08 11:49:12,066 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
om2_1        | 2022-04-08 11:49:12,068 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om2_1        | 2022-04-08 11:49:12,069 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om2_1        | 2022-04-08 11:49:12,070 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om2_1        | 2022-04-08 11:49:12,095 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om2_1        | 2022-04-08 11:49:12,134 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om2_1        | 2022-04-08 11:49:12,138 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om2_1        | 2022-04-08 11:49:14,334 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om2_1        | 2022-04-08 11:49:14,394 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om2_1        | 2022-04-08 11:49:14,398 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om2_1        | 2022-04-08 11:49:14,484 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om2_1        | 2022-04-08 11:49:14,520 [main] INFO server.RaftServer: om2: addNew group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] returns group-562213E44849:java.util.concurrent.CompletableFuture@720b52a7[Not completed]
om2_1        | 2022-04-08 11:49:14,524 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om2_1        | 2022-04-08 11:49:14,709 [pool-24-thread-1] INFO server.RaftServer$Division: om2: new RaftServerImpl for group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] with OzoneManagerStateMachine:uninitialized
om2_1        | 2022-04-08 11:49:14,717 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om2_1        | 2022-04-08 11:49:14,733 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om2_1        | 2022-04-08 11:49:14,735 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om2_1        | 2022-04-08 11:49:14,742 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om2_1        | 2022-04-08 11:49:14,746 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om2_1        | 2022-04-08 11:49:14,747 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om2_1        | 2022-04-08 11:49:14,749 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om2_1        | 2022-04-08 11:49:14,818 [pool-24-thread-1] INFO server.RaftServer$Division: om2@group-562213E44849: ConfigurationManager, init=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null, confs=<EMPTY_MAP>
om2_1        | 2022-04-08 11:49:14,833 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om2_1        | 2022-04-08 11:49:14,870 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om2_1        | 2022-04-08 11:49:14,907 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
om2_1        | 2022-04-08 11:49:14,914 [pool-24-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 does not exist. Creating ...
om2_1        | 2022-04-08 11:49:15,071 [pool-24-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/in_use.lock acquired by nodename 8@om2
om2_1        | 2022-04-08 11:49:15,433 [pool-24-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 has been successfully formatted.
om2_1        | 2022-04-08 11:49:15,448 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om2_1        | 2022-04-08 11:49:15,467 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om2_1        | 2022-04-08 11:49:15,572 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om2_1        | 2022-04-08 11:49:15,578 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om2_1        | 2022-04-08 11:49:15,854 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om2_1        | 2022-04-08 11:49:15,960 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om2_1        | 2022-04-08 11:49:15,967 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om2_1        | 2022-04-08 11:49:16,009 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: new om2@group-562213E44849-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849
om2_1        | 2022-04-08 11:49:16,010 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om2_1        | 2022-04-08 11:49:16,018 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om2_1        | 2022-04-08 11:49:16,020 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om2_1        | 2022-04-08 11:49:16,034 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om2_1        | 2022-04-08 11:49:16,035 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om2_1        | 2022-04-08 11:49:16,045 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om2_1        | 2022-04-08 11:49:16,052 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om2_1        | 2022-04-08 11:49:16,063 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om2_1        | 2022-04-08 11:49:16,188 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om2_1        | 2022-04-08 11:49:16,203 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om2_1        | 2022-04-08 11:49:16,266 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
om2_1        | 2022-04-08 11:49:16,266 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om2_1        | 2022-04-08 11:49:16,348 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om2_1        | 2022-04-08 11:49:16,360 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om2_1        | 2022-04-08 11:49:16,378 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om2_1        | 2022-04-08 11:49:16,391 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om2_1        | 2022-04-08 11:49:16,408 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
om2_1        | 2022-04-08 11:49:16,409 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om2_1        | 2022-04-08 11:49:17,415 [main] INFO reflections.Reflections: Reflections took 1934 ms to scan 7 urls, producing 19 keys and 316 values [using 2 cores]
om2_1        | 2022-04-08 11:49:17,462 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om2_1        | 2022-04-08 11:49:17,517 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om2_1        | 2022-04-08 11:49:18,183 [Listener at om2/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om2_1        | 2022-04-08 11:49:18,235 [Listener at om2/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om2_1        | 2022-04-08 11:49:18,235 [Listener at om2/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om2_1        | 2022-04-08 11:49:18,373 [Listener at om2/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om2/172.25.0.112:9862
om2_1        | 2022-04-08 11:49:18,374 [Listener at om2/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om2 at port 9872
om2_1        | 2022-04-08 11:49:18,381 [Listener at om2/9862] INFO server.RaftServer$Division: om2@group-562213E44849: start as a follower, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om2_1        | 2022-04-08 11:49:18,382 [Listener at om2/9862] INFO server.RaftServer$Division: om2@group-562213E44849: changes role from      null to FOLLOWER at term 0 for startAsFollower
om2_1        | 2022-04-08 11:49:18,389 [Listener at om2/9862] INFO impl.RoleInfo: om2: start om2@group-562213E44849-FollowerState
om2_1        | 2022-04-08 11:49:18,400 [Listener at om2/9862] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-562213E44849,id=om2
om2_1        | 2022-04-08 11:49:18,415 [Listener at om2/9862] INFO server.RaftServer: om2: start RPC server
om2_1        | 2022-04-08 11:49:18,561 [Listener at om2/9862] INFO server.GrpcService: om2: GrpcService started, listening on 9872
om2_1        | 2022-04-08 11:49:18,576 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$411/0x00000008405cf040@4485ca30] INFO util.JvmPauseMonitor: JvmPauseMonitor-om2: Started
om2_1        | 2022-04-08 11:49:18,577 [Listener at om2/9862] INFO om.OzoneManager: Starting OM block token secret manager
om2_1        | 2022-04-08 11:49:18,577 [Listener at om2/9862] INFO security.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
om2_1        | 2022-04-08 11:49:18,579 [Listener at om2/9862] INFO om.OzoneManager: Starting OM delegation token secret manager
om2_1        | 2022-04-08 11:49:18,579 [Listener at om2/9862] INFO security.OzoneDelegationTokenSecretManager: Updating the current master key for generating tokens
om2_1        | 2022-04-08 11:49:18,584 [Listener at om2/9862] INFO om.OzoneManager: Version File has different layout version (0) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
om2_1        | 2022-04-08 11:49:18,595 [Thread[Thread-17,5,main]] INFO security.OzoneDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
om2_1        | 2022-04-08 11:49:18,684 [Listener at om2/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om2_1        | 2022-04-08 11:49:18,685 [Listener at om2/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
om2_1        | 2022-04-08 11:49:18,685 [Listener at om2/9862] INFO http.BaseHttpServer: HttpAuthType: ozone.om.http.auth.type = kerberos
om2_1        | 2022-04-08 11:49:18,756 [Listener at om2/9862] INFO util.log: Logging initialized @40869ms to org.eclipse.jetty.util.log.Slf4jLog
om2_1        | 2022-04-08 11:49:19,216 [Listener at om2/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om2_1        | 2022-04-08 11:49:19,235 [Listener at om2/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om2_1        | 2022-04-08 11:49:19,238 [Listener at om2/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context ozoneManager
om2_1        | 2022-04-08 11:49:19,244 [Listener at om2/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
om2_1        | 2022-04-08 11:49:19,244 [Listener at om2/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
om2_1        | 2022-04-08 11:49:19,257 [Listener at om2/9862] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.om.http.auth.kerberos.principal keytabKey: ozone.om.http.auth.kerberos.keytab
om2_1        | 2022-04-08 11:49:19,404 [Listener at om2/9862] INFO http.HttpServer2: Jetty bound to port 9874
om2_1        | 2022-04-08 11:49:19,407 [Listener at om2/9862] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
om2_1        | 2022-04-08 11:49:19,532 [Listener at om2/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om2_1        | 2022-04-08 11:49:19,532 [Listener at om2/9862] INFO server.session: No SessionScavenger set, using defaults
om2_1        | 2022-04-08 11:49:19,548 [Listener at om2/9862] INFO server.session: node0 Scavenging every 600000ms
om2_1        | 2022-04-08 11:49:19,604 [Listener at om2/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om2_1        | 2022-04-08 11:49:19,609 [Listener at om2/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@57f2a68c{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om2_1        | 2022-04-08 11:49:19,612 [Listener at om2/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@763e1ec9{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om2_1        | 2022-04-08 11:49:19,856 [Listener at om2/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
datanode3_1  | 2022-04-08 11:49:01,651 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode3_1  | 2022-04-08 11:49:01,655 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode3_1  | 2022-04-08 11:49:01,655 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode3_1  | 2022-04-08 11:49:01,656 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2022-04-08 11:49:01,673 [pool-23-thread-1] INFO server.RaftServer$Division: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-7AF890CF2706: ConfigurationManager, init=-1: [4cf3df89-7b36-4576-a18a-5d0c57ddb620|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode3_1  | 2022-04-08 11:49:01,685 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode3_1  | 2022-04-08 11:49:01,703 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode3_1  | 2022-04-08 11:49:01,716 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode3_1  | 2022-04-08 11:49:01,719 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/cfd3e9b8-6c85-4577-8ecd-7af890cf2706 does not exist. Creating ...
datanode3_1  | 2022-04-08 11:49:01,756 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/cfd3e9b8-6c85-4577-8ecd-7af890cf2706/in_use.lock acquired by nodename 7@1e89468786a9
datanode3_1  | 2022-04-08 11:49:01,799 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/cfd3e9b8-6c85-4577-8ecd-7af890cf2706 has been successfully formatted.
datanode3_1  | 2022-04-08 11:49:01,840 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-7AF890CF2706: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode3_1  | 2022-04-08 11:49:01,938 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode3_1  | 2022-04-08 11:49:01,960 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode3_1  | 2022-04-08 11:49:02,095 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode3_1  | 2022-04-08 11:49:02,130 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2022-04-08 11:49:02,295 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2022-04-08 11:49:02,377 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode3_1  | 2022-04-08 11:49:02,385 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode3_1  | 2022-04-08 11:49:02,442 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-7AF890CF2706-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/cfd3e9b8-6c85-4577-8ecd-7af890cf2706
datanode3_1  | 2022-04-08 11:49:02,448 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode3_1  | 2022-04-08 11:49:02,448 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode3_1  | 2022-04-08 11:49:02,449 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2022-04-08 11:49:02,451 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode3_1  | 2022-04-08 11:49:02,451 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode3_1  | 2022-04-08 11:49:02,463 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode3_1  | 2022-04-08 11:49:02,464 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode3_1  | 2022-04-08 11:49:02,466 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode3_1  | 2022-04-08 11:49:02,558 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode3_1  | 2022-04-08 11:49:02,565 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode3_1  | 2022-04-08 11:49:02,617 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-7AF890CF2706-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode3_1  | 2022-04-08 11:49:02,626 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-7AF890CF2706-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode3_1  | 2022-04-08 11:49:02,736 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode3_1  | 2022-04-08 11:49:02,737 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode3_1  | 2022-04-08 11:49:02,737 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode3_1  | 2022-04-08 11:49:02,738 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode3_1  | 2022-04-08 11:49:02,741 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode3_1  | 2022-04-08 11:49:02,743 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode3_1  | 2022-04-08 11:49:02,864 [pool-23-thread-1] INFO server.RaftServer$Division: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-7AF890CF2706: start as a follower, conf=-1: [4cf3df89-7b36-4576-a18a-5d0c57ddb620|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode3_1  | 2022-04-08 11:49:02,873 [pool-23-thread-1] INFO server.RaftServer$Division: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-7AF890CF2706: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode3_1  | 2022-04-08 11:49:02,877 [pool-23-thread-1] INFO impl.RoleInfo: 4cf3df89-7b36-4576-a18a-5d0c57ddb620: start 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-7AF890CF2706-FollowerState
datanode3_1  | 2022-04-08 11:49:02,903 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-7AF890CF2706,id=4cf3df89-7b36-4576-a18a-5d0c57ddb620
datanode3_1  | 2022-04-08 11:49:02,980 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=cfd3e9b8-6c85-4577-8ecd-7af890cf2706
datanode3_1  | 2022-04-08 11:49:02,985 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=cfd3e9b8-6c85-4577-8ecd-7af890cf2706.
datanode3_1  | 2022-04-08 11:49:02,991 [Command processor thread] INFO server.RaftServer: 4cf3df89-7b36-4576-a18a-5d0c57ddb620: addNew group-0543FC7274B5:[0005597f-3053-4b02-96b8-efe2de95313b|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, 8b7f16e2-5fb9-442f-a717-cc893c5795e0|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 4cf3df89-7b36-4576-a18a-5d0c57ddb620|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1] returns group-0543FC7274B5:java.util.concurrent.CompletableFuture@52765f62[Not completed]
datanode3_1  | 2022-04-08 11:49:03,046 [pool-23-thread-1] INFO server.RaftServer$Division: 4cf3df89-7b36-4576-a18a-5d0c57ddb620: new RaftServerImpl for group-0543FC7274B5:[0005597f-3053-4b02-96b8-efe2de95313b|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, 8b7f16e2-5fb9-442f-a717-cc893c5795e0|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 4cf3df89-7b36-4576-a18a-5d0c57ddb620|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1] with ContainerStateMachine:uninitialized
datanode3_1  | 2022-04-08 11:49:03,046 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode3_1  | 2022-04-08 11:49:03,046 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode3_1  | 2022-04-08 11:49:03,046 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode3_1  | 2022-04-08 11:49:03,046 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode3_1  | 2022-04-08 11:49:03,046 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode3_1  | 2022-04-08 11:49:03,046 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode3_1  | 2022-04-08 11:49:03,046 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2022-04-08 11:49:03,046 [pool-23-thread-1] INFO server.RaftServer$Division: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5: ConfigurationManager, init=-1: [0005597f-3053-4b02-96b8-efe2de95313b|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, 8b7f16e2-5fb9-442f-a717-cc893c5795e0|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 4cf3df89-7b36-4576-a18a-5d0c57ddb620|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode3_1  | 2022-04-08 11:49:03,046 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode3_1  | 2022-04-08 11:49:03,047 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode3_1  | 2022-04-08 11:49:03,047 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode3_1  | 2022-04-08 11:49:03,047 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/a6f33c92-47f3-4bcf-8c55-0543fc7274b5 does not exist. Creating ...
datanode3_1  | 2022-04-08 11:49:03,098 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/a6f33c92-47f3-4bcf-8c55-0543fc7274b5/in_use.lock acquired by nodename 7@1e89468786a9
datanode3_1  | 2022-04-08 11:49:03,103 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/a6f33c92-47f3-4bcf-8c55-0543fc7274b5 has been successfully formatted.
datanode3_1  | 2022-04-08 11:49:03,104 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-0543FC7274B5: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode3_1  | 2022-04-08 11:49:03,104 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode3_1  | 2022-04-08 11:49:03,104 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode3_1  | 2022-04-08 11:49:03,105 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode3_1  | 2022-04-08 11:49:03,108 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2022-04-08 11:49:03,123 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2022-04-08 11:49:03,133 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode3_1  | 2022-04-08 11:49:03,147 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode3_1  | 2022-04-08 11:49:03,147 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/a6f33c92-47f3-4bcf-8c55-0543fc7274b5
datanode3_1  | 2022-04-08 11:49:03,151 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode3_1  | 2022-04-08 11:49:03,155 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode3_1  | 2022-04-08 11:49:03,155 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2022-04-08 11:49:03,156 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode3_1  | 2022-04-08 11:49:03,156 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode3_1  | 2022-04-08 11:49:03,157 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode3_1  | 2022-04-08 11:49:03,157 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode3_1  | 2022-04-08 11:49:03,157 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode3_1  | 2022-04-08 11:49:03,158 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode3_1  | 2022-04-08 11:49:03,179 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode3_1  | 2022-04-08 11:49:03,186 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode3_1  | 2022-04-08 11:49:03,186 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode3_1  | 2022-04-08 11:49:03,209 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode3_1  | 2022-04-08 11:49:03,209 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode3_1  | 2022-04-08 11:49:03,209 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode3_1  | 2022-04-08 11:49:03,209 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode3_1  | 2022-04-08 11:49:03,210 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode3_1  | 2022-04-08 11:49:03,210 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode3_1  | 2022-04-08 11:49:03,215 [pool-23-thread-1] INFO server.RaftServer$Division: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5: start as a follower, conf=-1: [0005597f-3053-4b02-96b8-efe2de95313b|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, 8b7f16e2-5fb9-442f-a717-cc893c5795e0|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 4cf3df89-7b36-4576-a18a-5d0c57ddb620|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode3_1  | 2022-04-08 11:49:03,216 [pool-23-thread-1] INFO server.RaftServer$Division: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5: changes role from      null to FOLLOWER at term 0 for startAsFollower
recon_1      | Sleeping for 5 seconds
recon_1      | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
recon_1      | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
recon_1      | 2022-04-08 11:46:52,479 [main] INFO recon.ReconServer: STARTUP_MSG: 
recon_1      | /************************************************************
recon_1      | STARTUP_MSG: Starting ReconServer
recon_1      | STARTUP_MSG:   host = recon/172.25.0.115
recon_1      | STARTUP_MSG:   args = []
recon_1      | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
recon_1      | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.6.1.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.6.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/aopalliance-1.0.jar:/opt/hadoop/share/ozone/lib/sqlite-jdbc-3.25.2.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guice-4.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.ws.rs-api-2.1.6.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-2.33.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.33.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/guice-multibindings-4.0.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/bonecp-0.8.0.RELEASE.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jakarta.validation-api-2.0.2.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.33.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-tools-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.33.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.33.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jooq-3.11.10.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.5.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.33.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.3.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/spring-beans-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/derby-10.14.2.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.0.4.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/spring-core-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/jooq-codegen-3.11.10.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/spring-tx-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/jersey-entity-filtering-2.33.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/guice-assistedinject-4.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-media-json-jackson-2.33.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/guice-servlet-4.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/guice-bridge-2.5.0.jar:/opt/hadoop/share/ozone/lib/jooq-meta-3.11.10.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/ozone-reconcodegen-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.33.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/spring-jdbc-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/spring-jcl-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-recon-1.3.0-SNAPSHOT.jar
recon_1      | STARTUP_MSG:   build = https://github.com/apache/ozone/805b5e1d3b8eaf7ab8aef1c57e2bb17b73dea398 ; compiled by 'runner' on 2022-04-08T11:25Z
recon_1      | STARTUP_MSG:   java = 11.0.14.1
recon_1      | ************************************************************/
recon_1      | 2022-04-08 11:46:52,518 [main] INFO recon.ReconServer: registered UNIX signal handlers for [TERM, HUP, INT]
recon_1      | 2022-04-08 11:46:54,570 [main] INFO reflections.Reflections: Reflections took 101 ms to scan 1 urls, producing 13 keys and 35 values 
recon_1      | 2022-04-08 11:46:56,395 [main] INFO recon.ReconServer: Initializing Recon server...
recon_1      | 2022-04-08 11:46:56,669 [main] INFO recon.ReconServer: Ozone security is enabled. Attempting login for Recon service. Principal: recon/recon@EXAMPLE.COM, keytab: /etc/security/keytabs/recon.keytab
recon_1      | 2022-04-08 11:46:57,373 [main] INFO security.UserGroupInformation: Login successful for user recon/recon@EXAMPLE.COM using keytab file recon.keytab. Keytab auto renewal enabled : false
recon_1      | 2022-04-08 11:46:57,381 [main] INFO recon.ReconServer: Recon login successful.
recon_1      | 2022-04-08 11:46:57,381 [main] INFO recon.ReconServer: Initializing secure Recon.
recon_1      | 2022-04-08 11:46:58,453 [main] ERROR client.ReconCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
recon_1      | 2022-04-08 11:46:58,459 [main] INFO client.ReconCertificateClient: Certificate client init case: 0
recon_1      | 2022-04-08 11:46:58,461 [main] INFO client.ReconCertificateClient: Creating keypair for client as keypair and certificate not found.
recon_1      | 2022-04-08 11:47:01,020 [main] INFO recon.ReconServer: Init response: GETCERT
recon_1      | 2022-04-08 11:47:01,065 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.115,host:recon
recon_1      | 2022-04-08 11:47:01,065 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
recon_1      | 2022-04-08 11:47:01,070 [main] ERROR client.ReconCertificateClient: Invalid domain recon
recon_1      | 2022-04-08 11:47:01,283 [main] INFO recon.ReconServer: Creating CSR for Recon.
recon_1      | 2022-04-08 11:47:03,935 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm2.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9961 after 1 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-08 11:47:05,937 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm3.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9961 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-08 11:47:07,939 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm1.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9961 after 3 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-08 11:47:09,940 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm2.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9961 after 4 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-08 11:47:11,942 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm3.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9961 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-08 11:47:13,944 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm1.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9961 after 6 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-08 11:47:15,945 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm2.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9961 after 7 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-08 11:47:17,947 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm3.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9961 after 8 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-08 11:47:20,126 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:088c2e91-0545-411d-8d31-8415832ed844 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
recon_1      | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
recon_1      | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:93)
recon_1      | 	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:16080)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy39.submitRequest over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9961 after 9 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-08 11:47:22,128 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm2.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9961 after 10 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-08 11:47:24,130 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm3.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9961 after 11 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-08 11:47:27,355 [main] INFO recon.ReconServer: Successfully stored SCM signed certificate, case:GETCERT.
recon_1      | 2022-04-08 11:47:27,841 [main] INFO persistence.DefaultDataSourceProvider: JDBC Url for Recon : jdbc:derby:/data/metadata/recon/ozone_recon_derby.db 
recon_1      | 2022-04-08 11:47:29,525 [main] INFO codegen.SqlDbUtils: Created derby database at jdbc:derby:/data/metadata/recon/ozone_recon_derby.db.
recon_1      | WARNING: An illegal reflective access operation has occurred
recon_1      | WARNING: Illegal reflective access by org.jooq.tools.reflect.Reflect (file:/opt/hadoop/share/ozone/lib/jooq-3.11.10.jar) to constructor java.lang.invoke.MethodHandles$Lookup(java.lang.Class)
recon_1      | WARNING: Please consider reporting this to the maintainers of org.jooq.tools.reflect.Reflect
recon_1      | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
recon_1      | WARNING: All illegal access operations will be denied in a future release
recon_1      | 2022-04-08 11:47:30,269 [main] INFO persistence.DefaultDataSourceProvider: JDBC Url for Recon : jdbc:derby:/data/metadata/recon/ozone_recon_derby.db 
recon_1      | 2022-04-08 11:47:30,304 [main] INFO codegen.SqlDbUtils: Created derby database at jdbc:derby:/data/metadata/recon/ozone_recon_derby.db.
recon_1      | 2022-04-08 11:47:30,305 [main] INFO recon.ReconServer: Creating Recon Schema.
recon_1      | 2022-04-08 11:47:32,098 [main] INFO http.BaseHttpServer: Starting Web-server for recon at: http://0.0.0.0:9888
recon_1      | 2022-04-08 11:47:32,099 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
recon_1      | 2022-04-08 11:47:32,099 [main] INFO http.BaseHttpServer: HttpAuthType: ozone.recon.http.auth.type = kerberos
recon_1      | 2022-04-08 11:47:32,123 [main] INFO util.log: Logging initialized @42695ms to org.eclipse.jetty.util.log.Slf4jLog
om3_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.0.4.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om3_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/805b5e1d3b8eaf7ab8aef1c57e2bb17b73dea398 ; compiled by 'runner' on 2022-04-08T11:25Z
om3_1        | STARTUP_MSG:   java = 11.0.14.1
om3_1        | ************************************************************/
om3_1        | 2022-04-08 11:48:47,271 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om3_1        | 2022-04-08 11:48:55,234 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om3_1        | 2022-04-08 11:48:56,130 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om3, RPC Address: om3:9862 and Ratis port: 9872
om3_1        | 2022-04-08 11:48:56,136 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om3: om3
om3_1        | 2022-04-08 11:48:56,139 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om3: om3
om3_1        | 2022-04-08 11:48:56,174 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2022-04-08 11:48:56,679 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = INITIAL_VERSION (version = 0), software layout = INITIAL_VERSION (version = 0)
om3_1        | 2022-04-08 11:48:58,370 [main] INFO reflections.Reflections: Reflections took 1371 ms to scan 1 urls, producing 101 keys and 277 values [using 2 cores]
om3_1        | 2022-04-08 11:48:59,508 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om3_1        | 2022-04-08 11:48:59,509 [main] INFO om.OzoneManager: Ozone Manager login successful.
om3_1        | 2022-04-08 11:48:59,511 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2022-04-08 11:49:05,098 [main] INFO client.OMCertificateClient: Loading certificate from location:/data/metadata/om/certs.
om3_1        | 2022-04-08 11:49:05,575 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/942544094207.crt.
om3_1        | 2022-04-08 11:49:05,600 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/ROOTCA-1.crt.
om3_1        | 2022-04-08 11:49:05,628 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/CA-848180596473.crt.
om3_1        | 2022-04-08 11:49:05,834 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2022-04-08 11:49:06,725 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om3_1        | 2022-04-08 11:49:06,756 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om3_1        | 2022-04-08 11:49:07,708 [main] INFO security.OzoneSecretStore: Loaded 0 tokens
om3_1        | 2022-04-08 11:49:07,708 [main] INFO security.OzoneDelegationTokenSecretManager: Loading token state into token manager.
om3_1        | 2022-04-08 11:49:08,143 [main] INFO om.OzoneManager: Created Volume s3v With Owner root required for S3Gateway operations.
om3_1        | 2022-04-08 11:49:08,598 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode2_1  | 2022-04-08 11:49:27,197 [grpc-default-executor-0] INFO impl.RoleInfo: 8b7f16e2-5fb9-442f-a717-cc893c5795e0: shutdown 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-FollowerState
datanode2_1  | 2022-04-08 11:49:27,197 [grpc-default-executor-0] INFO impl.RoleInfo: 8b7f16e2-5fb9-442f-a717-cc893c5795e0: start 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-FollowerState
datanode2_1  | 2022-04-08 11:49:27,197 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-FollowerState] INFO impl.FollowerState: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-FollowerState was interrupted: {}
datanode2_1  | java.lang.InterruptedException: sleep interrupted
datanode2_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode2_1  | 	at java.base/java.lang.Thread.sleep(Thread.java:334)
datanode2_1  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode2_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
datanode2_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode2_1  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
datanode2_1  | 2022-04-08 11:49:27,202 [grpc-default-executor-0] INFO server.RaftServer$Division: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A replies to ELECTION vote request: 4cf3df89-7b36-4576-a18a-5d0c57ddb620<-8b7f16e2-5fb9-442f-a717-cc893c5795e0#0:FAIL-t3. Peer's state: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A:t3, leader=null, voted=null, raftlog=8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-SegmentedRaftLog:OPENED:c-1, conf=-1: [0005597f-3053-4b02-96b8-efe2de95313b|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 8b7f16e2-5fb9-442f-a717-cc893c5795e0|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, 4cf3df89-7b36-4576-a18a-5d0c57ddb620|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode2_1  | 2022-04-08 11:49:28,066 [Command processor thread] INFO server.RaftServer: 8b7f16e2-5fb9-442f-a717-cc893c5795e0: addNew group-3B267E60A22D:[8b7f16e2-5fb9-442f-a717-cc893c5795e0|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1] returns group-3B267E60A22D:java.util.concurrent.CompletableFuture@2a0b79bf[Not completed]
datanode2_1  | 2022-04-08 11:49:28,069 [pool-23-thread-1] INFO server.RaftServer$Division: 8b7f16e2-5fb9-442f-a717-cc893c5795e0: new RaftServerImpl for group-3B267E60A22D:[8b7f16e2-5fb9-442f-a717-cc893c5795e0|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1] with ContainerStateMachine:uninitialized
datanode2_1  | 2022-04-08 11:49:28,069 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode2_1  | 2022-04-08 11:49:28,069 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode2_1  | 2022-04-08 11:49:28,070 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode2_1  | 2022-04-08 11:49:28,070 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode2_1  | 2022-04-08 11:49:28,070 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode2_1  | 2022-04-08 11:49:28,070 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode2_1  | 2022-04-08 11:49:28,070 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | 2022-04-08 11:49:28,074 [pool-23-thread-1] INFO server.RaftServer$Division: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-3B267E60A22D: ConfigurationManager, init=-1: [8b7f16e2-5fb9-442f-a717-cc893c5795e0|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode2_1  | 2022-04-08 11:49:28,075 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2022-04-08 11:49:28,076 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode2_1  | 2022-04-08 11:49:28,076 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode2_1  | 2022-04-08 11:49:28,076 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/a76fa8e1-27b1-4e30-acd2-3b267e60a22d does not exist. Creating ...
datanode2_1  | 2022-04-08 11:49:28,077 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/a76fa8e1-27b1-4e30-acd2-3b267e60a22d/in_use.lock acquired by nodename 8@19c25d99ddaf
datanode2_1  | 2022-04-08 11:49:28,081 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/a76fa8e1-27b1-4e30-acd2-3b267e60a22d has been successfully formatted.
datanode2_1  | 2022-04-08 11:49:28,087 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-3B267E60A22D: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode2_1  | 2022-04-08 11:49:28,087 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode2_1  | 2022-04-08 11:49:28,087 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode2_1  | 2022-04-08 11:49:28,087 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode2_1  | 2022-04-08 11:49:28,087 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2022-04-08 11:49:28,088 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2022-04-08 11:49:28,088 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode2_1  | 2022-04-08 11:49:28,088 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode2_1  | 2022-04-08 11:49:28,088 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-3B267E60A22D-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/a76fa8e1-27b1-4e30-acd2-3b267e60a22d
datanode2_1  | 2022-04-08 11:49:28,088 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode2_1  | 2022-04-08 11:49:28,088 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode2_1  | 2022-04-08 11:49:28,088 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2022-04-08 11:49:28,088 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode2_1  | 2022-04-08 11:49:28,089 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode2_1  | 2022-04-08 11:49:28,089 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode2_1  | 2022-04-08 11:49:28,089 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode2_1  | 2022-04-08 11:49:28,089 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode2_1  | 2022-04-08 11:49:28,089 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode2_1  | 2022-04-08 11:49:28,090 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
kdc_1        | Apr 08 11:53:42 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418814, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:53:42 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1649418822, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 08 11:53:45 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418822, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:53:49 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418822, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:53:53 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418822, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:53:56 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418822, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:53:57 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1649418837, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 08 11:54:00 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418837, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:54:03 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418837, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:54:10 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418837, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:54:13 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1649418853, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 08 11:54:16 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418853, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:54:19 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418853, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:54:23 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418853, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:54:33 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Apr 08 11:54:33 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Apr 08 11:54:50 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1649418890, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 08 11:54:53 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418890, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:54:57 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.114: ISSUE: authtime 1649418411, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, s3g/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:54:58 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1649418898, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 08 11:55:01 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418898, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:55:16 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1649418916, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 08 11:55:19 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418916, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:55:33 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Apr 08 11:55:33 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Apr 08 11:55:44 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1649418944, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 08 11:55:47 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418944, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:55:53 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1649418953, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 08 11:55:55 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418953, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:56:01 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1649418961, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 08 11:56:03 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418961, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:56:08 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1649418968, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 08 11:56:11 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418968, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:56:16 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1649418976, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 08 11:56:18 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649418976, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:56:33 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Apr 08 11:56:33 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Apr 08 11:57:33 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Apr 08 11:57:33 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Apr 08 11:57:51 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1649419071, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 08 11:57:53 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649419071, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:58:12 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1649419092, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 08 11:58:14 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649419092, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 11:58:33 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Apr 08 11:58:33 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Apr 08 11:59:33 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Apr 08 11:59:33 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Apr 08 12:00:33 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Apr 08 12:00:33 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Apr 08 12:01:33 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Apr 08 12:01:33 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Apr 08 12:02:33 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
datanode1_1  | 2022-04-08 11:49:32,249 [grpc-default-executor-0] INFO server.RaftServer$Division: 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A: receive requestVote(ELECTION, 4cf3df89-7b36-4576-a18a-5d0c57ddb620, group-BC074898D12A, 4, (t:0, i:0))
datanode1_1  | 2022-04-08 11:49:32,249 [grpc-default-executor-0] INFO impl.VoteContext: 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A-FOLLOWER: accept ELECTION from 4cf3df89-7b36-4576-a18a-5d0c57ddb620: our priority 0 <= candidate's priority 0
datanode1_1  | 2022-04-08 11:49:32,249 [grpc-default-executor-0] INFO server.RaftServer$Division: 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A: changes role from  FOLLOWER to FOLLOWER at term 4 for candidate:4cf3df89-7b36-4576-a18a-5d0c57ddb620
datanode1_1  | 2022-04-08 11:49:32,249 [grpc-default-executor-0] INFO impl.RoleInfo: 0005597f-3053-4b02-96b8-efe2de95313b: shutdown 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A-FollowerState
datanode1_1  | 2022-04-08 11:49:32,249 [grpc-default-executor-0] INFO impl.RoleInfo: 0005597f-3053-4b02-96b8-efe2de95313b: start 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A-FollowerState
datanode1_1  | 2022-04-08 11:49:32,249 [0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A-FollowerState] INFO impl.FollowerState: 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A-FollowerState was interrupted: {}
datanode1_1  | java.lang.InterruptedException: sleep interrupted
datanode1_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode1_1  | 	at java.base/java.lang.Thread.sleep(Thread.java:334)
datanode1_1  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode1_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
datanode1_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode1_1  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
datanode1_1  | 2022-04-08 11:49:32,269 [grpc-default-executor-0] INFO server.RaftServer$Division: 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A replies to ELECTION vote request: 4cf3df89-7b36-4576-a18a-5d0c57ddb620<-0005597f-3053-4b02-96b8-efe2de95313b#0:OK-t4. Peer's state: 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A:t4, leader=null, voted=4cf3df89-7b36-4576-a18a-5d0c57ddb620, raftlog=0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A-SegmentedRaftLog:OPENED:c-1, conf=-1: [0005597f-3053-4b02-96b8-efe2de95313b|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 8b7f16e2-5fb9-442f-a717-cc893c5795e0|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, 4cf3df89-7b36-4576-a18a-5d0c57ddb620|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-04-08 11:49:33,838 [0005597f-3053-4b02-96b8-efe2de95313b@group-E49E3DA5DF9C-FollowerState] INFO impl.FollowerState: 0005597f-3053-4b02-96b8-efe2de95313b@group-E49E3DA5DF9C-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5207579501ns, electionTimeout:5197ms
datanode1_1  | 2022-04-08 11:49:33,839 [0005597f-3053-4b02-96b8-efe2de95313b@group-E49E3DA5DF9C-FollowerState] INFO impl.RoleInfo: 0005597f-3053-4b02-96b8-efe2de95313b: shutdown 0005597f-3053-4b02-96b8-efe2de95313b@group-E49E3DA5DF9C-FollowerState
datanode1_1  | 2022-04-08 11:49:33,839 [0005597f-3053-4b02-96b8-efe2de95313b@group-E49E3DA5DF9C-FollowerState] INFO server.RaftServer$Division: 0005597f-3053-4b02-96b8-efe2de95313b@group-E49E3DA5DF9C: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode1_1  | 2022-04-08 11:49:33,842 [0005597f-3053-4b02-96b8-efe2de95313b@group-E49E3DA5DF9C-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode1_1  | 2022-04-08 11:49:33,842 [0005597f-3053-4b02-96b8-efe2de95313b@group-E49E3DA5DF9C-FollowerState] INFO impl.RoleInfo: 0005597f-3053-4b02-96b8-efe2de95313b: start 0005597f-3053-4b02-96b8-efe2de95313b@group-E49E3DA5DF9C-LeaderElection1
datanode1_1  | 2022-04-08 11:49:33,852 [0005597f-3053-4b02-96b8-efe2de95313b@group-E49E3DA5DF9C-LeaderElection1] INFO impl.LeaderElection: 0005597f-3053-4b02-96b8-efe2de95313b@group-E49E3DA5DF9C-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [0005597f-3053-4b02-96b8-efe2de95313b|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1], old=null
datanode1_1  | 2022-04-08 11:49:33,853 [0005597f-3053-4b02-96b8-efe2de95313b@group-E49E3DA5DF9C-LeaderElection1] INFO impl.LeaderElection: 0005597f-3053-4b02-96b8-efe2de95313b@group-E49E3DA5DF9C-LeaderElection1 ELECTION round 0: result PASSED (term=1)
datanode1_1  | 2022-04-08 11:49:33,853 [0005597f-3053-4b02-96b8-efe2de95313b@group-E49E3DA5DF9C-LeaderElection1] INFO impl.RoleInfo: 0005597f-3053-4b02-96b8-efe2de95313b: shutdown 0005597f-3053-4b02-96b8-efe2de95313b@group-E49E3DA5DF9C-LeaderElection1
datanode1_1  | 2022-04-08 11:49:33,862 [0005597f-3053-4b02-96b8-efe2de95313b@group-E49E3DA5DF9C-LeaderElection1] INFO server.RaftServer$Division: 0005597f-3053-4b02-96b8-efe2de95313b@group-E49E3DA5DF9C: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode1_1  | 2022-04-08 11:49:33,862 [0005597f-3053-4b02-96b8-efe2de95313b@group-E49E3DA5DF9C-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-E49E3DA5DF9C with new leaderId: 0005597f-3053-4b02-96b8-efe2de95313b
datanode1_1  | 2022-04-08 11:49:33,910 [0005597f-3053-4b02-96b8-efe2de95313b@group-E49E3DA5DF9C-LeaderElection1] INFO server.RaftServer$Division: 0005597f-3053-4b02-96b8-efe2de95313b@group-E49E3DA5DF9C: change Leader from null to 0005597f-3053-4b02-96b8-efe2de95313b at term 1 for becomeLeader, leader elected after 5306ms
datanode1_1  | 2022-04-08 11:49:33,937 [0005597f-3053-4b02-96b8-efe2de95313b@group-E49E3DA5DF9C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode1_1  | 2022-04-08 11:49:33,946 [0005597f-3053-4b02-96b8-efe2de95313b@group-E49E3DA5DF9C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode1_1  | 2022-04-08 11:49:33,949 [0005597f-3053-4b02-96b8-efe2de95313b@group-E49E3DA5DF9C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode1_1  | 2022-04-08 11:49:33,981 [0005597f-3053-4b02-96b8-efe2de95313b@group-E49E3DA5DF9C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode1_1  | 2022-04-08 11:49:33,983 [0005597f-3053-4b02-96b8-efe2de95313b@group-E49E3DA5DF9C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode1_1  | 2022-04-08 11:49:33,984 [0005597f-3053-4b02-96b8-efe2de95313b@group-E49E3DA5DF9C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode1_1  | 2022-04-08 11:49:34,073 [0005597f-3053-4b02-96b8-efe2de95313b@group-E49E3DA5DF9C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode1_1  | 2022-04-08 11:49:34,080 [0005597f-3053-4b02-96b8-efe2de95313b@group-E49E3DA5DF9C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode1_1  | 2022-04-08 11:49:34,096 [0005597f-3053-4b02-96b8-efe2de95313b@group-E49E3DA5DF9C-LeaderElection1] INFO impl.RoleInfo: 0005597f-3053-4b02-96b8-efe2de95313b: start 0005597f-3053-4b02-96b8-efe2de95313b@group-E49E3DA5DF9C-LeaderStateImpl
datanode1_1  | 2022-04-08 11:49:34,123 [0005597f-3053-4b02-96b8-efe2de95313b@group-E49E3DA5DF9C-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 0005597f-3053-4b02-96b8-efe2de95313b@group-E49E3DA5DF9C-SegmentedRaftLogWorker: Starting segment from index:0
datanode1_1  | 2022-04-08 11:49:34,133 [0005597f-3053-4b02-96b8-efe2de95313b@group-E49E3DA5DF9C-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 0005597f-3053-4b02-96b8-efe2de95313b@group-E49E3DA5DF9C-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/8c48fa47-1e15-404a-9159-e49e3da5df9c/current/log_inprogress_0
om3_1        | 2022-04-08 11:49:08,607 [main] WARN utils.OzoneManagerRatisUtils: ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
om3_1        | 2022-04-08 11:49:08,659 [main] INFO snapshot.OzoneManagerSnapshotProvider: Initializing OM Snapshot Provider
om3_1        | 2022-04-08 11:49:09,245 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om3_1        | 2022-04-08 11:49:09,301 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om3_1        | 2022-04-08 11:49:09,493 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with groupID: id1 and peers: om3:9872, om1:9872, om2:9872
om3_1        | 2022-04-08 11:49:09,575 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
om3_1        | 2022-04-08 11:49:10,914 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
om3_1        | 2022-04-08 11:49:11,547 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
om3_1        | 2022-04-08 11:49:11,560 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om3_1        | 2022-04-08 11:49:11,563 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
om3_1        | 2022-04-08 11:49:11,572 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om3_1        | 2022-04-08 11:49:11,577 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om3_1        | 2022-04-08 11:49:11,591 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om3_1        | 2022-04-08 11:49:11,607 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om3_1        | 2022-04-08 11:49:11,610 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om3_1        | 2022-04-08 11:49:11,611 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om3_1        | 2022-04-08 11:49:13,517 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om3_1        | 2022-04-08 11:49:13,520 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om3_1        | 2022-04-08 11:49:13,523 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om3_1        | 2022-04-08 11:49:13,544 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om3_1        | 2022-04-08 11:49:13,558 [main] INFO server.RaftServer: om3: addNew group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] returns group-562213E44849:java.util.concurrent.CompletableFuture@1a262e93[Not completed]
om3_1        | 2022-04-08 11:49:13,559 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om3_1        | 2022-04-08 11:49:13,768 [pool-24-thread-1] INFO server.RaftServer$Division: om3: new RaftServerImpl for group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] with OzoneManagerStateMachine:uninitialized
om3_1        | 2022-04-08 11:49:13,848 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om3_1        | 2022-04-08 11:49:13,849 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om3_1        | 2022-04-08 11:49:13,849 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om3_1        | 2022-04-08 11:49:13,849 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om3_1        | 2022-04-08 11:49:13,849 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om3_1        | 2022-04-08 11:49:13,849 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om3_1        | 2022-04-08 11:49:13,850 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om3_1        | 2022-04-08 11:49:13,887 [pool-24-thread-1] INFO server.RaftServer$Division: om3@group-562213E44849: ConfigurationManager, init=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null, confs=<EMPTY_MAP>
om3_1        | 2022-04-08 11:49:13,903 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om3_1        | 2022-04-08 11:49:13,945 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om3_1        | 2022-04-08 11:49:13,957 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
om3_1        | 2022-04-08 11:49:13,960 [pool-24-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 does not exist. Creating ...
om3_1        | 2022-04-08 11:49:14,046 [pool-24-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/in_use.lock acquired by nodename 7@om3
om3_1        | 2022-04-08 11:49:14,194 [pool-24-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 has been successfully formatted.
om3_1        | 2022-04-08 11:49:14,202 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om3_1        | 2022-04-08 11:49:14,241 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om3_1        | 2022-04-08 11:49:14,291 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om3_1        | 2022-04-08 11:49:14,302 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om3_1        | 2022-04-08 11:49:14,464 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om3_1        | 2022-04-08 11:49:14,578 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om3_1        | 2022-04-08 11:49:14,588 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om3_1        | 2022-04-08 11:49:14,683 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: new om3@group-562213E44849-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849
om3_1        | 2022-04-08 11:49:14,685 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om3_1        | 2022-04-08 11:49:14,689 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om3_1        | 2022-04-08 11:49:14,697 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om3_1        | 2022-04-08 11:49:14,720 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om3_1        | 2022-04-08 11:49:14,728 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om3_1        | 2022-04-08 11:49:14,754 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om3_1        | 2022-04-08 11:49:14,759 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om3_1        | 2022-04-08 11:49:14,764 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om3_1        | 2022-04-08 11:49:14,973 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om2_1        | 2022-04-08 11:49:19,896 [Listener at om2/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@4dd2f2db{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-ozone-manager-1_3_0-SNAPSHOT_jar-_-any-4954946964303661330/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/ozoneManager}
om2_1        | 2022-04-08 11:49:19,934 [Listener at om2/9862] INFO server.AbstractConnector: Started ServerConnector@77e0b681{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
om2_1        | 2022-04-08 11:49:19,936 [Listener at om2/9862] INFO server.Server: Started @42049ms
om2_1        | 2022-04-08 11:49:19,948 [Listener at om2/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om2_1        | 2022-04-08 11:49:19,948 [Listener at om2/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om2_1        | 2022-04-08 11:49:19,950 [Listener at om2/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om2_1        | 2022-04-08 11:49:19,950 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om2_1        | 2022-04-08 11:49:20,003 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om2_1        | 2022-04-08 11:49:20,160 [Listener at om2/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted will not move to trash
om2_1        | 2022-04-08 11:49:20,185 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5c3b3f04] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om2_1        | 2022-04-08 11:49:23,510 [om2@group-562213E44849-FollowerState] INFO impl.FollowerState: om2@group-562213E44849-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5121981333ns, electionTimeout:5107ms
om2_1        | 2022-04-08 11:49:23,511 [om2@group-562213E44849-FollowerState] INFO impl.RoleInfo: om2: shutdown om2@group-562213E44849-FollowerState
om2_1        | 2022-04-08 11:49:23,515 [om2@group-562213E44849-FollowerState] INFO server.RaftServer$Division: om2@group-562213E44849: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
om2_1        | 2022-04-08 11:49:23,580 [om2@group-562213E44849-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om2_1        | 2022-04-08 11:49:23,592 [om2@group-562213E44849-FollowerState] INFO impl.RoleInfo: om2: start om2@group-562213E44849-LeaderElection1
om2_1        | 2022-04-08 11:49:23,639 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om2@group-562213E44849-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om2_1        | 2022-04-08 11:49:25,570 [grpc-default-executor-1] INFO server.RaftServer$Division: om2@group-562213E44849: receive requestVote(ELECTION, om1, group-562213E44849, 1, (t:0, i:~))
om2_1        | 2022-04-08 11:49:25,587 [grpc-default-executor-1] INFO impl.VoteContext: om2@group-562213E44849-CANDIDATE: reject ELECTION from om1: already has voted for om2 at current term 1
om2_1        | 2022-04-08 11:49:25,598 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-562213E44849: receive requestVote(ELECTION, om3, group-562213E44849, 1, (t:0, i:~))
om2_1        | 2022-04-08 11:49:25,671 [grpc-default-executor-1] INFO server.RaftServer$Division: om2@group-562213E44849 replies to ELECTION vote request: om1<-om2#0:FAIL-t1. Peer's state: om2@group-562213E44849:t1, leader=null, voted=om2, raftlog=om2@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om2_1        | 2022-04-08 11:49:25,671 [grpc-default-executor-0] INFO impl.VoteContext: om2@group-562213E44849-CANDIDATE: reject ELECTION from om3: already has voted for om2 at current term 1
om2_1        | 2022-04-08 11:49:25,676 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-562213E44849 replies to ELECTION vote request: om3<-om2#0:FAIL-t1. Peer's state: om2@group-562213E44849:t1, leader=null, voted=om2, raftlog=om2@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om2_1        | 2022-04-08 11:49:25,760 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om2@group-562213E44849-LeaderElection1: ELECTION REJECTED received 2 response(s) and 0 exception(s):
om2_1        | 2022-04-08 11:49:25,762 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 0: om2<-om1#0:FAIL-t1
om2_1        | 2022-04-08 11:49:25,762 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 1: om2<-om3#0:FAIL-t1
om2_1        | 2022-04-08 11:49:25,762 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om2@group-562213E44849-LeaderElection1 ELECTION round 0: result REJECTED
om2_1        | 2022-04-08 11:49:25,764 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServer$Division: om2@group-562213E44849: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
om2_1        | 2022-04-08 11:49:25,765 [om2@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om2: shutdown om2@group-562213E44849-LeaderElection1
om2_1        | 2022-04-08 11:49:25,765 [om2@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om2: start om2@group-562213E44849-FollowerState
om2_1        | 2022-04-08 11:49:25,890 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:38069
om2_1        | 2022-04-08 11:49:25,906 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-04-08 11:49:29,859 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35346
om2_1        | 2022-04-08 11:49:29,867 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-04-08 11:49:30,822 [om2@group-562213E44849-FollowerState] INFO impl.FollowerState: om2@group-562213E44849-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5057298890ns, electionTimeout:5029ms
om2_1        | 2022-04-08 11:49:30,824 [om2@group-562213E44849-FollowerState] INFO impl.RoleInfo: om2: shutdown om2@group-562213E44849-FollowerState
om2_1        | 2022-04-08 11:49:30,825 [om2@group-562213E44849-FollowerState] INFO server.RaftServer$Division: om2@group-562213E44849: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
om2_1        | 2022-04-08 11:49:30,827 [om2@group-562213E44849-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om2_1        | 2022-04-08 11:49:30,827 [om2@group-562213E44849-FollowerState] INFO impl.RoleInfo: om2: start om2@group-562213E44849-LeaderElection2
om2_1        | 2022-04-08 11:49:30,831 [grpc-default-executor-1] INFO server.RaftServer$Division: om2@group-562213E44849: receive requestVote(ELECTION, om1, group-562213E44849, 2, (t:0, i:~))
om2_1        | 2022-04-08 11:49:30,832 [grpc-default-executor-1] INFO impl.VoteContext: om2@group-562213E44849-CANDIDATE: reject ELECTION from om1: already has voted for om2 at current term 2
om2_1        | 2022-04-08 11:49:30,833 [grpc-default-executor-1] INFO server.RaftServer$Division: om2@group-562213E44849 replies to ELECTION vote request: om1<-om2#0:FAIL-t2. Peer's state: om2@group-562213E44849:t2, leader=null, voted=om2, raftlog=om2@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1        | 2022-04-08 11:49:30,843 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServer$Division: om1@group-562213E44849: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
om1_1        | 2022-04-08 11:49:30,843 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServer$Division: om1@group-562213E44849: change Leader from null to om1 at term 2 for becomeLeader, leader elected after 16387ms
om1_1        | 2022-04-08 11:49:30,849 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
om1_1        | 2022-04-08 11:49:30,875 [grpc-default-executor-1] INFO server.RaftServer$Division: om1@group-562213E44849: receive requestVote(ELECTION, om2, group-562213E44849, 2, (t:0, i:~))
om1_1        | 2022-04-08 11:49:30,888 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
om1_1        | 2022-04-08 11:49:30,892 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
om1_1        | 2022-04-08 11:49:30,900 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
om1_1        | 2022-04-08 11:49:30,904 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
om1_1        | 2022-04-08 11:49:30,906 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
om1_1        | 2022-04-08 11:49:30,915 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
om1_1        | 2022-04-08 11:49:30,919 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
om1_1        | 2022-04-08 11:49:30,930 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
om1_1        | 2022-04-08 11:49:30,930 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om1_1        | 2022-04-08 11:49:30,931 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
om1_1        | 2022-04-08 11:49:30,956 [om1@group-562213E44849-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
om1_1        | 2022-04-08 11:49:30,956 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om1_1        | 2022-04-08 11:49:30,956 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om1_1        | 2022-04-08 11:49:30,962 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
om1_1        | 2022-04-08 11:49:30,963 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om1_1        | 2022-04-08 11:49:30,963 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
om1_1        | 2022-04-08 11:49:30,963 [om1@group-562213E44849-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
om1_1        | 2022-04-08 11:49:30,965 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om1_1        | 2022-04-08 11:49:30,965 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om1_1        | 2022-04-08 11:49:30,970 [om1@group-562213E44849-LeaderElection2] INFO impl.RoleInfo: om1: start om1@group-562213E44849-LeaderStateImpl
om1_1        | 2022-04-08 11:49:30,984 [om1@group-562213E44849-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: Starting segment from index:0
om1_1        | 2022-04-08 11:49:31,020 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServer$Division: om1@group-562213E44849: set configuration 0: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om1_1        | 2022-04-08 11:49:31,020 [grpc-default-executor-1] INFO impl.VoteContext: om1@group-562213E44849-LEADER: reject ELECTION from om2: already has voted for om1 at current term 2
om1_1        | 2022-04-08 11:49:31,021 [grpc-default-executor-1] INFO server.RaftServer$Division: om1@group-562213E44849 replies to ELECTION vote request: om2<-om1#0:FAIL-t2. Peer's state: om1@group-562213E44849:t2, leader=om1, voted=om1, raftlog=om1@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=0: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om1_1        | 2022-04-08 11:49:31,178 [om1@group-562213E44849-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/current/log_inprogress_0
om1_1        | 2022-04-08 11:49:31,434 [om1@group-562213E44849-StateMachineUpdater] INFO ratis.OzoneManagerStateMachine: Received Configuration change notification from Ratis. New Peer list:
om1_1        | [id: "om1"
om1_1        | address: "om1:9872"
om1_1        | , id: "om3"
om1_1        | address: "om3:9872"
om1_1        | , id: "om2"
om1_1        | address: "om2:9872"
om1_1        | ]
om1_1        | 2022-04-08 11:49:45,302 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41400
om1_1        | 2022-04-08 11:49:45,334 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:49:46,116 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:vol1 for user:root
om1_1        | 2022-04-08 11:49:46,560 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket1 of layout LEGACY in volume: vol1
om1_1        | 2022-04-08 11:49:58,718 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41454
om1_1        | 2022-04-08 11:49:58,733 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:49:59,302 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41456
om1_1        | 2022-04-08 11:49:59,309 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:50:03,983 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41470
om1_1        | 2022-04-08 11:50:04,001 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
recon_1      | 2022-04-08 11:47:32,416 [main] WARN http.HttpRequestLog: Jetty request log can only be enabled using Log4j
recon_1      | 2022-04-08 11:47:32,437 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
recon_1      | 2022-04-08 11:47:32,448 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context recon
recon_1      | 2022-04-08 11:47:32,448 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
recon_1      | 2022-04-08 11:47:32,450 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
recon_1      | 2022-04-08 11:47:32,455 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.recon.http.auth.kerberos.principal keytabKey: ozone.recon.http.auth.kerberos.keytab
recon_1      | 2022-04-08 11:47:32,709 [main] INFO tasks.ReconTaskControllerImpl: Registered task ContainerKeyMapperTask with controller.
recon_1      | 2022-04-08 11:47:33,202 [main] INFO tasks.ReconTaskControllerImpl: Registered task FileSizeCountTask with controller.
recon_1      | 2022-04-08 11:47:33,220 [main] INFO tasks.ReconTaskControllerImpl: Registered task TableCountTask with controller.
recon_1      | 2022-04-08 11:47:33,232 [main] INFO tasks.ReconTaskControllerImpl: Registered task NSSummaryTask with controller.
recon_1      | 2022-04-08 11:47:33,269 [main] INFO ozone.OmUtils: Using OzoneManager ServiceID 'id1'.
recon_1      | 2022-04-08 11:47:34,482 [main] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 2022-04-08 11:47:35,053 [main] WARN recon.ReconUtils: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 2022-04-08 11:47:35,176 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar!/network-topology-default.xml]
recon_1      | 2022-04-08 11:47:35,178 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
recon_1      | 2022-04-08 11:47:35,445 [main] WARN db.DBStoreBuilder: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 2022-04-08 11:47:35,810 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = SCM_HA (version = 2), software layout = SCM_HA (version = 2)
recon_1      | 2022-04-08 11:47:36,010 [main] INFO reflections.Reflections: Reflections took 189 ms to scan 3 urls, producing 105 keys and 220 values 
recon_1      | 2022-04-08 11:47:36,168 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
recon_1      | 2022-04-08 11:47:36,256 [main] INFO node.SCMNodeManager: Entering startup safe mode.
recon_1      | 2022-04-08 11:47:36,291 [main] INFO scm.ReconNodeManager: Loaded 0 nodes from node DB.
recon_1      | 2022-04-08 11:47:36,309 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
recon_1      | 2022-04-08 11:47:36,436 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
recon_1      | 2022-04-08 11:47:36,463 [Socket Reader #1 for port 9891] INFO ipc.Server: Starting Socket Reader #1 for port 9891
recon_1      | 2022-04-08 11:47:36,618 [Listener at 0.0.0.0/9891] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
recon_1      | 2022-04-08 11:47:36,853 [Listener at 0.0.0.0/9891] INFO recon.ReconServer: Recon server initialized successfully!
recon_1      | 2022-04-08 11:47:36,853 [Listener at 0.0.0.0/9891] INFO recon.ReconServer: Starting Recon server
recon_1      | 2022-04-08 11:47:36,990 [Listener at 0.0.0.0/9891] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
recon_1      | 2022-04-08 11:47:37,014 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
recon_1      | 2022-04-08 11:47:37,014 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Recon metrics system started
recon_1      | 2022-04-08 11:47:37,824 [Listener at 0.0.0.0/9891] INFO http.HttpServer2: Jetty bound to port 9888
recon_1      | 2022-04-08 11:47:37,825 [Listener at 0.0.0.0/9891] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
recon_1      | 2022-04-08 11:47:37,960 [Listener at 0.0.0.0/9891] INFO server.session: DefaultSessionIdManager workerName=node0
recon_1      | 2022-04-08 11:47:37,960 [Listener at 0.0.0.0/9891] INFO server.session: No SessionScavenger set, using defaults
recon_1      | 2022-04-08 11:47:37,966 [Listener at 0.0.0.0/9891] INFO server.session: node0 Scavenging every 600000ms
recon_1      | 2022-04-08 11:47:38,031 [Listener at 0.0.0.0/9891] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/recon.keytab, for principal HTTP/recon@EXAMPLE.COM
recon_1      | 2022-04-08 11:47:38,039 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@90b9695{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
recon_1      | 2022-04-08 11:47:38,039 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@d03cdc7{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-recon-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
recon_1      | 2022-04-08 11:47:38,929 [Listener at 0.0.0.0/9891] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/recon.keytab, for principal HTTP/recon@EXAMPLE.COM
recon_1      | 2022-04-08 11:47:38,973 [Listener at 0.0.0.0/9891] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/recon.keytab, for principal HTTP/recon@EXAMPLE.COM
recon_1      | 2022-04-08 11:47:41,902 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@5dc7cde5{recon,/,file:///tmp/jetty-0_0_0_0-9888-ozone-recon-1_3_0-SNAPSHOT_jar-_-any-1647216334600197921/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-recon-1.3.0-SNAPSHOT.jar!/webapps/recon}
recon_1      | 2022-04-08 11:47:41,925 [Listener at 0.0.0.0/9891] INFO server.AbstractConnector: Started ServerConnector@7da40bf4{HTTP/1.1, (http/1.1)}{0.0.0.0:9888}
recon_1      | 2022-04-08 11:47:41,926 [Listener at 0.0.0.0/9891] INFO server.Server: Started @52497ms
recon_1      | 2022-04-08 11:47:41,955 [Listener at 0.0.0.0/9891] INFO impl.MetricsSinkAdapter: Sink prometheus started
recon_1      | 2022-04-08 11:47:41,955 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Registered sink prometheus
recon_1      | 2022-04-08 11:47:41,958 [Listener at 0.0.0.0/9891] INFO http.BaseHttpServer: HTTP server of recon listening at http://0.0.0.0:9888
recon_1      | 2022-04-08 11:47:41,958 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Starting Ozone Manager Service Provider.
recon_1      | 2022-04-08 11:47:41,983 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Registered OmDeltaRequest task 
recon_1      | 2022-04-08 11:47:42,013 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Registered OmSnapshotRequest task 
recon_1      | 2022-04-08 11:47:42,013 [Listener at 0.0.0.0/9891] INFO recovery.ReconOmMetadataManagerImpl: Starting ReconOMMetadataManagerImpl
recon_1      | 2022-04-08 11:47:42,013 [Listener at 0.0.0.0/9891] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 2022-04-08 11:47:42,039 [Listener at 0.0.0.0/9891] INFO tasks.ReconTaskControllerImpl: Starting Recon Task Controller.
recon_1      | 2022-04-08 11:47:42,040 [Listener at 0.0.0.0/9891] INFO scm.ReconStorageContainerManagerFacade: Recon ScmDatanodeProtocol RPC server is listening at /0.0.0.0:9891
recon_1      | 2022-04-08 11:47:42,644 [Listener at 0.0.0.0/9891] INFO scm.ReconStorageContainerManagerFacade: Obtained 0 pipelines from SCM.
recon_1      | 2022-04-08 11:47:42,648 [Listener at 0.0.0.0/9891] INFO scm.ReconPipelineManager: Recon has 0 pipelines in house.
recon_1      | 2022-04-08 11:47:42,648 [Listener at 0.0.0.0/9891] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9891
recon_1      | 2022-04-08 11:47:42,671 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om2_1        | 2022-04-08 11:49:30,837 [om2@group-562213E44849-LeaderElection2] INFO impl.LeaderElection: om2@group-562213E44849-LeaderElection2 ELECTION round 0: submit vote requests at term 2 for -1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om2_1        | 2022-04-08 11:49:31,030 [om2@group-562213E44849-LeaderElection2] INFO impl.LeaderElection: om2@group-562213E44849-LeaderElection2: ELECTION REJECTED received 2 response(s) and 0 exception(s):
om2_1        | 2022-04-08 11:49:31,030 [om2@group-562213E44849-LeaderElection2] INFO impl.LeaderElection:   Response 0: om2<-om1#0:FAIL-t2
om2_1        | 2022-04-08 11:49:31,031 [om2@group-562213E44849-LeaderElection2] INFO impl.LeaderElection:   Response 1: om2<-om3#0:FAIL-t2
om2_1        | 2022-04-08 11:49:31,031 [om2@group-562213E44849-LeaderElection2] INFO impl.LeaderElection: om2@group-562213E44849-LeaderElection2 ELECTION round 0: result REJECTED
om2_1        | 2022-04-08 11:49:31,032 [om2@group-562213E44849-LeaderElection2] INFO server.RaftServer$Division: om2@group-562213E44849: changes role from CANDIDATE to FOLLOWER at term 2 for REJECTED
om2_1        | 2022-04-08 11:49:31,033 [om2@group-562213E44849-LeaderElection2] INFO impl.RoleInfo: om2: shutdown om2@group-562213E44849-LeaderElection2
om2_1        | 2022-04-08 11:49:31,033 [om2@group-562213E44849-LeaderElection2] INFO impl.RoleInfo: om2: start om2@group-562213E44849-FollowerState
om2_1        | 2022-04-08 11:49:31,073 [grpc-default-executor-1] INFO server.RaftServer$Division: om2@group-562213E44849: change Leader from null to om1 at term 2 for appendEntries, leader elected after 15625ms
om2_1        | 2022-04-08 11:49:31,252 [grpc-default-executor-1] INFO server.RaftServer$Division: om2@group-562213E44849: set configuration 0: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om2_1        | 2022-04-08 11:49:31,277 [grpc-default-executor-1] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: Starting segment from index:0
om2_1        | 2022-04-08 11:49:31,450 [om2@group-562213E44849-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/current/log_inprogress_0
om2_1        | 2022-04-08 11:49:34,344 [om2@group-562213E44849-StateMachineUpdater] INFO ratis.OzoneManagerStateMachine: Received Configuration change notification from Ratis. New Peer list:
om2_1        | [id: "om1"
om2_1        | address: "om1:9872"
om2_1        | , id: "om3"
om2_1        | address: "om3:9872"
om2_1        | , id: "om2"
om2_1        | address: "om2:9872"
om2_1        | ]
om2_1        | 2022-04-08 11:49:46,551 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:vol1 for user:root
om2_1        | 2022-04-08 11:49:46,663 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket1 of layout LEGACY in volume: vol1
om2_1        | 2022-04-08 11:50:04,509 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ombg0 of layout LEGACY in volume: vol1
om2_1        | 2022-04-08 11:50:24,094 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ombr0 of layout LEGACY in volume: vol1
om2_1        | 2022-04-08 11:50:47,849 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:38628-source for user:root
om2_1        | 2022-04-08 11:50:51,615 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:38628-target for user:root
om2_1        | 2022-04-08 11:50:55,324 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: readable-bucket of layout OBJECT_STORE in volume: 38628-source
om2_1        | 2022-04-08 11:51:07,717 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: unreadable-bucket of layout OBJECT_STORE in volume: 38628-source
om2_1        | 2022-04-08 11:51:11,228 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: readable-link of layout LEGACY in volume: 38628-target
om2_1        | 2022-04-08 11:51:15,196 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: unreadable-link of layout LEGACY in volume: 38628-target
om2_1        | 2022-04-08 11:51:19,367 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link-to-unreadable-bucket of layout LEGACY in volume: 38628-target
om2_1        | 2022-04-08 11:51:42,363 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: dangling-link of layout LEGACY in volume: 38628-target
om2_1        | 2022-04-08 11:51:49,939 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link1 of layout LEGACY in volume: 38628-target
om2_1        | 2022-04-08 11:51:53,977 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket1 of layout OBJECT_STORE in volume: 38628-source
om2_1        | 2022-04-08 11:53:15,082 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link2 of layout LEGACY in volume: 38628-target
om2_1        | 2022-04-08 11:53:18,907 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:link2 in volume:38628-target
om2_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om2_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:198)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-04-08 11:53:22,652 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket3 of layout OBJECT_STORE in volume: 38628-target
om2_1        | 2022-04-08 11:53:26,590 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket3 in volume:38628-target
om2_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om2_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:198)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode1_1  | 2022-04-08 11:49:34,157 [0005597f-3053-4b02-96b8-efe2de95313b@group-E49E3DA5DF9C-LeaderElection1] INFO server.RaftServer$Division: 0005597f-3053-4b02-96b8-efe2de95313b@group-E49E3DA5DF9C: set configuration 0: [0005597f-3053-4b02-96b8-efe2de95313b|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1], old=null
datanode1_1  | 2022-04-08 11:49:37,378 [grpc-default-executor-0] INFO server.RaftServer$Division: 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A: receive requestVote(ELECTION, 4cf3df89-7b36-4576-a18a-5d0c57ddb620, group-BC074898D12A, 5, (t:0, i:0))
datanode1_1  | 2022-04-08 11:49:37,378 [grpc-default-executor-0] INFO impl.VoteContext: 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A-FOLLOWER: accept ELECTION from 4cf3df89-7b36-4576-a18a-5d0c57ddb620: our priority 0 <= candidate's priority 0
datanode1_1  | 2022-04-08 11:49:37,379 [grpc-default-executor-0] INFO server.RaftServer$Division: 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A: changes role from  FOLLOWER to FOLLOWER at term 5 for candidate:4cf3df89-7b36-4576-a18a-5d0c57ddb620
datanode1_1  | 2022-04-08 11:49:37,379 [grpc-default-executor-0] INFO impl.RoleInfo: 0005597f-3053-4b02-96b8-efe2de95313b: shutdown 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A-FollowerState
datanode1_1  | 2022-04-08 11:49:37,379 [0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A-FollowerState] INFO impl.FollowerState: 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A-FollowerState was interrupted: {}
datanode1_1  | java.lang.InterruptedException: sleep interrupted
datanode1_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode1_1  | 	at java.base/java.lang.Thread.sleep(Thread.java:334)
datanode1_1  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode1_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
datanode1_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode1_1  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
datanode1_1  | 2022-04-08 11:49:37,380 [grpc-default-executor-0] INFO impl.RoleInfo: 0005597f-3053-4b02-96b8-efe2de95313b: start 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A-FollowerState
datanode1_1  | 2022-04-08 11:49:37,388 [grpc-default-executor-0] INFO server.RaftServer$Division: 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A replies to ELECTION vote request: 4cf3df89-7b36-4576-a18a-5d0c57ddb620<-0005597f-3053-4b02-96b8-efe2de95313b#0:OK-t5. Peer's state: 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A:t5, leader=null, voted=4cf3df89-7b36-4576-a18a-5d0c57ddb620, raftlog=0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A-SegmentedRaftLog:OPENED:c-1, conf=-1: [0005597f-3053-4b02-96b8-efe2de95313b|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 8b7f16e2-5fb9-442f-a717-cc893c5795e0|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, 4cf3df89-7b36-4576-a18a-5d0c57ddb620|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-04-08 11:49:42,485 [grpc-default-executor-0] INFO server.RaftServer$Division: 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A: receive requestVote(ELECTION, 4cf3df89-7b36-4576-a18a-5d0c57ddb620, group-BC074898D12A, 6, (t:0, i:0))
datanode1_1  | 2022-04-08 11:49:42,485 [grpc-default-executor-0] INFO impl.VoteContext: 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A-FOLLOWER: accept ELECTION from 4cf3df89-7b36-4576-a18a-5d0c57ddb620: our priority 0 <= candidate's priority 0
datanode1_1  | 2022-04-08 11:49:42,485 [grpc-default-executor-0] INFO server.RaftServer$Division: 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A: changes role from  FOLLOWER to FOLLOWER at term 6 for candidate:4cf3df89-7b36-4576-a18a-5d0c57ddb620
datanode1_1  | 2022-04-08 11:49:42,485 [grpc-default-executor-0] INFO impl.RoleInfo: 0005597f-3053-4b02-96b8-efe2de95313b: shutdown 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A-FollowerState
datanode1_1  | 2022-04-08 11:49:42,485 [grpc-default-executor-0] INFO impl.RoleInfo: 0005597f-3053-4b02-96b8-efe2de95313b: start 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A-FollowerState
datanode1_1  | 2022-04-08 11:49:42,485 [0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A-FollowerState] INFO impl.FollowerState: 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A-FollowerState was interrupted: {}
datanode1_1  | java.lang.InterruptedException: sleep interrupted
datanode1_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode1_1  | 	at java.base/java.lang.Thread.sleep(Thread.java:334)
datanode1_1  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode1_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
datanode1_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode1_1  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
datanode1_1  | 2022-04-08 11:49:42,489 [grpc-default-executor-0] INFO server.RaftServer$Division: 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A replies to ELECTION vote request: 4cf3df89-7b36-4576-a18a-5d0c57ddb620<-0005597f-3053-4b02-96b8-efe2de95313b#0:OK-t6. Peer's state: 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A:t6, leader=null, voted=4cf3df89-7b36-4576-a18a-5d0c57ddb620, raftlog=0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A-SegmentedRaftLog:OPENED:c-1, conf=-1: [0005597f-3053-4b02-96b8-efe2de95313b|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 8b7f16e2-5fb9-442f-a717-cc893c5795e0|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, 4cf3df89-7b36-4576-a18a-5d0c57ddb620|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-04-08 11:49:47,594 [grpc-default-executor-0] INFO server.RaftServer$Division: 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A: receive requestVote(ELECTION, 8b7f16e2-5fb9-442f-a717-cc893c5795e0, group-BC074898D12A, 7, (t:0, i:0))
datanode1_1  | 2022-04-08 11:49:47,595 [grpc-default-executor-0] INFO impl.VoteContext: 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A-FOLLOWER: accept ELECTION from 8b7f16e2-5fb9-442f-a717-cc893c5795e0: our priority 0 <= candidate's priority 1
datanode1_1  | 2022-04-08 11:49:47,595 [grpc-default-executor-0] INFO server.RaftServer$Division: 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A: changes role from  FOLLOWER to FOLLOWER at term 7 for candidate:8b7f16e2-5fb9-442f-a717-cc893c5795e0
datanode1_1  | 2022-04-08 11:49:47,595 [grpc-default-executor-0] INFO impl.RoleInfo: 0005597f-3053-4b02-96b8-efe2de95313b: shutdown 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A-FollowerState
datanode1_1  | 2022-04-08 11:49:47,595 [0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A-FollowerState] INFO impl.FollowerState: 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A-FollowerState was interrupted: {}
datanode1_1  | java.lang.InterruptedException: sleep interrupted
datanode1_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode1_1  | 	at java.base/java.lang.Thread.sleep(Thread.java:334)
datanode1_1  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode1_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
datanode1_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode1_1  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
datanode1_1  | 2022-04-08 11:49:47,598 [grpc-default-executor-0] INFO impl.RoleInfo: 0005597f-3053-4b02-96b8-efe2de95313b: start 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A-FollowerState
datanode1_1  | 2022-04-08 11:49:47,617 [grpc-default-executor-0] INFO server.RaftServer$Division: 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A replies to ELECTION vote request: 8b7f16e2-5fb9-442f-a717-cc893c5795e0<-0005597f-3053-4b02-96b8-efe2de95313b#0:OK-t7. Peer's state: 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A:t7, leader=null, voted=8b7f16e2-5fb9-442f-a717-cc893c5795e0, raftlog=0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A-SegmentedRaftLog:OPENED:c-1, conf=-1: [0005597f-3053-4b02-96b8-efe2de95313b|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 8b7f16e2-5fb9-442f-a717-cc893c5795e0|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, 4cf3df89-7b36-4576-a18a-5d0c57ddb620|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-04-08 11:49:47,969 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-BC074898D12A with new leaderId: 8b7f16e2-5fb9-442f-a717-cc893c5795e0
datanode1_1  | 2022-04-08 11:49:47,969 [grpc-default-executor-0] INFO server.RaftServer$Division: 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A: change Leader from null to 8b7f16e2-5fb9-442f-a717-cc893c5795e0 at term 7 for appendEntries, leader elected after 35879ms
datanode1_1  | 2022-04-08 11:49:48,026 [grpc-default-executor-0] INFO server.RaftServer$Division: 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A: set configuration 0: [0005597f-3053-4b02-96b8-efe2de95313b|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 8b7f16e2-5fb9-442f-a717-cc893c5795e0|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, 4cf3df89-7b36-4576-a18a-5d0c57ddb620|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-04-08 11:49:48,027 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A-SegmentedRaftLogWorker: Starting segment from index:0
datanode1_1  | 2022-04-08 11:49:48,028 [0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 0005597f-3053-4b02-96b8-efe2de95313b@group-BC074898D12A-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/d7bff567-93ff-485c-a104-bc074898d12a/current/log_inprogress_0
datanode1_1  | 2022-04-08 11:49:50,344 [ChunkWriter-1-0] INFO client.DNCertificateClient: Getting certificate with certSerialId:941464992973.
kdc_1        | Apr 08 12:02:34 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Apr 08 12:03:34 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Apr 08 12:03:34 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Apr 08 12:04:28 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1649419468, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 08 12:04:33 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649419468, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 12:04:34 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Apr 08 12:04:34 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Apr 08 12:04:43 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1649419483, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 08 12:04:47 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649419483, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 12:05:06 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1649419506, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 08 12:05:11 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1649419506, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 08 12:05:15 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1649419515, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 08 12:05:15 kdc krb5kdc[7](info): TGS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1649419515, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for HTTP/s3g@EXAMPLE.COM
kdc_1        | Apr 08 12:05:34 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Apr 08 12:05:34 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
datanode2_1  | 2022-04-08 11:49:28,090 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-3B267E60A22D-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode2_1  | 2022-04-08 11:49:28,090 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-3B267E60A22D-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode2_1  | 2022-04-08 11:49:28,092 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode2_1  | 2022-04-08 11:49:28,092 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode2_1  | 2022-04-08 11:49:28,092 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode2_1  | 2022-04-08 11:49:28,092 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode2_1  | 2022-04-08 11:49:28,092 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode2_1  | 2022-04-08 11:49:28,092 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode2_1  | 2022-04-08 11:49:28,097 [pool-23-thread-1] INFO server.RaftServer$Division: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-3B267E60A22D: start as a follower, conf=-1: [8b7f16e2-5fb9-442f-a717-cc893c5795e0|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1], old=null
datanode2_1  | 2022-04-08 11:49:28,098 [pool-23-thread-1] INFO server.RaftServer$Division: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-3B267E60A22D: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode2_1  | 2022-04-08 11:49:28,099 [pool-23-thread-1] INFO impl.RoleInfo: 8b7f16e2-5fb9-442f-a717-cc893c5795e0: start 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-3B267E60A22D-FollowerState
datanode2_1  | 2022-04-08 11:49:28,100 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-3B267E60A22D,id=8b7f16e2-5fb9-442f-a717-cc893c5795e0
datanode2_1  | 2022-04-08 11:49:28,100 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=a76fa8e1-27b1-4e30-acd2-3b267e60a22d
datanode2_1  | 2022-04-08 11:49:28,101 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=a76fa8e1-27b1-4e30-acd2-3b267e60a22d.
datanode2_1  | 2022-04-08 11:49:32,253 [grpc-default-executor-0] INFO server.RaftServer$Division: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A: receive requestVote(ELECTION, 4cf3df89-7b36-4576-a18a-5d0c57ddb620, group-BC074898D12A, 4, (t:0, i:0))
datanode2_1  | 2022-04-08 11:49:32,253 [grpc-default-executor-0] INFO impl.VoteContext: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-FOLLOWER: reject ELECTION from 4cf3df89-7b36-4576-a18a-5d0c57ddb620: our priority 1 > candidate's priority 0
datanode2_1  | 2022-04-08 11:49:32,254 [grpc-default-executor-0] INFO server.RaftServer$Division: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A: changes role from  FOLLOWER to FOLLOWER at term 4 for candidate:4cf3df89-7b36-4576-a18a-5d0c57ddb620
datanode2_1  | 2022-04-08 11:49:32,254 [grpc-default-executor-0] INFO impl.RoleInfo: 8b7f16e2-5fb9-442f-a717-cc893c5795e0: shutdown 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-FollowerState
datanode2_1  | 2022-04-08 11:49:32,254 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-FollowerState] INFO impl.FollowerState: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-FollowerState was interrupted: {}
datanode2_1  | java.lang.InterruptedException: sleep interrupted
datanode2_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode2_1  | 	at java.base/java.lang.Thread.sleep(Thread.java:334)
datanode2_1  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode2_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
datanode2_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode2_1  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
datanode2_1  | 2022-04-08 11:49:32,255 [grpc-default-executor-0] INFO impl.RoleInfo: 8b7f16e2-5fb9-442f-a717-cc893c5795e0: start 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-FollowerState
datanode2_1  | 2022-04-08 11:49:32,262 [grpc-default-executor-0] INFO server.RaftServer$Division: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A replies to ELECTION vote request: 4cf3df89-7b36-4576-a18a-5d0c57ddb620<-8b7f16e2-5fb9-442f-a717-cc893c5795e0#0:FAIL-t4. Peer's state: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A:t4, leader=null, voted=null, raftlog=8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-SegmentedRaftLog:OPENED:c-1, conf=-1: [0005597f-3053-4b02-96b8-efe2de95313b|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 8b7f16e2-5fb9-442f-a717-cc893c5795e0|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, 4cf3df89-7b36-4576-a18a-5d0c57ddb620|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode2_1  | 2022-04-08 11:49:33,210 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-3B267E60A22D-FollowerState] INFO impl.FollowerState: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-3B267E60A22D-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5111105936ns, electionTimeout:5110ms
datanode2_1  | 2022-04-08 11:49:33,210 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-3B267E60A22D-FollowerState] INFO impl.RoleInfo: 8b7f16e2-5fb9-442f-a717-cc893c5795e0: shutdown 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-3B267E60A22D-FollowerState
datanode2_1  | 2022-04-08 11:49:33,210 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-3B267E60A22D-FollowerState] INFO server.RaftServer$Division: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-3B267E60A22D: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode2_1  | 2022-04-08 11:49:33,211 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-3B267E60A22D-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode2_1  | 2022-04-08 11:49:33,211 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-3B267E60A22D-FollowerState] INFO impl.RoleInfo: 8b7f16e2-5fb9-442f-a717-cc893c5795e0: start 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-3B267E60A22D-LeaderElection2
datanode2_1  | 2022-04-08 11:49:33,218 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-3B267E60A22D-LeaderElection2] INFO impl.LeaderElection: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-3B267E60A22D-LeaderElection2 ELECTION round 0: submit vote requests at term 1 for -1: [8b7f16e2-5fb9-442f-a717-cc893c5795e0|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1], old=null
datanode2_1  | 2022-04-08 11:49:33,219 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-3B267E60A22D-LeaderElection2] INFO impl.LeaderElection: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-3B267E60A22D-LeaderElection2 ELECTION round 0: result PASSED (term=1)
datanode2_1  | 2022-04-08 11:49:33,219 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-3B267E60A22D-LeaderElection2] INFO impl.RoleInfo: 8b7f16e2-5fb9-442f-a717-cc893c5795e0: shutdown 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-3B267E60A22D-LeaderElection2
datanode2_1  | 2022-04-08 11:49:33,219 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-3B267E60A22D-LeaderElection2] INFO server.RaftServer$Division: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-3B267E60A22D: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode2_1  | 2022-04-08 11:49:33,220 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-3B267E60A22D-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-3B267E60A22D with new leaderId: 8b7f16e2-5fb9-442f-a717-cc893c5795e0
datanode3_1  | 2022-04-08 11:49:03,218 [pool-23-thread-1] INFO impl.RoleInfo: 4cf3df89-7b36-4576-a18a-5d0c57ddb620: start 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5-FollowerState
datanode3_1  | 2022-04-08 11:49:03,220 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-0543FC7274B5,id=4cf3df89-7b36-4576-a18a-5d0c57ddb620
datanode3_1  | 2022-04-08 11:49:03,241 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=a6f33c92-47f3-4bcf-8c55-0543fc7274b5
datanode3_1  | 2022-04-08 11:49:08,073 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-7AF890CF2706-FollowerState] INFO impl.FollowerState: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-7AF890CF2706-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5196514838ns, electionTimeout:5169ms
datanode3_1  | 2022-04-08 11:49:08,073 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-7AF890CF2706-FollowerState] INFO impl.RoleInfo: 4cf3df89-7b36-4576-a18a-5d0c57ddb620: shutdown 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-7AF890CF2706-FollowerState
datanode3_1  | 2022-04-08 11:49:08,074 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-7AF890CF2706-FollowerState] INFO server.RaftServer$Division: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-7AF890CF2706: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode3_1  | 2022-04-08 11:49:08,077 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-7AF890CF2706-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode3_1  | 2022-04-08 11:49:08,077 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-7AF890CF2706-FollowerState] INFO impl.RoleInfo: 4cf3df89-7b36-4576-a18a-5d0c57ddb620: start 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-7AF890CF2706-LeaderElection1
datanode3_1  | 2022-04-08 11:49:08,102 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-7AF890CF2706-LeaderElection1] INFO impl.LeaderElection: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-7AF890CF2706-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [4cf3df89-7b36-4576-a18a-5d0c57ddb620|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode3_1  | 2022-04-08 11:49:08,103 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-7AF890CF2706-LeaderElection1] INFO impl.LeaderElection: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-7AF890CF2706-LeaderElection1 ELECTION round 0: result PASSED (term=1)
datanode3_1  | 2022-04-08 11:49:08,104 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-7AF890CF2706-LeaderElection1] INFO impl.RoleInfo: 4cf3df89-7b36-4576-a18a-5d0c57ddb620: shutdown 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-7AF890CF2706-LeaderElection1
datanode3_1  | 2022-04-08 11:49:08,104 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-7AF890CF2706-LeaderElection1] INFO server.RaftServer$Division: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-7AF890CF2706: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode3_1  | 2022-04-08 11:49:08,104 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-7AF890CF2706-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-7AF890CF2706 with new leaderId: 4cf3df89-7b36-4576-a18a-5d0c57ddb620
datanode3_1  | 2022-04-08 11:49:08,129 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-7AF890CF2706-LeaderElection1] INFO server.RaftServer$Division: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-7AF890CF2706: change Leader from null to 4cf3df89-7b36-4576-a18a-5d0c57ddb620 at term 1 for becomeLeader, leader elected after 6193ms
datanode3_1  | 2022-04-08 11:49:08,163 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-7AF890CF2706-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode3_1  | 2022-04-08 11:49:08,169 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-7AF890CF2706-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode3_1  | 2022-04-08 11:49:08,178 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-7AF890CF2706-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode3_1  | 2022-04-08 11:49:08,201 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-7AF890CF2706-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode3_1  | 2022-04-08 11:49:08,229 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-7AF890CF2706-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode3_1  | 2022-04-08 11:49:08,230 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-7AF890CF2706-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode3_1  | 2022-04-08 11:49:08,239 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5-FollowerState] INFO impl.FollowerState: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5020401633ns, electionTimeout:5009ms
datanode3_1  | 2022-04-08 11:49:08,250 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5-FollowerState] INFO impl.RoleInfo: 4cf3df89-7b36-4576-a18a-5d0c57ddb620: shutdown 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5-FollowerState
datanode3_1  | 2022-04-08 11:49:08,250 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5-FollowerState] INFO server.RaftServer$Division: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode3_1  | 2022-04-08 11:49:08,251 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode3_1  | 2022-04-08 11:49:08,252 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5-FollowerState] INFO impl.RoleInfo: 4cf3df89-7b36-4576-a18a-5d0c57ddb620: start 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5-LeaderElection2
datanode3_1  | 2022-04-08 11:49:08,271 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5-LeaderElection2] INFO impl.LeaderElection: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5-LeaderElection2 ELECTION round 0: submit vote requests at term 1 for -1: [0005597f-3053-4b02-96b8-efe2de95313b|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, 8b7f16e2-5fb9-442f-a717-cc893c5795e0|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 4cf3df89-7b36-4576-a18a-5d0c57ddb620|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode3_1  | 2022-04-08 11:49:08,296 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-7AF890CF2706-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode3_1  | 2022-04-08 11:49:08,329 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-7AF890CF2706-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode3_1  | 2022-04-08 11:49:08,346 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-7AF890CF2706-LeaderElection1] INFO impl.RoleInfo: 4cf3df89-7b36-4576-a18a-5d0c57ddb620: start 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-7AF890CF2706-LeaderStateImpl
datanode3_1  | 2022-04-08 11:49:08,526 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-7AF890CF2706-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-7AF890CF2706-SegmentedRaftLogWorker: Starting segment from index:0
datanode3_1  | 2022-04-08 11:49:08,755 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-7AF890CF2706-LeaderElection1] INFO server.RaftServer$Division: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-7AF890CF2706: set configuration 0: [4cf3df89-7b36-4576-a18a-5d0c57ddb620|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1], old=null
datanode3_1  | 2022-04-08 11:49:09,207 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5-LeaderElection2] INFO impl.LeaderElection: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5-LeaderElection2: ELECTION PASSED received 1 response(s) and 0 exception(s):
datanode3_1  | 2022-04-08 11:49:09,221 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5-LeaderElection2] INFO impl.LeaderElection:   Response 0: 4cf3df89-7b36-4576-a18a-5d0c57ddb620<-8b7f16e2-5fb9-442f-a717-cc893c5795e0#0:OK-t1
datanode3_1  | 2022-04-08 11:49:09,230 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5-LeaderElection2] INFO impl.LeaderElection: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5-LeaderElection2 ELECTION round 0: result PASSED
datanode3_1  | 2022-04-08 11:49:09,231 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5-LeaderElection2] INFO impl.RoleInfo: 4cf3df89-7b36-4576-a18a-5d0c57ddb620: shutdown 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5-LeaderElection2
datanode3_1  | 2022-04-08 11:49:09,235 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5-LeaderElection2] INFO server.RaftServer$Division: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode3_1  | 2022-04-08 11:49:09,238 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-0543FC7274B5 with new leaderId: 4cf3df89-7b36-4576-a18a-5d0c57ddb620
datanode3_1  | 2022-04-08 11:49:09,238 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5-LeaderElection2] INFO server.RaftServer$Division: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5: change Leader from null to 4cf3df89-7b36-4576-a18a-5d0c57ddb620 at term 1 for becomeLeader, leader elected after 6133ms
datanode3_1  | 2022-04-08 11:49:09,238 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode3_1  | 2022-04-08 11:49:09,239 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode3_1  | 2022-04-08 11:49:09,266 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode3_1  | 2022-04-08 11:49:09,292 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode3_1  | 2022-04-08 11:49:09,292 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode3_1  | 2022-04-08 11:49:09,292 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode3_1  | 2022-04-08 11:49:09,295 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode3_1  | 2022-04-08 11:49:09,297 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode3_1  | 2022-04-08 11:49:09,330 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode3_1  | 2022-04-08 11:49:09,330 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2022-04-08 11:49:09,330 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode3_1  | 2022-04-08 11:49:09,360 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode3_1  | 2022-04-08 11:49:09,391 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode3_1  | 2022-04-08 11:49:09,391 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2022-04-08 11:49:09,425 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode3_1  | 2022-04-08 11:49:09,425 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2022-04-08 11:49:09,425 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode3_1  | 2022-04-08 11:49:09,425 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode3_1  | 2022-04-08 11:49:09,425 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode3_1  | 2022-04-08 11:49:09,425 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2022-04-08 11:49:09,479 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5-LeaderElection2] INFO impl.RoleInfo: 4cf3df89-7b36-4576-a18a-5d0c57ddb620: start 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5-LeaderStateImpl
datanode3_1  | 2022-04-08 11:49:09,480 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5-SegmentedRaftLogWorker: Starting segment from index:0
datanode3_1  | 2022-04-08 11:49:09,487 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/a6f33c92-47f3-4bcf-8c55-0543fc7274b5/current/log_inprogress_0
datanode3_1  | 2022-04-08 11:49:09,489 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-7AF890CF2706-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-7AF890CF2706-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/cfd3e9b8-6c85-4577-8ecd-7af890cf2706/current/log_inprogress_0
datanode3_1  | 2022-04-08 11:49:09,579 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5-LeaderElection2] INFO server.RaftServer$Division: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5: set configuration 0: [0005597f-3053-4b02-96b8-efe2de95313b|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 8b7f16e2-5fb9-442f-a717-cc893c5795e0|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 4cf3df89-7b36-4576-a18a-5d0c57ddb620|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1], old=null
datanode3_1  | 2022-04-08 11:49:11,526 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=a6f33c92-47f3-4bcf-8c55-0543fc7274b5.
datanode3_1  | 2022-04-08 11:49:11,526 [Command processor thread] INFO server.RaftServer: 4cf3df89-7b36-4576-a18a-5d0c57ddb620: addNew group-BC074898D12A:[0005597f-3053-4b02-96b8-efe2de95313b|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, 8b7f16e2-5fb9-442f-a717-cc893c5795e0|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1, 4cf3df89-7b36-4576-a18a-5d0c57ddb620|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0] returns group-BC074898D12A:java.util.concurrent.CompletableFuture@1bd6f7c9[Not completed]
datanode3_1  | 2022-04-08 11:49:11,528 [pool-23-thread-1] INFO server.RaftServer$Division: 4cf3df89-7b36-4576-a18a-5d0c57ddb620: new RaftServerImpl for group-BC074898D12A:[0005597f-3053-4b02-96b8-efe2de95313b|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, 8b7f16e2-5fb9-442f-a717-cc893c5795e0|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1, 4cf3df89-7b36-4576-a18a-5d0c57ddb620|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0] with ContainerStateMachine:uninitialized
datanode3_1  | 2022-04-08 11:49:11,529 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode3_1  | 2022-04-08 11:49:11,529 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode3_1  | 2022-04-08 11:49:11,529 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode3_1  | 2022-04-08 11:49:11,529 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode3_1  | 2022-04-08 11:49:11,529 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode3_1  | 2022-04-08 11:49:11,529 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode3_1  | 2022-04-08 11:49:11,529 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2022-04-08 11:49:11,530 [pool-23-thread-1] INFO server.RaftServer$Division: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A: ConfigurationManager, init=-1: [0005597f-3053-4b02-96b8-efe2de95313b|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, 8b7f16e2-5fb9-442f-a717-cc893c5795e0|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1, 4cf3df89-7b36-4576-a18a-5d0c57ddb620|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0], old=null, confs=<EMPTY_MAP>
datanode3_1  | 2022-04-08 11:49:11,531 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode3_1  | 2022-04-08 11:49:11,532 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode3_1  | 2022-04-08 11:49:11,532 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
om1_1        | 2022-04-08 11:50:04,491 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41472
om1_1        | 2022-04-08 11:50:04,493 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:50:04,506 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ombg0 of layout LEGACY in volume: vol1
om1_1        | 2022-04-08 11:50:09,171 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41486
om1_1        | 2022-04-08 11:50:09,192 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:50:18,432 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41512
om1_1        | 2022-04-08 11:50:18,446 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:50:23,515 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41548
om1_1        | 2022-04-08 11:50:23,544 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:50:24,063 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41550
om1_1        | 2022-04-08 11:50:24,071 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:50:24,088 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ombr0 of layout LEGACY in volume: vol1
om1_1        | 2022-04-08 11:50:28,689 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41562
om1_1        | 2022-04-08 11:50:28,712 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:50:33,097 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41566
om1_1        | 2022-04-08 11:50:33,115 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:50:33,409 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:41099
om1_1        | 2022-04-08 11:50:33,414 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:50:47,230 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41600
om1_1        | 2022-04-08 11:50:47,252 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:50:47,842 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:38628-source for user:root
om1_1        | 2022-04-08 11:50:51,181 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41612
om1_1        | 2022-04-08 11:50:51,191 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:50:51,586 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:38628-target for user:root
om1_1        | 2022-04-08 11:50:54,817 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41640
om1_1        | 2022-04-08 11:50:54,876 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:50:55,318 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: readable-bucket of layout OBJECT_STORE in volume: 38628-source
om1_1        | 2022-04-08 11:50:58,522 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41652
om1_1        | 2022-04-08 11:50:58,577 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:51:07,211 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41668
om1_1        | 2022-04-08 11:51:07,248 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:51:07,705 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: unreadable-bucket of layout OBJECT_STORE in volume: 38628-source
om1_1        | 2022-04-08 11:51:10,736 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41690
om1_1        | 2022-04-08 11:51:10,749 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:51:11,221 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: readable-link of layout LEGACY in volume: 38628-target
om1_1        | 2022-04-08 11:51:14,668 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41694
om1_1        | 2022-04-08 11:51:14,702 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:51:15,181 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: unreadable-link of layout LEGACY in volume: 38628-target
om1_1        | 2022-04-08 11:51:18,771 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41710
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-04-08 11:53:46,195 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop2 of layout LEGACY in volume: 38628-target
om2_1        | 2022-04-08 11:53:50,013 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop3 of layout LEGACY in volume: 38628-target
om2_1        | 2022-04-08 11:53:53,778 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop1 of layout LEGACY in volume: 38628-target
om2_1        | 2022-04-08 11:54:00,951 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link3 of layout LEGACY in volume: 38628-target
om2_1        | 2022-04-08 11:54:58,045 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-1592951654 of layout LEGACY in volume: s3v
om2_1        | 2022-04-08 11:55:04,408 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-8147954027 of layout LEGACY in volume: s3v
om2_1        | 2022-04-08 11:55:22,603 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-0372689255 of layout LEGACY in volume: s3v
om2_1        | 2022-04-08 11:55:23,153 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ozone-test-ntnaskidoy of layout LEGACY in volume: s3v
om2_1        | 2022-04-08 11:55:36,018 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-phfmxspesy of layout LEGACY in volume: s3v
om2_1        | 2022-04-08 11:55:50,392 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-3090789646 of layout LEGACY in volume: s3v
om2_1        | 2022-04-08 11:55:51,024 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-2505354869 of layout LEGACY in volume: s3v
om2_1        | 2022-04-08 11:55:51,672 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-9765919850 of layout LEGACY in volume: s3v
om2_1        | 2022-04-08 11:55:52,244 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket-ozone-test-9765919850 in volume:s3v
om2_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om2_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:198)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-04-08 11:55:58,954 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-9631101845 of layout LEGACY in volume: s3v
om2_1        | 2022-04-08 11:55:59,532 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-1703165167 of layout LEGACY in volume: s3v
om2_1        | 2022-04-08 11:56:00,734 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketDeleteRequest: Delete bucket failed for bucket:nosuchbucket-ozone-test-0525685448 in volume:s3v
om2_1        | BUCKET_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Bucket not found
om2_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.getBucketOwner(OzoneManager.java:2334)
om2_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.getBucketOwner(OzoneManager.java:2304)
om2_1        | 	at org.apache.hadoop.ozone.om.request.OMClientRequest.checkAcls(OMClientRequest.java:200)
om2_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketDeleteRequest.validateAndUpdateCache(OMBucketDeleteRequest.java:102)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-04-08 11:56:07,005 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-0143600893 of layout LEGACY in volume: s3v
om2_1        | 2022-04-08 11:56:14,294 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-3076197802 of layout LEGACY in volume: s3v
om2_1        | 2022-04-08 11:56:21,824 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-0491738847 of layout LEGACY in volume: s3v
om2_1        | 2022-04-08 11:56:44,953 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload: /s3v/bucket-ozone-test-0491738847/ozone-test-9528167901/multipartKey2 Part number: 1 size 6  is less than minimum part size 5242880
om2_1        | 2022-04-08 11:56:44,964 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-9528167901/multipartKey2 in Volume/Bucket s3v/bucket-ozone-test-0491738847
om2_1        | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-0491738847 key: ozone-test-9528167901/multipartKey2. Entity too small.
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:513)
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:192)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-04-08 11:56:46,265 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-ozone-test-0491738847/ozone-test-0981360713/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 1
om2_1        | partName: "etag1"
om2_1        | , partNumber: 2
om2_1        | partName: "etag2"
om2_1        | ]
om2_1        | 2022-04-08 11:56:46,273 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0981360713/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-0491738847
om2_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-0491738847 key: ozone-test-0981360713/multipartKey3
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:181)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-04-08 11:56:46,894 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-ozone-test-0491738847/ozone-test-0981360713/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 2
om2_1        | partName: "etag1"
om2_1        | , partNumber: 1
om2_1        | partName: "etag2"
om2_1        | ]
om2_1        | 2022-04-08 11:56:46,895 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0981360713/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-0491738847
om2_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-0491738847 key: ozone-test-0981360713/multipartKey3
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:181)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-04-08 11:56:53,055 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0981360713/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-0491738847
om2_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-0491738847 key: ozone-test-0981360713/multipartKey3. Provided Part info is { etag1, 1}, whereas OM has partName /s3v/bucket-ozone-test-0491738847/ozone-test-0981360713/multipartKey3-264276c9-564f-4799-903a-1c9a411a4b2c-108096323947724836-1
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:495)
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:192)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 2022-04-08 11:47:42,670 [IPC Server listener on 9891] INFO ipc.Server: IPC Server listener on 9891: starting
recon_1      | 2022-04-08 11:47:43,036 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Registered ContainerHealthTask task 
recon_1      | 2022-04-08 11:47:43,036 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Starting ContainerHealthTask Thread.
recon_1      | 2022-04-08 11:47:43,049 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Registered PipelineSyncTask task 
recon_1      | 2022-04-08 11:47:43,049 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Starting PipelineSyncTask Thread.
recon_1      | 2022-04-08 11:47:43,125 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 0 pipelines in house.
recon_1      | 2022-04-08 11:47:43,127 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 73 milliseconds.
recon_1      | 2022-04-08 11:48:02,040 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-04-08 11:48:02,041 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-04-08 11:48:02,376 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:48:02,394 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-08 11:48:04,398 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 3 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:48:04,399 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 4 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:48:04,400 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-08 11:48:06,402 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 6 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:48:06,403 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 7 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:48:06,404 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 8 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-08 11:48:08,405 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 9 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:48:08,407 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 10 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:48:08,408 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 11 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-08 11:48:10,409 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 12 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:48:10,410 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 13 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:48:10,411 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 14 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-08 11:48:12,413 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 15 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:48:12,414 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 16 failover attempts. Trying to failover immediately.
datanode2_1  | 2022-04-08 11:49:33,220 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-3B267E60A22D-LeaderElection2] INFO server.RaftServer$Division: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-3B267E60A22D: change Leader from null to 8b7f16e2-5fb9-442f-a717-cc893c5795e0 at term 1 for becomeLeader, leader elected after 5132ms
datanode2_1  | 2022-04-08 11:49:33,222 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-3B267E60A22D-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode2_1  | 2022-04-08 11:49:33,258 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-3B267E60A22D-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode2_1  | 2022-04-08 11:49:33,266 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-3B267E60A22D-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode2_1  | 2022-04-08 11:49:33,284 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-3B267E60A22D-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode2_1  | 2022-04-08 11:49:33,288 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-3B267E60A22D-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode2_1  | 2022-04-08 11:49:33,291 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-3B267E60A22D-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode2_1  | 2022-04-08 11:49:33,302 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-3B267E60A22D-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode2_1  | 2022-04-08 11:49:33,314 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-3B267E60A22D-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode2_1  | 2022-04-08 11:49:33,326 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-3B267E60A22D-LeaderElection2] INFO impl.RoleInfo: 8b7f16e2-5fb9-442f-a717-cc893c5795e0: start 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-3B267E60A22D-LeaderStateImpl
datanode2_1  | 2022-04-08 11:49:33,354 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-3B267E60A22D-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-3B267E60A22D-SegmentedRaftLogWorker: Starting segment from index:0
datanode2_1  | 2022-04-08 11:49:33,360 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-3B267E60A22D-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-3B267E60A22D-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/a76fa8e1-27b1-4e30-acd2-3b267e60a22d/current/log_inprogress_0
datanode2_1  | 2022-04-08 11:49:33,362 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-3B267E60A22D-LeaderElection2] INFO server.RaftServer$Division: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-3B267E60A22D: set configuration 0: [8b7f16e2-5fb9-442f-a717-cc893c5795e0|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1], old=null
datanode2_1  | 2022-04-08 11:49:37,398 [grpc-default-executor-0] INFO server.RaftServer$Division: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A: receive requestVote(ELECTION, 4cf3df89-7b36-4576-a18a-5d0c57ddb620, group-BC074898D12A, 5, (t:0, i:0))
datanode2_1  | 2022-04-08 11:49:37,398 [grpc-default-executor-0] INFO impl.VoteContext: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-FOLLOWER: reject ELECTION from 4cf3df89-7b36-4576-a18a-5d0c57ddb620: our priority 1 > candidate's priority 0
datanode2_1  | 2022-04-08 11:49:37,398 [grpc-default-executor-0] INFO server.RaftServer$Division: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A: changes role from  FOLLOWER to FOLLOWER at term 5 for candidate:4cf3df89-7b36-4576-a18a-5d0c57ddb620
datanode2_1  | 2022-04-08 11:49:37,398 [grpc-default-executor-0] INFO impl.RoleInfo: 8b7f16e2-5fb9-442f-a717-cc893c5795e0: shutdown 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-FollowerState
datanode2_1  | 2022-04-08 11:49:37,398 [grpc-default-executor-0] INFO impl.RoleInfo: 8b7f16e2-5fb9-442f-a717-cc893c5795e0: start 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-FollowerState
datanode2_1  | 2022-04-08 11:49:37,398 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-FollowerState] INFO impl.FollowerState: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-FollowerState was interrupted: {}
datanode2_1  | java.lang.InterruptedException: sleep interrupted
datanode2_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode2_1  | 	at java.base/java.lang.Thread.sleep(Thread.java:334)
datanode2_1  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode2_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
datanode2_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode2_1  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
datanode2_1  | 2022-04-08 11:49:37,401 [grpc-default-executor-0] INFO server.RaftServer$Division: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A replies to ELECTION vote request: 4cf3df89-7b36-4576-a18a-5d0c57ddb620<-8b7f16e2-5fb9-442f-a717-cc893c5795e0#0:FAIL-t5. Peer's state: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A:t5, leader=null, voted=null, raftlog=8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-SegmentedRaftLog:OPENED:c-1, conf=-1: [0005597f-3053-4b02-96b8-efe2de95313b|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 8b7f16e2-5fb9-442f-a717-cc893c5795e0|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, 4cf3df89-7b36-4576-a18a-5d0c57ddb620|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode2_1  | 2022-04-08 11:49:42,481 [grpc-default-executor-0] INFO server.RaftServer$Division: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A: receive requestVote(ELECTION, 4cf3df89-7b36-4576-a18a-5d0c57ddb620, group-BC074898D12A, 6, (t:0, i:0))
datanode2_1  | 2022-04-08 11:49:42,482 [grpc-default-executor-0] INFO impl.VoteContext: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-FOLLOWER: reject ELECTION from 4cf3df89-7b36-4576-a18a-5d0c57ddb620: our priority 1 > candidate's priority 0
datanode2_1  | 2022-04-08 11:49:42,482 [grpc-default-executor-0] INFO server.RaftServer$Division: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A: changes role from  FOLLOWER to FOLLOWER at term 6 for candidate:4cf3df89-7b36-4576-a18a-5d0c57ddb620
datanode2_1  | 2022-04-08 11:49:42,482 [grpc-default-executor-0] INFO impl.RoleInfo: 8b7f16e2-5fb9-442f-a717-cc893c5795e0: shutdown 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-FollowerState
datanode2_1  | 2022-04-08 11:49:42,482 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-FollowerState] INFO impl.FollowerState: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-FollowerState was interrupted: {}
datanode2_1  | java.lang.InterruptedException: sleep interrupted
datanode2_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode2_1  | 	at java.base/java.lang.Thread.sleep(Thread.java:334)
datanode2_1  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode2_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
datanode2_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode2_1  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
datanode2_1  | 2022-04-08 11:49:42,483 [grpc-default-executor-0] INFO impl.RoleInfo: 8b7f16e2-5fb9-442f-a717-cc893c5795e0: start 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-FollowerState
datanode2_1  | 2022-04-08 11:49:42,486 [grpc-default-executor-0] INFO server.RaftServer$Division: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A replies to ELECTION vote request: 4cf3df89-7b36-4576-a18a-5d0c57ddb620<-8b7f16e2-5fb9-442f-a717-cc893c5795e0#0:FAIL-t6. Peer's state: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A:t6, leader=null, voted=null, raftlog=8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-SegmentedRaftLog:OPENED:c-1, conf=-1: [0005597f-3053-4b02-96b8-efe2de95313b|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 8b7f16e2-5fb9-442f-a717-cc893c5795e0|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, 4cf3df89-7b36-4576-a18a-5d0c57ddb620|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode2_1  | 2022-04-08 11:49:47,565 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-FollowerState] INFO impl.FollowerState: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5082119786ns, electionTimeout:5080ms
datanode2_1  | 2022-04-08 11:49:47,566 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-FollowerState] INFO impl.RoleInfo: 8b7f16e2-5fb9-442f-a717-cc893c5795e0: shutdown 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-FollowerState
datanode2_1  | 2022-04-08 11:49:47,566 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-FollowerState] INFO server.RaftServer$Division: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A: changes role from  FOLLOWER to CANDIDATE at term 6 for changeToCandidate
datanode2_1  | 2022-04-08 11:49:47,566 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode2_1  | 2022-04-08 11:49:47,566 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-FollowerState] INFO impl.RoleInfo: 8b7f16e2-5fb9-442f-a717-cc893c5795e0: start 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-LeaderElection3
datanode2_1  | 2022-04-08 11:49:47,576 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-LeaderElection3] INFO impl.LeaderElection: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-LeaderElection3 ELECTION round 0: submit vote requests at term 7 for -1: [0005597f-3053-4b02-96b8-efe2de95313b|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 8b7f16e2-5fb9-442f-a717-cc893c5795e0|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, 4cf3df89-7b36-4576-a18a-5d0c57ddb620|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode2_1  | 2022-04-08 11:49:47,607 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-LeaderElection3] INFO impl.LeaderElection: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-LeaderElection3: ELECTION PASSED received 1 response(s) and 0 exception(s):
datanode2_1  | 2022-04-08 11:49:47,607 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-LeaderElection3] INFO impl.LeaderElection:   Response 0: 8b7f16e2-5fb9-442f-a717-cc893c5795e0<-4cf3df89-7b36-4576-a18a-5d0c57ddb620#0:OK-t7
datanode2_1  | 2022-04-08 11:49:47,607 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-LeaderElection3] INFO impl.LeaderElection: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-LeaderElection3 ELECTION round 0: result PASSED
datanode2_1  | 2022-04-08 11:49:47,607 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-LeaderElection3] INFO impl.RoleInfo: 8b7f16e2-5fb9-442f-a717-cc893c5795e0: shutdown 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-LeaderElection3
datanode2_1  | 2022-04-08 11:49:47,607 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-LeaderElection3] INFO server.RaftServer$Division: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A: changes role from CANDIDATE to LEADER at term 7 for changeToLeader
datanode2_1  | 2022-04-08 11:49:47,607 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-LeaderElection3] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-BC074898D12A with new leaderId: 8b7f16e2-5fb9-442f-a717-cc893c5795e0
datanode2_1  | 2022-04-08 11:49:47,610 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-LeaderElection3] INFO server.RaftServer$Division: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A: change Leader from null to 8b7f16e2-5fb9-442f-a717-cc893c5795e0 at term 7 for becomeLeader, leader elected after 35062ms
datanode2_1  | 2022-04-08 11:49:47,610 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode2_1  | 2022-04-08 11:49:47,612 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode2_1  | 2022-04-08 11:49:47,613 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode2_1  | 2022-04-08 11:49:47,635 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode2_1  | 2022-04-08 11:49:47,636 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode2_1  | 2022-04-08 11:49:47,639 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode2_1  | 2022-04-08 11:49:47,639 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode2_1  | 2022-04-08 11:49:47,641 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode2_1  | 2022-04-08 11:49:47,718 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode2_1  | 2022-04-08 11:49:47,725 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2022-04-08 11:49:47,728 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode2_1  | 2022-04-08 11:49:47,751 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-LeaderElection3] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode2_1  | 2022-04-08 11:49:47,752 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode2_1  | 2022-04-08 11:49:47,752 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | 2022-04-08 11:49:47,770 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode2_1  | 2022-04-08 11:49:47,770 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2022-04-08 11:49:47,771 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode2_1  | 2022-04-08 11:49:47,771 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-LeaderElection3] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode2_1  | 2022-04-08 11:49:47,783 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode2_1  | 2022-04-08 11:49:47,783 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
recon_1      | 2022-04-08 11:48:12,414 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 17 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-08 11:48:14,416 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 18 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:48:14,417 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 19 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:48:14,418 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 20 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-08 11:48:16,419 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 21 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:48:16,420 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 22 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:48:16,423 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 23 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-08 11:48:18,425 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 24 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:48:18,426 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 25 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:48:18,428 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 26 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-08 11:48:20,429 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 27 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:48:20,432 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 28 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:48:20,433 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 29 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-08 11:48:22,440 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 30 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:48:22,441 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 31 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:48:22,443 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 32 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-08 11:48:24,446 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 33 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:48:24,447 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 34 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:48:24,448 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 35 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-08 11:48:26,450 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 36 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:48:26,451 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 37 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:48:26,454 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 38 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-08 11:48:28,459 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 39 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:48:28,460 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 40 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:48:28,461 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 41 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-08 11:48:30,463 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 42 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:48:30,463 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 43 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:48:30,464 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 44 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-08 11:48:32,465 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 45 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:48:32,466 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 46 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:48:32,468 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 47 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-08 11:48:34,469 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 48 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:48:34,470 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 49 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:48:34,471 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 50 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-08 11:48:36,472 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 51 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:48:36,474 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 52 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:48:36,475 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 53 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-08 11:48:38,476 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 54 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:48:38,477 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 55 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:48:38,479 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 56 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-08 11:48:40,480 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 57 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:48:40,481 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 58 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:48:40,481 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 59 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-08 11:48:42,483 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 60 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:48:42,484 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 61 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:48:42,484 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 62 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-08 11:48:44,486 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 63 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:48:44,487 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 64 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:48:44,488 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 65 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-08 11:48:46,489 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 66 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:48:46,490 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 67 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:48:46,491 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 68 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-08 11:48:48,493 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 69 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:48:48,494 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 70 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:48:48,495 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 71 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-08 11:48:50,496 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 72 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:48:50,497 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 73 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:48:50,498 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 74 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-08 11:48:51,479 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:35436
recon_1      | 2022-04-08 11:48:51,499 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 11:48:52,524 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 75 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:48:52,528 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 76 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:48:52,536 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 77 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-08 11:48:54,066 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:59114
recon_1      | 2022-04-08 11:48:54,169 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 11:48:54,552 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 78 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:48:54,554 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 79 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:48:54,555 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 80 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-08 11:48:55,524 [IPC Server handler 4 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/8b7f16e2-5fb9-442f-a717-cc893c5795e0
recon_1      | 2022-04-08 11:48:55,565 [IPC Server handler 4 on default port 9891] INFO node.SCMNodeManager: Registered Data node : 8b7f16e2-5fb9-442f-a717-cc893c5795e0{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 932981906868, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-04-08 11:48:55,759 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 8b7f16e2-5fb9-442f-a717-cc893c5795e0 to Node DB.
recon_1      | 2022-04-08 11:48:55,893 [IPC Server handler 37 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/0005597f-3053-4b02-96b8-efe2de95313b
recon_1      | 2022-04-08 11:48:55,893 [IPC Server handler 37 on default port 9891] INFO node.SCMNodeManager: Registered Data node : 0005597f-3053-4b02-96b8-efe2de95313b{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 933750048452, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
om1_1        | 2022-04-08 11:51:18,827 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:51:19,349 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link-to-unreadable-bucket of layout LEGACY in volume: 38628-target
om1_1        | 2022-04-08 11:51:22,701 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41746
om1_1        | 2022-04-08 11:51:22,774 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:51:26,563 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41750
om1_1        | 2022-04-08 11:51:26,612 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:51:30,352 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41762
om1_1        | 2022-04-08 11:51:30,368 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:51:33,459 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:34173
om1_1        | 2022-04-08 11:51:33,473 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:51:34,085 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41776
om1_1        | 2022-04-08 11:51:34,136 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:51:37,937 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41780
om1_1        | 2022-04-08 11:51:37,981 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:51:41,797 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41792
om1_1        | 2022-04-08 11:51:41,813 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:51:42,353 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: dangling-link of layout LEGACY in volume: 38628-target
om1_1        | 2022-04-08 11:51:45,812 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41796
om1_1        | 2022-04-08 11:51:45,835 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:51:49,402 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41812
om1_1        | 2022-04-08 11:51:49,455 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:51:49,933 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link1 of layout LEGACY in volume: 38628-target
om1_1        | 2022-04-08 11:51:53,294 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41848
om1_1        | 2022-04-08 11:51:53,357 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:51:53,966 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket1 of layout OBJECT_STORE in volume: 38628-source
om1_1        | 2022-04-08 11:51:57,153 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41852
om1_1        | 2022-04-08 11:51:57,200 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:52:06,129 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41876
om1_1        | 2022-04-08 11:52:06,141 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:52:12,251 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41902
om1_1        | 2022-04-08 11:52:12,273 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:52:21,673 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41944
om1_1        | 2022-04-08 11:52:21,707 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:52:27,674 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41960
om1_1        | 2022-04-08 11:52:27,696 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:52:31,884 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41972
om1_1        | 2022-04-08 11:52:31,898 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:52:33,511 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:33829
om3_1        | 2022-04-08 11:49:15,012 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om3_1        | 2022-04-08 11:49:15,160 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
om3_1        | 2022-04-08 11:49:15,160 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om3_1        | 2022-04-08 11:49:15,224 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om3_1        | 2022-04-08 11:49:15,240 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om3_1        | 2022-04-08 11:49:15,248 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om3_1        | 2022-04-08 11:49:15,260 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om3_1        | 2022-04-08 11:49:15,287 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
om3_1        | 2022-04-08 11:49:15,288 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om3_1        | 2022-04-08 11:49:16,041 [main] INFO reflections.Reflections: Reflections took 2102 ms to scan 7 urls, producing 19 keys and 316 values [using 2 cores]
om3_1        | 2022-04-08 11:49:16,083 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om3_1        | 2022-04-08 11:49:16,136 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om3_1        | 2022-04-08 11:49:16,651 [Listener at om3/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om3_1        | 2022-04-08 11:49:16,730 [Listener at om3/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om3_1        | 2022-04-08 11:49:16,731 [Listener at om3/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om3_1        | 2022-04-08 11:49:16,974 [Listener at om3/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om3/172.25.0.113:9862
om3_1        | 2022-04-08 11:49:16,977 [Listener at om3/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om3 at port 9872
om3_1        | 2022-04-08 11:49:16,978 [Listener at om3/9862] INFO server.RaftServer$Division: om3@group-562213E44849: start as a follower, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1        | 2022-04-08 11:49:16,996 [Listener at om3/9862] INFO server.RaftServer$Division: om3@group-562213E44849: changes role from      null to FOLLOWER at term 0 for startAsFollower
om3_1        | 2022-04-08 11:49:17,006 [Listener at om3/9862] INFO impl.RoleInfo: om3: start om3@group-562213E44849-FollowerState
om3_1        | 2022-04-08 11:49:17,013 [Listener at om3/9862] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-562213E44849,id=om3
om3_1        | 2022-04-08 11:49:17,046 [Listener at om3/9862] INFO server.RaftServer: om3: start RPC server
om3_1        | 2022-04-08 11:49:17,227 [Listener at om3/9862] INFO server.GrpcService: om3: GrpcService started, listening on 9872
om3_1        | 2022-04-08 11:49:17,302 [Listener at om3/9862] INFO om.OzoneManager: Starting OM block token secret manager
om3_1        | 2022-04-08 11:49:17,306 [Listener at om3/9862] INFO security.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
om3_1        | 2022-04-08 11:49:17,314 [Listener at om3/9862] INFO om.OzoneManager: Starting OM delegation token secret manager
om3_1        | 2022-04-08 11:49:17,314 [Listener at om3/9862] INFO security.OzoneDelegationTokenSecretManager: Updating the current master key for generating tokens
om3_1        | 2022-04-08 11:49:17,315 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$411/0x00000008405cf040@7bec83d5] INFO util.JvmPauseMonitor: JvmPauseMonitor-om3: Started
om3_1        | 2022-04-08 11:49:17,320 [Listener at om3/9862] INFO om.OzoneManager: Version File has different layout version (0) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
om3_1        | 2022-04-08 11:49:17,326 [Thread[Thread-17,5,main]] INFO security.OzoneDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
om3_1        | 2022-04-08 11:49:17,497 [Listener at om3/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om3_1        | 2022-04-08 11:49:17,498 [Listener at om3/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
om3_1        | 2022-04-08 11:49:17,499 [Listener at om3/9862] INFO http.BaseHttpServer: HttpAuthType: ozone.om.http.auth.type = kerberos
om3_1        | 2022-04-08 11:49:17,622 [Listener at om3/9862] INFO util.log: Logging initialized @38421ms to org.eclipse.jetty.util.log.Slf4jLog
om3_1        | 2022-04-08 11:49:18,038 [Listener at om3/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om3_1        | 2022-04-08 11:49:18,091 [Listener at om3/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om3_1        | 2022-04-08 11:49:18,103 [Listener at om3/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context ozoneManager
om3_1        | 2022-04-08 11:49:18,103 [Listener at om3/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
om3_1        | 2022-04-08 11:49:18,103 [Listener at om3/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
om3_1        | 2022-04-08 11:49:18,123 [Listener at om3/9862] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.om.http.auth.kerberos.principal keytabKey: ozone.om.http.auth.kerberos.keytab
om3_1        | 2022-04-08 11:49:18,290 [Listener at om3/9862] INFO http.HttpServer2: Jetty bound to port 9874
om3_1        | 2022-04-08 11:49:18,298 [Listener at om3/9862] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
om3_1        | 2022-04-08 11:49:18,422 [Listener at om3/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om3_1        | 2022-04-08 11:49:18,422 [Listener at om3/9862] INFO server.session: No SessionScavenger set, using defaults
om3_1        | 2022-04-08 11:49:18,429 [Listener at om3/9862] INFO server.session: node0 Scavenging every 660000ms
om3_1        | 2022-04-08 11:49:18,483 [Listener at om3/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om3_1        | 2022-04-08 11:49:18,493 [Listener at om3/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2094a7be{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om3_1        | 2022-04-08 11:49:18,494 [Listener at om3/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6afed88d{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om3_1        | 2022-04-08 11:49:18,804 [Listener at om3/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
recon_1      | 2022-04-08 11:48:55,895 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 0005597f-3053-4b02-96b8-efe2de95313b to Node DB.
recon_1      | 2022-04-08 11:48:56,572 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 81 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:48:56,581 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 82 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:48:56,588 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 83 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-08 11:48:57,060 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33068
recon_1      | 2022-04-08 11:48:57,138 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 11:48:57,176 [IPC Server handler 4 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net
recon_1      | 2022-04-08 11:48:57,596 [IPC Server handler 8 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net
recon_1      | 2022-04-08 11:48:58,590 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 84 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:48:58,591 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 85 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:48:58,592 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 86 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-08 11:48:58,846 [IPC Server handler 33 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/4cf3df89-7b36-4576-a18a-5d0c57ddb620
recon_1      | 2022-04-08 11:48:58,846 [IPC Server handler 33 on default port 9891] INFO node.SCMNodeManager: Registered Data node : 4cf3df89-7b36-4576-a18a-5d0c57ddb620{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 936508841118, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-04-08 11:48:58,847 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 4cf3df89-7b36-4576-a18a-5d0c57ddb620 to Node DB.
recon_1      | 2022-04-08 11:49:00,581 [IPC Server handler 13 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net
recon_1      | 2022-04-08 11:49:00,593 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 87 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:49:00,594 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 88 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:49:00,595 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 89 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-08 11:49:01,890 [IPC Server handler 56 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net
recon_1      | 2022-04-08 11:49:01,892 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=cfd3e9b8-6c85-4577-8ecd-7af890cf2706. Trying to get from SCM.
recon_1      | 2022-04-08 11:49:02,029 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: cfd3e9b8-6c85-4577-8ecd-7af890cf2706, Nodes: 4cf3df89-7b36-4576-a18a-5d0c57ddb620{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-04-08T11:48:58.915Z[UTC]] to Recon pipeline metadata.
om1_1        | 2022-04-08 11:52:33,523 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:52:35,787 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41986
om1_1        | 2022-04-08 11:52:35,836 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:52:39,957 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41990
om1_1        | 2022-04-08 11:52:39,971 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:52:43,884 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42002
om1_1        | 2022-04-08 11:52:43,914 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:52:47,788 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42014
om1_1        | 2022-04-08 11:52:47,804 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:52:51,732 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42042
om1_1        | 2022-04-08 11:52:51,800 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:52:55,337 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42054
om1_1        | 2022-04-08 11:52:55,370 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:52:59,188 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42066
om1_1        | 2022-04-08 11:52:59,207 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:53:02,770 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42070
om1_1        | 2022-04-08 11:53:02,830 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:53:06,622 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42082
om1_1        | 2022-04-08 11:53:06,675 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:53:10,368 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42104
om1_1        | 2022-04-08 11:53:10,404 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:53:14,550 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42110
om1_1        | 2022-04-08 11:53:14,566 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:53:15,076 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link2 of layout LEGACY in volume: 38628-target
om1_1        | 2022-04-08 11:53:18,282 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42126
om1_1        | 2022-04-08 11:53:18,334 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:53:18,898 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:link2 in volume:38628-target
om1_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om1_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:198)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-04-08 11:53:22,151 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42154
om1_1        | 2022-04-08 11:53:22,178 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:53:22,642 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket3 of layout OBJECT_STORE in volume: 38628-target
om1_1        | 2022-04-08 11:53:26,032 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42166
om1_1        | 2022-04-08 11:53:26,059 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:53:26,578 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket3 in volume:38628-target
datanode3_1  | 2022-04-08 11:49:11,532 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/d7bff567-93ff-485c-a104-bc074898d12a does not exist. Creating ...
datanode3_1  | 2022-04-08 11:49:11,559 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/d7bff567-93ff-485c-a104-bc074898d12a/in_use.lock acquired by nodename 7@1e89468786a9
datanode3_1  | 2022-04-08 11:49:11,569 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/d7bff567-93ff-485c-a104-bc074898d12a has been successfully formatted.
datanode3_1  | 2022-04-08 11:49:11,570 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-BC074898D12A: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode3_1  | 2022-04-08 11:49:11,576 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode3_1  | 2022-04-08 11:49:11,576 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode3_1  | 2022-04-08 11:49:11,577 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode3_1  | 2022-04-08 11:49:11,580 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2022-04-08 11:49:11,580 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2022-04-08 11:49:11,581 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode3_1  | 2022-04-08 11:49:11,584 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode3_1  | 2022-04-08 11:49:11,599 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/d7bff567-93ff-485c-a104-bc074898d12a
datanode3_1  | 2022-04-08 11:49:11,600 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode3_1  | 2022-04-08 11:49:11,600 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode3_1  | 2022-04-08 11:49:11,600 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2022-04-08 11:49:11,600 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode3_1  | 2022-04-08 11:49:11,600 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode3_1  | 2022-04-08 11:49:11,600 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode3_1  | 2022-04-08 11:49:11,601 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode3_1  | 2022-04-08 11:49:11,601 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode3_1  | 2022-04-08 11:49:11,658 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode3_1  | 2022-04-08 11:49:11,659 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode3_1  | 2022-04-08 11:49:11,659 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode3_1  | 2022-04-08 11:49:11,663 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode3_1  | 2022-04-08 11:49:11,666 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode3_1  | 2022-04-08 11:49:11,671 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode3_1  | 2022-04-08 11:49:11,672 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode3_1  | 2022-04-08 11:49:11,672 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode3_1  | 2022-04-08 11:49:11,672 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode3_1  | 2022-04-08 11:49:11,675 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode3_1  | 2022-04-08 11:49:11,676 [pool-23-thread-1] INFO server.RaftServer$Division: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A: start as a follower, conf=-1: [0005597f-3053-4b02-96b8-efe2de95313b|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, 8b7f16e2-5fb9-442f-a717-cc893c5795e0|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1, 4cf3df89-7b36-4576-a18a-5d0c57ddb620|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0], old=null
datanode3_1  | 2022-04-08 11:49:11,678 [pool-23-thread-1] INFO server.RaftServer$Division: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode3_1  | 2022-04-08 11:49:11,678 [pool-23-thread-1] INFO impl.RoleInfo: 4cf3df89-7b36-4576-a18a-5d0c57ddb620: start 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-FollowerState
datanode3_1  | 2022-04-08 11:49:11,679 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-BC074898D12A,id=4cf3df89-7b36-4576-a18a-5d0c57ddb620
datanode3_1  | 2022-04-08 11:49:11,689 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=d7bff567-93ff-485c-a104-bc074898d12a
datanode3_1  | 2022-04-08 11:49:12,620 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=d7bff567-93ff-485c-a104-bc074898d12a.
datanode3_1  | 2022-04-08 11:49:12,824 [grpc-default-executor-0] INFO leader.FollowerInfo: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b: nextIndex: updateUnconditionally 1 -> 0
datanode3_1  | 2022-04-08 11:49:16,878 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-FollowerState] INFO impl.FollowerState: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5199995546ns, electionTimeout:5196ms
datanode3_1  | 2022-04-08 11:49:16,879 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-FollowerState] INFO impl.RoleInfo: 4cf3df89-7b36-4576-a18a-5d0c57ddb620: shutdown 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-FollowerState
datanode3_1  | 2022-04-08 11:49:16,879 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-FollowerState] INFO server.RaftServer$Division: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode3_1  | 2022-04-08 11:49:16,879 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode3_1  | 2022-04-08 11:49:16,879 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-FollowerState] INFO impl.RoleInfo: 4cf3df89-7b36-4576-a18a-5d0c57ddb620: start 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection3
datanode3_1  | 2022-04-08 11:49:16,888 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection3] INFO impl.LeaderElection: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection3 ELECTION round 0: submit vote requests at term 1 for -1: [0005597f-3053-4b02-96b8-efe2de95313b|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, 8b7f16e2-5fb9-442f-a717-cc893c5795e0|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1, 4cf3df89-7b36-4576-a18a-5d0c57ddb620|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0], old=null
datanode3_1  | 2022-04-08 11:49:16,915 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection3] INFO impl.LeaderElection: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection3: ELECTION REJECTED received 1 response(s) and 0 exception(s):
datanode3_1  | 2022-04-08 11:49:16,922 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection3] INFO impl.LeaderElection:   Response 0: 4cf3df89-7b36-4576-a18a-5d0c57ddb620<-8b7f16e2-5fb9-442f-a717-cc893c5795e0#0:FAIL-t1
datanode3_1  | 2022-04-08 11:49:16,922 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection3] INFO impl.LeaderElection: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection3 ELECTION round 0: result REJECTED
datanode3_1  | 2022-04-08 11:49:16,923 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection3] INFO server.RaftServer$Division: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
datanode3_1  | 2022-04-08 11:49:16,926 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection3] INFO impl.RoleInfo: 4cf3df89-7b36-4576-a18a-5d0c57ddb620: shutdown 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection3
datanode3_1  | 2022-04-08 11:49:16,930 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection3] INFO impl.RoleInfo: 4cf3df89-7b36-4576-a18a-5d0c57ddb620: start 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-FollowerState
datanode3_1  | 2022-04-08 11:49:22,044 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-FollowerState] INFO impl.FollowerState: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5114359337ns, electionTimeout:5100ms
datanode3_1  | 2022-04-08 11:49:22,045 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-FollowerState] INFO impl.RoleInfo: 4cf3df89-7b36-4576-a18a-5d0c57ddb620: shutdown 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-FollowerState
datanode3_1  | 2022-04-08 11:49:22,045 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-FollowerState] INFO server.RaftServer$Division: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
datanode3_1  | 2022-04-08 11:49:22,046 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode3_1  | 2022-04-08 11:49:22,046 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-FollowerState] INFO impl.RoleInfo: 4cf3df89-7b36-4576-a18a-5d0c57ddb620: start 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection4
datanode3_1  | 2022-04-08 11:49:22,056 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection4] INFO impl.LeaderElection: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection4 ELECTION round 0: submit vote requests at term 2 for -1: [0005597f-3053-4b02-96b8-efe2de95313b|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, 8b7f16e2-5fb9-442f-a717-cc893c5795e0|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1, 4cf3df89-7b36-4576-a18a-5d0c57ddb620|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0], old=null
datanode3_1  | 2022-04-08 11:49:22,081 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection4] INFO impl.LeaderElection: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection4: ELECTION REJECTED received 2 response(s) and 0 exception(s):
datanode3_1  | 2022-04-08 11:49:22,082 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection4] INFO impl.LeaderElection:   Response 0: 4cf3df89-7b36-4576-a18a-5d0c57ddb620<-0005597f-3053-4b02-96b8-efe2de95313b#0:OK-t2
datanode3_1  | 2022-04-08 11:49:22,082 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection4] INFO impl.LeaderElection:   Response 1: 4cf3df89-7b36-4576-a18a-5d0c57ddb620<-8b7f16e2-5fb9-442f-a717-cc893c5795e0#0:FAIL-t2
datanode3_1  | 2022-04-08 11:49:22,083 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection4] INFO impl.LeaderElection: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection4 ELECTION round 0: result REJECTED
datanode3_1  | 2022-04-08 11:49:22,083 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection4] INFO server.RaftServer$Division: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A: changes role from CANDIDATE to FOLLOWER at term 2 for REJECTED
datanode3_1  | 2022-04-08 11:49:22,083 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection4] INFO impl.RoleInfo: 4cf3df89-7b36-4576-a18a-5d0c57ddb620: shutdown 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection4
datanode3_1  | 2022-04-08 11:49:22,083 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection4] INFO impl.RoleInfo: 4cf3df89-7b36-4576-a18a-5d0c57ddb620: start 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-FollowerState
datanode3_1  | 2022-04-08 11:49:22,621 [grpc-default-executor-0] INFO server.RaftServer$Division: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A: receive requestVote(ELECTION, 8b7f16e2-5fb9-442f-a717-cc893c5795e0, group-BC074898D12A, 2, (t:0, i:0))
datanode3_1  | 2022-04-08 11:49:22,632 [grpc-default-executor-0] INFO impl.VoteContext: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-FOLLOWER: reject ELECTION from 8b7f16e2-5fb9-442f-a717-cc893c5795e0: already has voted for 4cf3df89-7b36-4576-a18a-5d0c57ddb620 at current term 2
datanode3_1  | 2022-04-08 11:49:22,649 [grpc-default-executor-0] INFO server.RaftServer$Division: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A replies to ELECTION vote request: 8b7f16e2-5fb9-442f-a717-cc893c5795e0<-4cf3df89-7b36-4576-a18a-5d0c57ddb620#0:FAIL-t2. Peer's state: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A:t2, leader=null, voted=4cf3df89-7b36-4576-a18a-5d0c57ddb620, raftlog=4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-SegmentedRaftLog:OPENED:c-1, conf=-1: [0005597f-3053-4b02-96b8-efe2de95313b|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, 8b7f16e2-5fb9-442f-a717-cc893c5795e0|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1, 4cf3df89-7b36-4576-a18a-5d0c57ddb620|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0], old=null
datanode3_1  | 2022-04-08 11:49:27,176 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-FollowerState] INFO impl.FollowerState: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5092371926ns, electionTimeout:5090ms
datanode3_1  | 2022-04-08 11:49:27,176 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-FollowerState] INFO impl.RoleInfo: 4cf3df89-7b36-4576-a18a-5d0c57ddb620: shutdown 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-FollowerState
datanode3_1  | 2022-04-08 11:49:27,176 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-FollowerState] INFO server.RaftServer$Division: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A: changes role from  FOLLOWER to CANDIDATE at term 2 for changeToCandidate
datanode3_1  | 2022-04-08 11:49:27,176 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode3_1  | 2022-04-08 11:49:27,176 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-FollowerState] INFO impl.RoleInfo: 4cf3df89-7b36-4576-a18a-5d0c57ddb620: start 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection5
datanode3_1  | 2022-04-08 11:49:27,183 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection5] INFO impl.LeaderElection: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection5 ELECTION round 0: submit vote requests at term 3 for -1: [0005597f-3053-4b02-96b8-efe2de95313b|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, 8b7f16e2-5fb9-442f-a717-cc893c5795e0|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1, 4cf3df89-7b36-4576-a18a-5d0c57ddb620|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0], old=null
datanode3_1  | 2022-04-08 11:49:27,211 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection5] INFO impl.LeaderElection: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection5: ELECTION REJECTED received 2 response(s) and 0 exception(s):
datanode3_1  | 2022-04-08 11:49:27,211 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection5] INFO impl.LeaderElection:   Response 0: 4cf3df89-7b36-4576-a18a-5d0c57ddb620<-0005597f-3053-4b02-96b8-efe2de95313b#0:OK-t3
datanode3_1  | 2022-04-08 11:49:27,212 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection5] INFO impl.LeaderElection:   Response 1: 4cf3df89-7b36-4576-a18a-5d0c57ddb620<-8b7f16e2-5fb9-442f-a717-cc893c5795e0#0:FAIL-t3
datanode3_1  | 2022-04-08 11:49:27,212 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection5] INFO impl.LeaderElection: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection5 ELECTION round 0: result REJECTED
om3_1        | 2022-04-08 11:49:18,865 [Listener at om3/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@1b7bab7e{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-ozone-manager-1_3_0-SNAPSHOT_jar-_-any-15473107591126864897/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/ozoneManager}
om3_1        | 2022-04-08 11:49:18,886 [Listener at om3/9862] INFO server.AbstractConnector: Started ServerConnector@19146ad8{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
om3_1        | 2022-04-08 11:49:18,889 [Listener at om3/9862] INFO server.Server: Started @39688ms
om3_1        | 2022-04-08 11:49:18,894 [Listener at om3/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om3_1        | 2022-04-08 11:49:18,905 [Listener at om3/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om3_1        | 2022-04-08 11:49:18,909 [Listener at om3/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om3_1        | 2022-04-08 11:49:18,919 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om3_1        | 2022-04-08 11:49:19,060 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om3_1        | 2022-04-08 11:49:19,104 [Listener at om3/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted will not move to trash
om3_1        | 2022-04-08 11:49:19,207 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@73b8c79b] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om3_1        | 2022-04-08 11:49:19,361 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:35557
om3_1        | 2022-04-08 11:49:19,375 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-04-08 11:49:22,224 [om3@group-562213E44849-FollowerState] INFO impl.FollowerState: om3@group-562213E44849-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5218938472ns, electionTimeout:5187ms
om3_1        | 2022-04-08 11:49:22,226 [om3@group-562213E44849-FollowerState] INFO impl.RoleInfo: om3: shutdown om3@group-562213E44849-FollowerState
om3_1        | 2022-04-08 11:49:22,227 [om3@group-562213E44849-FollowerState] INFO server.RaftServer$Division: om3@group-562213E44849: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
om3_1        | 2022-04-08 11:49:22,230 [om3@group-562213E44849-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om3_1        | 2022-04-08 11:49:22,230 [om3@group-562213E44849-FollowerState] INFO impl.RoleInfo: om3: start om3@group-562213E44849-LeaderElection1
om3_1        | 2022-04-08 11:49:22,254 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om3@group-562213E44849-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1        | 2022-04-08 11:49:25,659 [grpc-default-executor-0] INFO server.RaftServer$Division: om3@group-562213E44849: receive requestVote(ELECTION, om1, group-562213E44849, 1, (t:0, i:~))
om3_1        | 2022-04-08 11:49:25,666 [grpc-default-executor-0] INFO impl.VoteContext: om3@group-562213E44849-CANDIDATE: reject ELECTION from om1: already has voted for om3 at current term 1
om3_1        | 2022-04-08 11:49:25,675 [grpc-default-executor-0] INFO server.RaftServer$Division: om3@group-562213E44849 replies to ELECTION vote request: om1<-om3#0:FAIL-t1. Peer's state: om3@group-562213E44849:t1, leader=null, voted=om3, raftlog=om3@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1        | 2022-04-08 11:49:25,699 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om3@group-562213E44849-LeaderElection1: ELECTION REJECTED received 2 response(s) and 0 exception(s):
om3_1        | 2022-04-08 11:49:25,699 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 0: om3<-om1#0:FAIL-t1
om3_1        | 2022-04-08 11:49:25,700 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 1: om3<-om2#0:FAIL-t1
om3_1        | 2022-04-08 11:49:25,700 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om3@group-562213E44849-LeaderElection1 ELECTION round 0: result REJECTED
om3_1        | 2022-04-08 11:49:25,701 [om3@group-562213E44849-LeaderElection1] INFO server.RaftServer$Division: om3@group-562213E44849: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
om3_1        | 2022-04-08 11:49:25,707 [om3@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om3: shutdown om3@group-562213E44849-LeaderElection1
om3_1        | 2022-04-08 11:49:25,707 [om3@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om3: start om3@group-562213E44849-FollowerState
om3_1        | 2022-04-08 11:49:25,730 [grpc-default-executor-1] INFO server.RaftServer$Division: om3@group-562213E44849: receive requestVote(ELECTION, om2, group-562213E44849, 1, (t:0, i:~))
om3_1        | 2022-04-08 11:49:25,730 [grpc-default-executor-1] INFO impl.VoteContext: om3@group-562213E44849-FOLLOWER: reject ELECTION from om2: already has voted for om3 at current term 1
om3_1        | 2022-04-08 11:49:25,731 [grpc-default-executor-1] INFO server.RaftServer$Division: om3@group-562213E44849 replies to ELECTION vote request: om2<-om3#0:FAIL-t1. Peer's state: om3@group-562213E44849:t1, leader=null, voted=om3, raftlog=om3@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1        | 2022-04-08 11:49:29,895 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49782
om3_1        | 2022-04-08 11:49:29,904 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-04-08 11:49:30,825 [grpc-default-executor-0] INFO server.RaftServer$Division: om3@group-562213E44849: receive requestVote(ELECTION, om1, group-562213E44849, 2, (t:0, i:~))
om3_1        | 2022-04-08 11:49:30,826 [grpc-default-executor-0] INFO impl.VoteContext: om3@group-562213E44849-FOLLOWER: accept ELECTION from om1: our priority 0 <= candidate's priority 0
om3_1        | 2022-04-08 11:49:30,827 [grpc-default-executor-0] INFO server.RaftServer$Division: om3@group-562213E44849: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:om1
om3_1        | 2022-04-08 11:49:30,827 [grpc-default-executor-0] INFO impl.RoleInfo: om3: shutdown om3@group-562213E44849-FollowerState
om3_1        | 2022-04-08 11:49:30,828 [om3@group-562213E44849-FollowerState] INFO impl.FollowerState: om3@group-562213E44849-FollowerState was interrupted: {}
om3_1        | java.lang.InterruptedException: sleep interrupted
om3_1        | 	at java.base/java.lang.Thread.sleep(Native Method)
om3_1        | 	at java.base/java.lang.Thread.sleep(Thread.java:334)
om3_1        | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
om3_1        | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
om3_1        | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
om3_1        | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
om3_1        | 2022-04-08 11:49:30,828 [grpc-default-executor-0] INFO impl.RoleInfo: om3: start om3@group-562213E44849-FollowerState
om3_1        | 2022-04-08 11:49:30,834 [grpc-default-executor-0] INFO server.RaftServer$Division: om3@group-562213E44849 replies to ELECTION vote request: om1<-om3#0:OK-t2. Peer's state: om3@group-562213E44849:t2, leader=null, voted=om1, raftlog=om3@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1        | 2022-04-08 11:49:30,861 [grpc-default-executor-0] INFO server.RaftServer$Division: om3@group-562213E44849: receive requestVote(ELECTION, om2, group-562213E44849, 2, (t:0, i:~))
om3_1        | 2022-04-08 11:49:30,861 [grpc-default-executor-0] INFO impl.VoteContext: om3@group-562213E44849-FOLLOWER: reject ELECTION from om2: already has voted for om1 at current term 2
om3_1        | 2022-04-08 11:49:30,861 [grpc-default-executor-0] INFO server.RaftServer$Division: om3@group-562213E44849 replies to ELECTION vote request: om2<-om3#0:FAIL-t2. Peer's state: om3@group-562213E44849:t2, leader=null, voted=om1, raftlog=om3@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1        | 2022-04-08 11:49:31,078 [grpc-default-executor-0] INFO server.RaftServer$Division: om3@group-562213E44849: change Leader from null to om1 at term 2 for appendEntries, leader elected after 16875ms
om3_1        | 2022-04-08 11:49:31,121 [grpc-default-executor-0] INFO server.RaftServer$Division: om3@group-562213E44849: set configuration 0: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om3_1        | 2022-04-08 11:49:31,143 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: Starting segment from index:0
om3_1        | 2022-04-08 11:49:31,271 [om3@group-562213E44849-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/current/log_inprogress_0
om3_1        | 2022-04-08 11:49:34,036 [om3@group-562213E44849-StateMachineUpdater] INFO ratis.OzoneManagerStateMachine: Received Configuration change notification from Ratis. New Peer list:
om3_1        | [id: "om1"
om3_1        | address: "om1:9872"
om3_1        | , id: "om3"
om3_1        | address: "om3:9872"
om3_1        | , id: "om2"
om3_1        | address: "om2:9872"
om3_1        | ]
om3_1        | 2022-04-08 11:49:46,816 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:vol1 for user:root
om3_1        | 2022-04-08 11:49:46,976 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket1 of layout LEGACY in volume: vol1
om3_1        | 2022-04-08 11:50:04,515 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ombg0 of layout LEGACY in volume: vol1
om3_1        | 2022-04-08 11:50:24,100 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ombr0 of layout LEGACY in volume: vol1
om3_1        | 2022-04-08 11:50:47,851 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:38628-source for user:root
om3_1        | 2022-04-08 11:50:51,618 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:38628-target for user:root
om3_1        | 2022-04-08 11:50:55,327 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: readable-bucket of layout OBJECT_STORE in volume: 38628-source
om3_1        | 2022-04-08 11:51:07,716 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: unreadable-bucket of layout OBJECT_STORE in volume: 38628-source
om3_1        | 2022-04-08 11:51:11,232 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: readable-link of layout LEGACY in volume: 38628-target
om3_1        | 2022-04-08 11:51:15,190 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: unreadable-link of layout LEGACY in volume: 38628-target
om3_1        | 2022-04-08 11:51:19,357 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link-to-unreadable-bucket of layout LEGACY in volume: 38628-target
om3_1        | 2022-04-08 11:51:42,361 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: dangling-link of layout LEGACY in volume: 38628-target
om3_1        | 2022-04-08 11:51:49,945 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link1 of layout LEGACY in volume: 38628-target
om3_1        | 2022-04-08 11:51:53,981 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket1 of layout OBJECT_STORE in volume: 38628-source
om1_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om1_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:198)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-04-08 11:53:29,929 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42178
om1_1        | 2022-04-08 11:53:29,960 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:53:33,553 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:38793
om1_1        | 2022-04-08 11:53:33,559 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:53:34,192 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42184
om1_1        | 2022-04-08 11:53:34,222 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:53:34,722 [IPC Server handler 16 on default port 9862] WARN om.OzoneManager: User testuser2/scm@EXAMPLE.COM doesn't have READ permission to access bucket Volume:38628-target Bucket:unreadable-link 
om1_1        | 2022-04-08 11:53:38,078 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42196
om1_1        | 2022-04-08 11:53:38,093 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:53:42,044 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42208
om1_1        | 2022-04-08 11:53:42,088 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:53:42,553 [IPC Server handler 35 on default port 9862] WARN om.OzoneManager: User testuser2/scm@EXAMPLE.COM doesn't have LIST permission to access bucket Volume:38628-source Bucket:unreadable-bucket Key:
om1_1        | 2022-04-08 11:53:45,667 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42212
om1_1        | 2022-04-08 11:53:45,687 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:53:46,184 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop2 of layout LEGACY in volume: 38628-target
om1_1        | 2022-04-08 11:53:49,571 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42224
om1_1        | 2022-04-08 11:53:49,588 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:53:49,997 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop3 of layout LEGACY in volume: 38628-target
om1_1        | 2022-04-08 11:53:53,249 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42260
om1_1        | 2022-04-08 11:53:53,298 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:53:53,773 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop1 of layout LEGACY in volume: 38628-target
om1_1        | 2022-04-08 11:53:56,804 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42264
om1_1        | 2022-04-08 11:53:56,848 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:54:00,353 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42276
om1_1        | 2022-04-08 11:54:00,392 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:54:00,949 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link3 of layout LEGACY in volume: 38628-target
om1_1        | 2022-04-08 11:54:03,973 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42280
om1_1        | 2022-04-08 11:54:04,008 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:54:10,297 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42330
om1_1        | 2022-04-08 11:54:10,334 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:54:16,134 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42346
om1_1        | 2022-04-08 11:54:16,160 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:54:19,992 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42360
om1_1        | 2022-04-08 11:54:20,011 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:54:24,039 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42372
om1_1        | 2022-04-08 11:54:24,072 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:54:33,624 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:38699
datanode2_1  | 2022-04-08 11:49:47,785 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-LeaderElection3] INFO impl.RoleInfo: 8b7f16e2-5fb9-442f-a717-cc893c5795e0: start 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-LeaderStateImpl
datanode2_1  | 2022-04-08 11:49:47,790 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-LeaderElection3] INFO segmented.SegmentedRaftLogWorker: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-SegmentedRaftLogWorker: Starting segment from index:0
datanode2_1  | 2022-04-08 11:49:47,816 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/d7bff567-93ff-485c-a104-bc074898d12a/current/log_inprogress_0
datanode2_1  | 2022-04-08 11:49:47,859 [8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A-LeaderElection3] INFO server.RaftServer$Division: 8b7f16e2-5fb9-442f-a717-cc893c5795e0@group-BC074898D12A: set configuration 0: [0005597f-3053-4b02-96b8-efe2de95313b|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 8b7f16e2-5fb9-442f-a717-cc893c5795e0|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, 4cf3df89-7b36-4576-a18a-5d0c57ddb620|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode2_1  | 2022-04-08 11:49:50,455 [ChunkWriter-1-0] INFO client.DNCertificateClient: Getting certificate with certSerialId:941464992973.
om3_1        | 2022-04-08 11:53:15,092 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link2 of layout LEGACY in volume: 38628-target
om3_1        | 2022-04-08 11:53:18,923 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:link2 in volume:38628-target
om3_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om3_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:198)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-04-08 11:53:22,661 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket3 of layout OBJECT_STORE in volume: 38628-target
om3_1        | 2022-04-08 11:53:26,603 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket3 in volume:38628-target
om3_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om3_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:198)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-04-08 11:53:46,197 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop2 of layout LEGACY in volume: 38628-target
om3_1        | 2022-04-08 11:53:50,007 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop3 of layout LEGACY in volume: 38628-target
om3_1        | 2022-04-08 11:53:53,786 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop1 of layout LEGACY in volume: 38628-target
om3_1        | 2022-04-08 11:54:00,957 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link3 of layout LEGACY in volume: 38628-target
om3_1        | 2022-04-08 11:54:58,031 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-1592951654 of layout LEGACY in volume: s3v
om3_1        | 2022-04-08 11:55:04,408 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-8147954027 of layout LEGACY in volume: s3v
om3_1        | 2022-04-08 11:55:22,623 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-0372689255 of layout LEGACY in volume: s3v
om3_1        | 2022-04-08 11:55:23,152 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ozone-test-ntnaskidoy of layout LEGACY in volume: s3v
om3_1        | 2022-04-08 11:55:36,020 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-phfmxspesy of layout LEGACY in volume: s3v
om3_1        | 2022-04-08 11:55:50,396 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-3090789646 of layout LEGACY in volume: s3v
om3_1        | 2022-04-08 11:55:51,012 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-2505354869 of layout LEGACY in volume: s3v
om3_1        | 2022-04-08 11:55:51,671 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-9765919850 of layout LEGACY in volume: s3v
om3_1        | 2022-04-08 11:55:52,247 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket-ozone-test-9765919850 in volume:s3v
om3_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om3_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:198)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-04-08 11:55:58,952 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-9631101845 of layout LEGACY in volume: s3v
om3_1        | 2022-04-08 11:55:59,530 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-1703165167 of layout LEGACY in volume: s3v
om3_1        | 2022-04-08 11:56:00,726 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketDeleteRequest: Delete bucket failed for bucket:nosuchbucket-ozone-test-0525685448 in volume:s3v
om3_1        | BUCKET_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Bucket not found
om3_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.getBucketOwner(OzoneManager.java:2334)
om3_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.getBucketOwner(OzoneManager.java:2304)
om3_1        | 	at org.apache.hadoop.ozone.om.request.OMClientRequest.checkAcls(OMClientRequest.java:200)
om3_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketDeleteRequest.validateAndUpdateCache(OMBucketDeleteRequest.java:102)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-04-08 11:56:07,006 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-0143600893 of layout LEGACY in volume: s3v
om3_1        | 2022-04-08 11:56:14,277 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-3076197802 of layout LEGACY in volume: s3v
om3_1        | 2022-04-08 11:56:21,812 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-0491738847 of layout LEGACY in volume: s3v
om3_1        | 2022-04-08 11:56:44,950 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload: /s3v/bucket-ozone-test-0491738847/ozone-test-9528167901/multipartKey2 Part number: 1 size 6  is less than minimum part size 5242880
om3_1        | 2022-04-08 11:56:44,954 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-9528167901/multipartKey2 in Volume/Bucket s3v/bucket-ozone-test-0491738847
om3_1        | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-0491738847 key: ozone-test-9528167901/multipartKey2. Entity too small.
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:513)
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:192)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-04-08 11:56:46,256 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-ozone-test-0491738847/ozone-test-0981360713/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 1
om3_1        | partName: "etag1"
om3_1        | , partNumber: 2
om3_1        | partName: "etag2"
om3_1        | ]
om3_1        | 2022-04-08 11:56:46,275 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0981360713/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-0491738847
om3_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-0491738847 key: ozone-test-0981360713/multipartKey3
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:181)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-04-08 11:56:46,892 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-ozone-test-0491738847/ozone-test-0981360713/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 2
om3_1        | partName: "etag1"
om3_1        | , partNumber: 1
om3_1        | partName: "etag2"
om3_1        | ]
om3_1        | 2022-04-08 11:56:46,896 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0981360713/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-0491738847
om3_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-0491738847 key: ozone-test-0981360713/multipartKey3
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:181)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-04-08 11:56:53,068 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0981360713/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-0491738847
om3_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-0491738847 key: ozone-test-0981360713/multipartKey3. Provided Part info is { etag1, 1}, whereas OM has partName /s3v/bucket-ozone-test-0491738847/ozone-test-0981360713/multipartKey3-264276c9-564f-4799-903a-1c9a411a4b2c-108096323947724836-1
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:495)
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:192)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-04-08 11:56:53,626 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0981360713/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-0491738847
om3_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-0491738847 key: ozone-test-0981360713/multipartKey3. Provided Part info is { etag2, 2}, whereas OM has partName /s3v/bucket-ozone-test-0491738847/ozone-test-0981360713/multipartKey3-264276c9-564f-4799-903a-1c9a411a4b2c-108096323947724836-2
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:495)
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:192)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-04-08 11:56:54,285 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: PartNumber at index 1 is 2, and its previous partNumber at index 0 is 4 for ozonekey is /s3v/bucket-ozone-test-0491738847/ozone-test-0981360713/multipartKey3
om3_1        | 2022-04-08 11:56:54,288 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0981360713/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-0491738847
om3_1        | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-0491738847 key: ozone-test-0981360713/multipartKey3 because parts are in Invalid order.
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getPartsListSize(S3MultipartUploadCompleteRequest.java:461)
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:188)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-04-08 11:56:57,612 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadAbortRequest: Abort Multipart request is failed for KeyName ozone-test-7878972111/multipartKey5 in VolumeName/Bucket s3v/bucket-ozone-test-0491738847
datanode3_1  | 2022-04-08 11:49:27,212 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection5] INFO server.RaftServer$Division: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A: changes role from CANDIDATE to FOLLOWER at term 3 for REJECTED
datanode3_1  | 2022-04-08 11:49:27,212 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection5] INFO impl.RoleInfo: 4cf3df89-7b36-4576-a18a-5d0c57ddb620: shutdown 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection5
datanode3_1  | 2022-04-08 11:49:27,212 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection5] INFO impl.RoleInfo: 4cf3df89-7b36-4576-a18a-5d0c57ddb620: start 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-FollowerState
datanode3_1  | 2022-04-08 11:49:32,237 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-FollowerState] INFO impl.FollowerState: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5024849945ns, electionTimeout:5014ms
datanode3_1  | 2022-04-08 11:49:32,238 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-FollowerState] INFO impl.RoleInfo: 4cf3df89-7b36-4576-a18a-5d0c57ddb620: shutdown 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-FollowerState
datanode3_1  | 2022-04-08 11:49:32,238 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-FollowerState] INFO server.RaftServer$Division: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A: changes role from  FOLLOWER to CANDIDATE at term 3 for changeToCandidate
datanode3_1  | 2022-04-08 11:49:32,238 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode3_1  | 2022-04-08 11:49:32,239 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-FollowerState] INFO impl.RoleInfo: 4cf3df89-7b36-4576-a18a-5d0c57ddb620: start 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection6
datanode3_1  | 2022-04-08 11:49:32,245 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection6] INFO impl.LeaderElection: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection6 ELECTION round 0: submit vote requests at term 4 for -1: [0005597f-3053-4b02-96b8-efe2de95313b|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, 8b7f16e2-5fb9-442f-a717-cc893c5795e0|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1, 4cf3df89-7b36-4576-a18a-5d0c57ddb620|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0], old=null
datanode3_1  | 2022-04-08 11:49:32,264 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection6] INFO impl.LeaderElection: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection6: ELECTION REJECTED received 1 response(s) and 0 exception(s):
datanode3_1  | 2022-04-08 11:49:32,265 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection6] INFO impl.LeaderElection:   Response 0: 4cf3df89-7b36-4576-a18a-5d0c57ddb620<-8b7f16e2-5fb9-442f-a717-cc893c5795e0#0:FAIL-t4
datanode3_1  | 2022-04-08 11:49:32,265 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection6] INFO impl.LeaderElection: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection6 ELECTION round 0: result REJECTED
datanode3_1  | 2022-04-08 11:49:32,265 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection6] INFO server.RaftServer$Division: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A: changes role from CANDIDATE to FOLLOWER at term 4 for REJECTED
datanode3_1  | 2022-04-08 11:49:32,265 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection6] INFO impl.RoleInfo: 4cf3df89-7b36-4576-a18a-5d0c57ddb620: shutdown 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection6
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-04-08 11:56:53,630 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0981360713/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-0491738847
om2_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-0491738847 key: ozone-test-0981360713/multipartKey3. Provided Part info is { etag2, 2}, whereas OM has partName /s3v/bucket-ozone-test-0491738847/ozone-test-0981360713/multipartKey3-264276c9-564f-4799-903a-1c9a411a4b2c-108096323947724836-2
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:495)
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:192)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-04-08 11:56:54,245 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: PartNumber at index 1 is 2, and its previous partNumber at index 0 is 4 for ozonekey is /s3v/bucket-ozone-test-0491738847/ozone-test-0981360713/multipartKey3
om2_1        | 2022-04-08 11:56:54,246 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0981360713/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-0491738847
om2_1        | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-0491738847 key: ozone-test-0981360713/multipartKey3 because parts are in Invalid order.
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getPartsListSize(S3MultipartUploadCompleteRequest.java:461)
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:188)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-04-08 11:56:57,616 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadAbortRequest: Abort Multipart request is failed for KeyName ozone-test-7878972111/multipartKey5 in VolumeName/Bucket s3v/bucket-ozone-test-0491738847
om2_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: s3vbucket: bucket-ozone-test-0491738847key: ozone-test-7878972111/multipartKey5
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:154)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-04-08 11:56:58,210 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyCreateRequest: Key creation failed. Volume:s3v, Bucket:bucket-ozone-test-0491738847, Key:ozone-test-2269842426/multipartKey. 
om2_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartFileInfo(OMKeyRequest.java:757)
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareFileInfo(OMKeyRequest.java:646)
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:623)
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyCreateRequest.validateAndUpdateCache(OMKeyCreateRequest.java:267)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-04-08 11:57:56,910 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-5575003451 of layout LEGACY in volume: s3v
om2_1        | 2022-04-08 11:57:57,519 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: destbucket-38461 of layout LEGACY in volume: s3v
om2_1        | 2022-04-08 11:58:17,603 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-5420801628 of layout LEGACY in volume: s3v
om2_1        | 2022-04-08 12:04:37,488 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-0487653167 of layout LEGACY in volume: s3v
om2_1        | 2022-04-08 12:04:41,737 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:s3v, Bucket:bucket-ozone-test-0487653167, Key:ozone-test-2108438619/multidelete/key=value/f4.
om2_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:146)
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:92)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-04-08 12:04:51,506 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-2100108116 of layout LEGACY in volume: s3v
om2_1        | 2022-04-08 12:05:15,577 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-8208772603 of layout LEGACY in volume: s3v
om1_1        | 2022-04-08 11:54:33,626 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:54:53,022 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42606
om1_1        | 2022-04-08 11:54:53,033 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:54:57,279 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:34441
om1_1        | 2022-04-08 11:54:57,296 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:54:57,877 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:54:58,011 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:54:58,024 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-1592951654 of layout LEGACY in volume: s3v
om1_1        | 2022-04-08 11:55:01,310 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42620
om1_1        | 2022-04-08 11:55:01,323 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:55:04,386 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:04,392 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:04,402 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-8147954027 of layout LEGACY in volume: s3v
om1_1        | 2022-04-08 11:55:05,058 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:05,067 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:05,092 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:09,677 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:10,340 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:10,343 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:10,346 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:10,490 [IPC Server handler 89 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:11,075 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:11,079 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:11,088 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:11,095 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:11,707 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:11,710 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:11,713 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:11,716 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:12,264 [IPC Server handler 46 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:12,267 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:12,270 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
datanode3_1  | 2022-04-08 11:49:32,265 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection6] INFO impl.RoleInfo: 4cf3df89-7b36-4576-a18a-5d0c57ddb620: start 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-FollowerState
datanode3_1  | 2022-04-08 11:49:37,365 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-FollowerState] INFO impl.FollowerState: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5100566833ns, electionTimeout:5088ms
datanode3_1  | 2022-04-08 11:49:37,366 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-FollowerState] INFO impl.RoleInfo: 4cf3df89-7b36-4576-a18a-5d0c57ddb620: shutdown 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-FollowerState
datanode3_1  | 2022-04-08 11:49:37,366 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-FollowerState] INFO server.RaftServer$Division: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A: changes role from  FOLLOWER to CANDIDATE at term 4 for changeToCandidate
datanode3_1  | 2022-04-08 11:49:37,366 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode3_1  | 2022-04-08 11:49:37,366 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-FollowerState] INFO impl.RoleInfo: 4cf3df89-7b36-4576-a18a-5d0c57ddb620: start 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection7
datanode3_1  | 2022-04-08 11:49:37,374 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection7] INFO impl.LeaderElection: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection7 ELECTION round 0: submit vote requests at term 5 for -1: [0005597f-3053-4b02-96b8-efe2de95313b|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, 8b7f16e2-5fb9-442f-a717-cc893c5795e0|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1, 4cf3df89-7b36-4576-a18a-5d0c57ddb620|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0], old=null
datanode3_1  | 2022-04-08 11:49:37,406 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection7] INFO impl.LeaderElection: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection7: ELECTION REJECTED received 2 response(s) and 0 exception(s):
datanode3_1  | 2022-04-08 11:49:37,406 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection7] INFO impl.LeaderElection:   Response 0: 4cf3df89-7b36-4576-a18a-5d0c57ddb620<-0005597f-3053-4b02-96b8-efe2de95313b#0:OK-t5
datanode3_1  | 2022-04-08 11:49:37,406 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection7] INFO impl.LeaderElection:   Response 1: 4cf3df89-7b36-4576-a18a-5d0c57ddb620<-8b7f16e2-5fb9-442f-a717-cc893c5795e0#0:FAIL-t5
datanode3_1  | 2022-04-08 11:49:37,406 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection7] INFO impl.LeaderElection: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection7 ELECTION round 0: result REJECTED
datanode3_1  | 2022-04-08 11:49:37,406 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection7] INFO server.RaftServer$Division: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A: changes role from CANDIDATE to FOLLOWER at term 5 for REJECTED
datanode3_1  | 2022-04-08 11:49:37,407 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection7] INFO impl.RoleInfo: 4cf3df89-7b36-4576-a18a-5d0c57ddb620: shutdown 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection7
datanode3_1  | 2022-04-08 11:49:37,407 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection7] INFO impl.RoleInfo: 4cf3df89-7b36-4576-a18a-5d0c57ddb620: start 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-FollowerState
datanode3_1  | 2022-04-08 11:49:42,470 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-FollowerState] INFO impl.FollowerState: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5062780936ns, electionTimeout:5056ms
datanode3_1  | 2022-04-08 11:49:42,470 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-FollowerState] INFO impl.RoleInfo: 4cf3df89-7b36-4576-a18a-5d0c57ddb620: shutdown 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-FollowerState
datanode3_1  | 2022-04-08 11:49:42,470 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-FollowerState] INFO server.RaftServer$Division: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A: changes role from  FOLLOWER to CANDIDATE at term 5 for changeToCandidate
datanode3_1  | 2022-04-08 11:49:42,471 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode3_1  | 2022-04-08 11:49:42,471 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-FollowerState] INFO impl.RoleInfo: 4cf3df89-7b36-4576-a18a-5d0c57ddb620: start 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection8
datanode3_1  | 2022-04-08 11:49:42,476 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection8] INFO impl.LeaderElection: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection8 ELECTION round 0: submit vote requests at term 6 for -1: [0005597f-3053-4b02-96b8-efe2de95313b|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, 8b7f16e2-5fb9-442f-a717-cc893c5795e0|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1, 4cf3df89-7b36-4576-a18a-5d0c57ddb620|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0], old=null
datanode3_1  | 2022-04-08 11:49:42,499 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection8] INFO impl.LeaderElection: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection8: ELECTION REJECTED received 2 response(s) and 0 exception(s):
datanode3_1  | 2022-04-08 11:49:42,502 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection8] INFO impl.LeaderElection:   Response 0: 4cf3df89-7b36-4576-a18a-5d0c57ddb620<-0005597f-3053-4b02-96b8-efe2de95313b#0:OK-t6
datanode3_1  | 2022-04-08 11:49:42,502 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection8] INFO impl.LeaderElection:   Response 1: 4cf3df89-7b36-4576-a18a-5d0c57ddb620<-8b7f16e2-5fb9-442f-a717-cc893c5795e0#0:FAIL-t6
datanode3_1  | 2022-04-08 11:49:42,502 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection8] INFO impl.LeaderElection: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection8 ELECTION round 0: result REJECTED
datanode3_1  | 2022-04-08 11:49:42,502 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection8] INFO server.RaftServer$Division: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A: changes role from CANDIDATE to FOLLOWER at term 6 for REJECTED
datanode3_1  | 2022-04-08 11:49:42,505 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection8] INFO impl.RoleInfo: 4cf3df89-7b36-4576-a18a-5d0c57ddb620: shutdown 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection8
datanode3_1  | 2022-04-08 11:49:42,506 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-LeaderElection8] INFO impl.RoleInfo: 4cf3df89-7b36-4576-a18a-5d0c57ddb620: start 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-FollowerState
datanode3_1  | 2022-04-08 11:49:47,586 [grpc-default-executor-0] INFO server.RaftServer$Division: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A: receive requestVote(ELECTION, 8b7f16e2-5fb9-442f-a717-cc893c5795e0, group-BC074898D12A, 7, (t:0, i:0))
datanode3_1  | 2022-04-08 11:49:47,587 [grpc-default-executor-0] INFO impl.VoteContext: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-FOLLOWER: accept ELECTION from 8b7f16e2-5fb9-442f-a717-cc893c5795e0: our priority 0 <= candidate's priority 1
s3g_1        | Sleeping for 5 seconds
s3g_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
s3g_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
s3g_1        | 2022-04-08 11:46:51,911 [main] INFO security.UserGroupInformation: Login successful for user s3g/s3g@EXAMPLE.COM using keytab file s3g.keytab. Keytab auto renewal enabled : false
s3g_1        | 2022-04-08 11:46:51,911 [main] INFO s3.Gateway: S3Gateway login successful.
s3g_1        | 2022-04-08 11:46:52,153 [main] INFO http.BaseHttpServer: Starting Web-server for s3gateway at: http://0.0.0.0:9878
s3g_1        | 2022-04-08 11:46:52,154 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
s3g_1        | 2022-04-08 11:46:52,154 [main] INFO http.BaseHttpServer: HttpAuthType: ozone.s3g.http.auth.type = kerberos
s3g_1        | 2022-04-08 11:46:52,327 [main] INFO util.log: Logging initialized @4431ms to org.eclipse.jetty.util.log.Slf4jLog
s3g_1        | 2022-04-08 11:46:52,850 [main] INFO http.HttpRequestLog: Http request log for http.requests.s3gateway is not defined
s3g_1        | 2022-04-08 11:46:52,891 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
s3g_1        | 2022-04-08 11:46:52,900 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context s3gateway
s3g_1        | 2022-04-08 11:46:52,903 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
s3g_1        | 2022-04-08 11:46:52,903 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
s3g_1        | 2022-04-08 11:46:52,907 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.s3g.http.auth.kerberos.principal keytabKey: ozone.s3g.http.auth.kerberos.keytab
s3g_1        | 2022-04-08 11:46:53,347 [main] INFO s3.Gateway: STARTUP_MSG: 
s3g_1        | /************************************************************
s3g_1        | STARTUP_MSG: Starting Gateway
s3g_1        | STARTUP_MSG:   host = s3g/172.25.0.114
s3g_1        | STARTUP_MSG:   args = []
s3g_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
s3g_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.6.1.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.6.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.interceptor-api-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/javax.el-api-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jakarta.ws.rs-api-2.1.6.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/jackson-dataformat-xml-2.12.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.33.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/cdi-api-1.2.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.validation-api-2.0.2.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.33.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.33.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.33.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.5.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.33.jar:/opt/hadoop/share/ozone/lib/jersey-cdi1x-2.33.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.3.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.0.4.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.33.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.3.0-SNAPSHOT.jar
s3g_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/805b5e1d3b8eaf7ab8aef1c57e2bb17b73dea398 ; compiled by 'runner' on 2022-04-08T11:25Z
s3g_1        | STARTUP_MSG:   java = 11.0.14.1
s3g_1        | ************************************************************/
s3g_1        | 2022-04-08 11:46:53,387 [main] INFO s3.Gateway: registered UNIX signal handlers for [TERM, HUP, INT]
s3g_1        | 2022-04-08 11:46:53,513 [main] INFO s3.Gateway: Starting Ozone S3 gateway
s3g_1        | 2022-04-08 11:46:53,536 [main] INFO http.HttpServer2: Jetty bound to port 9878
s3g_1        | 2022-04-08 11:46:53,537 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
s3g_1        | 2022-04-08 11:46:53,666 [main] INFO server.session: DefaultSessionIdManager workerName=node0
s3g_1        | 2022-04-08 11:46:53,674 [main] INFO server.session: No SessionScavenger set, using defaults
s3g_1        | 2022-04-08 11:46:53,680 [main] INFO server.session: node0 Scavenging every 600000ms
s3g_1        | 2022-04-08 11:46:53,767 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/s3g@EXAMPLE.COM
s3g_1        | 2022-04-08 11:46:53,813 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@741b3bc3{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
s3g_1        | 2022-04-08 11:46:53,815 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@24faea88{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
s3g_1        | WARNING: An illegal reflective access operation has occurred
s3g_1        | WARNING: Illegal reflective access by org.jboss.weld.util.reflection.Formats (file:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar) to constructor com.sun.org.apache.bcel.internal.classfile.ClassParser(java.io.InputStream,java.lang.String)
s3g_1        | WARNING: Please consider reporting this to the maintainers of org.jboss.weld.util.reflection.Formats
s3g_1        | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
s3g_1        | WARNING: All illegal access operations will be denied in a future release
s3g_1        | 2022-04-08 11:46:59,852 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/s3g@EXAMPLE.COM
s3g_1        | Apr 08, 2022 11:47:02 AM org.glassfish.jersey.internal.Errors logErrors
s3g_1        | WARNING: The following warnings have been detected: WARNING: A HTTP GET method, public javax.ws.rs.core.Response org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.get(java.lang.String,java.lang.String,java.lang.String,int,java.lang.String,java.io.InputStream) throws java.io.IOException,org.apache.hadoop.ozone.s3.exception.OS3Exception, should not consume any entity.
s3g_1        | 
s3g_1        | 2022-04-08 11:47:02,295 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@38d525aa{s3gateway,/,file:///tmp/jetty-0_0_0_0-9878-ozone-s3gateway-1_3_0-SNAPSHOT_jar-_-any-11533061428710846794/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.3.0-SNAPSHOT.jar!/webapps/s3gateway}
s3g_1        | 2022-04-08 11:47:02,314 [main] INFO server.AbstractConnector: Started ServerConnector@4fcee388{HTTP/1.1, (http/1.1)}{0.0.0.0:9878}
s3g_1        | 2022-04-08 11:47:02,314 [main] INFO server.Server: Started @14419ms
s3g_1        | 2022-04-08 11:47:02,318 [main] INFO http.BaseHttpServer: HTTP server of s3gateway listening at http://0.0.0.0:9878
s3g_1        | 2022-04-08 11:47:02,453 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
s3g_1        | 2022-04-08 11:47:02,508 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
s3g_1        | 2022-04-08 11:47:02,509 [main] INFO impl.MetricsSystemImpl: S3Gateway metrics system started
s3g_1        | 2022-04-08 11:47:02,512 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
s3g_1        | 2022-04-08 11:47:02,512 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
s3g_1        | 2022-04-08 11:54:56,606 [qtp1423016050-21] INFO ozone.OmUtils: Using OzoneManager ServiceID 'id1'.
s3g_1        | 2022-04-08 11:54:57,991 [qtp1423016050-21] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-1592951654, with root as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-04-08 11:54:58,035 [qtp1423016050-21] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-1592951654
s3g_1        | 2022-04-08 11:55:04,389 [qtp1423016050-17] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-8147954027, with root as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-04-08 11:55:04,412 [qtp1423016050-17] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-8147954027
s3g_1        | 2022-04-08 11:55:05,769 [qtp1423016050-24] WARN impl.MetricsSystemImpl: S3Gateway metrics system already initialized!
s3g_1        | 2022-04-08 11:55:06,064 [qtp1423016050-24] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
s3g_1        | 2022-04-08 11:55:22,587 [qtp1423016050-19] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-0372689255, with root as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-04-08 11:55:22,605 [qtp1423016050-19] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-0372689255
s3g_1        | 2022-04-08 11:55:23,134 [qtp1423016050-19] INFO rpc.RpcClient: Creating Bucket: s3v/ozone-test-ntnaskidoy, with root as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-04-08 11:55:23,164 [qtp1423016050-19] INFO endpoint.BucketEndpoint: Location is /ozone-test-ntnaskidoy
s3g_1        | 2022-04-08 11:55:35,999 [qtp1423016050-19] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-phfmxspesy, with root as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-04-08 11:55:36,024 [qtp1423016050-19] INFO endpoint.BucketEndpoint: Location is /bucket-phfmxspesy
s3g_1        | 2022-04-08 11:55:50,377 [qtp1423016050-23] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-3090789646, with root as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-04-08 11:55:50,396 [qtp1423016050-23] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-3090789646
s3g_1        | 2022-04-08 11:55:51,000 [qtp1423016050-23] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-2505354869, with root as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-04-08 11:55:51,020 [qtp1423016050-23] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-2505354869
s3g_1        | 2022-04-08 11:55:51,654 [qtp1423016050-21] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-9765919850, with root as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-04-08 11:55:51,673 [qtp1423016050-21] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-9765919850
s3g_1        | 2022-04-08 11:55:52,227 [qtp1423016050-23] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-9765919850, with root as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-04-08 11:55:52,249 [qtp1423016050-23] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-9765919850
s3g_1        | 2022-04-08 11:55:58,936 [qtp1423016050-23] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-9631101845, with root as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-04-08 11:55:58,960 [qtp1423016050-23] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-9631101845
s3g_1        | 2022-04-08 11:55:59,515 [qtp1423016050-21] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-1703165167, with root as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-04-08 11:55:59,526 [qtp1423016050-21] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-1703165167
s3g_1        | 2022-04-08 11:56:06,991 [qtp1423016050-23] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-0143600893, with root as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-04-08 11:56:07,014 [qtp1423016050-23] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-0143600893
s3g_1        | 2022-04-08 11:56:14,261 [qtp1423016050-22] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-3076197802, with root as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-04-08 11:56:14,275 [qtp1423016050-22] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-3076197802
s3g_1        | 2022-04-08 11:56:15,867 [qtp1423016050-22] ERROR signature.AuthorizationV4HeaderParser: AWS access id shouldn't be empty. credential:/20220408/us-west-1/s3/aws4_request
s3g_1        | Apr 08, 2022 11:56:15 AM org.glassfish.jersey.internal.Errors logErrors
s3g_1        | WARNING: The following warnings have been detected: WARNING: Unknown HK2 failure detected:
s3g_1        | MultiException stack 1 of 1
s3g_1        | javax.ws.rs.WebApplicationException: The authorization header you provided is invalid.
s3g_1        | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.wrapOS3Exception(OzoneClientProducer.java:146)
s3g_1        | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getSignature(OzoneClientProducer.java:106)
s3g_1        | 	at jdk.internal.reflect.GeneratedMethodAccessor17.invoke(Unknown Source)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
s3g_1        | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1        | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1        | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
s3g_1        | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1        | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1        | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1        | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1        | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1        | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1        | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1        | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1        | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1        | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
s3g_1        | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1        | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
s3g_1        | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
s3g_1        | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:874)
s3g_1        | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1        | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1        | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1        | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1        | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1        | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1        | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
recon_1      | 2022-04-08 11:49:02,195 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: cfd3e9b8-6c85-4577-8ecd-7af890cf2706, Nodes: 4cf3df89-7b36-4576-a18a-5d0c57ddb620{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-04-08T11:48:58.915Z[UTC]].
recon_1      | 2022-04-08 11:49:02,232 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/ONE PipelineID=cfd3e9b8-6c85-4577-8ecd-7af890cf2706 reported by 4cf3df89-7b36-4576-a18a-5d0c57ddb620{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 936508841118, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-04-08 11:49:02,233 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: cfd3e9b8-6c85-4577-8ecd-7af890cf2706, Nodes: 4cf3df89-7b36-4576-a18a-5d0c57ddb620{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:4cf3df89-7b36-4576-a18a-5d0c57ddb620, CreationTimestamp2022-04-08T11:48:58.915Z[UTC]] moved to OPEN state
recon_1      | 2022-04-08 11:49:02,597 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 90 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:49:02,598 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 91 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:49:02,600 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 92 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-08 11:49:03,131 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=a6f33c92-47f3-4bcf-8c55-0543fc7274b5. Trying to get from SCM.
recon_1      | 2022-04-08 11:49:03,141 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: a6f33c92-47f3-4bcf-8c55-0543fc7274b5, Nodes: 8b7f16e2-5fb9-442f-a717-cc893c5795e0{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}0005597f-3053-4b02-96b8-efe2de95313b{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}4cf3df89-7b36-4576-a18a-5d0c57ddb620{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-04-08T11:48:59.048Z[UTC]] to Recon pipeline metadata.
recon_1      | 2022-04-08 11:49:03,142 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: a6f33c92-47f3-4bcf-8c55-0543fc7274b5, Nodes: 8b7f16e2-5fb9-442f-a717-cc893c5795e0{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}0005597f-3053-4b02-96b8-efe2de95313b{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}4cf3df89-7b36-4576-a18a-5d0c57ddb620{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-04-08T11:48:59.048Z[UTC]].
recon_1      | 2022-04-08 11:49:03,142 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=a6f33c92-47f3-4bcf-8c55-0543fc7274b5 reported by 4cf3df89-7b36-4576-a18a-5d0c57ddb620{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 936508841118, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-04-08 11:49:04,610 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 93 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:49:04,612 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 94 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:49:04,612 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 95 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-08 11:49:06,465 [IPC Server handler 13 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net
recon_1      | 2022-04-08 11:49:06,466 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=a6f33c92-47f3-4bcf-8c55-0543fc7274b5 reported by 8b7f16e2-5fb9-442f-a717-cc893c5795e0{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 932981906868, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-04-08 11:49:06,614 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 96 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:49:06,615 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 97 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:49:06,616 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 98 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-08 11:49:08,132 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=a6f33c92-47f3-4bcf-8c55-0543fc7274b5 reported by 4cf3df89-7b36-4576-a18a-5d0c57ddb620{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 936508841118, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-04-08 11:49:08,618 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 99 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:49:08,619 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 100 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:49:08,619 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 101 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-08 11:49:09,285 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=a6f33c92-47f3-4bcf-8c55-0543fc7274b5 reported by 4cf3df89-7b36-4576-a18a-5d0c57ddb620{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 936508841118, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-04-08 11:49:10,557 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:59182
recon_1      | 2022-04-08 11:49:10,621 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 102 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:49:10,624 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 103 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:49:10,625 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 104 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-08 11:49:10,632 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 11:49:10,633 [IPC Server handler 11 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net
recon_1      | 2022-04-08 11:49:10,633 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=a6f33c92-47f3-4bcf-8c55-0543fc7274b5 reported by 0005597f-3053-4b02-96b8-efe2de95313b{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 933750048452, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
om3_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: s3vbucket: bucket-ozone-test-0491738847key: ozone-test-7878972111/multipartKey5
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:154)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-04-08 11:56:58,205 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyCreateRequest: Key creation failed. Volume:s3v, Bucket:bucket-ozone-test-0491738847, Key:ozone-test-2269842426/multipartKey. 
om3_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartFileInfo(OMKeyRequest.java:757)
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareFileInfo(OMKeyRequest.java:646)
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:623)
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyCreateRequest.validateAndUpdateCache(OMKeyCreateRequest.java:267)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-04-08 11:57:56,912 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-5575003451 of layout LEGACY in volume: s3v
om3_1        | 2022-04-08 11:57:57,518 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: destbucket-38461 of layout LEGACY in volume: s3v
om3_1        | 2022-04-08 11:58:17,606 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-5420801628 of layout LEGACY in volume: s3v
om3_1        | 2022-04-08 12:04:37,478 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-0487653167 of layout LEGACY in volume: s3v
om3_1        | 2022-04-08 12:04:41,724 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:s3v, Bucket:bucket-ozone-test-0487653167, Key:ozone-test-2108438619/multidelete/key=value/f4.
om3_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:146)
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:92)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-04-08 12:04:51,510 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-2100108116 of layout LEGACY in volume: s3v
om3_1        | 2022-04-08 12:05:15,576 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-8208772603 of layout LEGACY in volume: s3v
om1_1        | 2022-04-08 11:55:12,274 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:12,847 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:12,850 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:12,856 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:15,550 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:16,158 [IPC Server handler 46 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:16,160 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:16,164 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:16,168 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:19,407 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42706
om1_1        | 2022-04-08 11:55:19,417 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:55:22,581 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:22,589 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:22,601 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-0372689255 of layout LEGACY in volume: s3v
om1_1        | 2022-04-08 11:55:23,130 [IPC Server handler 46 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:23,137 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:23,146 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ozone-test-ntnaskidoy of layout LEGACY in volume: s3v
om1_1        | 2022-04-08 11:55:23,179 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:23,184 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:23,189 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:25,839 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:25,889 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:25,893 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:25,896 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:28,494 [IPC Server handler 98 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:28,546 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:28,549 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:28,551 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:28,686 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:28,732 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:28,735 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:28,744 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:28,899 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:28,913 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:28,928 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:28,986 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:29,004 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:29,005 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:29,023 [IPC Server handler 46 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:29,081 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:30,181 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:32,308 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:32,373 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:32,377 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:32,390 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:32,494 [IPC Server handler 97 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:32,499 [IPC Server handler 89 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:32,505 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:32,558 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:32,561 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:32,565 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:32,592 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:32,694 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:32,708 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:32,714 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:32,786 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:33,669 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:40745
om1_1        | 2022-04-08 11:55:33,672 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:55:35,908 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:35,916 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:35,952 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:35,957 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:35,960 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:35,997 [IPC Server handler 46 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:36,003 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:36,014 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-phfmxspesy of layout LEGACY in volume: s3v
datanode3_1  | 2022-04-08 11:49:47,587 [grpc-default-executor-0] INFO server.RaftServer$Division: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A: changes role from  FOLLOWER to FOLLOWER at term 7 for candidate:8b7f16e2-5fb9-442f-a717-cc893c5795e0
datanode3_1  | 2022-04-08 11:49:47,587 [grpc-default-executor-0] INFO impl.RoleInfo: 4cf3df89-7b36-4576-a18a-5d0c57ddb620: shutdown 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-FollowerState
datanode3_1  | 2022-04-08 11:49:47,587 [grpc-default-executor-0] INFO impl.RoleInfo: 4cf3df89-7b36-4576-a18a-5d0c57ddb620: start 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-FollowerState
datanode3_1  | 2022-04-08 11:49:47,588 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-FollowerState] INFO impl.FollowerState: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-FollowerState was interrupted: {}
datanode3_1  | java.lang.InterruptedException: sleep interrupted
datanode3_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode3_1  | 	at java.base/java.lang.Thread.sleep(Thread.java:334)
datanode3_1  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode3_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
datanode3_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode3_1  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
datanode3_1  | 2022-04-08 11:49:47,603 [grpc-default-executor-0] INFO server.RaftServer$Division: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A replies to ELECTION vote request: 8b7f16e2-5fb9-442f-a717-cc893c5795e0<-4cf3df89-7b36-4576-a18a-5d0c57ddb620#0:OK-t7. Peer's state: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A:t7, leader=null, voted=8b7f16e2-5fb9-442f-a717-cc893c5795e0, raftlog=4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-SegmentedRaftLog:OPENED:c-1, conf=-1: [0005597f-3053-4b02-96b8-efe2de95313b|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, 8b7f16e2-5fb9-442f-a717-cc893c5795e0|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1, 4cf3df89-7b36-4576-a18a-5d0c57ddb620|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0], old=null
datanode3_1  | 2022-04-08 11:49:47,947 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-BC074898D12A with new leaderId: 8b7f16e2-5fb9-442f-a717-cc893c5795e0
datanode3_1  | 2022-04-08 11:49:47,950 [grpc-default-executor-0] INFO server.RaftServer$Division: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A: change Leader from null to 8b7f16e2-5fb9-442f-a717-cc893c5795e0 at term 7 for appendEntries, leader elected after 36370ms
datanode3_1  | 2022-04-08 11:49:48,039 [grpc-default-executor-0] INFO server.RaftServer$Division: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A: set configuration 0: [0005597f-3053-4b02-96b8-efe2de95313b|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 8b7f16e2-5fb9-442f-a717-cc893c5795e0|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, 4cf3df89-7b36-4576-a18a-5d0c57ddb620|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-04-08 11:49:48,042 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-SegmentedRaftLogWorker: Starting segment from index:0
datanode3_1  | 2022-04-08 11:49:48,058 [4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-BC074898D12A-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/d7bff567-93ff-485c-a104-bc074898d12a/current/log_inprogress_0
datanode3_1  | 2022-04-08 11:49:50,088 [ChunkWriter-1-0] INFO client.DNCertificateClient: Getting certificate with certSerialId:941464992973.
datanode3_1  | 2022-04-08 11:50:12,825 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4,entriesCount=1,lastEntry=(t:1, i:0)
datanode3_1  | 2022-04-08 11:50:50,025 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=264,entriesCount=1,lastEntry=(t:1, i:1)
datanode3_1  | 2022-04-08 11:50:50,046 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=265,entriesCount=1,lastEntry=(t:1, i:2)
datanode3_1  | 2022-04-08 11:50:51,231 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=266,entriesCount=1,lastEntry=(t:1, i:3)
datanode3_1  | 2022-04-08 11:50:51,254 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=270,entriesCount=1,lastEntry=(t:1, i:4)
datanode3_1  | 2022-04-08 11:51:11,387 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=519,entriesCount=1,lastEntry=(t:1, i:5)
datanode3_1  | 2022-04-08 11:51:11,404 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=520,entriesCount=1,lastEntry=(t:1, i:6)
datanode3_1  | 2022-04-08 11:51:11,427 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=525,entriesCount=1,lastEntry=(t:1, i:7)
datanode3_1  | 2022-04-08 11:51:11,443 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=528,entriesCount=1,lastEntry=(t:1, i:8)
datanode3_1  | 2022-04-08 11:52:00,854 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=794,entriesCount=1,lastEntry=(t:1, i:9)
datanode3_1  | 2022-04-08 11:52:00,869 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=795,entriesCount=1,lastEntry=(t:1, i:10)
datanode3_1  | 2022-04-08 11:52:00,884 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=796,entriesCount=1,lastEntry=(t:1, i:11)
datanode3_1  | 2022-04-08 11:52:00,901 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=798,entriesCount=1,lastEntry=(t:1, i:12)
datanode3_1  | 2022-04-08 11:52:59,787 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1069,entriesCount=1,lastEntry=(t:1, i:13)
datanode3_1  | 2022-04-08 11:52:59,802 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1070,entriesCount=1,lastEntry=(t:1, i:14)
datanode3_1  | 2022-04-08 11:52:59,819 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1074,entriesCount=1,lastEntry=(t:1, i:15)
datanode3_1  | 2022-04-08 11:52:59,835 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1077,entriesCount=1,lastEntry=(t:1, i:16)
datanode3_1  | 2022-04-08 11:53:14,968 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1332,entriesCount=1,lastEntry=(t:1, i:17)
datanode3_1  | 2022-04-08 11:53:14,981 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1333,entriesCount=1,lastEntry=(t:1, i:18)
datanode3_1  | 2022-04-08 11:53:14,998 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1335,entriesCount=1,lastEntry=(t:1, i:19)
datanode3_1  | 2022-04-08 11:53:15,027 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1337,entriesCount=1,lastEntry=(t:1, i:20)
datanode3_1  | 2022-04-08 11:56:12,951 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1656,entriesCount=1,lastEntry=(t:1, i:21)
datanode3_1  | 2022-04-08 11:56:12,963 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1657,entriesCount=1,lastEntry=(t:1, i:22)
datanode3_1  | 2022-04-08 11:56:12,976 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1658,entriesCount=1,lastEntry=(t:1, i:23)
datanode3_1  | 2022-04-08 11:56:12,997 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1660,entriesCount=1,lastEntry=(t:1, i:24)
datanode3_1  | 2022-04-08 11:56:23,301 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1914,entriesCount=1,lastEntry=(t:1, i:25)
datanode3_1  | 2022-04-08 11:56:23,308 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1915,entriesCount=1,lastEntry=(t:1, i:26)
datanode3_1  | 2022-04-08 11:56:23,321 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1916,entriesCount=1,lastEntry=(t:1, i:27)
datanode3_1  | 2022-04-08 11:56:23,328 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1917,entriesCount=1,lastEntry=(t:1, i:28)
datanode3_1  | 2022-04-08 11:56:25,939 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2168,entriesCount=1,lastEntry=(t:1, i:29)
datanode3_1  | 2022-04-08 11:56:25,949 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2169,entriesCount=1,lastEntry=(t:1, i:30)
datanode3_1  | 2022-04-08 11:56:25,953 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2170,entriesCount=1,lastEntry=(t:1, i:31)
datanode3_1  | 2022-04-08 11:56:25,982 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2172,entriesCount=1,lastEntry=(t:1, i:32)
datanode3_1  | 2022-04-08 11:56:29,546 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2422,entriesCount=1,lastEntry=(t:1, i:33)
datanode3_1  | 2022-04-08 11:56:29,592 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2423,entriesCount=1,lastEntry=(t:1, i:34)
datanode3_1  | 2022-04-08 11:56:29,797 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2424,entriesCount=1,lastEntry=(t:1, i:35)
datanode3_1  | 2022-04-08 11:56:29,799 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2425,entriesCount=1,lastEntry=(t:1, i:36)
datanode3_1  | 2022-04-08 11:56:32,719 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2669,entriesCount=1,lastEntry=(t:1, i:37)
datanode3_1  | 2022-04-08 11:56:32,778 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2670,entriesCount=1,lastEntry=(t:1, i:38)
datanode3_1  | 2022-04-08 11:56:32,844 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2671,entriesCount=1,lastEntry=(t:1, i:39)
datanode3_1  | 2022-04-08 11:56:32,857 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2672,entriesCount=1,lastEntry=(t:1, i:40)
datanode3_1  | 2022-04-08 11:56:33,026 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2687,entriesCount=1,lastEntry=(t:1, i:41)
datanode3_1  | 2022-04-08 11:56:33,146 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2694,entriesCount=1,lastEntry=(t:1, i:42)
datanode3_1  | 2022-04-08 11:56:33,156 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2695,entriesCount=1,lastEntry=(t:1, i:43)
datanode3_1  | 2022-04-08 11:56:33,302 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2708,entriesCount=1,lastEntry=(t:1, i:44)
datanode3_1  | 2022-04-08 11:56:33,383 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2716,entriesCount=1,lastEntry=(t:1, i:45)
datanode3_1  | 2022-04-08 11:56:33,398 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2717,entriesCount=1,lastEntry=(t:1, i:46)
datanode3_1  | 2022-04-08 11:56:36,192 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2970,entriesCount=1,lastEntry=(t:1, i:47)
datanode3_1  | 2022-04-08 11:56:36,202 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2971,entriesCount=1,lastEntry=(t:1, i:48)
datanode3_1  | 2022-04-08 11:56:36,219 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2972,entriesCount=1,lastEntry=(t:1, i:49)
datanode3_1  | 2022-04-08 11:56:36,230 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2975,entriesCount=1,lastEntry=(t:1, i:50)
datanode3_1  | 2022-04-08 11:57:24,898 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3234,entriesCount=1,lastEntry=(t:1, i:51)
datanode3_1  | 2022-04-08 11:57:24,905 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3235,entriesCount=1,lastEntry=(t:1, i:52)
datanode3_1  | 2022-04-08 11:57:24,975 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3236,entriesCount=1,lastEntry=(t:1, i:53)
datanode3_1  | 2022-04-08 11:57:24,991 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3238,entriesCount=1,lastEntry=(t:1, i:54)
datanode3_1  | 2022-04-08 11:57:40,904 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3494,entriesCount=1,lastEntry=(t:1, i:55)
datanode3_1  | 2022-04-08 11:57:40,918 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3495,entriesCount=1,lastEntry=(t:1, i:56)
scm1.org_1   | Sleeping for 5 seconds
scm1.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm1.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm1.org_1   | 2022-04-08 11:46:55,524 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm1.org_1   | /************************************************************
scm1.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm1.org_1   | STARTUP_MSG:   host = scm1.org/172.25.0.116
scm1.org_1   | STARTUP_MSG:   args = [--init]
scm1.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
scm1.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.0.4.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm1.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/805b5e1d3b8eaf7ab8aef1c57e2bb17b73dea398 ; compiled by 'runner' on 2022-04-08T11:25Z
scm1.org_1   | STARTUP_MSG:   java = 11.0.14.1
scm1.org_1   | ************************************************************/
scm1.org_1   | 2022-04-08 11:46:55,548 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm1.org_1   | 2022-04-08 11:46:55,764 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2022-04-08 11:46:55,870 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm1.org_1   | 2022-04-08 11:46:55,870 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm1.org_1   | 2022-04-08 11:46:56,068 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm1, RPC Address: scm1.org:9894 and Ratis port: 9894
scm1.org_1   | 2022-04-08 11:46:56,072 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm1: scm1.org
scm1.org_1   | 2022-04-08 11:46:56,082 [main] INFO ha.HASecurityUtils: Initializing secure StorageContainerManager.
scm1.org_1   | 2022-04-08 11:46:58,148 [main] ERROR client.SCMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
scm1.org_1   | 2022-04-08 11:46:58,148 [main] INFO client.SCMCertificateClient: Certificate client init case: 0
scm1.org_1   | 2022-04-08 11:46:58,163 [main] INFO client.SCMCertificateClient: Creating keypair for client as keypair and certificate not found.
scm1.org_1   | 2022-04-08 11:47:01,118 [main] INFO ha.HASecurityUtils: Init response: GETCERT
scm1.org_1   | 2022-04-08 11:47:02,912 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.116,host:scm1.org
scm1.org_1   | 2022-04-08 11:47:02,912 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm1.org_1   | 2022-04-08 11:47:03,122 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.116,host:scm1.org
scm1.org_1   | 2022-04-08 11:47:03,122 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm1.org_1   | 2022-04-08 11:47:03,123 [main] INFO ha.HASecurityUtils: Creating csr for SCM->hostName:scm1.org,scmId:088c2e91-0545-411d-8d31-8415832ed844,clusterId:CID-236d968d-b3de-4c14-8c61-a2ea220fd69f,subject:scm-sub@scm1.org
scm1.org_1   | 2022-04-08 11:47:03,254 [main] INFO ha.HASecurityUtils: Successfully stored SCM signed certificate.
scm1.org_1   | 2022-04-08 11:47:03,405 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
scm1.org_1   | 2022-04-08 11:47:03,520 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
scm1.org_1   | 2022-04-08 11:47:03,521 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2022-04-08 11:47:03,521 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
scm1.org_1   | 2022-04-08 11:47:03,521 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2022-04-08 11:47:03,521 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2022-04-08 11:47:03,522 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
scm1.org_1   | 2022-04-08 11:47:03,532 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2022-04-08 11:47:03,532 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm1.org_1   | 2022-04-08 11:47:03,533 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm1.org_1   | 2022-04-08 11:47:03,864 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
scm1.org_1   | 2022-04-08 11:47:03,866 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm1.org_1   | 2022-04-08 11:47:03,866 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm1.org_1   | 2022-04-08 11:47:03,890 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm1.org_1   | 2022-04-08 11:47:03,908 [main] INFO server.RaftServer: 088c2e91-0545-411d-8d31-8415832ed844: addNew group-A2EA220FD69F:[088c2e91-0545-411d-8d31-8415832ed844|rpc:scm1.org:9894|priority:0] returns group-A2EA220FD69F:java.util.concurrent.CompletableFuture@2d4608a6[Not completed]
scm1.org_1   | 2022-04-08 11:47:03,951 [pool-2-thread-1] INFO server.RaftServer$Division: 088c2e91-0545-411d-8d31-8415832ed844: new RaftServerImpl for group-A2EA220FD69F:[088c2e91-0545-411d-8d31-8415832ed844|rpc:scm1.org:9894|priority:0] with SCMStateMachine:uninitialized
scm1.org_1   | 2022-04-08 11:47:03,954 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm1.org_1   | 2022-04-08 11:47:03,954 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm1.org_1   | 2022-04-08 11:47:03,954 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm1.org_1   | 2022-04-08 11:47:03,954 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm1.org_1   | 2022-04-08 11:47:03,954 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm1.org_1   | 2022-04-08 11:47:03,954 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
scm1.org_1   | 2022-04-08 11:47:03,955 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm1.org_1   | 2022-04-08 11:47:03,959 [pool-2-thread-1] INFO server.RaftServer$Division: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F: ConfigurationManager, init=-1: [088c2e91-0545-411d-8d31-8415832ed844|rpc:scm1.org:9894|priority:0], old=null, confs=<EMPTY_MAP>
scm1.org_1   | 2022-04-08 11:47:03,960 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm1.org_1   | 2022-04-08 11:47:03,979 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm1.org_1   | 2022-04-08 11:47:03,980 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
scm1.org_1   | 2022-04-08 11:47:03,981 [pool-2-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/236d968d-b3de-4c14-8c61-a2ea220fd69f does not exist. Creating ...
scm1.org_1   | 2022-04-08 11:47:04,004 [pool-2-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/236d968d-b3de-4c14-8c61-a2ea220fd69f/in_use.lock acquired by nodename 90@scm1.org
scm1.org_1   | 2022-04-08 11:47:04,022 [pool-2-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/236d968d-b3de-4c14-8c61-a2ea220fd69f has been successfully formatted.
om1_1        | 2022-04-08 11:55:36,039 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:36,045 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:36,053 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:36,080 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:36,084 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:36,094 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:36,110 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:36,148 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:36,151 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:36,154 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:38,745 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:38,783 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:38,785 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:38,790 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:38,805 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:38,808 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:38,810 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:38,824 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:38,827 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:38,833 [IPC Server handler 46 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:38,869 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:39,047 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:39,049 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:39,055 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:39,081 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:39,132 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:39,135 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:39,138 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:39,160 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:39,164 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm2.org_1   | Sleeping for 5 seconds
scm2.org_1   | Waiting for the service scm1.org:9894
scm2.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm2.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm2.org_1   | 2022-04-08 11:47:06,521 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm2.org_1   | /************************************************************
scm2.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm2.org_1   | STARTUP_MSG:   host = scm2.org/172.25.0.117
scm2.org_1   | STARTUP_MSG:   args = [--bootstrap]
scm2.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
recon_1      | 2022-04-08 11:49:10,634 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: a6f33c92-47f3-4bcf-8c55-0543fc7274b5, Nodes: 8b7f16e2-5fb9-442f-a717-cc893c5795e0{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}0005597f-3053-4b02-96b8-efe2de95313b{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}4cf3df89-7b36-4576-a18a-5d0c57ddb620{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:4cf3df89-7b36-4576-a18a-5d0c57ddb620, CreationTimestamp2022-04-08T11:48:59.048Z[UTC]] moved to OPEN state
recon_1      | 2022-04-08 11:49:11,587 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=d7bff567-93ff-485c-a104-bc074898d12a. Trying to get from SCM.
recon_1      | 2022-04-08 11:49:11,612 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: d7bff567-93ff-485c-a104-bc074898d12a, Nodes: 0005597f-3053-4b02-96b8-efe2de95313b{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}4cf3df89-7b36-4576-a18a-5d0c57ddb620{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}8b7f16e2-5fb9-442f-a717-cc893c5795e0{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-04-08T11:48:59.171Z[UTC]] to Recon pipeline metadata.
recon_1      | 2022-04-08 11:49:11,613 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: d7bff567-93ff-485c-a104-bc074898d12a, Nodes: 0005597f-3053-4b02-96b8-efe2de95313b{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}4cf3df89-7b36-4576-a18a-5d0c57ddb620{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}8b7f16e2-5fb9-442f-a717-cc893c5795e0{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-04-08T11:48:59.171Z[UTC]].
recon_1      | 2022-04-08 11:49:11,614 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=d7bff567-93ff-485c-a104-bc074898d12a reported by 4cf3df89-7b36-4576-a18a-5d0c57ddb620{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 936508841118, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-04-08 11:49:12,121 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=d7bff567-93ff-485c-a104-bc074898d12a reported by 0005597f-3053-4b02-96b8-efe2de95313b{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 933750048452, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-04-08 11:49:12,558 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=d7bff567-93ff-485c-a104-bc074898d12a reported by 8b7f16e2-5fb9-442f-a717-cc893c5795e0{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 932981906868, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-04-08 11:49:12,626 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 105 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:49:12,628 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 106 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:49:12,628 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 107 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-08 11:49:14,630 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 108 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:49:14,631 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 109 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:49:14,632 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 110 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-08 11:49:16,633 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 111 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:49:16,634 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 112 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:49:20,494 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om3 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:226)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:213)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:206)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:165)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:137)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 113 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-08 11:49:25,818 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om1 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:226)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:213)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:206)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:165)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:137)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 114 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:49:26,417 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:226)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:213)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:206)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:165)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:137)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 115 failover attempts. Trying to failover immediately.
scm2.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.0.4.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm2.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/805b5e1d3b8eaf7ab8aef1c57e2bb17b73dea398 ; compiled by 'runner' on 2022-04-08T11:25Z
scm2.org_1   | STARTUP_MSG:   java = 11.0.14.1
scm2.org_1   | ************************************************************/
scm2.org_1   | 2022-04-08 11:47:06,539 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm2.org_1   | 2022-04-08 11:47:06,644 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm2.org_1   | 2022-04-08 11:47:06,644 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm2.org_1   | 2022-04-08 11:47:06,680 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm2, RPC Address: scm2.org:9894 and Ratis port: 9894
scm2.org_1   | 2022-04-08 11:47:06,687 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm2: scm2.org
scm2.org_1   | 2022-04-08 11:47:06,692 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2022-04-08 11:47:06,830 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm2.org_1   | 2022-04-08 11:47:06,830 [main] INFO server.StorageContainerManager: SCM login successful.
scm2.org_1   | 2022-04-08 11:47:09,003 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm2.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863 after 1 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-04-08 11:47:11,005 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-04-08 11:47:13,007 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm1.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863 after 3 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-04-08 11:47:15,009 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm2.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863 after 4 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-04-08 11:47:17,017 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-04-08 11:47:19,238 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:088c2e91-0545-411d-8d31-8415832ed844 is not the leader. Could not determine the leader node.
scm2.org_1   | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
scm2.org_1   | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
scm2.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:108)
scm2.org_1   | 	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13937)
scm2.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
scm2.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
scm2.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
scm2.org_1   | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
scm2.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
scm2.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
scm2.org_1   | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm2.org_1   | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm2.org_1   | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
scm2.org_1   | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
scm2.org_1   | , while invoking $Proxy15.send over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863 after 6 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-04-08 11:47:21,239 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm2.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863 after 7 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-04-08 11:47:23,241 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 8 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-04-08 11:47:25,334 [main] INFO ha.HASecurityUtils: Initializing secure StorageContainerManager.
scm2.org_1   | 2022-04-08 11:47:25,845 [main] ERROR client.SCMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode3_1  | 2022-04-08 11:57:40,925 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3496,entriesCount=1,lastEntry=(t:1, i:57)
datanode3_1  | 2022-04-08 11:57:40,944 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3500,entriesCount=1,lastEntry=(t:1, i:58)
datanode3_1  | 2022-04-08 11:57:47,678 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3752,entriesCount=1,lastEntry=(t:1, i:59)
datanode3_1  | 2022-04-08 11:57:47,710 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3753,entriesCount=1,lastEntry=(t:1, i:60)
datanode3_1  | 2022-04-08 11:57:47,718 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3754,entriesCount=1,lastEntry=(t:1, i:61)
datanode3_1  | 2022-04-08 11:57:47,802 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3755,entriesCount=1,lastEntry=(t:1, i:62)
datanode3_1  | 2022-04-08 11:57:47,812 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3756,entriesCount=1,lastEntry=(t:1, i:63)
datanode3_1  | 2022-04-08 11:57:47,821 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3757,entriesCount=1,lastEntry=(t:1, i:64)
datanode3_1  | 2022-04-08 11:57:59,667 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4013,entriesCount=1,lastEntry=(t:1, i:65)
datanode3_1  | 2022-04-08 11:57:59,684 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4014,entriesCount=1,lastEntry=(t:1, i:66)
datanode3_1  | 2022-04-08 11:57:59,719 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4015,entriesCount=1,lastEntry=(t:1, i:67)
datanode3_1  | 2022-04-08 11:57:59,785 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4016,entriesCount=1,lastEntry=(t:1, i:68)
datanode3_1  | 2022-04-08 11:57:59,795 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4017,entriesCount=1,lastEntry=(t:1, i:69)
datanode3_1  | 2022-04-08 11:57:59,841 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4019,entriesCount=1,lastEntry=(t:1, i:70)
datanode3_1  | 2022-04-08 11:58:03,124 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4271,entriesCount=1,lastEntry=(t:1, i:71)
datanode3_1  | 2022-04-08 11:58:03,129 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4272,entriesCount=1,lastEntry=(t:1, i:72)
datanode3_1  | 2022-04-08 11:58:03,144 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4273,entriesCount=1,lastEntry=(t:1, i:73)
datanode3_1  | 2022-04-08 11:58:03,166 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4275,entriesCount=1,lastEntry=(t:1, i:74)
datanode3_1  | 2022-04-08 11:58:09,681 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4526,entriesCount=1,lastEntry=(t:1, i:75)
datanode3_1  | 2022-04-08 11:58:09,897 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4527,entriesCount=1,lastEntry=(t:1, i:76)
datanode3_1  | 2022-04-08 11:58:09,940 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4528,entriesCount=1,lastEntry=(t:1, i:77)
datanode3_1  | 2022-04-08 11:58:09,965 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4529,entriesCount=1,lastEntry=(t:1, i:78)
datanode3_1  | 2022-04-08 11:58:10,125 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4538,entriesCount=1,lastEntry=(t:1, i:79)
s3g_1        | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
s3g_1        | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:127)
s3g_1        | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:69)
s3g_1        | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:103)
s3g_1        | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:46)
s3g_1        | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:53)
s3g_1        | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:129)
s3g_1        | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:463)
s3g_1        | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:46)
s3g_1        | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2102)
s3g_1        | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:758)
s3g_1        | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:721)
s3g_1        | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:691)
s3g_1        | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:160)
s3g_1        | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:30)
s3g_1        | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:105)
s3g_1        | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:260)
s3g_1        | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:51)
s3g_1        | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:86)
s3g_1        | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:89)
s3g_1        | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:89)
s3g_1        | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:89)
s3g_1        | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:69)
s3g_1        | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:38)
s3g_1        | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:173)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:247)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1679)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
datanode3_1  | 2022-04-08 11:58:10,244 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4549,entriesCount=1,lastEntry=(t:1, i:80)
datanode3_1  | 2022-04-08 11:58:10,305 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4550,entriesCount=1,lastEntry=(t:1, i:81)
datanode3_1  | 2022-04-08 11:58:10,321 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4552,entriesCount=1,lastEntry=(t:1, i:82)
datanode3_1  | 2022-04-08 11:58:10,664 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4566,entriesCount=1,lastEntry=(t:1, i:83)
datanode3_1  | 2022-04-08 11:58:10,949 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4593,entriesCount=1,lastEntry=(t:1, i:84)
datanode3_1  | 2022-04-08 11:58:10,974 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4595,entriesCount=1,lastEntry=(t:1, i:85)
datanode3_1  | 2022-04-08 11:58:16,661 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4851,entriesCount=1,lastEntry=(t:1, i:86)
datanode3_1  | 2022-04-08 11:58:16,717 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4852,entriesCount=1,lastEntry=(t:1, i:87)
datanode3_1  | 2022-04-08 11:58:16,784 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4853,entriesCount=1,lastEntry=(t:1, i:88)
datanode3_1  | 2022-04-08 11:58:16,860 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4854,entriesCount=1,lastEntry=(t:1, i:89)
datanode3_1  | 2022-04-08 11:58:16,863 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4855,entriesCount=1,lastEntry=(t:1, i:90)
datanode3_1  | 2022-04-08 11:58:16,872 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4856,entriesCount=1,lastEntry=(t:1, i:91)
datanode3_1  | 2022-04-08 11:58:20,856 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5110,entriesCount=1,lastEntry=(t:1, i:92)
datanode3_1  | 2022-04-08 11:58:20,937 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5111,entriesCount=1,lastEntry=(t:1, i:93)
datanode3_1  | 2022-04-08 11:58:20,948 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5112,entriesCount=1,lastEntry=(t:1, i:94)
datanode3_1  | 2022-04-08 11:58:20,971 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5114,entriesCount=1,lastEntry=(t:1, i:95)
datanode3_1  | 2022-04-08 11:58:20,985 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5117,entriesCount=1,lastEntry=(t:1, i:96)
datanode3_1  | 2022-04-08 11:58:20,996 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5118,entriesCount=1,lastEntry=(t:1, i:97)
datanode3_1  | 2022-04-08 11:58:25,966 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5369,entriesCount=1,lastEntry=(t:1, i:98)
datanode3_1  | 2022-04-08 11:58:26,153 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5370,entriesCount=1,lastEntry=(t:1, i:99)
datanode3_1  | 2022-04-08 11:58:26,222 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5371,entriesCount=1,lastEntry=(t:1, i:100)
datanode3_1  | 2022-04-08 11:58:26,257 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5374,entriesCount=1,lastEntry=(t:1, i:101)
datanode3_1  | 2022-04-08 11:58:26,264 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5375,entriesCount=1,lastEntry=(t:1, i:102)
scm3.org_1   | Sleeping for 5 seconds
scm3.org_1   | Waiting for the service scm2.org:9894
scm3.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm3.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm3.org_1   | 2022-04-08 11:47:47,005 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm3.org_1   | /************************************************************
scm3.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm3.org_1   | STARTUP_MSG:   host = scm3.org/172.25.0.118
scm3.org_1   | STARTUP_MSG:   args = [--bootstrap]
scm3.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
scm3.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.0.4.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm3.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/805b5e1d3b8eaf7ab8aef1c57e2bb17b73dea398 ; compiled by 'runner' on 2022-04-08T11:25Z
scm3.org_1   | STARTUP_MSG:   java = 11.0.14.1
scm3.org_1   | ************************************************************/
scm3.org_1   | 2022-04-08 11:47:47,064 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm3.org_1   | 2022-04-08 11:47:47,337 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm3.org_1   | 2022-04-08 11:47:47,341 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm3.org_1   | 2022-04-08 11:47:47,515 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm3, RPC Address: scm3.org:9894 and Ratis port: 9894
scm3.org_1   | 2022-04-08 11:47:47,515 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm3: scm3.org
scm3.org_1   | 2022-04-08 11:47:47,534 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm3.org_1   | 2022-04-08 11:47:47,946 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm3.org_1   | 2022-04-08 11:47:47,946 [main] INFO server.StorageContainerManager: SCM login successful.
scm3.org_1   | 2022-04-08 11:47:48,901 [main] INFO ha.HASecurityUtils: Initializing secure StorageContainerManager.
scm3.org_1   | 2022-04-08 11:47:49,657 [main] ERROR client.SCMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
scm3.org_1   | 2022-04-08 11:47:49,657 [main] INFO client.SCMCertificateClient: Certificate client init case: 0
scm3.org_1   | 2022-04-08 11:47:49,659 [main] INFO client.SCMCertificateClient: Creating keypair for client as keypair and certificate not found.
scm3.org_1   | 2022-04-08 11:47:50,523 [main] INFO ha.HASecurityUtils: Init response: GETCERT
scm3.org_1   | 2022-04-08 11:47:50,597 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.118,host:scm3.org
scm3.org_1   | 2022-04-08 11:47:50,597 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm3.org_1   | 2022-04-08 11:47:50,606 [main] INFO ha.HASecurityUtils: Creating csr for SCM->hostName:scm3.org,scmId:9ebec731-0724-46e8-adb1-25fbc2c43c85,clusterId:CID-236d968d-b3de-4c14-8c61-a2ea220fd69f,subject:scm-sub@scm3.org
scm3.org_1   | 2022-04-08 11:47:51,432 [main] INFO ha.HASecurityUtils: Successfully stored SCM signed certificate.
scm3.org_1   | 2022-04-08 11:47:51,475 [main] INFO server.StorageContainerManager: SCM BootStrap  is successful for ClusterID CID-236d968d-b3de-4c14-8c61-a2ea220fd69f, SCMID 9ebec731-0724-46e8-adb1-25fbc2c43c85
scm3.org_1   | 2022-04-08 11:47:51,475 [main] INFO server.StorageContainerManager: Primary SCM Node ID 088c2e91-0545-411d-8d31-8415832ed844
scm3.org_1   | 2022-04-08 11:47:51,531 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm3.org_1   | /************************************************************
scm3.org_1   | SHUTDOWN_MSG: Shutting down StorageContainerManager at scm3.org/172.25.0.118
scm3.org_1   | ************************************************************/
scm3.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm3.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm3.org_1   | 2022-04-08 11:47:53,664 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm3.org_1   | /************************************************************
scm3.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm3.org_1   | STARTUP_MSG:   host = scm3.org/172.25.0.118
scm3.org_1   | STARTUP_MSG:   args = []
scm3.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
datanode3_1  | 2022-04-08 11:58:26,274 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5376,entriesCount=1,lastEntry=(t:1, i:103)
datanode3_1  | 2022-04-08 11:58:26,307 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5380,entriesCount=1,lastEntry=(t:1, i:104)
datanode3_1  | 2022-04-08 11:58:31,623 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5632,entriesCount=1,lastEntry=(t:1, i:105)
datanode3_1  | 2022-04-08 11:58:31,626 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5633,entriesCount=1,lastEntry=(t:1, i:106)
datanode3_1  | 2022-04-08 11:58:31,634 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5634,entriesCount=1,lastEntry=(t:1, i:107)
datanode3_1  | 2022-04-08 11:58:31,641 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5635,entriesCount=1,lastEntry=(t:1, i:108)
datanode3_1  | 2022-04-08 11:58:44,389 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5891,entriesCount=1,lastEntry=(t:1, i:109)
datanode3_1  | 2022-04-08 11:58:44,492 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5892,entriesCount=1,lastEntry=(t:1, i:110)
datanode3_1  | 2022-04-08 11:58:44,522 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5893,entriesCount=1,lastEntry=(t:1, i:111)
datanode3_1  | 2022-04-08 11:58:44,533 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5894,entriesCount=1,lastEntry=(t:1, i:112)
datanode3_1  | 2022-04-08 11:58:44,576 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5895,entriesCount=1,lastEntry=(t:1, i:113)
datanode3_1  | 2022-04-08 11:58:44,701 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5906,entriesCount=1,lastEntry=(t:1, i:114)
datanode3_1  | 2022-04-08 11:58:58,166 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=6163,entriesCount=1,lastEntry=(t:1, i:115)
datanode3_1  | 2022-04-08 11:58:58,175 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=6164,entriesCount=1,lastEntry=(t:1, i:116)
datanode3_1  | 2022-04-08 11:58:58,176 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=6165,entriesCount=1,lastEntry=(t:1, i:117)
datanode3_1  | 2022-04-08 11:58:58,183 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=6166,entriesCount=1,lastEntry=(t:1, i:118)
datanode3_1  | 2022-04-08 11:59:02,041 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=6416,entriesCount=1,lastEntry=(t:1, i:119)
datanode3_1  | 2022-04-08 11:59:02,043 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=6417,entriesCount=1,lastEntry=(t:1, i:120)
datanode3_1  | 2022-04-08 11:59:02,048 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=6418,entriesCount=1,lastEntry=(t:1, i:121)
datanode3_1  | 2022-04-08 11:59:02,053 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=6419,entriesCount=1,lastEntry=(t:1, i:122)
datanode3_1  | 2022-04-08 11:59:05,845 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=6671,entriesCount=1,lastEntry=(t:1, i:123)
datanode3_1  | 2022-04-08 11:59:05,846 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=6672,entriesCount=1,lastEntry=(t:1, i:124)
scm1.org_1   | 2022-04-08 11:47:04,026 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm1.org_1   | 2022-04-08 11:47:04,029 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm1.org_1   | 2022-04-08 11:47:04,048 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm1.org_1   | 2022-04-08 11:47:04,048 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2022-04-08 11:47:04,074 [pool-2-thread-1] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm1.org_1   | 2022-04-08 11:47:04,248 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm1.org_1   | 2022-04-08 11:47:04,261 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm1.org_1   | 2022-04-08 11:47:04,262 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
scm1.org_1   | 2022-04-08 11:47:04,266 [pool-2-thread-1] INFO segmented.SegmentedRaftLogWorker: new 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/236d968d-b3de-4c14-8c61-a2ea220fd69f
scm1.org_1   | 2022-04-08 11:47:04,267 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
scm1.org_1   | 2022-04-08 11:47:04,268 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm1.org_1   | 2022-04-08 11:47:04,270 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm1.org_1   | 2022-04-08 11:47:04,272 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
scm1.org_1   | 2022-04-08 11:47:04,272 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm1.org_1   | 2022-04-08 11:47:04,276 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm1.org_1   | 2022-04-08 11:47:04,277 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm1.org_1   | 2022-04-08 11:47:04,277 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm1.org_1   | 2022-04-08 11:47:04,314 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
scm1.org_1   | 2022-04-08 11:47:04,314 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
scm1.org_1   | 2022-04-08 11:47:04,333 [pool-2-thread-1] INFO segmented.SegmentedRaftLogWorker: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm1.org_1   | 2022-04-08 11:47:04,333 [pool-2-thread-1] INFO segmented.SegmentedRaftLogWorker: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm1.org_1   | 2022-04-08 11:47:04,364 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm1.org_1   | 2022-04-08 11:47:04,373 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
scm1.org_1   | 2022-04-08 11:47:04,373 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
scm1.org_1   | 2022-04-08 11:47:04,374 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm1.org_1   | 2022-04-08 11:47:04,375 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
scm1.org_1   | 2022-04-08 11:47:04,375 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm1.org_1   | 2022-04-08 11:47:04,513 [main] INFO server.RaftServer$Division: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F: start as a follower, conf=-1: [088c2e91-0545-411d-8d31-8415832ed844|rpc:scm1.org:9894|priority:0], old=null
scm1.org_1   | 2022-04-08 11:47:04,514 [main] INFO server.RaftServer$Division: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F: changes role from      null to FOLLOWER at term 0 for startAsFollower
scm1.org_1   | 2022-04-08 11:47:04,515 [main] INFO impl.RoleInfo: 088c2e91-0545-411d-8d31-8415832ed844: start 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-FollowerState
scm1.org_1   | 2022-04-08 11:47:04,523 [main] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A2EA220FD69F,id=088c2e91-0545-411d-8d31-8415832ed844
scm1.org_1   | 2022-04-08 11:47:04,540 [main] INFO server.RaftServer: 088c2e91-0545-411d-8d31-8415832ed844: start RPC server
scm1.org_1   | 2022-04-08 11:47:04,644 [main] INFO server.GrpcService: 088c2e91-0545-411d-8d31-8415832ed844: GrpcService started, listening on 9894
scm1.org_1   | 2022-04-08 11:47:04,656 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$338/0x000000084031fc40@593a6726] INFO util.JvmPauseMonitor: JvmPauseMonitor-088c2e91-0545-411d-8d31-8415832ed844: Started
scm1.org_1   | 2022-04-08 11:47:09,600 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-FollowerState] INFO impl.FollowerState: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5084618236ns, electionTimeout:5079ms
scm1.org_1   | 2022-04-08 11:47:09,601 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-FollowerState] INFO impl.RoleInfo: 088c2e91-0545-411d-8d31-8415832ed844: shutdown 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-FollowerState
scm1.org_1   | 2022-04-08 11:47:09,602 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-FollowerState] INFO server.RaftServer$Division: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
scm1.org_1   | 2022-04-08 11:47:09,604 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
scm1.org_1   | 2022-04-08 11:47:09,607 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-FollowerState] INFO impl.RoleInfo: 088c2e91-0545-411d-8d31-8415832ed844: start 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-LeaderElection1
scm1.org_1   | 2022-04-08 11:47:09,612 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-LeaderElection1] INFO impl.LeaderElection: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [088c2e91-0545-411d-8d31-8415832ed844|rpc:scm1.org:9894|priority:0], old=null
scm1.org_1   | 2022-04-08 11:47:09,613 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-LeaderElection1] INFO impl.LeaderElection: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-LeaderElection1 ELECTION round 0: result PASSED (term=1)
scm1.org_1   | 2022-04-08 11:47:09,614 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-LeaderElection1] INFO impl.RoleInfo: 088c2e91-0545-411d-8d31-8415832ed844: shutdown 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-LeaderElection1
scm1.org_1   | 2022-04-08 11:47:09,614 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-LeaderElection1] INFO server.RaftServer$Division: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
scm3.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.0.4.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm3.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/805b5e1d3b8eaf7ab8aef1c57e2bb17b73dea398 ; compiled by 'runner' on 2022-04-08T11:25Z
scm3.org_1   | STARTUP_MSG:   java = 11.0.14.1
scm3.org_1   | ************************************************************/
scm3.org_1   | 2022-04-08 11:47:53,684 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm3.org_1   | 2022-04-08 11:47:53,855 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm3.org_1   | 2022-04-08 11:47:53,856 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm3.org_1   | 2022-04-08 11:47:53,967 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm3, RPC Address: scm3.org:9894 and Ratis port: 9894
scm3.org_1   | 2022-04-08 11:47:53,967 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm3: scm3.org
scm3.org_1   | 2022-04-08 11:47:54,027 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm3.org_1   | 2022-04-08 11:47:54,072 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = SCM_HA (version = 2), software layout = SCM_HA (version = 2)
scm3.org_1   | 2022-04-08 11:47:54,423 [main] INFO reflections.Reflections: Reflections took 146 ms to scan 3 urls, producing 105 keys and 220 values 
scm3.org_1   | 2022-04-08 11:47:55,266 [main] INFO client.SCMCertificateClient: Loading certificate from location:/data/metadata/scm/sub-ca/certs.
scm3.org_1   | 2022-04-08 11:47:55,420 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/896053593816.crt.
scm3.org_1   | 2022-04-08 11:47:55,429 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/CA-1.crt.
scm3.org_1   | 2022-04-08 11:47:55,434 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/certificate.crt.
scm3.org_1   | 2022-04-08 11:47:55,651 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm3.org_1   | 2022-04-08 11:47:55,651 [main] INFO server.StorageContainerManager: SCM login successful.
scm3.org_1   | 2022-04-08 11:47:55,771 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm3.org_1   | 2022-04-08 11:47:55,992 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
datanode3_1  | 2022-04-08 11:59:05,846 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=6673,entriesCount=1,lastEntry=(t:1, i:125)
datanode3_1  | 2022-04-08 11:59:05,854 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=6674,entriesCount=1,lastEntry=(t:1, i:126)
datanode3_1  | 2022-04-08 11:59:18,276 [java.util.concurrent.ThreadPoolExecutor$Worker@161caa6[State = -1, empty queue]] WARN server.GrpcLogAppender: 4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5->0005597f-3053-4b02-96b8-efe2de95313b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=6924,entriesCount=1,lastEntry=(t:1, i:127)
datanode3_1  | 2022-04-08 12:01:19,054 [Thread-674] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-B8E9661C5A08->4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5, cid=163, seq=0, Watch-ALL_COMMITTED(129), Message:<EMPTY>, reply=RaftClientReply:client-B8E9661C5A08->4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5, cid=163, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 163 and log index 129 is not yet replicated to ALL_COMMITTED, logIndex=129, commits[4cf3df89-7b36-4576-a18a-5d0c57ddb620:c138, 0005597f-3053-4b02-96b8-efe2de95313b:c127, 8b7f16e2-5fb9-442f-a717-cc893c5795e0:c138]
datanode3_1  | 2022-04-08 12:02:28,051 [Thread-715] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-D9FD5F0C75B5->4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5, cid=174, seq=0, Watch-ALL_COMMITTED(132), Message:<EMPTY>, reply=RaftClientReply:client-D9FD5F0C75B5->4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5, cid=174, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 174 and log index 132 is not yet replicated to ALL_COMMITTED, logIndex=132, commits[4cf3df89-7b36-4576-a18a-5d0c57ddb620:c142, 0005597f-3053-4b02-96b8-efe2de95313b:c127, 8b7f16e2-5fb9-442f-a717-cc893c5795e0:c142]
datanode3_1  | 2022-04-08 12:03:29,050 [Thread-752] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-7B40C1715F7C->4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5, cid=178, seq=0, Watch-ALL_COMMITTED(136), Message:<EMPTY>, reply=RaftClientReply:client-7B40C1715F7C->4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5, cid=178, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 178 and log index 136 is not yet replicated to ALL_COMMITTED, logIndex=136, commits[4cf3df89-7b36-4576-a18a-5d0c57ddb620:c146, 0005597f-3053-4b02-96b8-efe2de95313b:c127, 8b7f16e2-5fb9-442f-a717-cc893c5795e0:c146]
datanode3_1  | 2022-04-08 12:04:30,050 [Thread-790] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-3FE5CBBB1968->4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5, cid=183, seq=0, Watch-ALL_COMMITTED(141), Message:<EMPTY>, reply=RaftClientReply:client-3FE5CBBB1968->4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5, cid=183, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 183 and log index 141 is not yet replicated to ALL_COMMITTED, logIndex=141, commits[4cf3df89-7b36-4576-a18a-5d0c57ddb620:c150, 0005597f-3053-4b02-96b8-efe2de95313b:c127, 8b7f16e2-5fb9-442f-a717-cc893c5795e0:c150]
datanode3_1  | 2022-04-08 12:05:31,050 [Thread-838] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-3B5B81BD023B->4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5, cid=188, seq=0, Watch-ALL_COMMITTED(144), Message:<EMPTY>, reply=RaftClientReply:client-3B5B81BD023B->4cf3df89-7b36-4576-a18a-5d0c57ddb620@group-0543FC7274B5, cid=188, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 188 and log index 144 is not yet replicated to ALL_COMMITTED, logIndex=144, commits[4cf3df89-7b36-4576-a18a-5d0c57ddb620:c150, 0005597f-3053-4b02-96b8-efe2de95313b:c127, 8b7f16e2-5fb9-442f-a717-cc893c5795e0:c150]
om1_1        | 2022-04-08 11:55:39,167 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:39,202 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:39,209 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:39,212 [IPC Server handler 43 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:39,236 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:39,239 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:39,243 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:39,261 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:39,264 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:39,266 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:39,340 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:42,919 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:42,974 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:42,977 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:42,986 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:43,016 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:43,023 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:43,029 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:43,041 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:43,043 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:43,046 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:43,122 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:44,093 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:44,149 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:44,153 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:44,163 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:47,200 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42804
om1_1        | 2022-04-08 11:55:47,217 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:55:50,375 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:50,378 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:50,386 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-3090789646 of layout LEGACY in volume: s3v
om1_1        | 2022-04-08 11:55:50,998 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:51,001 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:51,013 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-2505354869 of layout LEGACY in volume: s3v
om1_1        | 2022-04-08 11:55:51,652 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:51,655 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:51,664 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-9765919850 of layout LEGACY in volume: s3v
om1_1        | 2022-04-08 11:55:52,226 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:52,229 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:52,237 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket-ozone-test-9765919850 in volume:s3v
om1_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om1_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:198)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 2022-04-08 11:49:26,421 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om3 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:226)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:213)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:206)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:165)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:137)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 116 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-08 11:49:28,143 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:35586
recon_1      | 2022-04-08 11:49:28,177 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 11:49:28,179 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=a76fa8e1-27b1-4e30-acd2-3b267e60a22d. Trying to get from SCM.
recon_1      | 2022-04-08 11:49:28,249 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: a76fa8e1-27b1-4e30-acd2-3b267e60a22d, Nodes: 8b7f16e2-5fb9-442f-a717-cc893c5795e0{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:8b7f16e2-5fb9-442f-a717-cc893c5795e0, CreationTimestamp2022-04-08T11:48:56.511Z[UTC]] to Recon pipeline metadata.
recon_1      | 2022-04-08 11:49:28,251 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: a76fa8e1-27b1-4e30-acd2-3b267e60a22d, Nodes: 8b7f16e2-5fb9-442f-a717-cc893c5795e0{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:8b7f16e2-5fb9-442f-a717-cc893c5795e0, CreationTimestamp2022-04-08T11:48:56.511Z[UTC]].
recon_1      | 2022-04-08 11:49:28,252 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=d7bff567-93ff-485c-a104-bc074898d12a reported by 8b7f16e2-5fb9-442f-a717-cc893c5795e0{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 932981906868, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-04-08 11:49:28,425 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om1 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:226)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:213)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:206)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:165)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:137)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 117 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:49:28,430 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:226)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:213)
scm2.org_1   | 2022-04-08 11:47:25,846 [main] INFO client.SCMCertificateClient: Certificate client init case: 0
scm2.org_1   | 2022-04-08 11:47:25,847 [main] INFO client.SCMCertificateClient: Creating keypair for client as keypair and certificate not found.
scm2.org_1   | 2022-04-08 11:47:26,698 [main] INFO ha.HASecurityUtils: Init response: GETCERT
scm2.org_1   | 2022-04-08 11:47:26,778 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.117,host:scm2.org
scm2.org_1   | 2022-04-08 11:47:26,778 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm2.org_1   | 2022-04-08 11:47:26,794 [main] INFO ha.HASecurityUtils: Creating csr for SCM->hostName:scm2.org,scmId:028f51fd-62f3-478d-a538-df850a92e5c2,clusterId:CID-236d968d-b3de-4c14-8c61-a2ea220fd69f,subject:scm-sub@scm2.org
scm2.org_1   | 2022-04-08 11:47:29,825 [main] INFO ha.HASecurityUtils: Successfully stored SCM signed certificate.
scm2.org_1   | 2022-04-08 11:47:29,851 [main] INFO server.StorageContainerManager: SCM BootStrap  is successful for ClusterID CID-236d968d-b3de-4c14-8c61-a2ea220fd69f, SCMID 028f51fd-62f3-478d-a538-df850a92e5c2
scm2.org_1   | 2022-04-08 11:47:29,852 [main] INFO server.StorageContainerManager: Primary SCM Node ID 088c2e91-0545-411d-8d31-8415832ed844
scm2.org_1   | 2022-04-08 11:47:29,920 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm2.org_1   | /************************************************************
scm2.org_1   | SHUTDOWN_MSG: Shutting down StorageContainerManager at scm2.org/172.25.0.117
scm2.org_1   | ************************************************************/
scm2.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm2.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm2.org_1   | 2022-04-08 11:47:33,322 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm2.org_1   | /************************************************************
scm2.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm2.org_1   | STARTUP_MSG:   host = scm2.org/172.25.0.117
scm2.org_1   | STARTUP_MSG:   args = []
scm2.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
scm2.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.0.4.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm2.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/805b5e1d3b8eaf7ab8aef1c57e2bb17b73dea398 ; compiled by 'runner' on 2022-04-08T11:25Z
scm2.org_1   | STARTUP_MSG:   java = 11.0.14.1
scm2.org_1   | ************************************************************/
scm2.org_1   | 2022-04-08 11:47:33,354 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm2.org_1   | 2022-04-08 11:47:33,607 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm2.org_1   | 2022-04-08 11:47:33,611 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm2.org_1   | 2022-04-08 11:47:33,779 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm2, RPC Address: scm2.org:9894 and Ratis port: 9894
scm2.org_1   | 2022-04-08 11:47:33,787 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm2: scm2.org
scm2.org_1   | 2022-04-08 11:47:33,916 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2022-04-08 11:47:33,974 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = SCM_HA (version = 2), software layout = SCM_HA (version = 2)
scm2.org_1   | 2022-04-08 11:47:34,577 [main] INFO reflections.Reflections: Reflections took 275 ms to scan 3 urls, producing 105 keys and 220 values 
scm2.org_1   | 2022-04-08 11:47:35,966 [main] INFO client.SCMCertificateClient: Loading certificate from location:/data/metadata/scm/sub-ca/certs.
scm2.org_1   | 2022-04-08 11:47:36,220 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/872627140406.crt.
scm2.org_1   | 2022-04-08 11:47:36,229 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/CA-1.crt.
scm2.org_1   | 2022-04-08 11:47:36,243 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/certificate.crt.
scm2.org_1   | 2022-04-08 11:47:36,565 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm2.org_1   | 2022-04-08 11:47:36,565 [main] INFO server.StorageContainerManager: SCM login successful.
scm2.org_1   | 2022-04-08 11:47:36,831 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2022-04-08 11:47:37,276 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2022-04-08 11:47:37,665 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar!/network-topology-default.xml]
scm2.org_1   | 2022-04-08 11:47:37,665 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm2.org_1   | 2022-04-08 11:47:37,771 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm2.org_1   | 2022-04-08 11:47:37,856 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:028f51fd-62f3-478d-a538-df850a92e5c2
scm2.org_1   | 2022-04-08 11:47:38,206 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
scm2.org_1   | 2022-04-08 11:47:38,463 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
scm2.org_1   | 2022-04-08 11:47:38,472 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm2.org_1   | 2022-04-08 11:47:38,473 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
scm2.org_1   | 2022-04-08 11:47:38,474 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm2.org_1   | 2022-04-08 11:47:38,474 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm2.org_1   | 2022-04-08 11:47:38,474 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
scm2.org_1   | 2022-04-08 11:47:38,479 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm2.org_1   | 2022-04-08 11:47:38,483 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm2.org_1   | 2022-04-08 11:47:38,484 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm2.org_1   | 2022-04-08 11:47:39,339 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
scm2.org_1   | 2022-04-08 11:47:39,341 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm2.org_1   | 2022-04-08 11:47:39,341 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm2.org_1   | 2022-04-08 11:47:39,358 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm2.org_1   | 2022-04-08 11:47:39,388 [main] INFO server.RaftServer: 028f51fd-62f3-478d-a538-df850a92e5c2: addNew group-A2EA220FD69F:[] returns group-A2EA220FD69F:java.util.concurrent.CompletableFuture@288728e[Not completed]
scm2.org_1   | 2022-04-08 11:47:39,442 [pool-14-thread-1] INFO server.RaftServer$Division: 028f51fd-62f3-478d-a538-df850a92e5c2: new RaftServerImpl for group-A2EA220FD69F:[] with SCMStateMachine:uninitialized
scm2.org_1   | 2022-04-08 11:47:39,451 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm2.org_1   | 2022-04-08 11:47:39,460 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-04-08 11:55:52,845 [IPC Server handler 46 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:55,938 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42826
om1_1        | 2022-04-08 11:55:55,952 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:55:58,934 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:58,937 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:58,944 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-9631101845 of layout LEGACY in volume: s3v
om1_1        | 2022-04-08 11:55:59,513 [IPC Server handler 99 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:59,516 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:55:59,524 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-1703165167 of layout LEGACY in volume: s3v
om1_1        | 2022-04-08 11:56:00,136 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:00,139 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:00,711 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:00,714 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:00,721 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketDeleteRequest: Delete bucket failed for bucket:nosuchbucket-ozone-test-0525685448 in volume:s3v
om1_1        | BUCKET_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Bucket not found
om1_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.getBucketOwner(OzoneManager.java:2334)
om1_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.getBucketOwner(OzoneManager.java:2304)
om1_1        | 	at org.apache.hadoop.ozone.om.request.OMClientRequest.checkAcls(OMClientRequest.java:200)
om1_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketDeleteRequest.validateAndUpdateCache(OMBucketDeleteRequest.java:102)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-04-08 11:56:03,657 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42846
om1_1        | 2022-04-08 11:56:03,672 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:56:06,988 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:06,992 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:07,011 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-0143600893 of layout LEGACY in volume: s3v
om1_1        | 2022-04-08 11:56:07,597 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:07,599 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:08,189 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:08,191 [IPC Server handler 43 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:11,312 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42906
om1_1        | 2022-04-08 11:56:11,329 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:56:14,257 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:14,262 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:14,272 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-3076197802 of layout LEGACY in volume: s3v
om1_1        | 2022-04-08 11:56:14,851 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:14,853 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:14,857 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:18,804 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42928
om1_1        | 2022-04-08 11:56:18,820 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:56:21,790 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:21,795 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:206)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:165)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:137)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 118 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:49:28,433 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om3 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:226)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:213)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:206)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:165)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:137)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 119 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-08 11:49:28,603 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:59260
recon_1      | 2022-04-08 11:49:28,655 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 11:49:28,657 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=d7bff567-93ff-485c-a104-bc074898d12a reported by 0005597f-3053-4b02-96b8-efe2de95313b{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 933750048452, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-04-08 11:49:28,658 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=8c48fa47-1e15-404a-9159-e49e3da5df9c. Trying to get from SCM.
recon_1      | 2022-04-08 11:49:28,670 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: 8c48fa47-1e15-404a-9159-e49e3da5df9c, Nodes: 0005597f-3053-4b02-96b8-efe2de95313b{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-04-08T11:48:57.726Z[UTC]] to Recon pipeline metadata.
recon_1      | 2022-04-08 11:49:28,671 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 8c48fa47-1e15-404a-9159-e49e3da5df9c, Nodes: 0005597f-3053-4b02-96b8-efe2de95313b{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-04-08T11:48:57.726Z[UTC]].
recon_1      | 2022-04-08 11:49:28,672 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/ONE PipelineID=8c48fa47-1e15-404a-9159-e49e3da5df9c reported by 0005597f-3053-4b02-96b8-efe2de95313b{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 933750048452, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-04-08 11:49:28,672 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 8c48fa47-1e15-404a-9159-e49e3da5df9c, Nodes: 0005597f-3053-4b02-96b8-efe2de95313b{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:0005597f-3053-4b02-96b8-efe2de95313b, CreationTimestamp2022-04-08T11:48:57.726Z[UTC]] moved to OPEN state
recon_1      | 2022-04-08 11:49:30,437 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om1 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:226)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:213)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:206)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:165)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:137)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 120 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:49:30,442 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:226)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:213)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:206)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:165)
scm1.org_1   | 2022-04-08 11:47:09,614 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-LeaderElection1] INFO server.RaftServer$Division: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F: change Leader from null to 088c2e91-0545-411d-8d31-8415832ed844 at term 1 for becomeLeader, leader elected after 5588ms
scm1.org_1   | 2022-04-08 11:47:09,619 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
om1_1        | 2022-04-08 11:56:21,802 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-0491738847 of layout LEGACY in volume: s3v
scm1.org_1   | 2022-04-08 11:47:09,623 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm1.org_1   | 2022-04-08 11:47:09,623 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
scm3.org_1   | 2022-04-08 11:47:56,392 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar!/network-topology-default.xml]
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1        | Caused by: org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.newError(S3ErrorTable.java:139)
om1_1        | 2022-04-08 11:56:22,523 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm1.org_1   | 2022-04-08 11:47:09,628 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
scm1.org_1   | 2022-04-08 11:47:09,628 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
scm3.org_1   | 2022-04-08 11:47:56,392 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.newError(S3ErrorTable.java:126)
s3g_1        | 	at org.apache.hadoop.ozone.s3.signature.AuthorizationV4HeaderParser.parseCredentials(AuthorizationV4HeaderParser.java:171)
s3g_1        | 	at org.apache.hadoop.ozone.s3.signature.AuthorizationV4HeaderParser.parseSignature(AuthorizationV4HeaderParser.java:91)
om1_1        | 2022-04-08 11:56:22,526 [IPC Server handler 98 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm1.org_1   | 2022-04-08 11:47:09,629 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
scm1.org_1   | 2022-04-08 11:47:09,632 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm1.org_1   | 2022-04-08 11:47:09,633 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
scm1.org_1   | 2022-04-08 11:47:09,635 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-LeaderElection1] INFO impl.RoleInfo: 088c2e91-0545-411d-8d31-8415832ed844: start 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-LeaderStateImpl
scm3.org_1   | 2022-04-08 11:47:56,495 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm3.org_1   | 2022-04-08 11:47:56,550 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:9ebec731-0724-46e8-adb1-25fbc2c43c85
scm2.org_1   | 2022-04-08 11:47:39,460 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm2.org_1   | 2022-04-08 11:47:39,460 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:137)
om1_1        | 2022-04-08 11:56:22,528 [IPC Server handler 74 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm2.org_1   | 2022-04-08 11:47:39,460 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
s3g_1        | 	at org.apache.hadoop.ozone.s3.signature.AWSSignatureProcessor.parseSignature(AWSSignatureProcessor.java:70)
s3g_1        | 	at org.apache.hadoop.ozone.s3.signature.AWSSignatureProcessor$Proxy$_$$_WeldClientProxy.parseSignature(Unknown Source)
s3g_1        | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getSignature(OzoneClientProducer.java:87)
s3g_1        | 	... 114 more
scm3.org_1   | 2022-04-08 11:47:56,735 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
om1_1        | 2022-04-08 11:56:23,221 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:23,224 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
s3g_1        | 
scm2.org_1   | 2022-04-08 11:47:39,461 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
scm2.org_1   | 2022-04-08 11:47:39,461 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm2.org_1   | 2022-04-08 11:47:39,476 [pool-14-thread-1] INFO server.RaftServer$Division: 028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
scm2.org_1   | 2022-04-08 11:47:39,478 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm2.org_1   | 2022-04-08 11:47:39,504 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm2.org_1   | 2022-04-08 11:47:39,504 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
scm2.org_1   | 2022-04-08 11:47:39,506 [pool-14-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/236d968d-b3de-4c14-8c61-a2ea220fd69f does not exist. Creating ...
scm2.org_1   | 2022-04-08 11:47:39,527 [pool-14-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/236d968d-b3de-4c14-8c61-a2ea220fd69f/in_use.lock acquired by nodename 8@scm2.org
scm2.org_1   | 2022-04-08 11:47:39,568 [pool-14-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/236d968d-b3de-4c14-8c61-a2ea220fd69f has been successfully formatted.
scm2.org_1   | 2022-04-08 11:47:39,576 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm2.org_1   | 2022-04-08 11:47:39,583 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm2.org_1   | 2022-04-08 11:47:39,599 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm3.org_1   | 2022-04-08 11:47:56,871 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
scm2.org_1   | 2022-04-08 11:47:39,600 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm2.org_1   | 2022-04-08 11:47:39,633 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm2.org_1   | 2022-04-08 11:47:39,651 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm2.org_1   | 2022-04-08 11:47:39,652 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
scm2.org_1   | 2022-04-08 11:47:39,661 [pool-14-thread-1] INFO segmented.SegmentedRaftLogWorker: new 028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/236d968d-b3de-4c14-8c61-a2ea220fd69f
scm2.org_1   | 2022-04-08 11:47:39,664 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
scm2.org_1   | 2022-04-08 11:47:39,665 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm2.org_1   | 2022-04-08 11:47:39,668 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm2.org_1   | 2022-04-08 11:47:39,670 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
scm2.org_1   | 2022-04-08 11:47:39,671 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
s3g_1        | 
s3g_1        | 2022-04-08 11:56:21,793 [qtp1423016050-23] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-0491738847, with root as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-04-08 11:56:21,805 [qtp1423016050-23] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-0491738847
scm3.org_1   | 2022-04-08 11:47:56,872 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2022-04-08 11:47:09,674 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-SegmentedRaftLogWorker: Starting segment from index:0
scm1.org_1   | 2022-04-08 11:47:09,725 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-LeaderElection1] INFO server.RaftServer$Division: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F: set configuration 0: [088c2e91-0545-411d-8d31-8415832ed844|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2022-04-08 11:47:09,769 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/236d968d-b3de-4c14-8c61-a2ea220fd69f/current/log_inprogress_0
scm1.org_1   | 2022-04-08 11:47:10,658 [main] INFO server.RaftServer: 088c2e91-0545-411d-8d31-8415832ed844: close
scm1.org_1   | 2022-04-08 11:47:10,659 [main] INFO server.RaftServer$Division: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F: shutdown
scm1.org_1   | 2022-04-08 11:47:10,659 [main] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-A2EA220FD69F,id=088c2e91-0545-411d-8d31-8415832ed844
scm1.org_1   | 2022-04-08 11:47:10,659 [main] INFO impl.RoleInfo: 088c2e91-0545-411d-8d31-8415832ed844: shutdown 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-LeaderStateImpl
scm1.org_1   | 2022-04-08 11:47:10,665 [main] INFO impl.PendingRequests: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-PendingRequests: sendNotLeaderResponses
scm2.org_1   | 2022-04-08 11:47:39,673 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm2.org_1   | 2022-04-08 11:47:39,677 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm2.org_1   | 2022-04-08 11:47:39,678 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm2.org_1   | 2022-04-08 11:47:39,705 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
scm2.org_1   | 2022-04-08 11:47:39,708 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
scm2.org_1   | 2022-04-08 11:47:39,721 [pool-14-thread-1] INFO segmented.SegmentedRaftLogWorker: 028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm2.org_1   | 2022-04-08 11:47:39,721 [pool-14-thread-1] INFO segmented.SegmentedRaftLogWorker: 028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
s3g_1        | 2022-04-08 11:57:56,899 [qtp1423016050-21] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-5575003451, with root as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-04-08 11:57:56,914 [qtp1423016050-21] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-5575003451
s3g_1        | 2022-04-08 11:57:57,505 [qtp1423016050-20] INFO rpc.RpcClient: Creating Bucket: s3v/destbucket-38461, with root as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-04-08 11:57:57,524 [qtp1423016050-20] INFO endpoint.BucketEndpoint: Location is /destbucket-38461
s3g_1        | 2022-04-08 11:58:17,592 [qtp1423016050-20] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-5420801628, with root as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
scm2.org_1   | 2022-04-08 11:47:39,725 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm2.org_1   | 2022-04-08 11:47:39,729 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
scm2.org_1   | 2022-04-08 11:47:39,730 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
scm2.org_1   | 2022-04-08 11:47:39,739 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm3.org_1   | 2022-04-08 11:47:56,872 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
s3g_1        | 2022-04-08 11:58:17,608 [qtp1423016050-20] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-5420801628
scm2.org_1   | 2022-04-08 11:47:39,741 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
scm2.org_1   | 2022-04-08 11:47:39,743 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm2.org_1   | 2022-04-08 11:47:39,826 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
scm2.org_1   | 2022-04-08 11:47:39,826 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
scm3.org_1   | 2022-04-08 11:47:56,872 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
s3g_1        | 2022-04-08 12:01:18,309 [qtp1423016050-21] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: a6f33c92-47f3-4bcf-8c55-0543fc7274b5, Nodes: 8b7f16e2-5fb9-442f-a717-cc893c5795e0{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}0005597f-3053-4b02-96b8-efe2de95313b{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}4cf3df89-7b36-4576-a18a-5d0c57ddb620{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:4cf3df89-7b36-4576-a18a-5d0c57ddb620, CreationTimestamp2022-04-08T11:48:59.048Z[UTC]]
scm2.org_1   | 2022-04-08 11:47:39,827 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
scm1.org_1   | 2022-04-08 11:47:10,674 [main] INFO impl.StateMachineUpdater: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-StateMachineUpdater: set stopIndex = 0
scm1.org_1   | 2022-04-08 11:47:10,675 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-StateMachineUpdater] INFO impl.StateMachineUpdater: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-StateMachineUpdater: Took a snapshot at index 0
scm1.org_1   | 2022-04-08 11:47:10,675 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-StateMachineUpdater] INFO impl.StateMachineUpdater: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
scm1.org_1   | 2022-04-08 11:47:10,679 [main] INFO server.RaftServer$Division: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F: closes. applyIndex: 0
scm1.org_1   | 2022-04-08 11:47:10,680 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
s3g_1        | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #163 timeout 180s
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1        | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:263)
scm3.org_1   | 2022-04-08 11:47:56,873 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
scm1.org_1   | 2022-04-08 11:47:10,681 [main] INFO segmented.SegmentedRaftLogWorker: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-SegmentedRaftLogWorker close()
scm1.org_1   | 2022-04-08 11:47:10,682 [main] INFO server.GrpcService: 088c2e91-0545-411d-8d31-8415832ed844: shutdown server with port 9894 now
scm1.org_1   | 2022-04-08 11:47:10,687 [main] INFO server.GrpcService: 088c2e91-0545-411d-8d31-8415832ed844: shutdown server with port 9894 successfully
scm1.org_1   | 2022-04-08 11:47:10,688 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$338/0x000000084031fc40@593a6726] INFO util.JvmPauseMonitor: JvmPauseMonitor-088c2e91-0545-411d-8d31-8415832ed844: Stopped
scm3.org_1   | 2022-04-08 11:47:56,878 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.RatisBlockOutputStream.sendWatchForCommit(RatisBlockOutputStream.java:101)
scm2.org_1   | 2022-04-08 11:47:40,145 [main] INFO ha.SequenceIdGenerator: upgrade localId to 109611004723200000
scm2.org_1   | 2022-04-08 11:47:40,146 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
scm2.org_1   | 2022-04-08 11:47:40,149 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
scm1.org_1   | 2022-04-08 11:47:10,688 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:373)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:533)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:547)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
om1_1        | 2022-04-08 11:56:23,233 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:23,246 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:23,707 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:24,783 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:24,786 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:24,790 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:24,808 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:27,499 [IPC Server handler 62 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm1.org_1   | 2022-04-08 11:47:10,690 [main] INFO server.StorageContainerManager: SCM initialization succeeded. Current cluster id for sd=/data/metadata/scm; cid=CID-236d968d-b3de-4c14-8c61-a2ea220fd69f; layoutVersion=2; scmId=088c2e91-0545-411d-8d31-8415832ed844
scm1.org_1   | 2022-04-08 11:47:10,701 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
s3g_1        | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:137)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:495)
scm2.org_1   | 2022-04-08 11:47:40,157 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
scm2.org_1   | 2022-04-08 11:47:40,276 [main] INFO node.SCMNodeManager: Entering startup safe mode.
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
scm1.org_1   | /************************************************************
scm3.org_1   | 2022-04-08 11:47:56,880 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:469)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:522)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:235)
s3g_1        | 	at jdk.internal.reflect.GeneratedMethodAccessor28.invoke(Unknown Source)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
scm2.org_1   | 2022-04-08 11:47:40,324 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm2.org_1   | 2022-04-08 11:47:40,347 [main] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
scm2.org_1   | 2022-04-08 11:47:40,428 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
scm2.org_1   | 2022-04-08 11:47:40,453 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
scm2.org_1   | 2022-04-08 11:47:40,453 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
scm2.org_1   | 2022-04-08 11:47:40,539 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
scm2.org_1   | 2022-04-08 11:47:40,560 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
scm2.org_1   | 2022-04-08 11:47:40,593 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm1.org_1   | SHUTDOWN_MSG: Shutting down StorageContainerManager at scm1.org/172.25.0.116
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om1_1        | 2022-04-08 11:56:28,165 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:28,168 [IPC Server handler 43 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:28,171 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:28,810 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:28,812 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:28,814 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
scm3.org_1   | 2022-04-08 11:47:56,880 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm3.org_1   | 2022-04-08 11:47:56,881 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm3.org_1   | 2022-04-08 11:47:57,831 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
scm3.org_1   | 2022-04-08 11:47:57,840 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm3.org_1   | 2022-04-08 11:47:57,840 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm3.org_1   | 2022-04-08 11:47:57,858 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm3.org_1   | 2022-04-08 11:47:57,871 [main] INFO server.RaftServer: 9ebec731-0724-46e8-adb1-25fbc2c43c85: addNew group-A2EA220FD69F:[] returns group-A2EA220FD69F:java.util.concurrent.CompletableFuture@288728e[Not completed]
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
scm3.org_1   | 2022-04-08 11:47:57,943 [pool-14-thread-1] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85: new RaftServerImpl for group-A2EA220FD69F:[] with SCMStateMachine:uninitialized
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 121 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-08 11:49:30,446 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om3 is not the leader. Could not determine the leader node.
scm1.org_1   | ************************************************************/
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
scm3.org_1   | 2022-04-08 11:47:57,949 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
om1_1        | 2022-04-08 11:56:28,868 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:226)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:213)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:206)
scm1.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm1.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm1.org_1   | 2022-04-08 11:47:12,178 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm1.org_1   | /************************************************************
scm2.org_1   | 2022-04-08 11:47:40,625 [main] INFO container.ReplicationManager: Starting Replication Monitor Thread.
scm2.org_1   | 2022-04-08 11:47:40,641 [ReplicationMonitor] INFO container.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:165)
scm2.org_1   | 2022-04-08 11:47:40,672 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
scm2.org_1   | 2022-04-08 11:47:40,691 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1        | 2022-04-08 11:56:29,854 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm2.org_1   | 2022-04-08 11:47:40,694 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm2.org_1   | 2022-04-08 11:47:40,763 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
scm2.org_1   | 2022-04-08 11:47:40,883 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm3.org_1   | 2022-04-08 11:47:57,950 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm3.org_1   | 2022-04-08 11:47:57,950 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm3.org_1   | 2022-04-08 11:47:57,950 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm1.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm1.org_1   | STARTUP_MSG:   host = scm1.org/172.25.0.116
scm1.org_1   | STARTUP_MSG:   args = []
scm1.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
scm1.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.0.4.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm1.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/805b5e1d3b8eaf7ab8aef1c57e2bb17b73dea398 ; compiled by 'runner' on 2022-04-08T11:25Z
scm1.org_1   | STARTUP_MSG:   java = 11.0.14.1
scm2.org_1   | 2022-04-08 11:47:41,119 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
scm1.org_1   | ************************************************************/
scm2.org_1   | 2022-04-08 11:47:42,979 [Listener at 0.0.0.0/9961] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om1_1        | 2022-04-08 11:56:29,858 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:29,863 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:30,530 [IPC Server handler 74 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm1.org_1   | 2022-04-08 11:47:12,184 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm2.org_1   | 2022-04-08 11:47:43,003 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm2.org_1   | 2022-04-08 11:47:43,133 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm2.org_1   | 2022-04-08 11:47:43,144 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm2.org_1   | 2022-04-08 11:47:43,222 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm2.org_1   | 2022-04-08 11:47:43,224 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm2.org_1   | 2022-04-08 11:47:43,510 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: 
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
scm3.org_1   | 2022-04-08 11:47:57,951 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om1_1        | 2022-04-08 11:56:30,533 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:30,536 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:137)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
scm3.org_1   | 2022-04-08 11:47:57,951 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
scm3.org_1   | 2022-04-08 11:47:57,952 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm2.org_1   | Container Balancer status:
scm2.org_1   | Key                            Value
scm2.org_1   | Running                        false
scm2.org_1   | Container Balancer Configuration values:
scm2.org_1   | Key                                                Value
scm3.org_1   | 2022-04-08 11:47:57,961 [pool-14-thread-1] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
scm3.org_1   | 2022-04-08 11:47:57,962 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm3.org_1   | 2022-04-08 11:47:57,972 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om1_1        | 2022-04-08 11:56:31,279 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:31,281 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:31,283 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:31,313 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:31,662 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm3.org_1   | 2022-04-08 11:47:57,972 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
scm3.org_1   | 2022-04-08 11:47:57,973 [pool-14-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/236d968d-b3de-4c14-8c61-a2ea220fd69f does not exist. Creating ...
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
scm1.org_1   | 2022-04-08 11:47:12,279 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm1.org_1   | 2022-04-08 11:47:12,280 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm1.org_1   | 2022-04-08 11:47:12,348 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm1, RPC Address: scm1.org:9894 and Ratis port: 9894
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
om1_1        | 2022-04-08 11:56:32,435 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm1.org_1   | 2022-04-08 11:47:12,349 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm1: scm1.org
scm1.org_1   | 2022-04-08 11:47:12,395 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2022-04-08 11:47:12,428 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = SCM_HA (version = 2), software layout = SCM_HA (version = 2)
scm3.org_1   | 2022-04-08 11:47:57,996 [pool-14-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/236d968d-b3de-4c14-8c61-a2ea220fd69f/in_use.lock acquired by nodename 7@scm3.org
scm3.org_1   | 2022-04-08 11:47:58,042 [pool-14-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/236d968d-b3de-4c14-8c61-a2ea220fd69f has been successfully formatted.
om1_1        | 2022-04-08 11:56:32,440 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm1.org_1   | 2022-04-08 11:47:12,643 [main] INFO reflections.Reflections: Reflections took 92 ms to scan 3 urls, producing 105 keys and 220 values 
scm1.org_1   | 2022-04-08 11:47:13,147 [main] INFO client.SCMCertificateClient: Loading certificate from location:/data/metadata/scm/sub-ca/certs.
scm1.org_1   | 2022-04-08 11:47:13,226 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/848180596473.crt.
scm1.org_1   | 2022-04-08 11:47:13,230 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/CA-1.crt.
scm1.org_1   | 2022-04-08 11:47:13,233 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/certificate.crt.
scm1.org_1   | 2022-04-08 11:47:13,360 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
om1_1        | 2022-04-08 11:56:32,445 [IPC Server handler 42 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:32,484 [IPC Server handler 59 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:32,975 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
scm1.org_1   | 2022-04-08 11:47:13,360 [main] INFO server.StorageContainerManager: SCM login successful.
scm1.org_1   | 2022-04-08 11:47:13,411 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm3.org_1   | 2022-04-08 11:47:58,045 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm2.org_1   | Threshold                                          10
scm2.org_1   | Max Datanodes to Involve per Iteration(percent)    20
scm2.org_1   | Max Size to Move per Iteration                     500GB
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 122 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-08 11:49:33,255 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=d7bff567-93ff-485c-a104-bc074898d12a reported by 8b7f16e2-5fb9-442f-a717-cc893c5795e0{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 932981906868, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm1.org_1   | 2022-04-08 11:47:13,613 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | Max Size Entering Target per Iteration             26GB
scm2.org_1   | Max Size Leaving Source per Iteration              26GB
om1_1        | 2022-04-08 11:56:33,709 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm3.org_1   | 2022-04-08 11:47:58,048 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm3.org_1   | 2022-04-08 11:47:58,075 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm3.org_1   | 2022-04-08 11:47:58,076 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm3.org_1   | 2022-04-08 11:47:58,107 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm1.org_1   | 2022-04-08 11:47:13,776 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar!/network-topology-default.xml]
recon_1      | 2022-04-08 11:49:33,368 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
om1_1        | 2022-04-08 11:56:33,714 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm3.org_1   | 2022-04-08 11:47:58,119 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
recon_1      | java.lang.reflect.UndeclaredThrowableException
scm1.org_1   | 2022-04-08 11:47:13,776 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
scm2.org_1   | 
scm2.org_1   | 2022-04-08 11:47:43,518 [Listener at 0.0.0.0/9860] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
om1_1        | 2022-04-08 11:56:33,719 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm3.org_1   | 2022-04-08 11:47:58,120 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
scm3.org_1   | 2022-04-08 11:47:58,140 [pool-14-thread-1] INFO segmented.SegmentedRaftLogWorker: new 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/236d968d-b3de-4c14-8c61-a2ea220fd69f
scm3.org_1   | 2022-04-08 11:47:58,141 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
scm3.org_1   | 2022-04-08 11:47:58,143 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm3.org_1   | 2022-04-08 11:47:58,143 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
scm2.org_1   | 2022-04-08 11:47:43,519 [Listener at 0.0.0.0/9860] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
scm2.org_1   | 2022-04-08 11:47:43,522 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm2.org_1   | 2022-04-08 11:47:43,529 [Listener at 0.0.0.0/9860] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
scm2.org_1   | 2022-04-08 11:47:43,533 [Listener at 0.0.0.0/9860] INFO server.RaftServer$Division: 028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F: start with initializing state, conf=-1: [], old=null
scm2.org_1   | 2022-04-08 11:47:43,553 [Listener at 0.0.0.0/9860] INFO server.RaftServer$Division: 028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F: changes role from      null to FOLLOWER at term 0 for startInitializing
scm2.org_1   | 2022-04-08 11:47:43,554 [Listener at 0.0.0.0/9860] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A2EA220FD69F,id=028f51fd-62f3-478d-a538-df850a92e5c2
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
scm1.org_1   | 2022-04-08 11:47:13,816 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm1.org_1   | 2022-04-08 11:47:13,832 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:088c2e91-0545-411d-8d31-8415832ed844
scm1.org_1   | 2022-04-08 11:47:13,928 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
scm1.org_1   | 2022-04-08 11:47:13,983 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
scm1.org_1   | 2022-04-08 11:47:13,983 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
om1_1        | 2022-04-08 11:56:33,736 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:36013
om1_1        | 2022-04-08 11:56:33,748 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:56:34,450 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:34,453 [IPC Server handler 86 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1679)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1        | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #163 timeout 180s
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:368)
s3g_1        | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:373)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:368)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:357)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
scm3.org_1   | 2022-04-08 11:47:58,144 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
scm3.org_1   | 2022-04-08 11:47:58,145 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm3.org_1   | 2022-04-08 11:47:58,146 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm2.org_1   | 2022-04-08 11:47:43,578 [Listener at 0.0.0.0/9860] INFO server.RaftServer: 028f51fd-62f3-478d-a538-df850a92e5c2: start RPC server
scm2.org_1   | 2022-04-08 11:47:43,689 [Listener at 0.0.0.0/9860] INFO server.GrpcService: 028f51fd-62f3-478d-a538-df850a92e5c2: GrpcService started, listening on 9894
scm2.org_1   | 2022-04-08 11:47:43,698 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$421/0x0000000840527040@80081d7] INFO util.JvmPauseMonitor: JvmPauseMonitor-028f51fd-62f3-478d-a538-df850a92e5c2: Started
scm2.org_1   | 2022-04-08 11:47:43,718 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
scm2.org_1   | 2022-04-08 11:47:43,725 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
scm2.org_1   | 2022-04-08 11:47:43,725 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 2022-04-08 11:56:34,457 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:34,484 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:37,286 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:37,898 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm1.org_1   | 2022-04-08 11:47:13,984 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
scm1.org_1   | 2022-04-08 11:47:13,984 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2022-04-08 11:47:13,984 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2022-04-08 11:47:13,985 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
scm1.org_1   | 2022-04-08 11:47:13,986 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2022-04-08 11:47:13,986 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm3.org_1   | 2022-04-08 11:47:58,146 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm3.org_1   | 2022-04-08 11:47:58,147 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm3.org_1   | 2022-04-08 11:47:58,164 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
scm3.org_1   | 2022-04-08 11:47:58,165 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
scm3.org_1   | 2022-04-08 11:47:58,180 [pool-14-thread-1] INFO segmented.SegmentedRaftLogWorker: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
om1_1        | 2022-04-08 11:56:37,901 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:37,905 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:37,925 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:37,998 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:38,628 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
scm2.org_1   | 2022-04-08 11:47:45,301 [grpc-default-executor-0] INFO server.RaftServer$Division: 028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F: receive installSnapshot: 088c2e91-0545-411d-8d31-8415832ed844->028f51fd-62f3-478d-a538-df850a92e5c2#0-t2,notify:(t:2, i:6)
scm2.org_1   | 2022-04-08 11:47:45,310 [grpc-default-executor-0] INFO ha.SCMStateMachine: leader changed, yet current SCM is still follower.
scm2.org_1   | 2022-04-08 11:47:45,311 [grpc-default-executor-0] INFO server.RaftServer$Division: 028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F: change Leader from null to 088c2e91-0545-411d-8d31-8415832ed844 at term 2 for installSnapshot, leader elected after 5734ms
scm2.org_1   | 2022-04-08 11:47:45,313 [grpc-default-executor-0] INFO server.RaftServer$Division: 028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F: Received notification to install snapshot at index 6
scm2.org_1   | 2022-04-08 11:47:45,355 [grpc-default-executor-0] INFO server.RaftServer$Division: 028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F: notifyInstallSnapshot: nextIndex is 0 but the leader's first available index is 6.
scm1.org_1   | 2022-04-08 11:47:13,987 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm1.org_1   | 2022-04-08 11:47:14,358 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
scm1.org_1   | 2022-04-08 11:47:14,360 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm1.org_1   | 2022-04-08 11:47:14,360 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm1.org_1   | 2022-04-08 11:47:14,370 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm3.org_1   | 2022-04-08 11:47:58,180 [pool-14-thread-1] INFO segmented.SegmentedRaftLogWorker: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm3.org_1   | 2022-04-08 11:47:58,187 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om1_1        | 2022-04-08 11:56:38,630 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:38,632 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:39,224 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:39,227 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:39,229 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:39,339 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:40,177 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:40,179 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:40,181 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
scm2.org_1   | 2022-04-08 11:47:45,360 [grpc-default-executor-0] INFO ha.SCMStateMachine: Received install snapshot notification from SCM leader: scm1.org:9894 with term index: (t:2, i:6)
scm2.org_1   | 2022-04-08 11:47:45,361 [pool-16-thread-1] INFO ha.SCMHAManagerImpl: Downloading checkpoint from leader SCM scm1 and reloading state from the checkpoint.
scm2.org_1   | 2022-04-08 11:47:46,503 [grpc-default-executor-1] INFO ha.InterSCMGrpcClient: Checkpoint is downloaded to /data/metadata/snapshot/scm.db-scm1-1649418465362.tar.gz
scm2.org_1   | 2022-04-08 11:47:46,605 [pool-16-thread-1] INFO ha.SCMSnapshotProvider: Successfully downloaded latest checkpoint from leader SCM: scm1 path /data/metadata/snapshot/scm.db-scm1-1649418465362
scm2.org_1   | 2022-04-08 11:47:46,606 [pool-16-thread-1] INFO ha.SCMHAManagerImpl: Downloaded checkpoint from Leader scm1 to the location /data/metadata/snapshot/scm.db-scm1-1649418465362
scm2.org_1   | 2022-04-08 11:47:46,824 [pool-16-thread-1] INFO ha.SCMHAManagerImpl: Installing checkpoint with SCMTransactionInfo 2#6
scm1.org_1   | 2022-04-08 11:47:14,372 [main] INFO server.RaftServer: 088c2e91-0545-411d-8d31-8415832ed844: found a subdirectory /data/metadata/scm-ha/236d968d-b3de-4c14-8c61-a2ea220fd69f
scm1.org_1   | 2022-04-08 11:47:14,376 [main] INFO server.RaftServer: 088c2e91-0545-411d-8d31-8415832ed844: addNew group-A2EA220FD69F:[] returns group-A2EA220FD69F:java.util.concurrent.CompletableFuture@641ed324[Not completed]
scm1.org_1   | 2022-04-08 11:47:14,392 [pool-14-thread-1] INFO server.RaftServer$Division: 088c2e91-0545-411d-8d31-8415832ed844: new RaftServerImpl for group-A2EA220FD69F:[] with SCMStateMachine:uninitialized
scm2.org_1   | 2022-04-08 11:47:46,824 [pool-16-thread-1] INFO server.RaftServer$Division: 028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F: StateMachine successfully installed snapshot index 6. Reloading the StateMachine.
scm3.org_1   | 2022-04-08 11:47:58,188 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
scm3.org_1   | 2022-04-08 11:47:58,189 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om1_1        | 2022-04-08 11:56:40,783 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
s3g_1        | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1        | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1        | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
scm1.org_1   | 2022-04-08 11:47:14,394 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm2.org_1   | 2022-04-08 11:47:46,824 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: 028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F-SegmentedRaftLogWorker: flushIndex: setUnconditionally -1 -> 6
s3g_1        | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
scm3.org_1   | 2022-04-08 11:47:58,190 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm3.org_1   | 2022-04-08 11:47:58,191 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
scm3.org_1   | 2022-04-08 11:47:58,194 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm3.org_1   | 2022-04-08 11:47:58,313 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
scm3.org_1   | 2022-04-08 11:47:58,314 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
scm1.org_1   | 2022-04-08 11:47:14,395 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm1.org_1   | 2022-04-08 11:47:14,395 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm1.org_1   | 2022-04-08 11:47:14,395 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm1.org_1   | 2022-04-08 11:47:14,395 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm2.org_1   | 2022-04-08 11:47:46,825 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: 028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally -1 -> 6
scm1.org_1   | 2022-04-08 11:47:14,396 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
scm1.org_1   | 2022-04-08 11:47:14,396 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
om1_1        | 2022-04-08 11:56:40,786 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:40,790 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm2.org_1   | 2022-04-08 11:47:46,826 [pool-16-thread-1] INFO raftlog.RaftLog: 028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F-SegmentedRaftLog: snapshotIndex: updateIncreasingly -1 -> 6
scm2.org_1   | 2022-04-08 11:47:46,893 [grpc-default-executor-0] INFO server.RaftServer$Division: 028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F: set new configuration index: 1
scm2.org_1   | configurationEntry {
scm2.org_1   |   peers {
s3g_1        | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
om1_1        | 2022-04-08 11:56:40,807 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:43,453 [IPC Server handler 86 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:44,165 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:44,168 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:44,170 [IPC Server handler 43 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1        | 2022-04-08 11:56:44,185 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm1.org_1   | 2022-04-08 11:47:14,400 [pool-14-thread-1] INFO server.RaftServer$Division: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
scm3.org_1   | 2022-04-08 11:47:58,314 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
scm2.org_1   |     id: "088c2e91-0545-411d-8d31-8415832ed844"
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
scm1.org_1   | 2022-04-08 11:47:14,401 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm2.org_1   |     address: "scm1.org:9894"
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
scm3.org_1   | 2022-04-08 11:47:58,616 [main] INFO ha.SequenceIdGenerator: upgrade localId to 109611004723200000
scm3.org_1   | 2022-04-08 11:47:58,616 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
scm3.org_1   | 2022-04-08 11:47:58,632 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
scm3.org_1   | 2022-04-08 11:47:58,638 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
scm3.org_1   | 2022-04-08 11:47:58,743 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm1.org_1   | 2022-04-08 11:47:14,403 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm1.org_1   | 2022-04-08 11:47:14,403 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
scm3.org_1   | 2022-04-08 11:47:58,761 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm1.org_1   | 2022-04-08 11:47:14,423 [pool-14-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/236d968d-b3de-4c14-8c61-a2ea220fd69f/in_use.lock acquired by nodename 10@scm1.org
om1_1        | 2022-04-08 11:56:44,269 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:44,930 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:44,932 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm2.org_1   |   }
scm1.org_1   | 2022-04-08 11:47:14,435 [pool-14-thread-1] INFO storage.RaftStorage: Read RaftStorageMetadata{term=1, votedFor=088c2e91-0545-411d-8d31-8415832ed844} from /data/metadata/scm-ha/236d968d-b3de-4c14-8c61-a2ea220fd69f/current/raft-meta
scm3.org_1   | 2022-04-08 11:47:58,776 [main] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
scm1.org_1   | 2022-04-08 11:47:14,467 [pool-14-thread-1] INFO server.RaftServer$Division: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F: set configuration 0: [088c2e91-0545-411d-8d31-8415832ed844|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm3.org_1   | 2022-04-08 11:47:58,921 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
scm3.org_1   | 2022-04-08 11:47:58,944 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
scm3.org_1   | 2022-04-08 11:47:58,944 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
scm3.org_1   | 2022-04-08 11:47:59,007 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
scm3.org_1   | 2022-04-08 11:47:59,051 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
scm1.org_1   | 2022-04-08 11:47:14,467 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
s3g_1        | 	... 1 more
scm2.org_1   | }
scm2.org_1   |  from snapshot
om1_1        | 2022-04-08 11:56:44,935 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm1.org_1   | 2022-04-08 11:47:14,468 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om1_1        | 2022-04-08 11:56:44,942 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload: /s3v/bucket-ozone-test-0491738847/ozone-test-9528167901/multipartKey2 Part number: 1 size 6  is less than minimum part size 5242880
scm2.org_1   | 2022-04-08 11:47:46,919 [grpc-default-executor-0] INFO server.RaftServer$Division: 028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F: set configuration 1: [088c2e91-0545-411d-8d31-8415832ed844|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2022-04-08 11:47:46,928 [grpc-default-executor-0] INFO server.RaftServer$Division: 028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F: reply installSnapshot: 088c2e91-0545-411d-8d31-8415832ed844<-028f51fd-62f3-478d-a538-df850a92e5c2#0:FAIL-t0,IN_PROGRESS
scm3.org_1   | 2022-04-08 11:47:59,114 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
scm3.org_1   | 2022-04-08 11:47:59,144 [main] INFO container.ReplicationManager: Starting Replication Monitor Thread.
scm3.org_1   | 2022-04-08 11:47:59,154 [ReplicationMonitor] INFO container.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm2.org_1   | 2022-04-08 11:47:46,937 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 028f51fd-62f3-478d-a538-df850a92e5c2: Completed INSTALL_SNAPSHOT, lastRequest: 088c2e91-0545-411d-8d31-8415832ed844->028f51fd-62f3-478d-a538-df850a92e5c2#0-t2,notify:(t:2, i:6)
scm2.org_1   | 2022-04-08 11:47:47,006 [grpc-default-executor-0] INFO impl.RoleInfo: 028f51fd-62f3-478d-a538-df850a92e5c2: start 028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F-FollowerState
om1_1        | 2022-04-08 11:56:44,943 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-9528167901/multipartKey2 in Volume/Bucket s3v/bucket-ozone-test-0491738847
om1_1        | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-0491738847 key: ozone-test-9528167901/multipartKey2. Entity too small.
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:513)
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:192)
scm3.org_1   | 2022-04-08 11:47:59,188 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
scm3.org_1   | 2022-04-08 11:47:59,207 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-04-08 11:47:47,006 [grpc-default-executor-0] INFO server.RaftServer$Division: 028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F: Failed appendEntries as snapshot (6) installation is in progress
scm2.org_1   | 2022-04-08 11:47:47,030 [028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F-StateMachineUpdater] INFO ha.SCMHAManagerImpl: Installing checkpoint with SCMTransactionInfo 2#6
scm2.org_1   | 2022-04-08 11:47:47,034 [grpc-default-executor-0] INFO server.RaftServer$Division: 028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F: inconsistency entries. Reply:088c2e91-0545-411d-8d31-8415832ed844<-028f51fd-62f3-478d-a538-df850a92e5c2#0:FAIL-t2,INCONSISTENCY,nextIndex=7,followerCommit=6
scm1.org_1   | 2022-04-08 11:47:14,477 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
scm3.org_1   | 2022-04-08 11:47:59,212 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
scm1.org_1   | 2022-04-08 11:47:14,477 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2022-04-08 11:47:14,488 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm1.org_1   | 2022-04-08 11:47:14,518 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm3.org_1   | 2022-04-08 11:47:59,297 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
scm3.org_1   | 2022-04-08 11:47:59,343 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm3.org_1   | 2022-04-08 11:47:59,450 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
scm2.org_1   | 2022-04-08 11:47:47,054 [grpc-default-executor-0] INFO server.RaftServer$Division: 028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F: receive installSnapshot: 088c2e91-0545-411d-8d31-8415832ed844->028f51fd-62f3-478d-a538-df850a92e5c2#0-t2,notify:(t:2, i:6)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
scm2.org_1   | 2022-04-08 11:47:47,065 [grpc-default-executor-0] INFO server.RaftServer$Division: 028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F: InstallSnapshot notification result: SNAPSHOT_INSTALLED, at index: 6
s3g_1        | 2022-04-08 12:01:18,319 [qtp1423016050-21] INFO scm.XceiverClientRatis: Could not commit index 129 on pipeline Pipeline[ Id: a6f33c92-47f3-4bcf-8c55-0543fc7274b5, Nodes: 8b7f16e2-5fb9-442f-a717-cc893c5795e0{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}0005597f-3053-4b02-96b8-efe2de95313b{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}4cf3df89-7b36-4576-a18a-5d0c57ddb620{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:4cf3df89-7b36-4576-a18a-5d0c57ddb620, CreationTimestamp2022-04-08T11:48:59.048Z[UTC]] to all the nodes. Server 0005597f-3053-4b02-96b8-efe2de95313b has failed. Committed by majority.
s3g_1        | 2022-04-08 12:01:18,319 [qtp1423016050-21] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 1 locID: 109611004723200049 bcsId: 129 on Pipeline[ Id: a6f33c92-47f3-4bcf-8c55-0543fc7274b5, Nodes: 8b7f16e2-5fb9-442f-a717-cc893c5795e0{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}0005597f-3053-4b02-96b8-efe2de95313b{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}4cf3df89-7b36-4576-a18a-5d0c57ddb620{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:4cf3df89-7b36-4576-a18a-5d0c57ddb620, CreationTimestamp2022-04-08T11:48:59.048Z[UTC]]. Failed nodes: [0005597f-3053-4b02-96b8-efe2de95313b{ip: null, host: null, ports: [], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm1.org_1   | 2022-04-08 11:47:14,519 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
scm2.org_1   | 2022-04-08 11:47:47,072 [grpc-default-executor-0] INFO server.RaftServer$Division: 028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F: set new configuration index: 1
scm2.org_1   | configurationEntry {
scm2.org_1   |   peers {
s3g_1        | 2022-04-08 12:02:27,591 [qtp1423016050-19] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: a6f33c92-47f3-4bcf-8c55-0543fc7274b5, Nodes: 8b7f16e2-5fb9-442f-a717-cc893c5795e0{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}0005597f-3053-4b02-96b8-efe2de95313b{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}4cf3df89-7b36-4576-a18a-5d0c57ddb620{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:4cf3df89-7b36-4576-a18a-5d0c57ddb620, CreationTimestamp2022-04-08T11:48:59.048Z[UTC]]
s3g_1        | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #174 timeout 180s
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
scm1.org_1   | 2022-04-08 11:47:14,528 [pool-14-thread-1] INFO segmented.SegmentedRaftLogWorker: new 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/236d968d-b3de-4c14-8c61-a2ea220fd69f
scm3.org_1   | 2022-04-08 11:48:00,593 [Listener at 0.0.0.0/9961] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm3.org_1   | 2022-04-08 11:48:00,594 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm3.org_1   | 2022-04-08 11:48:00,632 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm3.org_1   | 2022-04-08 11:48:00,640 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm3.org_1   | 2022-04-08 11:48:00,676 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
scm2.org_1   |     id: "088c2e91-0545-411d-8d31-8415832ed844"
scm2.org_1   |     address: "scm1.org:9894"
scm1.org_1   | 2022-04-08 11:47:14,529 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om1_1        | 2022-04-08 11:56:45,538 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:45,541 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
s3g_1        | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:263)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
scm2.org_1   |   }
scm2.org_1   | }
scm3.org_1   | 2022-04-08 11:48:00,678 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
om1_1        | 2022-04-08 11:56:45,549 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm1.org_1   | 2022-04-08 11:47:14,530 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm1.org_1   | 2022-04-08 11:47:14,531 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm2.org_1   |  from snapshot
om1_1        | 2022-04-08 11:56:46,238 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm3.org_1   | 2022-04-08 11:48:00,785 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: 
scm3.org_1   | Container Balancer status:
scm2.org_1   | 2022-04-08 11:47:47,073 [grpc-default-executor-0] INFO server.RaftServer$Division: 028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F: set configuration 1: [088c2e91-0545-411d-8d31-8415832ed844|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.RatisBlockOutputStream.sendWatchForCommit(RatisBlockOutputStream.java:101)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:373)
scm1.org_1   | 2022-04-08 11:47:14,532 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
scm1.org_1   | 2022-04-08 11:47:14,532 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm1.org_1   | 2022-04-08 11:47:14,533 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm1.org_1   | 2022-04-08 11:47:14,534 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om1_1        | 2022-04-08 11:56:46,243 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
scm3.org_1   | Key                            Value
scm2.org_1   | 2022-04-08 11:47:47,083 [grpc-default-executor-0] INFO server.RaftServer$Division: 028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F: reply installSnapshot: 088c2e91-0545-411d-8d31-8415832ed844<-028f51fd-62f3-478d-a538-df850a92e5c2#0:FAIL-t2,SNAPSHOT_INSTALLED,snapshotIndex=6
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-04-08 11:49:33,932 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=d7bff567-93ff-485c-a104-bc074898d12a reported by 0005597f-3053-4b02-96b8-efe2de95313b{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 933750048452, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-04-08 11:49:41,654 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33232
recon_1      | 2022-04-08 11:49:41,695 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 11:49:47,679 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:35648
recon_1      | 2022-04-08 11:49:47,721 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 11:49:47,722 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=d7bff567-93ff-485c-a104-bc074898d12a reported by 8b7f16e2-5fb9-442f-a717-cc893c5795e0{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 932981906868, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-04-08 11:49:47,727 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: d7bff567-93ff-485c-a104-bc074898d12a, Nodes: 0005597f-3053-4b02-96b8-efe2de95313b{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}4cf3df89-7b36-4576-a18a-5d0c57ddb620{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}8b7f16e2-5fb9-442f-a717-cc893c5795e0{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:8b7f16e2-5fb9-442f-a717-cc893c5795e0, CreationTimestamp2022-04-08T11:48:59.171Z[UTC]] moved to OPEN state
recon_1      | 2022-04-08 11:49:50,684 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #1 got from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net.
recon_1      | 2022-04-08 11:49:50,912 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: Successfully added container #1 to Recon.
recon_1      | 2022-04-08 11:49:51,100 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:59332
recon_1      | 2022-04-08 11:49:51,199 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 11:50:20,711 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33358
recon_1      | 2022-04-08 11:50:20,774 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 11:50:21,010 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:35760
recon_1      | 2022-04-08 11:50:21,073 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 11:50:21,097 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:59434
recon_1      | 2022-04-08 11:50:21,107 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm1.org_1   | 2022-04-08 11:47:14,534 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm1.org_1   | 2022-04-08 11:47:14,554 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
scm1.org_1   | 2022-04-08 11:47:14,555 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
scm1.org_1   | 2022-04-08 11:47:14,576 [pool-14-thread-1] INFO server.RaftServer$Division: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F: set configuration 0: [088c2e91-0545-411d-8d31-8415832ed844|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2022-04-08 11:47:14,576 [pool-14-thread-1] INFO segmented.LogSegment: Successfully read 1 entries from segment file /data/metadata/scm-ha/236d968d-b3de-4c14-8c61-a2ea220fd69f/current/log_inprogress_0
scm1.org_1   | 2022-04-08 11:47:14,579 [pool-14-thread-1] INFO segmented.SegmentedRaftLogWorker: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 0
scm1.org_1   | 2022-04-08 11:47:14,579 [pool-14-thread-1] INFO segmented.SegmentedRaftLogWorker: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm1.org_1   | 2022-04-08 11:47:14,642 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm1.org_1   | 2022-04-08 11:47:14,643 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
scm1.org_1   | 2022-04-08 11:47:14,644 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:533)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:547)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:137)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:495)
scm3.org_1   | Running                        false
scm1.org_1   | 2022-04-08 11:47:14,646 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm1.org_1   | 2022-04-08 11:47:14,647 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
scm1.org_1   | 2022-04-08 11:47:14,647 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm1.org_1   | 2022-04-08 11:47:14,686 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
scm1.org_1   | 2022-04-08 11:47:14,686 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
scm1.org_1   | 2022-04-08 11:47:14,686 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
scm1.org_1   | 2022-04-08 11:47:14,851 [main] INFO ha.SequenceIdGenerator: upgrade localId to 109611004723200000
scm1.org_1   | 2022-04-08 11:47:14,851 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
scm2.org_1   | 2022-04-08 11:47:47,089 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 028f51fd-62f3-478d-a538-df850a92e5c2: Completed INSTALL_SNAPSHOT, lastRequest: 088c2e91-0545-411d-8d31-8415832ed844->028f51fd-62f3-478d-a538-df850a92e5c2#0-t2,notify:(t:2, i:6)
scm2.org_1   | 2022-04-08 11:47:47,110 [028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F-StateMachineUpdater] INFO ha.SCMHAManagerImpl: Replaced DB with checkpoint, term: 2, index: 6
scm2.org_1   | 2022-04-08 11:47:47,110 [028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F-StateMachineUpdater] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2022-04-08 11:47:47,156 [028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F-StateMachineUpdater] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm3.org_1   | Container Balancer Configuration values:
scm2.org_1   | 2022-04-08 11:47:47,332 [028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F-StateMachineUpdater] INFO ha.SequenceIdGenerator: reinitialize SequenceIdGenerator.
scm2.org_1   | 2022-04-08 11:47:47,346 [028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
om1_1        | 2022-04-08 11:56:46,246 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:46,253 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-ozone-test-0491738847/ozone-test-0981360713/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 1
om1_1        | partName: "etag1"
om1_1        | , partNumber: 2
om1_1        | partName: "etag2"
om1_1        | ]
om1_1        | 2022-04-08 11:56:46,255 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0981360713/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-0491738847
om1_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-0491738847 key: ozone-test-0981360713/multipartKey3
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:181)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:469)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:522)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:235)
s3g_1        | 	at jdk.internal.reflect.GeneratedMethodAccessor28.invoke(Unknown Source)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
scm3.org_1   | Key                                                Value
scm3.org_1   | Threshold                                          10
scm2.org_1   | 2022-04-08 11:47:47,347 [028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F-StateMachineUpdater] INFO ha.SCMHAManagerImpl: Reloaded SCM state with Term: 2 and Index: 6
recon_1      | 2022-04-08 11:50:33,393 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
scm1.org_1   | 2022-04-08 11:47:14,855 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
scm1.org_1   | 2022-04-08 11:47:14,857 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
scm1.org_1   | 2022-04-08 11:47:14,903 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm2.org_1   | 2022-04-08 11:47:47,348 [028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F-StateMachineUpdater] INFO impl.StateMachineUpdater: 028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F-StateMachineUpdater: snapshotIndex: setUnconditionally -1 -> 6
scm2.org_1   | 2022-04-08 11:47:47,352 [028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F-StateMachineUpdater] INFO impl.StateMachineUpdater: 028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F-StateMachineUpdater: appliedIndex: setUnconditionally -1 -> 6
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm3.org_1   | Max Datanodes to Involve per Iteration(percent)    20
scm3.org_1   | Max Size to Move per Iteration                     500GB
scm1.org_1   | 2022-04-08 11:47:14,914 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm1.org_1   | 2022-04-08 11:47:14,938 [main] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
scm2.org_1   | 2022-04-08 11:47:50,348 [grpc-default-executor-0] INFO server.RaftServer$Division: 028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F: set configuration 7: [088c2e91-0545-411d-8d31-8415832ed844|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 028f51fd-62f3-478d-a538-df850a92e5c2|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=[088c2e91-0545-411d-8d31-8415832ed844|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm2.org_1   | 2022-04-08 11:47:50,360 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F-SegmentedRaftLogWorker: Starting segment from index:7
scm2.org_1   | 2022-04-08 11:47:50,521 [028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/236d968d-b3de-4c14-8c61-a2ea220fd69f/current/log_inprogress_7
scm2.org_1   | 2022-04-08 11:47:50,581 [028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-04-08 11:47:50,582 [028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
scm2.org_1   | 2022-04-08 11:47:50,583 [028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm2.org_1   | 2022-04-08 11:47:50,584 [028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9861
scm2.org_1   | 2022-04-08 11:47:50,596 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm2.org_1   | 2022-04-08 11:47:50,611 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm2.org_1   | 2022-04-08 11:47:50,645 [grpc-default-executor-0] INFO server.RaftServer$Division: 028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F: set configuration 9: [088c2e91-0545-411d-8d31-8415832ed844|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 028f51fd-62f3-478d-a538-df850a92e5c2|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2022-04-08 11:47:50,912 [Listener at 0.0.0.0/9860] INFO ha.SCMHAManagerImpl: Successfully added SCM scm2 to group group-A2EA220FD69F:[088c2e91-0545-411d-8d31-8415832ed844|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 028f51fd-62f3-478d-a538-df850a92e5c2|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0]
scm2.org_1   | 2022-04-08 11:47:50,921 [Listener at 0.0.0.0/9860] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
scm2.org_1   | 2022-04-08 11:47:50,923 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Starting token manager
scm1.org_1   | 2022-04-08 11:47:14,968 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
scm2.org_1   | 2022-04-08 11:47:50,923 [Listener at 0.0.0.0/9860] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
scm2.org_1   | 2022-04-08 11:47:51,193 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm1.org_1   | 2022-04-08 11:47:14,973 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
recon_1      | 2022-04-08 11:50:33,394 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
scm2.org_1   | 2022-04-08 11:47:51,223 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm1.org_1   | 2022-04-08 11:47:14,974 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
scm3.org_1   | Max Size Entering Target per Iteration             26GB
om1_1        | 2022-04-08 11:56:46,875 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:46,878 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:46,881 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:46,890 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-ozone-test-0491738847/ozone-test-0981360713/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 2
om1_1        | partName: "etag1"
om1_1        | , partNumber: 1
om1_1        | partName: "etag2"
om1_1        | ]
om1_1        | 2022-04-08 11:56:46,897 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0981360713/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-0491738847
om1_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-0491738847 key: ozone-test-0981360713/multipartKey3
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:181)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
scm3.org_1   | Max Size Leaving Source per Iteration              26GB
scm3.org_1   | 
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
scm2.org_1   | 2022-04-08 11:47:51,223 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm2.org_1   | 2022-04-08 11:47:51,465 [028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
scm3.org_1   | 2022-04-08 11:48:00,785 [Listener at 0.0.0.0/9860] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm3.org_1   | 2022-04-08 11:48:00,785 [Listener at 0.0.0.0/9860] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
scm3.org_1   | 2022-04-08 11:48:00,791 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm3.org_1   | 2022-04-08 11:48:00,794 [Listener at 0.0.0.0/9860] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
recon_1      | 2022-04-08 11:50:33,433 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
scm3.org_1   | 2022-04-08 11:48:00,794 [Listener at 0.0.0.0/9860] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: start with initializing state, conf=-1: [], old=null
scm3.org_1   | 2022-04-08 11:48:00,816 [Listener at 0.0.0.0/9860] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: changes role from      null to FOLLOWER at term 0 for startInitializing
scm3.org_1   | 2022-04-08 11:48:00,817 [Listener at 0.0.0.0/9860] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A2EA220FD69F,id=9ebec731-0724-46e8-adb1-25fbc2c43c85
scm3.org_1   | 2022-04-08 11:48:00,832 [Listener at 0.0.0.0/9860] INFO server.RaftServer: 9ebec731-0724-46e8-adb1-25fbc2c43c85: start RPC server
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
scm1.org_1   | 2022-04-08 11:47:15,006 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
scm1.org_1   | 2022-04-08 11:47:15,021 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
scm3.org_1   | 2022-04-08 11:48:00,872 [Listener at 0.0.0.0/9860] INFO server.GrpcService: 9ebec731-0724-46e8-adb1-25fbc2c43c85: GrpcService started, listening on 9894
scm3.org_1   | 2022-04-08 11:48:00,882 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$418/0x0000000840527c40@247877f3] INFO util.JvmPauseMonitor: JvmPauseMonitor-9ebec731-0724-46e8-adb1-25fbc2c43c85: Started
scm3.org_1   | 2022-04-08 11:48:00,882 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
scm3.org_1   | 2022-04-08 11:48:00,884 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
scm3.org_1   | 2022-04-08 11:48:00,884 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
scm2.org_1   | 2022-04-08 11:47:51,465 [028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F-StateMachineUpdater] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
scm2.org_1   | 2022-04-08 11:47:51,465 [028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F-StateMachineUpdater] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm3.org_1   | 2022-04-08 11:48:04,154 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: receive installSnapshot: 088c2e91-0545-411d-8d31-8415832ed844->9ebec731-0724-46e8-adb1-25fbc2c43c85#0-t2,notify:(t:2, i:12)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
scm2.org_1   | 2022-04-08 11:47:51,687 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm2.org_1   | 2022-04-08 11:47:51,688 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1679)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
scm1.org_1   | 2022-04-08 11:47:15,045 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
scm1.org_1   | 2022-04-08 11:47:15,055 [main] INFO container.ReplicationManager: Starting Replication Monitor Thread.
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
scm1.org_1   | 2022-04-08 11:47:15,065 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
scm1.org_1   | 2022-04-08 11:47:15,066 [ReplicationMonitor] INFO container.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm3.org_1   | 2022-04-08 11:48:04,203 [grpc-default-executor-0] INFO ha.SCMStateMachine: leader changed, yet current SCM is still follower.
scm3.org_1   | 2022-04-08 11:48:04,204 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: change Leader from null to 088c2e91-0545-411d-8d31-8415832ed844 at term 2 for installSnapshot, leader elected after 6154ms
scm3.org_1   | 2022-04-08 11:48:04,224 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: Received notification to install snapshot at index 12
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
om1_1        | 2022-04-08 11:56:47,559 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:47,561 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:47,563 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm2.org_1   | 2022-04-08 11:47:51,696 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm2.org_1   | 2022-04-08 11:47:51,766 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
scm3.org_1   | 2022-04-08 11:48:04,395 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: notifyInstallSnapshot: nextIndex is 0 but the leader's first available index is 12.
om1_1        | 2022-04-08 11:56:47,593 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:50,328 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
scm2.org_1   | 2022-04-08 11:47:51,768 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm3.org_1   | 2022-04-08 11:48:04,416 [grpc-default-executor-0] INFO ha.SCMStateMachine: Received install snapshot notification from SCM leader: scm1.org:9894 with term index: (t:2, i:12)
scm3.org_1   | 2022-04-08 11:48:04,459 [pool-16-thread-1] INFO ha.SCMHAManagerImpl: Downloading checkpoint from leader SCM scm1 and reloading state from the checkpoint.
scm1.org_1   | 2022-04-08 11:47:15,069 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-04-08 11:47:15,072 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm1.org_1   | 2022-04-08 11:47:15,095 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
scm1.org_1   | 2022-04-08 11:47:15,118 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
scm1.org_1   | 2022-04-08 11:47:15,119 [main] INFO server.StorageContainerManager: Storing sub-ca certificate serialId 848180596473 on primary SCM
scm1.org_1   | 2022-04-08 11:47:15,125 [main] INFO server.StorageContainerManager: Storing root certificate serialId 1
om1_1        | 2022-04-08 11:56:50,992 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm1.org_1   | 2022-04-08 11:47:15,158 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm1.org_1   | 2022-04-08 11:47:15,199 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
scm2.org_1   | 2022-04-08 11:47:51,769 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm2.org_1   | 2022-04-08 11:47:51,770 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm3.org_1   | 2022-04-08 11:48:06,805 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: set new configuration index: 9
scm3.org_1   | configurationEntry {
scm3.org_1   |   peers {
scm3.org_1   |     id: "088c2e91-0545-411d-8d31-8415832ed844"
scm3.org_1   |     address: "scm1.org:9894"
scm3.org_1   |   }
scm3.org_1   |   peers {
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
scm1.org_1   | 2022-04-08 11:47:15,870 [Listener at 0.0.0.0/9961] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm1.org_1   | 2022-04-08 11:47:15,871 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm1.org_1   | 2022-04-08 11:47:15,894 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
om1_1        | 2022-04-08 11:56:50,995 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:50,999 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:51,021 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:51,415 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:52,300 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:52,306 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:52,311 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm1.org_1   | 2022-04-08 11:47:15,903 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm1.org_1   | 2022-04-08 11:47:15,928 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm1.org_1   | 2022-04-08 11:47:15,943 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
om1_1        | 2022-04-08 11:56:52,335 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:52,423 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:53,032 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:53,037 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
scm1.org_1   | 2022-04-08 11:47:16,022 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: 
scm1.org_1   | Container Balancer status:
scm2.org_1   | 2022-04-08 11:47:51,799 [Listener at 0.0.0.0/9860] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
scm2.org_1   | 2022-04-08 11:47:51,800 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm2.org_1   | 2022-04-08 11:47:51,800 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
scm2.org_1   | 2022-04-08 11:47:51,800 [Listener at 0.0.0.0/9860] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService starting
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm3.org_1   |     id: "028f51fd-62f3-478d-a538-df850a92e5c2"
scm3.org_1   |     address: "scm2.org:9894"
scm3.org_1   |   }
scm3.org_1   | }
scm3.org_1   |  from snapshot
scm3.org_1   | 2022-04-08 11:48:06,822 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: set configuration 9: [088c2e91-0545-411d-8d31-8415832ed844|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 028f51fd-62f3-478d-a538-df850a92e5c2|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-04-08 11:48:06,834 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: reply installSnapshot: 088c2e91-0545-411d-8d31-8415832ed844<-9ebec731-0724-46e8-adb1-25fbc2c43c85#0:FAIL-t0,IN_PROGRESS
scm3.org_1   | 2022-04-08 11:48:06,889 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 9ebec731-0724-46e8-adb1-25fbc2c43c85: Completed INSTALL_SNAPSHOT, lastRequest: 088c2e91-0545-411d-8d31-8415832ed844->9ebec731-0724-46e8-adb1-25fbc2c43c85#0-t2,notify:(t:2, i:12)
om1_1        | 2022-04-08 11:56:53,041 [IPC Server handler 43 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:53,049 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0981360713/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-0491738847
scm1.org_1   | Key                            Value
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
scm2.org_1   | 2022-04-08 11:47:51,858 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
scm2.org_1   | 2022-04-08 11:47:51,859 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
scm3.org_1   | 2022-04-08 11:48:07,044 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: receive installSnapshot: 088c2e91-0545-411d-8d31-8415832ed844->9ebec731-0724-46e8-adb1-25fbc2c43c85#0-t2,notify:(t:2, i:12)
scm3.org_1   | 2022-04-08 11:48:07,068 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: set new configuration index: 9
om1_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-0491738847 key: ozone-test-0981360713/multipartKey3. Provided Part info is { etag1, 1}, whereas OM has partName /s3v/bucket-ozone-test-0491738847/ozone-test-0981360713/multipartKey3-264276c9-564f-4799-903a-1c9a411a4b2c-108096323947724836-1
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:495)
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:192)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
scm1.org_1   | Running                        false
scm3.org_1   | configurationEntry {
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
scm2.org_1   | 2022-04-08 11:47:51,859 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
scm2.org_1   | 2022-04-08 11:47:52,114 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6b886e86] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm1.org_1   | Container Balancer Configuration values:
scm1.org_1   | Key                                                Value
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
scm2.org_1   | 2022-04-08 11:47:52,136 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm1.org_1   | Threshold                                          10
scm1.org_1   | Max Datanodes to Involve per Iteration(percent)    20
scm1.org_1   | Max Size to Move per Iteration                     500GB
scm2.org_1   | 2022-04-08 11:47:52,137 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
scm1.org_1   | Max Size Entering Target per Iteration             26GB
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm3.org_1   |   peers {
scm3.org_1   |     id: "088c2e91-0545-411d-8d31-8415832ed844"
scm3.org_1   |     address: "scm1.org:9894"
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
scm3.org_1   |   }
scm2.org_1   | 2022-04-08 11:47:52,138 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
scm1.org_1   | Max Size Leaving Source per Iteration              26GB
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-04-08 11:56:53,602 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:53,610 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:53,613 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:53,621 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0981360713/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-0491738847
om1_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-0491738847 key: ozone-test-0981360713/multipartKey3. Provided Part info is { etag2, 2}, whereas OM has partName /s3v/bucket-ozone-test-0491738847/ozone-test-0981360713/multipartKey3-264276c9-564f-4799-903a-1c9a411a4b2c-108096323947724836-2
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:495)
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:192)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
scm3.org_1   |   peers {
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
scm1.org_1   | 
scm1.org_1   | 2022-04-08 11:47:16,023 [Listener at 0.0.0.0/9860] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm1.org_1   | 2022-04-08 11:47:16,023 [Listener at 0.0.0.0/9860] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
scm1.org_1   | 2022-04-08 11:47:16,025 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
om1_1        | 2022-04-08 11:56:54,212 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:54,214 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm3.org_1   |     id: "028f51fd-62f3-478d-a538-df850a92e5c2"
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
scm2.org_1   | 2022-04-08 11:47:52,186 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @21883ms to org.eclipse.jetty.util.log.Slf4jLog
scm2.org_1   | 2022-04-08 11:47:52,363 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm2.org_1   | 2022-04-08 11:47:52,375 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm2.org_1   | 2022-04-08 11:47:52,376 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
scm2.org_1   | 2022-04-08 11:47:52,376 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
scm2.org_1   | 2022-04-08 11:47:52,376 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
scm2.org_1   | 2022-04-08 11:47:52,380 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
scm1.org_1   | 2022-04-08 11:47:16,026 [Listener at 0.0.0.0/9860] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
scm2.org_1   | 2022-04-08 11:47:52,446 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
scm2.org_1   | 2022-04-08 11:47:52,447 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
scm2.org_1   | 2022-04-08 11:47:52,514 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm2.org_1   | 2022-04-08 11:47:52,514 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm2.org_1   | 2022-04-08 11:47:52,516 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 600000ms
scm2.org_1   | 2022-04-08 11:47:52,575 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm2.org_1   | 2022-04-08 11:47:52,578 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@31881213{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm2.org_1   | 2022-04-08 11:47:52,584 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@16e6a643{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm2.org_1   | 2022-04-08 11:47:52,813 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm2.org_1   | 2022-04-08 11:47:52,832 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@b997735{scm,/,file:///tmp/jetty-0_0_0_0-9876-hdds-server-scm-1_3_0-SNAPSHOT_jar-_-any-17310300252615132463/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/scm}
scm1.org_1   | 2022-04-08 11:47:16,027 [Listener at 0.0.0.0/9860] INFO server.RaftServer$Division: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F: start as a follower, conf=0: [088c2e91-0545-411d-8d31-8415832ed844|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1        | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #174 timeout 180s
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:368)
scm1.org_1   | 2022-04-08 11:47:16,040 [Listener at 0.0.0.0/9860] INFO server.RaftServer$Division: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F: changes role from      null to FOLLOWER at term 1 for startAsFollower
s3g_1        | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:373)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:368)
scm3.org_1   |     address: "scm2.org:9894"
om1_1        | 2022-04-08 11:56:54,217 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:54,230 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: PartNumber at index 1 is 2, and its previous partNumber at index 0 is 4 for ozonekey is /s3v/bucket-ozone-test-0491738847/ozone-test-0981360713/multipartKey3
om1_1        | 2022-04-08 11:56:54,231 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0981360713/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-0491738847
scm1.org_1   | 2022-04-08 11:47:16,041 [Listener at 0.0.0.0/9860] INFO impl.RoleInfo: 088c2e91-0545-411d-8d31-8415832ed844: start 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-FollowerState
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
om1_1        | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-0491738847 key: ozone-test-0981360713/multipartKey3 because parts are in Invalid order.
scm2.org_1   | 2022-04-08 11:47:52,844 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@3df88502{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:357)
scm1.org_1   | 2022-04-08 11:47:16,052 [Listener at 0.0.0.0/9860] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A2EA220FD69F,id=088c2e91-0545-411d-8d31-8415832ed844
scm1.org_1   | 2022-04-08 11:47:16,063 [Listener at 0.0.0.0/9860] INFO server.RaftServer: 088c2e91-0545-411d-8d31-8415832ed844: start RPC server
scm1.org_1   | 2022-04-08 11:47:16,200 [Listener at 0.0.0.0/9860] INFO server.GrpcService: 088c2e91-0545-411d-8d31-8415832ed844: GrpcService started, listening on 9894
scm1.org_1   | 2022-04-08 11:47:16,210 [Listener at 0.0.0.0/9860] INFO ha.SCMHAManagerImpl:  scm role is FOLLOWER peers [088c2e91-0545-411d-8d31-8415832ed844|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm1.org_1   | 2022-04-08 11:47:16,211 [Listener at 0.0.0.0/9860] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
scm1.org_1   | 2022-04-08 11:47:16,212 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Starting token manager
scm1.org_1   | 2022-04-08 11:47:16,212 [Listener at 0.0.0.0/9860] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
scm1.org_1   | 2022-04-08 11:47:16,227 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$437/0x0000000840547c40@b21cbbf] INFO util.JvmPauseMonitor: JvmPauseMonitor-088c2e91-0545-411d-8d31-8415832ed844: Started
scm1.org_1   | 2022-04-08 11:47:16,310 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm1.org_1   | 2022-04-08 11:47:16,322 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm1.org_1   | 2022-04-08 11:47:16,323 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm1.org_1   | 2022-04-08 11:47:16,622 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm1.org_1   | 2022-04-08 11:47:16,623 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm1.org_1   | 2022-04-08 11:47:16,625 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm1.org_1   | 2022-04-08 11:47:16,646 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm1.org_1   | 2022-04-08 11:47:16,651 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm1.org_1   | 2022-04-08 11:47:16,652 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
scm3.org_1   |   }
scm3.org_1   | }
scm3.org_1   |  from snapshot
scm3.org_1   | 2022-04-08 11:48:07,068 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: set configuration 9: [088c2e91-0545-411d-8d31-8415832ed844|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 028f51fd-62f3-478d-a538-df850a92e5c2|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-04-08 11:48:07,069 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: reply installSnapshot: 088c2e91-0545-411d-8d31-8415832ed844<-9ebec731-0724-46e8-adb1-25fbc2c43c85#0:FAIL-t2,IN_PROGRESS
scm3.org_1   | 2022-04-08 11:48:07,070 [grpc-default-executor-2] INFO impl.RoleInfo: 9ebec731-0724-46e8-adb1-25fbc2c43c85: start 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F-FollowerState
scm3.org_1   | 2022-04-08 11:48:07,076 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 9ebec731-0724-46e8-adb1-25fbc2c43c85: Completed INSTALL_SNAPSHOT, lastRequest: 088c2e91-0545-411d-8d31-8415832ed844->9ebec731-0724-46e8-adb1-25fbc2c43c85#0-t2,notify:(t:2, i:12)
scm3.org_1   | 2022-04-08 11:48:07,094 [grpc-default-executor-2] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: Failed appendEntries as snapshot (12) installation is in progress
scm3.org_1   | 2022-04-08 11:48:07,140 [grpc-default-executor-2] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: inconsistency entries. Reply:088c2e91-0545-411d-8d31-8415832ed844<-9ebec731-0724-46e8-adb1-25fbc2c43c85#0:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
scm2.org_1   | 2022-04-08 11:47:52,844 [Listener at 0.0.0.0/9860] INFO server.Server: Started @22541ms
scm2.org_1   | 2022-04-08 11:47:52,846 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm2.org_1   | 2022-04-08 11:47:52,846 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm2.org_1   | 2022-04-08 11:47:52,848 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm2.org_1   | 2022-04-08 11:48:12,208 [grpc-default-executor-0] INFO server.RaftServer$Division: 028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F: set configuration 13: [088c2e91-0545-411d-8d31-8415832ed844|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 9ebec731-0724-46e8-adb1-25fbc2c43c85|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0, 028f51fd-62f3-478d-a538-df850a92e5c2|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=[088c2e91-0545-411d-8d31-8415832ed844|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 028f51fd-62f3-478d-a538-df850a92e5c2|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0]
scm2.org_1   | 2022-04-08 11:48:12,257 [grpc-default-executor-0] INFO server.RaftServer$Division: 028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F: set configuration 15: [088c2e91-0545-411d-8d31-8415832ed844|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 9ebec731-0724-46e8-adb1-25fbc2c43c85|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0, 028f51fd-62f3-478d-a538-df850a92e5c2|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2022-04-08 11:48:28,398 [028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-04-08 11:48:29,141 [028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-04-08 11:48:31,818 [028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-04-08 11:48:36,192 [028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-04-08 11:48:36,754 [028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-04-08 11:48:37,703 [028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-04-08 11:48:51,644 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47984
scm2.org_1   | 2022-04-08 11:48:51,712 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 11:48:52,071 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$421/0x0000000840527040@80081d7] WARN util.JvmPauseMonitor: JvmPauseMonitor-028f51fd-62f3-478d-a538-df850a92e5c2: Detected pause in JVM or host machine (eg GC): pause of approximately 206189163ns.
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getPartsListSize(S3MultipartUploadCompleteRequest.java:461)
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:188)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
scm3.org_1   | 2022-04-08 11:48:07,162 [grpc-default-executor-0] INFO ha.InterSCMGrpcClient: Checkpoint is downloaded to /data/metadata/snapshot/scm.db-scm1-1649418484461.tar.gz
scm3.org_1   | 2022-04-08 11:48:07,250 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: Failed appendEntries as snapshot (12) installation is in progress
scm3.org_1   | 2022-04-08 11:48:07,250 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: inconsistency entries. Reply:088c2e91-0545-411d-8d31-8415832ed844<-9ebec731-0724-46e8-adb1-25fbc2c43c85#1:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
scm3.org_1   | 2022-04-08 11:48:07,257 [grpc-default-executor-2] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: receive installSnapshot: 088c2e91-0545-411d-8d31-8415832ed844->9ebec731-0724-46e8-adb1-25fbc2c43c85#0-t2,notify:(t:2, i:12)
scm3.org_1   | 2022-04-08 11:48:07,268 [grpc-default-executor-2] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: set new configuration index: 9
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
s3g_1        | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1        | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1        | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1        | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1        | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1        | 	... 1 more
s3g_1        | 2022-04-08 12:02:27,598 [qtp1423016050-19] INFO scm.XceiverClientRatis: Could not commit index 132 on pipeline Pipeline[ Id: a6f33c92-47f3-4bcf-8c55-0543fc7274b5, Nodes: 8b7f16e2-5fb9-442f-a717-cc893c5795e0{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}0005597f-3053-4b02-96b8-efe2de95313b{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}4cf3df89-7b36-4576-a18a-5d0c57ddb620{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:4cf3df89-7b36-4576-a18a-5d0c57ddb620, CreationTimestamp2022-04-08T11:48:59.048Z[UTC]] to all the nodes. Server 0005597f-3053-4b02-96b8-efe2de95313b has failed. Committed by majority.
s3g_1        | 2022-04-08 12:02:27,603 [qtp1423016050-19] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 1 locID: 109611004723200052 bcsId: 132 on Pipeline[ Id: a6f33c92-47f3-4bcf-8c55-0543fc7274b5, Nodes: 8b7f16e2-5fb9-442f-a717-cc893c5795e0{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}0005597f-3053-4b02-96b8-efe2de95313b{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}4cf3df89-7b36-4576-a18a-5d0c57ddb620{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:4cf3df89-7b36-4576-a18a-5d0c57ddb620, CreationTimestamp2022-04-08T11:48:59.048Z[UTC]]. Failed nodes: [0005597f-3053-4b02-96b8-efe2de95313b{ip: null, host: null, ports: [], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1        | 2022-04-08 12:03:28,255 [qtp1423016050-22] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: a6f33c92-47f3-4bcf-8c55-0543fc7274b5, Nodes: 8b7f16e2-5fb9-442f-a717-cc893c5795e0{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}0005597f-3053-4b02-96b8-efe2de95313b{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}4cf3df89-7b36-4576-a18a-5d0c57ddb620{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:4cf3df89-7b36-4576-a18a-5d0c57ddb620, CreationTimestamp2022-04-08T11:48:59.048Z[UTC]]
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-04-08 11:56:54,828 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm3.org_1   | configurationEntry {
scm3.org_1   |   peers {
scm1.org_1   | 2022-04-08 11:47:16,653 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
s3g_1        | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #178 timeout 180s
recon_1      | 2022-04-08 11:50:50,738 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33444
om1_1        | 2022-04-08 11:56:54,831 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:54,833 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
recon_1      | 2022-04-08 11:50:50,804 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 11:50:51,035 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:35852
recon_1      | 2022-04-08 11:50:51,060 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:59526
recon_1      | 2022-04-08 11:50:51,075 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm3.org_1   |     id: "088c2e91-0545-411d-8d31-8415832ed844"
scm3.org_1   |     address: "scm1.org:9894"
scm1.org_1   | 2022-04-08 11:47:16,673 [Listener at 0.0.0.0/9860] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
scm2.org_1   | GC pool 'ParNew' had collection(s): count=1 time=223ms
scm3.org_1   |   }
scm3.org_1   |   peers {
scm3.org_1   |     id: "028f51fd-62f3-478d-a538-df850a92e5c2"
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
om1_1        | 2022-04-08 11:56:55,425 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:55,428 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm2.org_1   | 2022-04-08 11:48:53,977 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55188
scm3.org_1   |     address: "scm2.org:9894"
scm3.org_1   |   }
om1_1        | 2022-04-08 11:56:55,432 [IPC Server handler 86 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm1.org_1   | 2022-04-08 11:47:16,679 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm2.org_1   | 2022-04-08 11:48:54,166 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | }
recon_1      | 2022-04-08 11:50:51,102 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 11:51:20,719 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33554
recon_1      | 2022-04-08 11:51:20,733 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 11:51:21,067 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:59634
recon_1      | 2022-04-08 11:51:21,071 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:35958
recon_1      | 2022-04-08 11:51:21,102 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm1.org_1   | 2022-04-08 11:47:16,680 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
scm1.org_1   | 2022-04-08 11:47:16,680 [Listener at 0.0.0.0/9860] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService starting
scm1.org_1   | 2022-04-08 11:47:16,763 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@37227aa7] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm1.org_1   | 2022-04-08 11:47:16,773 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm1.org_1   | 2022-04-08 11:47:16,773 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
scm1.org_1   | 2022-04-08 11:47:16,774 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
scm2.org_1   | 2022-04-08 11:48:55,590 [IPC Server handler 4 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/8b7f16e2-5fb9-442f-a717-cc893c5795e0
recon_1      | 2022-04-08 11:51:21,125 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 11:51:33,434 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1        | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:263)
om1_1        | 2022-04-08 11:56:55,538 [IPC Server handler 99 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:56,390 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:56,392 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:56,394 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:57,003 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm1.org_1   | 2022-04-08 11:47:16,797 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @5616ms to org.eclipse.jetty.util.log.Slf4jLog
scm3.org_1   |  from snapshot
scm3.org_1   | 2022-04-08 11:48:07,270 [grpc-default-executor-2] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: set configuration 9: [088c2e91-0545-411d-8d31-8415832ed844|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 028f51fd-62f3-478d-a538-df850a92e5c2|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-04-08 11:48:07,270 [grpc-default-executor-2] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: reply installSnapshot: 088c2e91-0545-411d-8d31-8415832ed844<-9ebec731-0724-46e8-adb1-25fbc2c43c85#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2022-04-08 11:47:16,878 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm1.org_1   | 2022-04-08 11:47:16,884 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om1_1        | 2022-04-08 11:56:57,005 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm3.org_1   | 2022-04-08 11:48:07,283 [grpc-default-executor-2] INFO server.GrpcServerProtocolService: 9ebec731-0724-46e8-adb1-25fbc2c43c85: Completed INSTALL_SNAPSHOT, lastRequest: 088c2e91-0545-411d-8d31-8415832ed844->9ebec731-0724-46e8-adb1-25fbc2c43c85#0-t2,notify:(t:2, i:12)
scm3.org_1   | 2022-04-08 11:48:07,362 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: Failed appendEntries as snapshot (12) installation is in progress
scm3.org_1   | 2022-04-08 11:48:07,368 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: inconsistency entries. Reply:088c2e91-0545-411d-8d31-8415832ed844<-9ebec731-0724-46e8-adb1-25fbc2c43c85#2:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm3.org_1   | 2022-04-08 11:48:07,372 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: receive installSnapshot: 088c2e91-0545-411d-8d31-8415832ed844->9ebec731-0724-46e8-adb1-25fbc2c43c85#0-t2,notify:(t:2, i:12)
scm3.org_1   | 2022-04-08 11:48:07,384 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: set new configuration index: 9
recon_1      | 2022-04-08 11:51:33,434 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-04-08 11:51:33,493 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
scm3.org_1   | configurationEntry {
scm3.org_1   |   peers {
scm2.org_1   | 2022-04-08 11:48:55,648 [IPC Server handler 4 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 8b7f16e2-5fb9-442f-a717-cc893c5795e0{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 932981906868, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
scm1.org_1   | 2022-04-08 11:47:16,885 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
scm1.org_1   | 2022-04-08 11:47:16,886 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
scm1.org_1   | 2022-04-08 11:47:16,886 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
scm1.org_1   | 2022-04-08 11:47:16,888 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
scm1.org_1   | 2022-04-08 11:47:16,918 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
scm3.org_1   |     id: "088c2e91-0545-411d-8d31-8415832ed844"
om1_1        | 2022-04-08 11:56:57,011 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
scm2.org_1   | 2022-04-08 11:48:55,736 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.RatisBlockOutputStream.sendWatchForCommit(RatisBlockOutputStream.java:101)
om1_1        | 2022-04-08 11:56:57,598 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
scm1.org_1   | 2022-04-08 11:47:16,919 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
scm2.org_1   | 2022-04-08 11:48:55,818 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
scm2.org_1   | 2022-04-08 11:48:55,997 [IPC Server handler 69 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/0005597f-3053-4b02-96b8-efe2de95313b
scm3.org_1   |     address: "scm1.org:9894"
scm3.org_1   |   }
om1_1        | 2022-04-08 11:56:57,600 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:57,602 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm1.org_1   | 2022-04-08 11:47:16,944 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm2.org_1   | 2022-04-08 11:48:56,011 [IPC Server handler 69 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 0005597f-3053-4b02-96b8-efe2de95313b{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 933750048452, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm2.org_1   | 2022-04-08 11:48:56,012 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm2.org_1   | 2022-04-08 11:48:56,012 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:373)
om1_1        | 2022-04-08 11:56:57,608 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadAbortRequest: Abort Multipart request is failed for KeyName ozone-test-7878972111/multipartKey5 in VolumeName/Bucket s3v/bucket-ozone-test-0491738847
om1_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: s3vbucket: bucket-ozone-test-0491738847key: ozone-test-7878972111/multipartKey5
scm2.org_1   | 2022-04-08 11:48:56,990 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46174
scm1.org_1   | 2022-04-08 11:47:16,945 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm1.org_1   | 2022-04-08 11:47:16,946 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 600000ms
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:533)
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:154)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
scm2.org_1   | 2022-04-08 11:48:57,138 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:547)
scm1.org_1   | 2022-04-08 11:47:16,959 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm1.org_1   | 2022-04-08 11:47:16,964 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@761d3c20{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm2.org_1   | 2022-04-08 11:48:57,875 [028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: a76fa8e1-27b1-4e30-acd2-3b267e60a22d, Nodes: 8b7f16e2-5fb9-442f-a717-cc893c5795e0{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-04-08T11:48:56.511Z[UTC]].
s3g_1        | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:137)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:495)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:469)
scm3.org_1   |   peers {
scm3.org_1   |     id: "028f51fd-62f3-478d-a538-df850a92e5c2"
scm3.org_1   |     address: "scm2.org:9894"
scm3.org_1   |   }
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
scm2.org_1   | 2022-04-08 11:48:57,885 [028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | }
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm3.org_1   |  from snapshot
scm3.org_1   | 2022-04-08 11:48:07,385 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: set configuration 9: [088c2e91-0545-411d-8d31-8415832ed844|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 028f51fd-62f3-478d-a538-df850a92e5c2|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-04-08 11:48:07,386 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: reply installSnapshot: 088c2e91-0545-411d-8d31-8415832ed844<-9ebec731-0724-46e8-adb1-25fbc2c43c85#0:FAIL-t2,IN_PROGRESS
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm2.org_1   | 2022-04-08 11:48:58,008 [028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 8c48fa47-1e15-404a-9159-e49e3da5df9c, Nodes: 0005597f-3053-4b02-96b8-efe2de95313b{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-04-08T11:48:57.726Z[UTC]].
scm1.org_1   | 2022-04-08 11:47:16,965 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@d65ba64{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm1.org_1   | 2022-04-08 11:47:17,059 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-04-08 11:56:58,187 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm1.org_1   | 2022-04-08 11:47:17,069 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@761d679f{scm,/,file:///tmp/jetty-0_0_0_0-9876-hdds-server-scm-1_3_0-SNAPSHOT_jar-_-any-494506888932199037/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/scm}
scm3.org_1   | 2022-04-08 11:48:07,391 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 9ebec731-0724-46e8-adb1-25fbc2c43c85: Completed INSTALL_SNAPSHOT, lastRequest: 088c2e91-0545-411d-8d31-8415832ed844->9ebec731-0724-46e8-adb1-25fbc2c43c85#0-t2,notify:(t:2, i:12)
scm3.org_1   | 2022-04-08 11:48:07,431 [pool-16-thread-1] INFO ha.SCMSnapshotProvider: Successfully downloaded latest checkpoint from leader SCM: scm1 path /data/metadata/snapshot/scm.db-scm1-1649418484461
scm3.org_1   | 2022-04-08 11:48:07,439 [pool-16-thread-1] INFO ha.SCMHAManagerImpl: Downloaded checkpoint from Leader scm1 to the location /data/metadata/snapshot/scm.db-scm1-1649418484461
scm3.org_1   | 2022-04-08 11:48:07,446 [grpc-default-executor-2] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: Failed appendEntries as snapshot (12) installation is in progress
scm3.org_1   | 2022-04-08 11:48:07,454 [grpc-default-executor-2] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: inconsistency entries. Reply:088c2e91-0545-411d-8d31-8415832ed844<-9ebec731-0724-46e8-adb1-25fbc2c43c85#3:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:522)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
om1_1        | 2022-04-08 11:56:58,189 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:58,191 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
scm3.org_1   | 2022-04-08 11:48:07,487 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: receive installSnapshot: 088c2e91-0545-411d-8d31-8415832ed844->9ebec731-0724-46e8-adb1-25fbc2c43c85#0-t2,notify:(t:2, i:12)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:235)
s3g_1        | 	at jdk.internal.reflect.GeneratedMethodAccessor28.invoke(Unknown Source)
om1_1        | 2022-04-08 11:56:58,201 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyCreateRequest: Key creation failed. Volume:s3v, Bucket:bucket-ozone-test-0491738847, Key:ozone-test-2269842426/multipartKey. 
om1_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
scm1.org_1   | 2022-04-08 11:47:17,078 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@4ca83ec3{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
scm1.org_1   | 2022-04-08 11:47:17,078 [Listener at 0.0.0.0/9860] INFO server.Server: Started @5898ms
scm3.org_1   | 2022-04-08 11:48:07,496 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: set new configuration index: 9
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
scm1.org_1   | 2022-04-08 11:47:17,081 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm1.org_1   | 2022-04-08 11:47:17,081 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartFileInfo(OMKeyRequest.java:757)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
scm2.org_1   | 2022-04-08 11:48:58,010 [028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-04-08 11:48:58,850 [IPC Server handler 4 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/4cf3df89-7b36-4576-a18a-5d0c57ddb620
scm2.org_1   | 2022-04-08 11:48:58,851 [IPC Server handler 4 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 4cf3df89-7b36-4576-a18a-5d0c57ddb620{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 936508841118, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm3.org_1   | configurationEntry {
scm3.org_1   |   peers {
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareFileInfo(OMKeyRequest.java:646)
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:623)
scm2.org_1   | 2022-04-08 11:48:58,851 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm3.org_1   |     id: "088c2e91-0545-411d-8d31-8415832ed844"
scm3.org_1   |     address: "scm1.org:9894"
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
scm2.org_1   | 2022-04-08 11:48:58,853 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
scm3.org_1   |   }
scm3.org_1   |   peers {
scm1.org_1   | 2022-04-08 11:47:17,083 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm1.org_1   | 2022-04-08 11:47:17,480 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41740
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyCreateRequest.validateAndUpdateCache(OMKeyCreateRequest.java:267)
scm2.org_1   | 2022-04-08 11:48:58,853 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm2.org_1   | 2022-04-08 11:48:58,853 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm2.org_1   | 2022-04-08 11:48:58,853 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm2.org_1   | 2022-04-08 11:48:58,865 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
scm1.org_1   | 2022-04-08 11:47:17,517 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm3.org_1   |     id: "028f51fd-62f3-478d-a538-df850a92e5c2"
scm3.org_1   |     address: "scm2.org:9894"
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm2.org_1   | 2022-04-08 11:48:58,865 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm3.org_1   |   }
scm3.org_1   | }
scm3.org_1   |  from snapshot
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
scm1.org_1   | 2022-04-08 11:47:19,130 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:60584
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
scm1.org_1   | 2022-04-08 11:47:19,161 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
scm1.org_1   | 2022-04-08 11:47:20,049 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:35255
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
scm3.org_1   | 2022-04-08 11:48:07,496 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: set configuration 9: [088c2e91-0545-411d-8d31-8415832ed844|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 028f51fd-62f3-478d-a538-df850a92e5c2|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-04-08 11:48:07,499 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: reply installSnapshot: 088c2e91-0545-411d-8d31-8415832ed844<-9ebec731-0724-46e8-adb1-25fbc2c43c85#0:FAIL-t2,IN_PROGRESS
scm2.org_1   | 2022-04-08 11:48:58,989 [028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: cfd3e9b8-6c85-4577-8ecd-7af890cf2706, Nodes: 4cf3df89-7b36-4576-a18a-5d0c57ddb620{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-04-08T11:48:58.915Z[UTC]].
scm1.org_1   | 2022-04-08 11:47:20,065 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-04-08 11:47:20,110 [IPC Server handler 0 on default port 9961] INFO ipc.Server: IPC Server handler 0 on default port 9961, call Call#0 Retry#9 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from 172.25.0.115:35255
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-04-08 11:56:58,769 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm2.org_1   | 2022-04-08 11:48:58,990 [028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:088c2e91-0545-411d-8d31-8415832ed844 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
scm3.org_1   | 2022-04-08 11:48:07,506 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 9ebec731-0724-46e8-adb1-25fbc2c43c85: Completed INSTALL_SNAPSHOT, lastRequest: 088c2e91-0545-411d-8d31-8415832ed844->9ebec731-0724-46e8-adb1-25fbc2c43c85#0-t2,notify:(t:2, i:12)
scm3.org_1   | 2022-04-08 11:48:07,522 [grpc-default-executor-2] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: Failed appendEntries as snapshot (12) installation is in progress
scm1.org_1   | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
scm3.org_1   | 2022-04-08 11:48:07,527 [grpc-default-executor-2] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: inconsistency entries. Reply:088c2e91-0545-411d-8d31-8415832ed844<-9ebec731-0724-46e8-adb1-25fbc2c43c85#4:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
om1_1        | 2022-04-08 11:56:58,771 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm2.org_1   | 2022-04-08 11:48:59,263 [028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: a6f33c92-47f3-4bcf-8c55-0543fc7274b5, Nodes: 8b7f16e2-5fb9-442f-a717-cc893c5795e0{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}0005597f-3053-4b02-96b8-efe2de95313b{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}4cf3df89-7b36-4576-a18a-5d0c57ddb620{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-04-08T11:48:59.048Z[UTC]].
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
om1_1        | 2022-04-08 11:56:58,773 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:59,487 [IPC Server handler 61 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
om1_1        | 2022-04-08 11:56:59,489 [IPC Server handler 72 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:93)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
scm2.org_1   | 2022-04-08 11:48:59,275 [028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-04-08 11:48:07,558 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: receive installSnapshot: 088c2e91-0545-411d-8d31-8415832ed844->9ebec731-0724-46e8-adb1-25fbc2c43c85#0-t2,notify:(t:2, i:12)
scm3.org_1   | 2022-04-08 11:48:07,567 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: set new configuration index: 9
om1_1        | 2022-04-08 11:56:59,491 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:56:59,511 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:02,349 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
scm2.org_1   | 2022-04-08 11:48:59,358 [028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: d7bff567-93ff-485c-a104-bc074898d12a, Nodes: 0005597f-3053-4b02-96b8-efe2de95313b{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}4cf3df89-7b36-4576-a18a-5d0c57ddb620{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}8b7f16e2-5fb9-442f-a717-cc893c5795e0{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-04-08T11:48:59.171Z[UTC]].
scm1.org_1   | 	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:16080)
om1_1        | 2022-04-08 11:57:03,040 [IPC Server handler 43 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:03,042 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:03,044 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm3.org_1   | configurationEntry {
scm3.org_1   |   peers {
scm3.org_1   |     id: "088c2e91-0545-411d-8d31-8415832ed844"
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
scm2.org_1   | 2022-04-08 11:48:59,359 [028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-04-08 11:49:02,049 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: cfd3e9b8-6c85-4577-8ecd-7af890cf2706, Nodes: 4cf3df89-7b36-4576-a18a-5d0c57ddb620{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:4cf3df89-7b36-4576-a18a-5d0c57ddb620, CreationTimestamp2022-04-08T11:48:58.915Z[UTC]] moved to OPEN state
scm2.org_1   | 2022-04-08 11:49:02,293 [028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1679)
scm3.org_1   |     address: "scm1.org:9894"
scm1.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
om1_1        | 2022-04-08 11:57:03,062 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:05,683 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:06,382 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm2.org_1   | 2022-04-08 11:49:03,132 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm2.org_1   | 2022-04-08 11:49:08,131 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm2.org_1   | 2022-04-08 11:49:09,270 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
scm3.org_1   |   }
scm3.org_1   |   peers {
scm1.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
scm1.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
scm1.org_1   | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
scm2.org_1   | 2022-04-08 11:49:10,785 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55254
scm2.org_1   | 2022-04-08 11:49:10,844 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 11:49:10,847 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: a6f33c92-47f3-4bcf-8c55-0543fc7274b5, Nodes: 8b7f16e2-5fb9-442f-a717-cc893c5795e0{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}0005597f-3053-4b02-96b8-efe2de95313b{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}4cf3df89-7b36-4576-a18a-5d0c57ddb620{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:4cf3df89-7b36-4576-a18a-5d0c57ddb620, CreationTimestamp2022-04-08T11:48:59.048Z[UTC]] moved to OPEN state
scm3.org_1   |     id: "028f51fd-62f3-478d-a538-df850a92e5c2"
scm3.org_1   |     address: "scm2.org:9894"
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
om1_1        | 2022-04-08 11:57:06,392 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:06,430 [IPC Server handler 42 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
scm1.org_1   | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm3.org_1   |   }
scm3.org_1   | }
scm3.org_1   |  from snapshot
om1_1        | 2022-04-08 11:57:07,239 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:07,242 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
scm2.org_1   | 2022-04-08 11:49:11,176 [028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
scm2.org_1   | 2022-04-08 11:49:11,588 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm2.org_1   | 2022-04-08 11:49:11,590 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
om1_1        | 2022-04-08 11:57:07,248 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
scm3.org_1   | 2022-04-08 11:48:07,568 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: set configuration 9: [088c2e91-0545-411d-8d31-8415832ed844|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 028f51fd-62f3-478d-a538-df850a92e5c2|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-04-08 11:48:07,569 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: reply installSnapshot: 088c2e91-0545-411d-8d31-8415832ed844<-9ebec731-0724-46e8-adb1-25fbc2c43c85#0:FAIL-t2,IN_PROGRESS
om1_1        | 2022-04-08 11:57:07,889 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:07,891 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm1.org_1   | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm1.org_1   | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
scm3.org_1   | 2022-04-08 11:48:07,570 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 9ebec731-0724-46e8-adb1-25fbc2c43c85: Completed INSTALL_SNAPSHOT, lastRequest: 088c2e91-0545-411d-8d31-8415832ed844->9ebec731-0724-46e8-adb1-25fbc2c43c85#0-t2,notify:(t:2, i:12)
scm3.org_1   | 2022-04-08 11:48:07,606 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: Failed appendEntries as snapshot (12) installation is in progress
scm2.org_1   | 2022-04-08 11:49:11,590 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-04-08 11:51:50,704 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33656
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
scm1.org_1   | 2022-04-08 11:47:21,149 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-FollowerState] INFO impl.FollowerState: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5107584291ns, electionTimeout:5096ms
recon_1      | 2022-04-08 11:51:50,772 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 11:51:50,977 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36056
scm3.org_1   | 2022-04-08 11:48:07,612 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: inconsistency entries. Reply:088c2e91-0545-411d-8d31-8415832ed844<-9ebec731-0724-46e8-adb1-25fbc2c43c85#5:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm3.org_1   | 2022-04-08 11:48:07,625 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: receive installSnapshot: 088c2e91-0545-411d-8d31-8415832ed844->9ebec731-0724-46e8-adb1-25fbc2c43c85#0-t2,notify:(t:2, i:12)
scm3.org_1   | 2022-04-08 11:48:07,631 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: set new configuration index: 9
scm3.org_1   | configurationEntry {
scm3.org_1   |   peers {
recon_1      | 2022-04-08 11:51:51,047 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:59736
om1_1        | 2022-04-08 11:57:07,894 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:08,537 [IPC Server handler 86 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm2.org_1   | 2022-04-08 11:49:11,590 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm2.org_1   | 2022-04-08 11:49:11,590 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
scm2.org_1   | 2022-04-08 11:49:11,590 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm2.org_1   | 2022-04-08 11:49:11,591 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
scm2.org_1   | 2022-04-08 11:49:28,168 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48138
scm2.org_1   | 2022-04-08 11:49:28,181 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 11:49:28,183 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: a76fa8e1-27b1-4e30-acd2-3b267e60a22d, Nodes: 8b7f16e2-5fb9-442f-a717-cc893c5795e0{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:8b7f16e2-5fb9-442f-a717-cc893c5795e0, CreationTimestamp2022-04-08T11:48:56.511Z[UTC]] moved to OPEN state
scm2.org_1   | 2022-04-08 11:49:28,609 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55326
scm2.org_1   | 2022-04-08 11:49:28,654 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 11:49:28,663 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 8c48fa47-1e15-404a-9159-e49e3da5df9c, Nodes: 0005597f-3053-4b02-96b8-efe2de95313b{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:0005597f-3053-4b02-96b8-efe2de95313b, CreationTimestamp2022-04-08T11:48:57.726Z[UTC]] moved to OPEN state
scm2.org_1   | 2022-04-08 11:49:41,650 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46344
scm2.org_1   | 2022-04-08 11:49:41,668 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 11:49:47,270 [028f51fd-62f3-478d-a538-df850a92e5c2@group-A2EA220FD69F-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 109611004723200000.
scm2.org_1   | 2022-04-08 11:49:47,701 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48200
scm2.org_1   | 2022-04-08 11:49:47,720 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 11:49:47,724 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: d7bff567-93ff-485c-a104-bc074898d12a, Nodes: 0005597f-3053-4b02-96b8-efe2de95313b{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}4cf3df89-7b36-4576-a18a-5d0c57ddb620{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}8b7f16e2-5fb9-442f-a717-cc893c5795e0{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:8b7f16e2-5fb9-442f-a717-cc893c5795e0, CreationTimestamp2022-04-08T11:48:59.171Z[UTC]] moved to OPEN state
scm2.org_1   | 2022-04-08 11:49:51,092 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55398
scm2.org_1   | 2022-04-08 11:49:51,170 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 11:50:20,737 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46470
scm2.org_1   | 2022-04-08 11:50:20,778 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 11:50:21,033 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55504
scm2.org_1   | 2022-04-08 11:50:21,036 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48308
scm2.org_1   | 2022-04-08 11:50:21,048 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 11:50:21,128 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 11:50:50,759 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46556
scm2.org_1   | 2022-04-08 11:50:50,800 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 11:50:51,044 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48398
scm2.org_1   | 2022-04-08 11:50:51,044 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55592
scm2.org_1   | 2022-04-08 11:50:51,058 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 11:50:51,077 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 11:51:20,711 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46662
om1_1        | 2022-04-08 11:57:08,539 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:08,541 [IPC Server handler 59 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:09,311 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:09,315 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
recon_1      | 2022-04-08 11:51:51,095 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 11:51:51,105 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 11:52:20,735 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33764
scm3.org_1   |     id: "088c2e91-0545-411d-8d31-8415832ed844"
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
recon_1      | 2022-04-08 11:52:20,771 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 11:52:21,086 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:59838
recon_1      | 2022-04-08 11:52:21,106 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36164
recon_1      | 2022-04-08 11:52:21,112 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 11:52:21,135 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 11:52:33,494 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
om1_1        | 2022-04-08 11:57:09,318 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm1.org_1   | 2022-04-08 11:47:21,150 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-FollowerState] INFO impl.RoleInfo: 088c2e91-0545-411d-8d31-8415832ed844: shutdown 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-FollowerState
scm3.org_1   |     address: "scm1.org:9894"
scm3.org_1   |   }
recon_1      | 2022-04-08 11:52:33,494 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-04-08 11:52:33,538 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
om1_1        | 2022-04-08 11:57:09,395 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:09,398 [IPC Server handler 42 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:09,409 [IPC Server handler 71 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:09,431 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:09,503 [IPC Server handler 87 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:09,513 [IPC Server handler 89 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:09,517 [IPC Server handler 93 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:09,539 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:09,539 [IPC Server handler 74 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:09,555 [IPC Server handler 59 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:09,558 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:09,587 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:10,916 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:13,483 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:13,485 [IPC Server handler 56 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:13,550 [IPC Server handler 74 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:13,552 [IPC Server handler 59 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:13,554 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:14,175 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:14,179 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:14,182 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:14,208 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:14,210 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:14,212 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:14,214 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:14,215 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:14,222 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:14,231 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:14,233 [IPC Server handler 42 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:14,237 [IPC Server handler 71 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:14,278 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:14,289 [IPC Server handler 68 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:14,297 [IPC Server handler 67 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:15,629 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
scm2.org_1   | 2022-04-08 11:51:20,724 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 11:51:21,041 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48506
scm3.org_1   |   peers {
scm3.org_1   |     id: "028f51fd-62f3-478d-a538-df850a92e5c2"
scm3.org_1   |     address: "scm2.org:9894"
scm3.org_1   |   }
scm3.org_1   | }
scm2.org_1   | 2022-04-08 11:51:21,046 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55700
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1        | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #178 timeout 180s
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:368)
s3g_1        | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:373)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:368)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:357)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1        | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1        | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1        | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1        | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1        | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1        | 	... 1 more
s3g_1        | 2022-04-08 12:03:28,265 [qtp1423016050-22] INFO scm.XceiverClientRatis: Could not commit index 136 on pipeline Pipeline[ Id: a6f33c92-47f3-4bcf-8c55-0543fc7274b5, Nodes: 8b7f16e2-5fb9-442f-a717-cc893c5795e0{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}0005597f-3053-4b02-96b8-efe2de95313b{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}4cf3df89-7b36-4576-a18a-5d0c57ddb620{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:4cf3df89-7b36-4576-a18a-5d0c57ddb620, CreationTimestamp2022-04-08T11:48:59.048Z[UTC]] to all the nodes. Server 0005597f-3053-4b02-96b8-efe2de95313b has failed. Committed by majority.
s3g_1        | 2022-04-08 12:03:28,265 [qtp1423016050-22] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 1 locID: 109611004723200053 bcsId: 136 on Pipeline[ Id: a6f33c92-47f3-4bcf-8c55-0543fc7274b5, Nodes: 8b7f16e2-5fb9-442f-a717-cc893c5795e0{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}0005597f-3053-4b02-96b8-efe2de95313b{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}4cf3df89-7b36-4576-a18a-5d0c57ddb620{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:4cf3df89-7b36-4576-a18a-5d0c57ddb620, CreationTimestamp2022-04-08T11:48:59.048Z[UTC]]. Failed nodes: [0005597f-3053-4b02-96b8-efe2de95313b{ip: null, host: null, ports: [], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1        | 2022-04-08 12:04:30,031 [qtp1423016050-20] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: a6f33c92-47f3-4bcf-8c55-0543fc7274b5, Nodes: 8b7f16e2-5fb9-442f-a717-cc893c5795e0{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}0005597f-3053-4b02-96b8-efe2de95313b{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}4cf3df89-7b36-4576-a18a-5d0c57ddb620{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:4cf3df89-7b36-4576-a18a-5d0c57ddb620, CreationTimestamp2022-04-08T11:48:59.048Z[UTC]]
s3g_1        | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #183 timeout 180s
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1        | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:263)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.RatisBlockOutputStream.sendWatchForCommit(RatisBlockOutputStream.java:101)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:373)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:533)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:547)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:137)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:495)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:469)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:522)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:235)
s3g_1        | 	at jdk.internal.reflect.GeneratedMethodAccessor28.invoke(Unknown Source)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
scm2.org_1   | 2022-04-08 11:51:21,095 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 11:51:21,122 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 11:47:21,151 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-FollowerState] INFO server.RaftServer$Division: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
scm1.org_1   | 2022-04-08 11:47:21,154 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
scm1.org_1   | 2022-04-08 11:47:21,154 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-FollowerState] INFO impl.RoleInfo: 088c2e91-0545-411d-8d31-8415832ed844: start 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-LeaderElection1
scm2.org_1   | 2022-04-08 11:51:50,751 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46770
scm2.org_1   | 2022-04-08 11:51:50,782 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 11:51:51,049 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48612
scm2.org_1   | 2022-04-08 11:51:51,062 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55800
scm1.org_1   | 2022-04-08 11:47:21,166 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-LeaderElection1] INFO impl.LeaderElection: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-LeaderElection1 ELECTION round 0: submit vote requests at term 2 for 0: [088c2e91-0545-411d-8d31-8415832ed844|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2022-04-08 11:47:21,167 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-LeaderElection1] INFO impl.LeaderElection: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-LeaderElection1 ELECTION round 0: result PASSED (term=2)
scm1.org_1   | 2022-04-08 11:47:21,168 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-LeaderElection1] INFO impl.RoleInfo: 088c2e91-0545-411d-8d31-8415832ed844: shutdown 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-LeaderElection1
scm1.org_1   | 2022-04-08 11:47:21,168 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-LeaderElection1] INFO server.RaftServer$Division: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
scm1.org_1   | 2022-04-08 11:47:21,168 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-LeaderElection1] INFO ha.SCMStateMachine: current SCM becomes leader of term 2.
scm3.org_1   |  from snapshot
scm3.org_1   | 2022-04-08 11:48:07,632 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: set configuration 9: [088c2e91-0545-411d-8d31-8415832ed844|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 028f51fd-62f3-478d-a538-df850a92e5c2|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-04-08 11:48:07,640 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: reply installSnapshot: 088c2e91-0545-411d-8d31-8415832ed844<-9ebec731-0724-46e8-adb1-25fbc2c43c85#0:FAIL-t2,IN_PROGRESS
scm3.org_1   | 2022-04-08 11:48:07,642 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 9ebec731-0724-46e8-adb1-25fbc2c43c85: Completed INSTALL_SNAPSHOT, lastRequest: 088c2e91-0545-411d-8d31-8415832ed844->9ebec731-0724-46e8-adb1-25fbc2c43c85#0-t2,notify:(t:2, i:12)
scm3.org_1   | 2022-04-08 11:48:07,701 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: Failed appendEntries as snapshot (12) installation is in progress
scm3.org_1   | 2022-04-08 11:48:07,706 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: inconsistency entries. Reply:088c2e91-0545-411d-8d31-8415832ed844<-9ebec731-0724-46e8-adb1-25fbc2c43c85#6:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
recon_1      | java.lang.reflect.UndeclaredThrowableException
scm1.org_1   | 2022-04-08 11:47:21,168 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-LeaderElection1] INFO ha.SCMContext: update <isLeader,term> from <false,0> to <true,2>
scm1.org_1   | 2022-04-08 11:47:21,170 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-LeaderElection1] INFO server.RaftServer$Division: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F: change Leader from null to 088c2e91-0545-411d-8d31-8415832ed844 at term 2 for becomeLeader, leader elected after 6701ms
scm2.org_1   | 2022-04-08 11:51:51,096 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 11:51:51,109 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 11:52:20,728 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46872
scm2.org_1   | 2022-04-08 11:52:20,768 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 11:52:20,979 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48710
scm2.org_1   | 2022-04-08 11:52:21,083 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55904
scm2.org_1   | 2022-04-08 11:52:21,090 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 11:52:21,126 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 11:52:40,641 [ReplicationMonitor] INFO container.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm2.org_1   | 2022-04-08 11:52:50,716 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46970
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
scm2.org_1   | 2022-04-08 11:52:50,724 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 11:52:50,998 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48812
scm2.org_1   | 2022-04-08 11:52:51,040 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56004
scm1.org_1   | 2022-04-08 11:47:21,175 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
om1_1        | 2022-04-08 11:57:15,631 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:15,632 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:15,644 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
scm3.org_1   | 2022-04-08 11:48:07,716 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: receive installSnapshot: 088c2e91-0545-411d-8d31-8415832ed844->9ebec731-0724-46e8-adb1-25fbc2c43c85#0-t2,notify:(t:2, i:12)
scm3.org_1   | 2022-04-08 11:48:07,725 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: set new configuration index: 9
scm3.org_1   | configurationEntry {
om1_1        | 2022-04-08 11:57:16,576 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm2.org_1   | 2022-04-08 11:52:51,090 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 11:52:51,110 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 11:53:20,675 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47082
scm2.org_1   | 2022-04-08 11:53:20,710 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
scm3.org_1   |   peers {
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
scm2.org_1   | 2022-04-08 11:53:20,997 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48922
scm2.org_1   | 2022-04-08 11:53:21,043 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56114
scm1.org_1   | 2022-04-08 11:47:21,179 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm1.org_1   | 2022-04-08 11:47:21,179 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
scm3.org_1   |     id: "088c2e91-0545-411d-8d31-8415832ed844"
scm2.org_1   | 2022-04-08 11:53:21,053 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 11:53:21,068 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 11:53:50,710 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47180
scm1.org_1   | 2022-04-08 11:47:21,184 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
scm2.org_1   | 2022-04-08 11:53:50,744 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 11:53:51,003 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56214
scm2.org_1   | 2022-04-08 11:53:51,066 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49024
scm2.org_1   | 2022-04-08 11:53:51,072 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 11:53:51,107 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 11:54:06,356 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47248
scm2.org_1   | 2022-04-08 11:54:06,377 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 11:54:06,439 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56268
scm3.org_1   |     address: "scm1.org:9894"
scm3.org_1   |   }
scm3.org_1   |   peers {
scm3.org_1   |     id: "028f51fd-62f3-478d-a538-df850a92e5c2"
scm3.org_1   |     address: "scm2.org:9894"
scm3.org_1   |   }
scm3.org_1   | }
scm3.org_1   |  from snapshot
scm2.org_1   | 2022-04-08 11:54:06,452 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 11:54:06,541 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49092
scm1.org_1   | 2022-04-08 11:47:21,184 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
scm1.org_1   | 2022-04-08 11:47:21,184 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
om1_1        | 2022-04-08 11:57:16,578 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1679)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
scm3.org_1   | 2022-04-08 11:48:07,738 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: set configuration 9: [088c2e91-0545-411d-8d31-8415832ed844|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 028f51fd-62f3-478d-a538-df850a92e5c2|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-04-08 11:48:07,743 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: reply installSnapshot: 088c2e91-0545-411d-8d31-8415832ed844<-9ebec731-0724-46e8-adb1-25fbc2c43c85#0:FAIL-t2,IN_PROGRESS
scm3.org_1   | 2022-04-08 11:48:07,746 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 9ebec731-0724-46e8-adb1-25fbc2c43c85: Completed INSTALL_SNAPSHOT, lastRequest: 088c2e91-0545-411d-8d31-8415832ed844->9ebec731-0724-46e8-adb1-25fbc2c43c85#0-t2,notify:(t:2, i:12)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
scm3.org_1   | 2022-04-08 11:48:07,797 [grpc-default-executor-2] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: Failed appendEntries as snapshot (12) installation is in progress
scm3.org_1   | 2022-04-08 11:48:07,797 [grpc-default-executor-2] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: inconsistency entries. Reply:088c2e91-0545-411d-8d31-8415832ed844<-9ebec731-0724-46e8-adb1-25fbc2c43c85#7:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm1.org_1   | 2022-04-08 11:47:21,188 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm2.org_1   | 2022-04-08 11:54:06,637 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 11:54:36,356 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47412
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
om1_1        | 2022-04-08 11:57:16,580 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:19,379 [IPC Server handler 52 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm2.org_1   | 2022-04-08 11:54:36,367 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 11:54:36,424 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56442
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
scm1.org_1   | 2022-04-08 11:47:21,189 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
scm1.org_1   | 2022-04-08 11:47:21,190 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-LeaderElection1] INFO impl.RoleInfo: 088c2e91-0545-411d-8d31-8415832ed844: start 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-LeaderStateImpl
scm1.org_1   | 2022-04-08 11:47:21,196 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
om1_1        | 2022-04-08 11:57:19,969 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:19,971 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
scm3.org_1   | 2022-04-08 11:48:07,807 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: receive installSnapshot: 088c2e91-0545-411d-8d31-8415832ed844->9ebec731-0724-46e8-adb1-25fbc2c43c85#0-t2,notify:(t:2, i:12)
scm3.org_1   | 2022-04-08 11:48:07,812 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: set new configuration index: 9
scm3.org_1   | configurationEntry {
scm3.org_1   |   peers {
scm3.org_1   |     id: "088c2e91-0545-411d-8d31-8415832ed844"
scm3.org_1   |     address: "scm1.org:9894"
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
scm1.org_1   | 2022-04-08 11:47:21,201 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/236d968d-b3de-4c14-8c61-a2ea220fd69f/current/log_inprogress_0 to /data/metadata/scm-ha/236d968d-b3de-4c14-8c61-a2ea220fd69f/current/log_0-0
scm1.org_1   | 2022-04-08 11:47:21,219 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-LeaderElection1] INFO server.RaftServer$Division: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F: set configuration 1: [088c2e91-0545-411d-8d31-8415832ed844|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2022-04-08 11:47:21,224 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/236d968d-b3de-4c14-8c61-a2ea220fd69f/current/log_inprogress_1
scm1.org_1   | 2022-04-08 11:47:21,229 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-StateMachineUpdater] INFO ha.SCMContext: update <isLeaderReady> from <false> to <true>
scm1.org_1   | 2022-04-08 11:47:21,230 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-StateMachineUpdater] INFO pipeline.BackgroundPipelineCreator: Service BackgroundPipelineCreator transitions to RUNNING.
scm2.org_1   | 2022-04-08 11:54:36,445 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 11:54:36,503 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49266
scm2.org_1   | 2022-04-08 11:54:36,535 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 11:55:06,389 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47584
scm2.org_1   | 2022-04-08 11:55:06,457 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56616
scm2.org_1   | 2022-04-08 11:55:06,480 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49436
scm2.org_1   | 2022-04-08 11:55:06,494 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   |   }
scm3.org_1   |   peers {
scm3.org_1   |     id: "028f51fd-62f3-478d-a538-df850a92e5c2"
scm3.org_1   |     address: "scm2.org:9894"
scm3.org_1   |   }
scm3.org_1   | }
scm2.org_1   | 2022-04-08 11:55:06,509 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 11:55:06,581 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 11:55:36,363 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47698
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
scm2.org_1   | 2022-04-08 11:55:36,393 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56722
scm3.org_1   |  from snapshot
scm1.org_1   | 2022-04-08 11:47:21,236 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-04-08 11:47:21,238 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
scm1.org_1   | 2022-04-08 11:47:21,244 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm2.org_1   | 2022-04-08 11:55:36,405 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 11:55:36,432 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49552
scm2.org_1   | 2022-04-08 11:55:36,434 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 11:55:36,482 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 11:56:06,344 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47808
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
scm3.org_1   | 2022-04-08 11:48:07,812 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: set configuration 9: [088c2e91-0545-411d-8d31-8415832ed844|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 028f51fd-62f3-478d-a538-df850a92e5c2|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-04-08 11:48:07,812 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: reply installSnapshot: 088c2e91-0545-411d-8d31-8415832ed844<-9ebec731-0724-46e8-adb1-25fbc2c43c85#0:FAIL-t2,IN_PROGRESS
scm2.org_1   | 2022-04-08 11:56:06,361 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 11:47:21,245 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9861
scm1.org_1   | 2022-04-08 11:47:21,249 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm1.org_1   | 2022-04-08 11:47:21,257 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm1.org_1   | 2022-04-08 11:47:26,188 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for RECON recon, UUID: 39ef8526-40f2-477a-8b20-b33d8dabe0f7
scm1.org_1   | 2022-04-08 11:47:27,079 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
om1_1        | 2022-04-08 11:57:19,973 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:20,629 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
scm3.org_1   | 2022-04-08 11:48:07,831 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 9ebec731-0724-46e8-adb1-25fbc2c43c85: Completed INSTALL_SNAPSHOT, lastRequest: 088c2e91-0545-411d-8d31-8415832ed844->9ebec731-0724-46e8-adb1-25fbc2c43c85#0-t2,notify:(t:2, i:12)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
scm2.org_1   | 2022-04-08 11:56:06,394 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56836
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
scm2.org_1   | 2022-04-08 11:56:06,441 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 11:56:06,482 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49660
scm2.org_1   | 2022-04-08 11:56:06,507 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2022-04-08 11:57:20,633 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:20,635 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:20,651 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:20,657 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:20,659 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:20,669 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:20,673 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:20,676 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:20,705 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:23,510 [IPC Server handler 84 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:24,149 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm3.org_1   | 2022-04-08 11:48:07,881 [grpc-default-executor-2] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: Failed appendEntries as snapshot (12) installation is in progress
scm3.org_1   | 2022-04-08 11:48:07,890 [grpc-default-executor-2] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: inconsistency entries. Reply:088c2e91-0545-411d-8d31-8415832ed844<-9ebec731-0724-46e8-adb1-25fbc2c43c85#8:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm3.org_1   | 2022-04-08 11:48:07,904 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: receive installSnapshot: 088c2e91-0545-411d-8d31-8415832ed844->9ebec731-0724-46e8-adb1-25fbc2c43c85#0-t2,notify:(t:2, i:12)
scm3.org_1   | 2022-04-08 11:48:07,925 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: set new configuration index: 9
scm3.org_1   | configurationEntry {
scm3.org_1   |   peers {
scm3.org_1   |     id: "088c2e91-0545-411d-8d31-8415832ed844"
scm3.org_1   |     address: "scm1.org:9894"
scm3.org_1   |   }
scm3.org_1   |   peers {
scm3.org_1   |     id: "028f51fd-62f3-478d-a538-df850a92e5c2"
scm3.org_1   |     address: "scm2.org:9894"
scm3.org_1   |   }
scm1.org_1   | 2022-04-08 11:47:27,080 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-StateMachineUpdater] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm1.org_1   | 2022-04-08 11:47:27,080 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-StateMachineUpdater] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm1.org_1   | 2022-04-08 11:47:27,607 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:38826
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1        | 2022-04-08 11:57:24,151 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm3.org_1   | }
scm3.org_1   |  from snapshot
scm1.org_1   | 2022-04-08 11:47:27,622 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
scm2.org_1   | 2022-04-08 11:56:36,362 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47942
scm2.org_1   | 2022-04-08 11:56:36,368 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 11:56:36,409 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56968
scm3.org_1   | 2022-04-08 11:48:07,925 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: set configuration 9: [088c2e91-0545-411d-8d31-8415832ed844|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 028f51fd-62f3-478d-a538-df850a92e5c2|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
scm3.org_1   | 2022-04-08 11:48:07,929 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: reply installSnapshot: 088c2e91-0545-411d-8d31-8415832ed844<-9ebec731-0724-46e8-adb1-25fbc2c43c85#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2022-04-08 11:47:27,627 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for scm scm2.org, nodeId: 028f51fd-62f3-478d-a538-df850a92e5c2
scm1.org_1   | 2022-04-08 11:47:29,503 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-04-08 11:56:36,420 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 11:56:36,461 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49792
scm2.org_1   | 2022-04-08 11:56:36,508 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 11:48:07,941 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 9ebec731-0724-46e8-adb1-25fbc2c43c85: Completed INSTALL_SNAPSHOT, lastRequest: 088c2e91-0545-411d-8d31-8415832ed844->9ebec731-0724-46e8-adb1-25fbc2c43c85#0-t2,notify:(t:2, i:12)
om1_1        | 2022-04-08 11:57:24,153 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
scm3.org_1   | 2022-04-08 11:48:07,977 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: Failed appendEntries as snapshot (12) installation is in progress
scm3.org_1   | 2022-04-08 11:48:07,979 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: inconsistency entries. Reply:088c2e91-0545-411d-8d31-8415832ed844<-9ebec731-0724-46e8-adb1-25fbc2c43c85#9:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm3.org_1   | 2022-04-08 11:48:07,997 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: receive installSnapshot: 088c2e91-0545-411d-8d31-8415832ed844->9ebec731-0724-46e8-adb1-25fbc2c43c85#0-t2,notify:(t:2, i:12)
scm3.org_1   | 2022-04-08 11:48:08,000 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: set new configuration index: 9
scm3.org_1   | configurationEntry {
scm1.org_1   | 2022-04-08 11:47:38,019 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42064
scm1.org_1   | 2022-04-08 11:47:38,051 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-04-08 11:47:42,300 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:46461
scm1.org_1   | 2022-04-08 11:47:42,308 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-04-08 11:47:44,520 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:60988
scm1.org_1   | 2022-04-08 11:47:44,625 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
scm2.org_1   | 2022-04-08 11:57:06,362 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48072
scm2.org_1   | 2022-04-08 11:57:06,428 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:57100
scm2.org_1   | 2022-04-08 11:57:06,459 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 11:57:06,536 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 11:57:06,543 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49924
scm2.org_1   | 2022-04-08 11:57:06,565 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 11:57:36,367 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48212
scm2.org_1   | 2022-04-08 11:57:36,400 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:57240
scm2.org_1   | 2022-04-08 11:57:36,448 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 11:57:36,479 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 11:57:36,480 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50058
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
scm1.org_1   | 2022-04-08 11:47:44,630 [IPC Server handler 2 on default port 9863] INFO ha.SCMRatisServerImpl: 088c2e91-0545-411d-8d31-8415832ed844: Submitting SetConfiguration request to Ratis server with new SCM peers list: [088c2e91-0545-411d-8d31-8415832ed844|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 028f51fd-62f3-478d-a538-df850a92e5c2|rpc:scm2.org:9894|priority:0]
scm1.org_1   | 2022-04-08 11:47:44,632 [IPC Server handler 2 on default port 9863] INFO server.RaftServer$Division: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F: receive setConfiguration SetConfigurationRequest:client-1BB8EDAD5B8D->088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F, cid=1, seq=0, RW, null, peers:[088c2e91-0545-411d-8d31-8415832ed844|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 028f51fd-62f3-478d-a538-df850a92e5c2|rpc:scm2.org:9894|priority:0]
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
om1_1        | 2022-04-08 11:57:24,753 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:24,755 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:24,758 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:24,770 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:25,829 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:25,833 [IPC Server handler 46 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm1.org_1   | 2022-04-08 11:47:44,636 [IPC Server handler 2 on default port 9863] INFO server.RaftServer$Division: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-LeaderStateImpl: startSetConfiguration SetConfigurationRequest:client-1BB8EDAD5B8D->088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F, cid=1, seq=0, RW, null, peers:[088c2e91-0545-411d-8d31-8415832ed844|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 028f51fd-62f3-478d-a538-df850a92e5c2|rpc:scm2.org:9894|priority:0]
scm1.org_1   | 2022-04-08 11:47:44,660 [IPC Server handler 2 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
scm1.org_1   | 2022-04-08 11:47:44,675 [IPC Server handler 2 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2022-04-08 11:47:44,676 [IPC Server handler 2 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
scm3.org_1   |   peers {
scm3.org_1   |     id: "088c2e91-0545-411d-8d31-8415832ed844"
scm3.org_1   |     address: "scm1.org:9894"
scm3.org_1   |   }
scm3.org_1   |   peers {
scm2.org_1   | 2022-04-08 11:57:36,527 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 11:57:40,642 [ReplicationMonitor] INFO container.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm2.org_1   | 2022-04-08 11:58:06,386 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48332
scm2.org_1   | 2022-04-08 11:58:06,422 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
scm1.org_1   | 2022-04-08 11:47:44,702 [IPC Server handler 2 on default port 9863] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
om1_1        | 2022-04-08 11:57:25,839 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:28,816 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:29,372 [IPC Server handler 52 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:29,375 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm2.org_1   | 2022-04-08 11:58:06,449 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:57362
scm2.org_1   | 2022-04-08 11:58:06,485 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50186
scm2.org_1   | 2022-04-08 11:58:06,497 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 11:58:06,506 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 11:58:36,366 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48438
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
scm1.org_1   | 2022-04-08 11:47:44,708 [IPC Server handler 2 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm3.org_1   |     id: "028f51fd-62f3-478d-a538-df850a92e5c2"
scm3.org_1   |     address: "scm2.org:9894"
scm3.org_1   |   }
scm3.org_1   | }
scm3.org_1   |  from snapshot
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
scm1.org_1   | 2022-04-08 11:47:44,708 [IPC Server handler 2 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm1.org_1   | 2022-04-08 11:47:44,757 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->028f51fd-62f3-478d-a538-df850a92e5c2-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->028f51fd-62f3-478d-a538-df850a92e5c2-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:6)
s3g_1        | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #183 timeout 180s
om1_1        | 2022-04-08 11:57:29,378 [IPC Server handler 61 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:368)
s3g_1        | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:373)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:368)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:357)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
scm1.org_1   | 2022-04-08 11:47:44,795 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->028f51fd-62f3-478d-a538-df850a92e5c2-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->028f51fd-62f3-478d-a538-df850a92e5c2-GrpcLogAppender: send 088c2e91-0545-411d-8d31-8415832ed844->028f51fd-62f3-478d-a538-df850a92e5c2#0-t2,notify:(t:2, i:6)
scm1.org_1   | 2022-04-08 11:47:46,057 [grpc-default-executor-0] INFO ha.SCMDBCheckpointProvider: Received request to obtain SCM DB checkpoint snapshot
scm1.org_1   | 2022-04-08 11:47:46,117 [grpc-default-executor-0] INFO db.RDBCheckpointManager: Created checkpoint at /data/metadata/db.checkpoints/scm.db_checkpoint_1649418466057 in 59 milliseconds
scm1.org_1   | 2022-04-08 11:47:46,343 [grpc-default-executor-0] INFO ha.SCMGrpcOutputStream: Sent 8875 bytes for cluster CID-236d968d-b3de-4c14-8c61-a2ea220fd69f
scm1.org_1   | 2022-04-08 11:47:46,344 [grpc-default-executor-0] INFO ha.SCMDBCheckpointProvider: Time taken to write the checkpoint to response output stream: 225 milliseconds
om1_1        | 2022-04-08 11:57:29,999 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:30,002 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:30,006 [IPC Server handler 43 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:30,023 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:30,028 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm2.org_1   | 2022-04-08 11:58:36,427 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:57460
scm2.org_1   | 2022-04-08 11:58:36,453 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 11:58:36,456 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50282
scm2.org_1   | 2022-04-08 11:58:36,484 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 11:48:08,003 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: set configuration 9: [088c2e91-0545-411d-8d31-8415832ed844|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 028f51fd-62f3-478d-a538-df850a92e5c2|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-04-08 11:48:08,004 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: reply installSnapshot: 088c2e91-0545-411d-8d31-8415832ed844<-9ebec731-0724-46e8-adb1-25fbc2c43c85#0:FAIL-t2,IN_PROGRESS
scm3.org_1   | 2022-04-08 11:48:08,011 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 9ebec731-0724-46e8-adb1-25fbc2c43c85: Completed INSTALL_SNAPSHOT, lastRequest: 088c2e91-0545-411d-8d31-8415832ed844->9ebec731-0724-46e8-adb1-25fbc2c43c85#0-t2,notify:(t:2, i:12)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
scm3.org_1   | 2022-04-08 11:48:08,052 [grpc-default-executor-2] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: Failed appendEntries as snapshot (12) installation is in progress
scm3.org_1   | 2022-04-08 11:48:08,055 [grpc-default-executor-2] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: inconsistency entries. Reply:088c2e91-0545-411d-8d31-8415832ed844<-9ebec731-0724-46e8-adb1-25fbc2c43c85#10:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm3.org_1   | 2022-04-08 11:48:08,060 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: receive installSnapshot: 088c2e91-0545-411d-8d31-8415832ed844->9ebec731-0724-46e8-adb1-25fbc2c43c85#0-t2,notify:(t:2, i:12)
scm3.org_1   | 2022-04-08 11:48:08,076 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: set new configuration index: 9
scm3.org_1   | configurationEntry {
scm2.org_1   | 2022-04-08 11:58:36,500 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 11:47:46,351 [grpc-default-executor-0] INFO db.RocksDBCheckpoint: Cleaning up RocksDB checkpoint at /data/metadata/db.checkpoints/scm.db_checkpoint_1649418466057
om1_1        | 2022-04-08 11:57:30,030 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:30,038 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:30,053 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm2.org_1   | 2022-04-08 11:59:06,379 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48502
scm2.org_1   | 2022-04-08 11:59:06,414 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:57524
scm2.org_1   | 2022-04-08 11:59:06,466 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 11:59:06,471 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50350
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1        | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1        | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1        | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1        | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1        | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm1.org_1   | 2022-04-08 11:47:46,945 [grpc-default-executor-0] INFO server.GrpcLogAppender: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->028f51fd-62f3-478d-a538-df850a92e5c2-InstallSnapshotResponseHandler: received the first reply 088c2e91-0545-411d-8d31-8415832ed844<-028f51fd-62f3-478d-a538-df850a92e5c2#0:FAIL-t0,IN_PROGRESS
scm1.org_1   | 2022-04-08 11:47:46,947 [grpc-default-executor-0] INFO server.GrpcLogAppender: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->028f51fd-62f3-478d-a538-df850a92e5c2-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2022-04-08 11:47:46,994 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->028f51fd-62f3-478d-a538-df850a92e5c2-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->028f51fd-62f3-478d-a538-df850a92e5c2-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:6)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-04-08 11:52:43,073 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 31 milliseconds to process 0 existing database records.
recon_1      | 2022-04-08 11:52:43,091 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 18 milliseconds for processing 1 containers.
recon_1      | 2022-04-08 11:52:43,261 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 5 pipelines in house.
scm3.org_1   |   peers {
scm3.org_1   |     id: "088c2e91-0545-411d-8d31-8415832ed844"
scm3.org_1   |     address: "scm1.org:9894"
scm3.org_1   |   }
scm3.org_1   |   peers {
scm3.org_1   |     id: "028f51fd-62f3-478d-a538-df850a92e5c2"
om1_1        | 2022-04-08 11:57:30,055 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:30,100 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:30,714 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:31,516 [IPC Server handler 84 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:31,518 [IPC Server handler 86 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm1.org_1   | 2022-04-08 11:47:46,994 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->028f51fd-62f3-478d-a538-df850a92e5c2-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->028f51fd-62f3-478d-a538-df850a92e5c2-GrpcLogAppender: send 088c2e91-0545-411d-8d31-8415832ed844->028f51fd-62f3-478d-a538-df850a92e5c2#0-t2,notify:(t:2, i:6)
scm1.org_1   | 2022-04-08 11:47:47,071 [grpc-default-executor-0] INFO leader.FollowerInfo: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->028f51fd-62f3-478d-a538-df850a92e5c2: nextIndex: updateUnconditionally 0 -> 7
scm1.org_1   | 2022-04-08 11:47:47,108 [grpc-default-executor-0] INFO server.GrpcLogAppender: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->028f51fd-62f3-478d-a538-df850a92e5c2-InstallSnapshotResponseHandler: received a reply 088c2e91-0545-411d-8d31-8415832ed844<-028f51fd-62f3-478d-a538-df850a92e5c2#0:FAIL-t2,SNAPSHOT_INSTALLED,snapshotIndex=6
scm1.org_1   | 2022-04-08 11:47:47,109 [grpc-default-executor-0] INFO server.GrpcLogAppender: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->028f51fd-62f3-478d-a538-df850a92e5c2-InstallSnapshotResponseHandler: Follower installed snapshot at index 6
scm1.org_1   | 2022-04-08 11:47:47,109 [grpc-default-executor-0] INFO leader.FollowerInfo: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->028f51fd-62f3-478d-a538-df850a92e5c2: snapshotIndex: setUnconditionally 0 -> 6
scm1.org_1   | 2022-04-08 11:47:47,109 [grpc-default-executor-0] INFO leader.FollowerInfo: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->028f51fd-62f3-478d-a538-df850a92e5c2: matchIndex: setUnconditionally 0 -> 6
scm2.org_1   | 2022-04-08 11:59:06,486 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 11:59:06,507 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 11:59:36,371 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48616
scm2.org_1   | 2022-04-08 11:59:36,448 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 11:59:36,451 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:57644
scm2.org_1   | 2022-04-08 11:59:36,470 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50466
scm2.org_1   | 2022-04-08 11:59:36,489 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 11:59:36,499 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 12:00:06,500 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48678
scm2.org_1   | 2022-04-08 12:00:06,522 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50528
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1        | 	... 1 more
s3g_1        | 2022-04-08 12:04:30,038 [qtp1423016050-20] INFO scm.XceiverClientRatis: Could not commit index 141 on pipeline Pipeline[ Id: a6f33c92-47f3-4bcf-8c55-0543fc7274b5, Nodes: 8b7f16e2-5fb9-442f-a717-cc893c5795e0{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}0005597f-3053-4b02-96b8-efe2de95313b{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}4cf3df89-7b36-4576-a18a-5d0c57ddb620{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:4cf3df89-7b36-4576-a18a-5d0c57ddb620, CreationTimestamp2022-04-08T11:48:59.048Z[UTC]] to all the nodes. Server 0005597f-3053-4b02-96b8-efe2de95313b has failed. Committed by majority.
om1_1        | 2022-04-08 11:57:31,520 [IPC Server handler 62 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:31,528 [IPC Server handler 89 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:31,536 [IPC Server handler 56 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:31,540 [IPC Server handler 93 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:31,550 [IPC Server handler 98 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
recon_1      | 2022-04-08 11:52:43,265 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 40 milliseconds.
recon_1      | 2022-04-08 11:52:50,684 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33858
scm3.org_1   |     address: "scm2.org:9894"
scm3.org_1   |   }
scm3.org_1   | }
s3g_1        | 2022-04-08 12:04:30,038 [qtp1423016050-20] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 1 locID: 109611004723200054 bcsId: 141 on Pipeline[ Id: a6f33c92-47f3-4bcf-8c55-0543fc7274b5, Nodes: 8b7f16e2-5fb9-442f-a717-cc893c5795e0{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}0005597f-3053-4b02-96b8-efe2de95313b{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}4cf3df89-7b36-4576-a18a-5d0c57ddb620{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:4cf3df89-7b36-4576-a18a-5d0c57ddb620, CreationTimestamp2022-04-08T11:48:59.048Z[UTC]]. Failed nodes: [0005597f-3053-4b02-96b8-efe2de95313b{ip: null, host: null, ports: [], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1        | 2022-04-08 12:04:37,453 [qtp1423016050-19] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-0487653167, with root as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-04-08 12:04:37,466 [qtp1423016050-19] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-0487653167
scm1.org_1   | 2022-04-08 11:47:47,109 [grpc-default-executor-0] INFO leader.FollowerInfo: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->028f51fd-62f3-478d-a538-df850a92e5c2: nextIndex: setUnconditionally 7 -> 7
scm1.org_1   | 2022-04-08 11:47:47,109 [grpc-default-executor-0] INFO leader.FollowerInfo: Follower 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->028f51fd-62f3-478d-a538-df850a92e5c2 acknowledged installing snapshot
scm1.org_1   | 2022-04-08 11:47:47,110 [grpc-default-executor-0] INFO leader.FollowerInfo: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->028f51fd-62f3-478d-a538-df850a92e5c2: nextIndex: updateToMax old=7, new=7, updated? false
scm1.org_1   | 2022-04-08 11:47:48,772 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.118:58274
scm1.org_1   | 2022-04-08 11:47:48,812 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-04-08 11:47:50,076 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42252
scm1.org_1   | 2022-04-08 11:47:50,100 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-04-08 11:47:50,322 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-LeaderStateImpl] INFO server.RaftServer$Division: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F: set configuration 7: [088c2e91-0545-411d-8d31-8415832ed844|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 028f51fd-62f3-478d-a538-df850a92e5c2|rpc:scm2.org:9894|priority:0], old=[088c2e91-0545-411d-8d31-8415832ed844|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm1.org_1   | 2022-04-08 11:47:50,583 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-LeaderStateImpl] INFO server.RaftServer$Division: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F: set configuration 9: [088c2e91-0545-411d-8d31-8415832ed844|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 028f51fd-62f3-478d-a538-df850a92e5c2|rpc:scm2.org:9894|priority:0], old=null
scm1.org_1   | 2022-04-08 11:47:50,754 [IPC Server handler 2 on default port 9863] INFO ha.SCMRatisServerImpl: Successfully added new SCM: 028f51fd-62f3-478d-a538-df850a92e5c2.
scm1.org_1   | 2022-04-08 11:47:51,083 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.118:46344
scm1.org_1   | 2022-04-08 11:47:51,098 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-04-08 11:47:51,098 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for scm scm3.org, nodeId: 9ebec731-0724-46e8-adb1-25fbc2c43c85
scm1.org_1   | 2022-04-08 11:47:51,303 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-04-08 11:47:51,974 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:39206
scm1.org_1   | 2022-04-08 11:47:51,980 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-04-08 11:47:59,866 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42400
scm1.org_1   | 2022-04-08 11:47:59,908 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-04-08 11:48:01,566 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.118:58450
scm1.org_1   | 2022-04-08 11:48:01,848 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-04-08 11:48:01,851 [IPC Server handler 7 on default port 9863] INFO ha.SCMRatisServerImpl: 088c2e91-0545-411d-8d31-8415832ed844: Submitting SetConfiguration request to Ratis server with new SCM peers list: [088c2e91-0545-411d-8d31-8415832ed844|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 028f51fd-62f3-478d-a538-df850a92e5c2|rpc:scm2.org:9894|priority:0, 9ebec731-0724-46e8-adb1-25fbc2c43c85|rpc:scm3.org:9894|priority:0]
scm1.org_1   | 2022-04-08 11:48:01,851 [IPC Server handler 7 on default port 9863] INFO server.RaftServer$Division: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F: receive setConfiguration SetConfigurationRequest:client-1BB8EDAD5B8D->088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F, cid=2, seq=0, RW, null, peers:[088c2e91-0545-411d-8d31-8415832ed844|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 028f51fd-62f3-478d-a538-df850a92e5c2|rpc:scm2.org:9894|priority:0, 9ebec731-0724-46e8-adb1-25fbc2c43c85|rpc:scm3.org:9894|priority:0]
scm1.org_1   | 2022-04-08 11:48:01,851 [IPC Server handler 7 on default port 9863] INFO server.RaftServer$Division: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-LeaderStateImpl: startSetConfiguration SetConfigurationRequest:client-1BB8EDAD5B8D->088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F, cid=2, seq=0, RW, null, peers:[088c2e91-0545-411d-8d31-8415832ed844|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 028f51fd-62f3-478d-a538-df850a92e5c2|rpc:scm2.org:9894|priority:0, 9ebec731-0724-46e8-adb1-25fbc2c43c85|rpc:scm3.org:9894|priority:0]
scm1.org_1   | 2022-04-08 11:48:01,851 [IPC Server handler 7 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
scm1.org_1   | 2022-04-08 11:48:01,851 [IPC Server handler 7 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2022-04-08 11:48:01,851 [IPC Server handler 7 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
scm1.org_1   | 2022-04-08 11:48:01,852 [IPC Server handler 7 on default port 9863] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
scm1.org_1   | 2022-04-08 11:48:01,852 [IPC Server handler 7 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm1.org_1   | 2022-04-08 11:48:01,853 [IPC Server handler 7 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm1.org_1   | 2022-04-08 11:48:01,853 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:12)
scm1.org_1   | 2022-04-08 11:48:01,854 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-GrpcLogAppender: send 088c2e91-0545-411d-8d31-8415832ed844->9ebec731-0724-46e8-adb1-25fbc2c43c85#0-t2,notify:(t:2, i:12)
scm1.org_1   | 2022-04-08 11:48:02,084 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$437/0x0000000840547c40@b21cbbf] WARN util.JvmPauseMonitor: JvmPauseMonitor-088c2e91-0545-411d-8d31-8415832ed844: Detected pause in JVM or host machine (eg GC): pause of approximately 111289392ns.
scm1.org_1   | GC pool 'ParNew' had collection(s): count=1 time=131ms
scm1.org_1   | 2022-04-08 11:48:06,807 [grpc-default-executor-0] INFO ha.SCMDBCheckpointProvider: Received request to obtain SCM DB checkpoint snapshot
scm1.org_1   | 2022-04-08 11:48:06,882 [grpc-default-executor-0] INFO db.RDBCheckpointManager: Created checkpoint at /data/metadata/db.checkpoints/scm.db_checkpoint_1649418486821 in 60 milliseconds
scm1.org_1   | 2022-04-08 11:48:06,889 [grpc-default-executor-2] INFO server.GrpcLogAppender: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-InstallSnapshotResponseHandler: received the first reply 088c2e91-0545-411d-8d31-8415832ed844<-9ebec731-0724-46e8-adb1-25fbc2c43c85#0:FAIL-t0,IN_PROGRESS
scm1.org_1   | 2022-04-08 11:48:06,891 [grpc-default-executor-2] INFO server.GrpcLogAppender: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2022-04-08 11:48:06,976 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:12)
scm1.org_1   | 2022-04-08 11:48:06,979 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-GrpcLogAppender: send 088c2e91-0545-411d-8d31-8415832ed844->9ebec731-0724-46e8-adb1-25fbc2c43c85#0-t2,notify:(t:2, i:12)
scm1.org_1   | 2022-04-08 11:48:07,040 [grpc-default-executor-0] INFO ha.SCMGrpcOutputStream: Sent 10019 bytes for cluster CID-236d968d-b3de-4c14-8c61-a2ea220fd69f
scm1.org_1   | 2022-04-08 11:48:07,043 [grpc-default-executor-0] INFO ha.SCMDBCheckpointProvider: Time taken to write the checkpoint to response output stream: 153 milliseconds
scm1.org_1   | 2022-04-08 11:48:07,044 [grpc-default-executor-0] INFO db.RocksDBCheckpoint: Cleaning up RocksDB checkpoint at /data/metadata/db.checkpoints/scm.db_checkpoint_1649418486821
scm1.org_1   | 2022-04-08 11:48:07,140 [grpc-default-executor-2] INFO server.GrpcLogAppender: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-InstallSnapshotResponseHandler: received a reply 088c2e91-0545-411d-8d31-8415832ed844<-9ebec731-0724-46e8-adb1-25fbc2c43c85#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2022-04-08 11:48:07,146 [grpc-default-executor-2] INFO server.GrpcLogAppender: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm3.org_1   |  from snapshot
recon_1      | 2022-04-08 11:52:50,713 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 11:52:51,012 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36264
recon_1      | 2022-04-08 11:52:51,042 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:59934
recon_1      | 2022-04-08 11:52:51,080 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 11:52:51,101 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 11:53:20,708 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33970
recon_1      | 2022-04-08 11:53:20,730 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 11:53:21,021 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:60050
recon_1      | 2022-04-08 11:53:21,057 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36376
recon_1      | 2022-04-08 11:53:21,064 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 11:53:21,067 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 11:53:33,539 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
scm3.org_1   | 2022-04-08 11:48:08,079 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: set configuration 9: [088c2e91-0545-411d-8d31-8415832ed844|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 028f51fd-62f3-478d-a538-df850a92e5c2|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2022-04-08 12:00:06,535 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 12:00:06,548 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:57706
scm2.org_1   | 2022-04-08 12:00:06,552 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 12:00:06,560 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 12:00:36,362 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48766
scm3.org_1   | 2022-04-08 11:48:08,080 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: reply installSnapshot: 088c2e91-0545-411d-8d31-8415832ed844<-9ebec731-0724-46e8-adb1-25fbc2c43c85#0:FAIL-t2,IN_PROGRESS
scm3.org_1   | 2022-04-08 11:48:08,095 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 9ebec731-0724-46e8-adb1-25fbc2c43c85: Completed INSTALL_SNAPSHOT, lastRequest: 088c2e91-0545-411d-8d31-8415832ed844->9ebec731-0724-46e8-adb1-25fbc2c43c85#0-t2,notify:(t:2, i:12)
scm3.org_1   | 2022-04-08 11:48:08,128 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: Failed appendEntries as snapshot (12) installation is in progress
scm2.org_1   | 2022-04-08 12:00:36,445 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:57794
scm2.org_1   | 2022-04-08 12:00:36,467 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50618
scm3.org_1   | 2022-04-08 11:48:08,128 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: inconsistency entries. Reply:088c2e91-0545-411d-8d31-8415832ed844<-9ebec731-0724-46e8-adb1-25fbc2c43c85#11:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm3.org_1   | 2022-04-08 11:48:08,133 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: receive installSnapshot: 088c2e91-0545-411d-8d31-8415832ed844->9ebec731-0724-46e8-adb1-25fbc2c43c85#0-t2,notify:(t:2, i:12)
scm3.org_1   | 2022-04-08 11:48:08,139 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: set new configuration index: 9
scm3.org_1   | configurationEntry {
scm3.org_1   |   peers {
scm3.org_1   |     id: "088c2e91-0545-411d-8d31-8415832ed844"
s3g_1        | 2022-04-08 12:04:51,492 [qtp1423016050-19] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-2100108116, with root as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-04-08 12:04:51,504 [qtp1423016050-19] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-2100108116
scm3.org_1   |     address: "scm1.org:9894"
scm3.org_1   |   }
scm3.org_1   |   peers {
scm3.org_1   |     id: "028f51fd-62f3-478d-a538-df850a92e5c2"
scm3.org_1   |     address: "scm2.org:9894"
scm3.org_1   |   }
scm3.org_1   | }
scm3.org_1   |  from snapshot
s3g_1        | 2022-04-08 12:05:15,566 [qtp1423016050-19] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-8208772603, with root as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-04-08 12:05:15,574 [qtp1423016050-19] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-8208772603
scm3.org_1   | 2022-04-08 11:48:08,147 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: set configuration 9: [088c2e91-0545-411d-8d31-8415832ed844|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 028f51fd-62f3-478d-a538-df850a92e5c2|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-04-08 11:48:08,148 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: reply installSnapshot: 088c2e91-0545-411d-8d31-8415832ed844<-9ebec731-0724-46e8-adb1-25fbc2c43c85#0:FAIL-t2,IN_PROGRESS
scm3.org_1   | 2022-04-08 11:48:08,148 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 9ebec731-0724-46e8-adb1-25fbc2c43c85: Completed INSTALL_SNAPSHOT, lastRequest: 088c2e91-0545-411d-8d31-8415832ed844->9ebec731-0724-46e8-adb1-25fbc2c43c85#0-t2,notify:(t:2, i:12)
scm3.org_1   | 2022-04-08 11:48:08,176 [pool-16-thread-1] INFO ha.SCMHAManagerImpl: Installing checkpoint with SCMTransactionInfo 2#12
scm3.org_1   | 2022-04-08 11:48:08,192 [pool-16-thread-1] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: StateMachine successfully installed snapshot index 12. Reloading the StateMachine.
scm3.org_1   | 2022-04-08 11:48:08,219 [grpc-default-executor-2] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: Failed appendEntries as snapshot (12) installation is in progress
scm3.org_1   | 2022-04-08 11:48:08,219 [grpc-default-executor-2] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: inconsistency entries. Reply:088c2e91-0545-411d-8d31-8415832ed844<-9ebec731-0724-46e8-adb1-25fbc2c43c85#12:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm3.org_1   | 2022-04-08 11:48:08,193 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F-SegmentedRaftLogWorker: flushIndex: setUnconditionally -1 -> 12
s3g_1        | 2022-04-08 12:05:30,429 [qtp1423016050-21] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: a6f33c92-47f3-4bcf-8c55-0543fc7274b5, Nodes: 8b7f16e2-5fb9-442f-a717-cc893c5795e0{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}0005597f-3053-4b02-96b8-efe2de95313b{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}4cf3df89-7b36-4576-a18a-5d0c57ddb620{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:4cf3df89-7b36-4576-a18a-5d0c57ddb620, CreationTimestamp2022-04-08T11:48:59.048Z[UTC]]
s3g_1        | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #188 timeout 180s
recon_1      | 2022-04-08 11:53:33,539 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-04-08 11:53:33,586 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
scm3.org_1   | 2022-04-08 11:48:08,223 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally -1 -> 12
scm3.org_1   | 2022-04-08 11:48:08,224 [pool-16-thread-1] INFO raftlog.RaftLog: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F-SegmentedRaftLog: snapshotIndex: updateIncreasingly -1 -> 12
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
scm2.org_1   | 2022-04-08 12:00:36,484 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 12:00:36,493 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 12:00:36,512 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1        | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:263)
scm3.org_1   | 2022-04-08 11:48:08,267 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: receive installSnapshot: 088c2e91-0545-411d-8d31-8415832ed844->9ebec731-0724-46e8-adb1-25fbc2c43c85#0-t2,notify:(t:2, i:12)
scm3.org_1   | 2022-04-08 11:48:08,271 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: InstallSnapshot notification result: SNAPSHOT_INSTALLED, at index: 12
scm3.org_1   | 2022-04-08 11:48:08,272 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: set new configuration index: 9
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
scm3.org_1   | configurationEntry {
scm3.org_1   |   peers {
scm3.org_1   |     id: "088c2e91-0545-411d-8d31-8415832ed844"
scm2.org_1   | 2022-04-08 12:01:06,359 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48832
scm2.org_1   | 2022-04-08 12:01:06,387 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 12:01:06,398 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:57856
scm3.org_1   |     address: "scm1.org:9894"
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
scm1.org_1   | 2022-04-08 11:48:07,148 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:12)
scm1.org_1   | 2022-04-08 11:48:07,159 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-GrpcLogAppender: send 088c2e91-0545-411d-8d31-8415832ed844->9ebec731-0724-46e8-adb1-25fbc2c43c85#0-t2,notify:(t:2, i:12)
scm1.org_1   | 2022-04-08 11:48:07,245 [grpc-default-executor-2] INFO leader.FollowerInfo: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2022-04-08 11:48:07,275 [grpc-default-executor-2] INFO leader.FollowerInfo: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85: nextIndex: updateUnconditionally 0 -> 0
scm3.org_1   |   }
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.RatisBlockOutputStream.sendWatchForCommit(RatisBlockOutputStream.java:101)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:373)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:533)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:547)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:137)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:495)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
om1_1        | 2022-04-08 11:57:31,552 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:31,553 [IPC Server handler 59 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:31,586 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:33,798 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:39569
om1_1        | 2022-04-08 11:57:33,808 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:57:34,149 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
om1_1        | 2022-04-08 11:57:34,779 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:34,782 [IPC Server handler 46 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:34,783 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:35,391 [IPC Server handler 61 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:35,393 [IPC Server handler 85 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm2.org_1   | 2022-04-08 12:01:06,447 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 12:01:06,453 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50682
scm1.org_1   | 2022-04-08 11:48:07,292 [grpc-default-executor-2] INFO server.GrpcLogAppender: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-InstallSnapshotResponseHandler: received a reply 088c2e91-0545-411d-8d31-8415832ed844<-9ebec731-0724-46e8-adb1-25fbc2c43c85#0:FAIL-t2,IN_PROGRESS
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:469)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:522)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
scm3.org_1   |   peers {
scm3.org_1   |     id: "028f51fd-62f3-478d-a538-df850a92e5c2"
om1_1        | 2022-04-08 11:57:35,395 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:35,407 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:36,657 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm2.org_1   | 2022-04-08 12:01:06,479 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
scm3.org_1   |     address: "scm2.org:9894"
scm3.org_1   |   }
scm3.org_1   | }
scm3.org_1   |  from snapshot
scm2.org_1   | 2022-04-08 12:01:36,350 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48914
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:235)
scm1.org_1   | 2022-04-08 11:48:07,302 [grpc-default-executor-2] INFO server.GrpcLogAppender: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-InstallSnapshotResponseHandler: InstallSnapshot in progress.
om1_1        | 2022-04-08 11:57:36,660 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:36,664 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
s3g_1        | 	at jdk.internal.reflect.GeneratedMethodAccessor28.invoke(Unknown Source)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
scm3.org_1   | 2022-04-08 11:48:08,273 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: set configuration 9: [088c2e91-0545-411d-8d31-8415832ed844|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 028f51fd-62f3-478d-a538-df850a92e5c2|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2022-04-08 12:01:36,376 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 12:01:36,431 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:57942
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
scm1.org_1   | 2022-04-08 11:48:07,319 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:12)
om1_1        | 2022-04-08 11:57:37,135 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:37,752 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm3.org_1   | 2022-04-08 11:48:08,273 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: reply installSnapshot: 088c2e91-0545-411d-8d31-8415832ed844<-9ebec731-0724-46e8-adb1-25fbc2c43c85#0:FAIL-t2,SNAPSHOT_INSTALLED,snapshotIndex=12
scm3.org_1   | 2022-04-08 11:48:08,275 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 9ebec731-0724-46e8-adb1-25fbc2c43c85: Completed INSTALL_SNAPSHOT, lastRequest: 088c2e91-0545-411d-8d31-8415832ed844->9ebec731-0724-46e8-adb1-25fbc2c43c85#0-t2,notify:(t:2, i:12)
scm2.org_1   | 2022-04-08 12:01:36,438 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50762
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
scm1.org_1   | 2022-04-08 11:48:07,320 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-GrpcLogAppender: send 088c2e91-0545-411d-8d31-8415832ed844->9ebec731-0724-46e8-adb1-25fbc2c43c85#0-t2,notify:(t:2, i:12)
scm1.org_1   | 2022-04-08 11:48:07,395 [grpc-default-executor-2] INFO leader.FollowerInfo: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2022-04-08 11:48:07,413 [grpc-default-executor-2] INFO server.GrpcLogAppender: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-InstallSnapshotResponseHandler: received a reply 088c2e91-0545-411d-8d31-8415832ed844<-9ebec731-0724-46e8-adb1-25fbc2c43c85#0:FAIL-t2,IN_PROGRESS
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
scm2.org_1   | 2022-04-08 12:01:36,447 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 12:01:36,471 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 11:48:08,635 [9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F-StateMachineUpdater] INFO ha.SCMHAManagerImpl: Installing checkpoint with SCMTransactionInfo 2#12
om1_1        | 2022-04-08 11:57:37,755 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:37,757 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:38,423 [IPC Server handler 72 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:38,427 [IPC Server handler 80 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:38,428 [IPC Server handler 66 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:40,470 [IPC Server handler 95 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
om1_1        | 2022-04-08 11:57:40,472 [IPC Server handler 81 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm3.org_1   | 2022-04-08 11:48:08,693 [9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F-StateMachineUpdater] INFO ha.SCMHAManagerImpl: Replaced DB with checkpoint, term: 2, index: 12
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
scm1.org_1   | 2022-04-08 11:48:07,415 [grpc-default-executor-2] INFO server.GrpcLogAppender: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-InstallSnapshotResponseHandler: InstallSnapshot in progress.
om1_1        | 2022-04-08 11:57:40,481 [IPC Server handler 73 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm1.org_1   | 2022-04-08 11:48:07,417 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:12)
scm1.org_1   | 2022-04-08 11:48:07,427 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-GrpcLogAppender: send 088c2e91-0545-411d-8d31-8415832ed844->9ebec731-0724-46e8-adb1-25fbc2c43c85#0-t2,notify:(t:2, i:12)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
scm2.org_1   | 2022-04-08 12:02:06,363 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48974
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
scm3.org_1   | 2022-04-08 11:48:08,704 [9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F-StateMachineUpdater] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm3.org_1   | 2022-04-08 11:48:08,707 [9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F-StateMachineUpdater] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm3.org_1   | 2022-04-08 11:48:08,850 [9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F-StateMachineUpdater] INFO ha.SequenceIdGenerator: reinitialize SequenceIdGenerator.
om1_1        | 2022-04-08 11:57:40,503 [IPC Server handler 78 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm1.org_1   | 2022-04-08 11:48:07,474 [grpc-default-executor-2] INFO leader.FollowerInfo: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2022-04-08 11:48:07,512 [grpc-default-executor-2] INFO server.GrpcLogAppender: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-InstallSnapshotResponseHandler: received a reply 088c2e91-0545-411d-8d31-8415832ed844<-9ebec731-0724-46e8-adb1-25fbc2c43c85#0:FAIL-t2,IN_PROGRESS
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
scm2.org_1   | 2022-04-08 12:02:06,400 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 12:02:06,428 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50826
scm2.org_1   | 2022-04-08 12:02:06,430 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58006
scm2.org_1   | 2022-04-08 12:02:06,464 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 11:48:08,873 [9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
scm3.org_1   | 2022-04-08 11:48:08,897 [9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F-StateMachineUpdater] INFO ha.SCMHAManagerImpl: Reloaded SCM state with Term: 2 and Index: 12
scm3.org_1   | 2022-04-08 11:48:08,900 [9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F-StateMachineUpdater] INFO impl.StateMachineUpdater: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F-StateMachineUpdater: snapshotIndex: setUnconditionally -1 -> 12
scm3.org_1   | 2022-04-08 11:48:08,903 [9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F-StateMachineUpdater] INFO impl.StateMachineUpdater: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F-StateMachineUpdater: appliedIndex: setUnconditionally -1 -> 12
scm1.org_1   | 2022-04-08 11:48:07,513 [grpc-default-executor-2] INFO server.GrpcLogAppender: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2022-04-08 11:48:07,514 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:12)
scm1.org_1   | 2022-04-08 11:48:07,519 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-GrpcLogAppender: send 088c2e91-0545-411d-8d31-8415832ed844->9ebec731-0724-46e8-adb1-25fbc2c43c85#0-t2,notify:(t:2, i:12)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
scm3.org_1   | 2022-04-08 11:48:12,215 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: set configuration 13: [088c2e91-0545-411d-8d31-8415832ed844|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 9ebec731-0724-46e8-adb1-25fbc2c43c85|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0, 028f51fd-62f3-478d-a538-df850a92e5c2|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=[088c2e91-0545-411d-8d31-8415832ed844|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 028f51fd-62f3-478d-a538-df850a92e5c2|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0]
scm3.org_1   | 2022-04-08 11:48:12,235 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F-SegmentedRaftLogWorker: Starting segment from index:13
scm3.org_1   | 2022-04-08 11:48:12,535 [grpc-default-executor-0] INFO server.RaftServer$Division: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F: set configuration 15: [088c2e91-0545-411d-8d31-8415832ed844|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 9ebec731-0724-46e8-adb1-25fbc2c43c85|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0, 028f51fd-62f3-478d-a538-df850a92e5c2|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
scm3.org_1   | 2022-04-08 11:48:12,657 [Listener at 0.0.0.0/9860] INFO ha.SCMHAManagerImpl: Successfully added SCM scm3 to group group-A2EA220FD69F:[088c2e91-0545-411d-8d31-8415832ed844|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 9ebec731-0724-46e8-adb1-25fbc2c43c85|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0, 028f51fd-62f3-478d-a538-df850a92e5c2|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0]
scm3.org_1   | 2022-04-08 11:48:12,686 [Listener at 0.0.0.0/9860] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
om1_1        | 2022-04-08 11:57:40,506 [IPC Server handler 65 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:40,513 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm2.org_1   | 2022-04-08 12:02:06,484 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 12:02:36,351 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49060
recon_1      | 	... 27 more
scm3.org_1   | 2022-04-08 11:48:12,700 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Starting token manager
scm3.org_1   | 2022-04-08 11:48:12,700 [Listener at 0.0.0.0/9860] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
scm3.org_1   | 2022-04-08 11:48:12,875 [9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/236d968d-b3de-4c14-8c61-a2ea220fd69f/current/log_inprogress_13
om1_1        | 2022-04-08 11:57:40,528 [IPC Server handler 89 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:41,081 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm2.org_1   | 2022-04-08 12:02:36,393 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 12:02:36,414 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58090
scm2.org_1   | 2022-04-08 12:02:36,439 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50910
scm2.org_1   | 2022-04-08 12:02:36,445 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 11:48:07,548 [grpc-default-executor-2] INFO leader.FollowerInfo: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2022-04-08 11:48:07,586 [grpc-default-executor-2] INFO server.GrpcLogAppender: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-InstallSnapshotResponseHandler: received a reply 088c2e91-0545-411d-8d31-8415832ed844<-9ebec731-0724-46e8-adb1-25fbc2c43c85#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2022-04-08 11:48:07,586 [grpc-default-executor-2] INFO server.GrpcLogAppender: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2022-04-08 11:48:07,587 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:12)
scm1.org_1   | 2022-04-08 11:48:07,598 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-GrpcLogAppender: send 088c2e91-0545-411d-8d31-8415832ed844->9ebec731-0724-46e8-adb1-25fbc2c43c85#0-t2,notify:(t:2, i:12)
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
scm3.org_1   | 2022-04-08 11:48:13,071 [9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-04-08 11:48:13,073 [9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
scm3.org_1   | 2022-04-08 11:48:13,073 [9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
scm1.org_1   | 2022-04-08 11:48:07,659 [grpc-default-executor-2] INFO leader.FollowerInfo: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2022-04-08 11:48:07,672 [grpc-default-executor-2] INFO server.GrpcLogAppender: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-InstallSnapshotResponseHandler: received a reply 088c2e91-0545-411d-8d31-8415832ed844<-9ebec731-0724-46e8-adb1-25fbc2c43c85#0:FAIL-t2,IN_PROGRESS
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-04-08 11:53:50,713 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34068
recon_1      | 2022-04-08 11:53:50,735 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 11:53:51,053 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36472
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
scm3.org_1   | 2022-04-08 11:48:13,074 [9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9861
scm3.org_1   | 2022-04-08 11:48:13,502 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm3.org_1   | 2022-04-08 11:48:13,672 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om1_1        | 2022-04-08 11:57:41,083 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
recon_1      | 2022-04-08 11:53:51,067 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:60144
scm2.org_1   | 2022-04-08 12:02:36,467 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 11:48:07,674 [grpc-default-executor-2] INFO server.GrpcLogAppender: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2022-04-08 11:48:07,685 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:12)
scm1.org_1   | 2022-04-08 11:48:07,690 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-GrpcLogAppender: send 088c2e91-0545-411d-8d31-8415832ed844->9ebec731-0724-46e8-adb1-25fbc2c43c85#0-t2,notify:(t:2, i:12)
om1_1        | 2022-04-08 11:57:41,088 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm1.org_1   | 2022-04-08 11:48:07,771 [grpc-default-executor-2] INFO leader.FollowerInfo: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85: nextIndex: updateUnconditionally 0 -> 0
scm2.org_1   | 2022-04-08 12:02:40,642 [ReplicationMonitor] INFO container.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm3.org_1   | 2022-04-08 11:48:13,686 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
recon_1      | 2022-04-08 11:53:51,075 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om1_1        | 2022-04-08 11:57:41,104 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:41,106 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:41,108 [IPC Server handler 42 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:41,116 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:41,741 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm2.org_1   | 2022-04-08 12:03:06,362 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49124
scm2.org_1   | 2022-04-08 12:03:06,396 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58154
scm2.org_1   | 2022-04-08 12:03:06,430 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 12:03:06,445 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50978
scm2.org_1   | 2022-04-08 12:03:06,455 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 12:03:06,480 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 2022-04-08 11:53:51,083 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 11:54:06,409 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34134
scm3.org_1   | 2022-04-08 11:48:15,388 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm3.org_1   | 2022-04-08 11:48:15,411 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm3.org_1   | 2022-04-08 11:48:15,677 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm3.org_1   | 2022-04-08 11:48:15,702 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm3.org_1   | 2022-04-08 11:48:15,710 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm1.org_1   | 2022-04-08 11:48:07,775 [grpc-default-executor-0] INFO server.GrpcLogAppender: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-InstallSnapshotResponseHandler: received a reply 088c2e91-0545-411d-8d31-8415832ed844<-9ebec731-0724-46e8-adb1-25fbc2c43c85#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2022-04-08 11:48:07,784 [grpc-default-executor-0] INFO server.GrpcLogAppender: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm2.org_1   | 2022-04-08 12:03:36,353 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49206
scm2.org_1   | 2022-04-08 12:03:36,373 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
scm1.org_1   | 2022-04-08 11:48:07,785 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:12)
scm3.org_1   | 2022-04-08 11:48:16,232 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
om1_1        | 2022-04-08 11:57:41,743 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm2.org_1   | 2022-04-08 12:03:36,459 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51060
scm2.org_1   | 2022-04-08 12:03:36,473 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58230
scm2.org_1   | 2022-04-08 12:03:36,509 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 12:03:36,528 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 12:04:06,353 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49268
scm2.org_1   | 2022-04-08 12:04:06,361 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 12:04:06,394 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58294
scm2.org_1   | 2022-04-08 12:04:06,438 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51120
scm2.org_1   | 2022-04-08 12:04:06,454 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 12:04:06,474 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 12:04:36,354 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49360
scm2.org_1   | 2022-04-08 12:04:36,442 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 12:04:36,448 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58388
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
scm3.org_1   | 2022-04-08 11:48:16,238 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
recon_1      | 2022-04-08 11:54:06,436 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:60204
recon_1      | 2022-04-08 11:54:06,444 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm2.org_1   | 2022-04-08 12:04:36,504 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51210
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
scm1.org_1   | 2022-04-08 11:48:07,791 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-GrpcLogAppender: send 088c2e91-0545-411d-8d31-8415832ed844->9ebec731-0724-46e8-adb1-25fbc2c43c85#0-t2,notify:(t:2, i:12)
scm1.org_1   | 2022-04-08 11:48:07,816 [grpc-default-executor-0] INFO leader.FollowerInfo: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85: nextIndex: updateUnconditionally 0 -> 0
scm2.org_1   | 2022-04-08 12:04:36,510 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 11:48:16,239 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm3.org_1   | 2022-04-08 11:48:16,239 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
recon_1      | 2022-04-08 11:54:06,445 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #2 got from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net.
recon_1      | 2022-04-08 11:54:06,511 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 11:54:06,539 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36544
recon_1      | 2022-04-08 11:54:06,561 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 11:54:06,631 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: Successfully added container #2 to Recon.
recon_1      | 2022-04-08 11:54:33,607 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
recon_1      | 2022-04-08 11:54:33,607 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
om1_1        | 2022-04-08 11:57:41,745 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm1.org_1   | 2022-04-08 11:48:07,847 [grpc-default-executor-0] INFO server.GrpcLogAppender: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-InstallSnapshotResponseHandler: received a reply 088c2e91-0545-411d-8d31-8415832ed844<-9ebec731-0724-46e8-adb1-25fbc2c43c85#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2022-04-08 11:48:07,848 [grpc-default-executor-0] INFO server.GrpcLogAppender: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2022-04-08 11:48:07,849 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:12)
scm3.org_1   | 2022-04-08 11:48:16,374 [Listener at 0.0.0.0/9860] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
scm3.org_1   | 2022-04-08 11:48:16,375 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm3.org_1   | 2022-04-08 11:48:16,376 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
scm3.org_1   | 2022-04-08 11:48:16,383 [Listener at 0.0.0.0/9860] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService starting
scm3.org_1   | 2022-04-08 11:48:17,058 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
om1_1        | 2022-04-08 11:57:41,762 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:41,764 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:41,766 [IPC Server handler 46 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:41,773 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm1.org_1   | 2022-04-08 11:48:07,852 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-GrpcLogAppender: send 088c2e91-0545-411d-8d31-8415832ed844->9ebec731-0724-46e8-adb1-25fbc2c43c85#0-t2,notify:(t:2, i:12)
scm1.org_1   | 2022-04-08 11:48:07,946 [grpc-default-executor-0] INFO leader.FollowerInfo: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2022-04-08 11:48:07,953 [grpc-default-executor-0] INFO server.GrpcLogAppender: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-InstallSnapshotResponseHandler: received a reply 088c2e91-0545-411d-8d31-8415832ed844<-9ebec731-0724-46e8-adb1-25fbc2c43c85#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2022-04-08 11:48:07,958 [grpc-default-executor-0] INFO server.GrpcLogAppender: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2022-04-08 11:48:07,960 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:12)
scm1.org_1   | 2022-04-08 11:48:07,961 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-GrpcLogAppender: send 088c2e91-0545-411d-8d31-8415832ed844->9ebec731-0724-46e8-adb1-25fbc2c43c85#0-t2,notify:(t:2, i:12)
om1_1        | 2022-04-08 11:57:41,775 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:41,779 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:41,826 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:42,459 [IPC Server handler 95 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:43,191 [IPC Server handler 71 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm3.org_1   | 2022-04-08 11:48:17,058 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
scm3.org_1   | 2022-04-08 11:48:17,058 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1679)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
scm1.org_1   | 2022-04-08 11:48:08,006 [grpc-default-executor-0] INFO leader.FollowerInfo: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85: nextIndex: updateUnconditionally 0 -> 0
scm2.org_1   | 2022-04-08 12:04:36,527 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 12:05:06,371 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49494
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
scm3.org_1   | 2022-04-08 11:48:18,418 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@43baf0b9] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm3.org_1   | 2022-04-08 11:48:18,489 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm1.org_1   | 2022-04-08 11:48:08,035 [grpc-default-executor-0] INFO server.GrpcLogAppender: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-InstallSnapshotResponseHandler: received a reply 088c2e91-0545-411d-8d31-8415832ed844<-9ebec731-0724-46e8-adb1-25fbc2c43c85#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2022-04-08 11:48:08,039 [grpc-default-executor-0] INFO server.GrpcLogAppender: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2022-04-08 11:48:08,040 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:12)
scm1.org_1   | 2022-04-08 11:48:08,043 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-GrpcLogAppender: send 088c2e91-0545-411d-8d31-8415832ed844->9ebec731-0724-46e8-adb1-25fbc2c43c85#0-t2,notify:(t:2, i:12)
scm1.org_1   | 2022-04-08 11:48:08,079 [grpc-default-executor-0] INFO leader.FollowerInfo: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2022-04-08 11:48:08,084 [grpc-default-executor-0] INFO server.GrpcLogAppender: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-InstallSnapshotResponseHandler: received a reply 088c2e91-0545-411d-8d31-8415832ed844<-9ebec731-0724-46e8-adb1-25fbc2c43c85#0:FAIL-t2,IN_PROGRESS
om1_1        | 2022-04-08 11:57:43,193 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
recon_1      | 2022-04-08 11:54:33,641 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
scm2.org_1   | 2022-04-08 12:05:06,404 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 11:48:08,089 [grpc-default-executor-0] INFO server.GrpcLogAppender: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-InstallSnapshotResponseHandler: InstallSnapshot in progress.
om1_1        | 2022-04-08 11:57:43,195 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:43,209 [IPC Server handler 67 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:43,212 [IPC Server handler 68 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:43,215 [IPC Server handler 52 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:43,226 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
scm1.org_1   | 2022-04-08 11:48:08,112 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:12)
scm1.org_1   | 2022-04-08 11:48:08,115 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-GrpcLogAppender: send 088c2e91-0545-411d-8d31-8415832ed844->9ebec731-0724-46e8-adb1-25fbc2c43c85#0-t2,notify:(t:2, i:12)
scm3.org_1   | 2022-04-08 11:48:18,489 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
scm3.org_1   | 2022-04-08 11:48:18,495 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
scm3.org_1   | 2022-04-08 11:48:18,662 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @26795ms to org.eclipse.jetty.util.log.Slf4jLog
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
om1_1        | 2022-04-08 11:57:43,227 [IPC Server handler 61 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm3.org_1   | 2022-04-08 11:48:19,395 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm2.org_1   | 2022-04-08 12:05:06,432 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51346
scm2.org_1   | 2022-04-08 12:05:06,442 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58524
scm1.org_1   | 2022-04-08 11:48:08,189 [grpc-default-executor-0] INFO leader.FollowerInfo: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2022-04-08 11:48:08,192 [grpc-default-executor-0] INFO server.GrpcLogAppender: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-InstallSnapshotResponseHandler: received a reply 088c2e91-0545-411d-8d31-8415832ed844<-9ebec731-0724-46e8-adb1-25fbc2c43c85#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2022-04-08 11:48:08,200 [grpc-default-executor-0] INFO server.GrpcLogAppender: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2022-04-08 11:48:08,208 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:12)
scm1.org_1   | 2022-04-08 11:48:08,210 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-GrpcLogAppender: send 088c2e91-0545-411d-8d31-8415832ed844->9ebec731-0724-46e8-adb1-25fbc2c43c85#0-t2,notify:(t:2, i:12)
om1_1        | 2022-04-08 11:57:43,230 [IPC Server handler 85 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:43,257 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:43,367 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
scm3.org_1   | 2022-04-08 11:48:19,442 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm2.org_1   | 2022-04-08 12:05:06,471 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 12:05:06,478 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 12:05:36,362 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49586
scm2.org_1   | 2022-04-08 12:05:36,422 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 12:05:36,441 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58614
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
om1_1        | 2022-04-08 11:57:44,001 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:44,006 [IPC Server handler 43 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:44,008 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:44,029 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:44,032 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm3.org_1   | 2022-04-08 11:48:19,450 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
scm3.org_1   | 2022-04-08 11:48:19,459 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
scm3.org_1   | 2022-04-08 11:48:19,463 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
scm3.org_1   | 2022-04-08 11:48:19,469 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
scm3.org_1   | 2022-04-08 11:48:19,743 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
scm3.org_1   | 2022-04-08 11:48:19,753 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
scm3.org_1   | 2022-04-08 11:48:20,029 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
scm2.org_1   | 2022-04-08 12:05:36,467 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-08 12:05:36,496 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51434
scm2.org_1   | 2022-04-08 12:05:36,500 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
om1_1        | 2022-04-08 11:57:44,035 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:44,054 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
om1_1        | 2022-04-08 11:57:44,056 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:44,057 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:44,083 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:47,238 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:47,865 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:47,867 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm3.org_1   | 2022-04-08 11:48:20,049 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm3.org_1   | 2022-04-08 11:48:20,053 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 660000ms
scm3.org_1   | 2022-04-08 11:48:20,163 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm3.org_1   | 2022-04-08 11:48:20,172 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@38ad8c75{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm3.org_1   | 2022-04-08 11:48:20,181 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1928930{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm3.org_1   | 2022-04-08 11:48:21,002 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm3.org_1   | 2022-04-08 11:48:21,102 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@11303cb{scm,/,file:///tmp/jetty-0_0_0_0-9876-hdds-server-scm-1_3_0-SNAPSHOT_jar-_-any-4339804805439156498/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/scm}
scm1.org_1   | 2022-04-08 11:48:08,231 [grpc-default-executor-0] INFO leader.FollowerInfo: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2022-04-08 11:48:08,306 [grpc-default-executor-0] INFO server.GrpcLogAppender: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-InstallSnapshotResponseHandler: received a reply 088c2e91-0545-411d-8d31-8415832ed844<-9ebec731-0724-46e8-adb1-25fbc2c43c85#0:FAIL-t2,SNAPSHOT_INSTALLED,snapshotIndex=12
scm1.org_1   | 2022-04-08 11:48:08,313 [grpc-default-executor-0] INFO server.GrpcLogAppender: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85-InstallSnapshotResponseHandler: Follower installed snapshot at index 12
scm1.org_1   | 2022-04-08 11:48:08,314 [grpc-default-executor-0] INFO leader.FollowerInfo: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85: snapshotIndex: setUnconditionally 0 -> 12
scm1.org_1   | 2022-04-08 11:48:08,314 [grpc-default-executor-0] INFO leader.FollowerInfo: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85: matchIndex: setUnconditionally 0 -> 12
scm1.org_1   | 2022-04-08 11:48:08,314 [grpc-default-executor-0] INFO leader.FollowerInfo: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85: nextIndex: setUnconditionally 0 -> 13
scm1.org_1   | 2022-04-08 11:48:08,314 [grpc-default-executor-0] INFO leader.FollowerInfo: Follower 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85 acknowledged installing snapshot
scm1.org_1   | 2022-04-08 11:48:08,330 [grpc-default-executor-0] INFO leader.FollowerInfo: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F->9ebec731-0724-46e8-adb1-25fbc2c43c85: nextIndex: updateToMax old=13, new=13, updated? false
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
om1_1        | 2022-04-08 11:57:47,869 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:48,495 [IPC Server handler 73 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
scm3.org_1   | 2022-04-08 11:48:21,189 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@4095ebff{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
scm3.org_1   | 2022-04-08 11:48:21,189 [Listener at 0.0.0.0/9860] INFO server.Server: Started @29323ms
om1_1        | 2022-04-08 11:57:48,497 [IPC Server handler 65 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm1.org_1   | 2022-04-08 11:48:12,202 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-LeaderStateImpl] INFO server.RaftServer$Division: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F: set configuration 13: [088c2e91-0545-411d-8d31-8415832ed844|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 9ebec731-0724-46e8-adb1-25fbc2c43c85|rpc:scm3.org:9894|priority:0, 028f51fd-62f3-478d-a538-df850a92e5c2|rpc:scm2.org:9894|priority:0], old=[088c2e91-0545-411d-8d31-8415832ed844|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 028f51fd-62f3-478d-a538-df850a92e5c2|rpc:scm2.org:9894|priority:0]
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
scm3.org_1   | 2022-04-08 11:48:21,216 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm3.org_1   | 2022-04-08 11:48:21,216 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm3.org_1   | 2022-04-08 11:48:21,232 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1        | 2022-04-08 11:57:48,502 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm1.org_1   | 2022-04-08 11:48:12,237 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-LeaderStateImpl] INFO server.RaftServer$Division: 088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F: set configuration 15: [088c2e91-0545-411d-8d31-8415832ed844|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 9ebec731-0724-46e8-adb1-25fbc2c43c85|rpc:scm3.org:9894|priority:0, 028f51fd-62f3-478d-a538-df850a92e5c2|rpc:scm2.org:9894|priority:0], old=null
scm1.org_1   | 2022-04-08 11:48:12,277 [IPC Server handler 7 on default port 9863] INFO ha.SCMRatisServerImpl: Successfully added new SCM: 9ebec731-0724-46e8-adb1-25fbc2c43c85.
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
scm3.org_1   | 2022-04-08 11:48:28,641 [9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-04-08 11:48:28,660 [9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F-StateMachineUpdater] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm3.org_1   | 2022-04-08 11:48:28,663 [9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F-StateMachineUpdater] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
om1_1        | 2022-04-08 11:57:48,512 [IPC Server handler 63 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
scm3.org_1   | 2022-04-08 11:48:29,151 [9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-04-08 11:48:17,864 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.118:46550
om1_1        | 2022-04-08 11:57:49,418 [IPC Server handler 72 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
scm3.org_1   | 2022-04-08 11:48:31,802 [9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om1_1        | 2022-04-08 11:57:49,420 [IPC Server handler 80 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:49,422 [IPC Server handler 66 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:50,057 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:50,064 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1        | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #188 timeout 180s
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:368)
scm3.org_1   | 2022-04-08 11:48:36,187 [9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-04-08 11:48:36,790 [9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-04-08 11:48:37,708 [9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-04-08 11:48:51,683 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37780
scm3.org_1   | 2022-04-08 11:48:51,730 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 11:48:53,998 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45198
scm3.org_1   | 2022-04-08 11:48:54,166 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2022-04-08 11:57:50,065 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:50,700 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
s3g_1        | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
om1_1        | 2022-04-08 11:57:50,702 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:50,706 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
scm1.org_1   | 2022-04-08 11:48:17,911 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-04-08 11:48:24,152 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:44098
scm1.org_1   | 2022-04-08 11:48:24,259 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
scm3.org_1   | 2022-04-08 11:48:55,636 [IPC Server handler 11 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/8b7f16e2-5fb9-442f-a717-cc893c5795e0
scm3.org_1   | 2022-04-08 11:48:55,675 [IPC Server handler 11 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 8b7f16e2-5fb9-442f-a717-cc893c5795e0{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 932981906868, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
om1_1        | 2022-04-08 11:57:53,923 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43342
om1_1        | 2022-04-08 11:57:53,942 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:57:56,898 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:56,900 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:56,907 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-5575003451 of layout LEGACY in volume: s3v
om1_1        | 2022-04-08 11:57:57,503 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:57,506 [IPC Server handler 96 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm3.org_1   | 2022-04-08 11:48:55,762 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm3.org_1   | 2022-04-08 11:48:55,875 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
scm3.org_1   | 2022-04-08 11:48:55,879 [IPC Server handler 1 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/0005597f-3053-4b02-96b8-efe2de95313b
scm3.org_1   | 2022-04-08 11:48:56,065 [IPC Server handler 1 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 0005597f-3053-4b02-96b8-efe2de95313b{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 933750048452, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
scm1.org_1   | 2022-04-08 11:48:25,021 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:56022
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:373)
scm3.org_1   | 2022-04-08 11:48:56,068 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm3.org_1   | 2022-04-08 11:48:56,073 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
scm1.org_1   | 2022-04-08 11:48:25,128 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-04-08 11:48:25,620 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:44618
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:368)
om1_1        | 2022-04-08 11:57:57,513 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: destbucket-38461 of layout LEGACY in volume: s3v
om1_1        | 2022-04-08 11:57:58,090 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:57:58,094 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm3.org_1   | 2022-04-08 11:48:56,962 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45966
scm3.org_1   | 2022-04-08 11:48:57,135 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2022-04-08 11:57:58,096 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:58:00,690 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:58:01,301 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:58:01,302 [IPC Server handler 72 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:58:01,305 [IPC Server handler 80 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm1.org_1   | 2022-04-08 11:48:25,719 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-04-08 11:48:27,872 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52804
scm1.org_1   | 2022-04-08 11:48:27,971 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:357)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
om1_1        | 2022-04-08 11:58:01,310 [IPC Server handler 66 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm1.org_1   | 2022-04-08 11:48:27,976 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn 19c25d99ddaf, UUID: 8b7f16e2-5fb9-442f-a717-cc893c5795e0
scm1.org_1   | 2022-04-08 11:48:28,414 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-04-08 11:48:28,722 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:47872
scm1.org_1   | 2022-04-08 11:48:28,759 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-04-08 11:48:28,762 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn e7d6b6474bc4, UUID: 0005597f-3053-4b02-96b8-efe2de95313b
scm1.org_1   | 2022-04-08 11:48:29,136 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
s3g_1        | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1        | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1        | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1        | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1        | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
om1_1        | 2022-04-08 11:58:01,916 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1        | 	... 1 more
s3g_1        | 2022-04-08 12:05:30,443 [qtp1423016050-21] INFO scm.XceiverClientRatis: Could not commit index 144 on pipeline Pipeline[ Id: a6f33c92-47f3-4bcf-8c55-0543fc7274b5, Nodes: 8b7f16e2-5fb9-442f-a717-cc893c5795e0{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}0005597f-3053-4b02-96b8-efe2de95313b{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}4cf3df89-7b36-4576-a18a-5d0c57ddb620{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:4cf3df89-7b36-4576-a18a-5d0c57ddb620, CreationTimestamp2022-04-08T11:48:59.048Z[UTC]] to all the nodes. Server 0005597f-3053-4b02-96b8-efe2de95313b has failed. Committed by majority.
s3g_1        | 2022-04-08 12:05:30,443 [qtp1423016050-21] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 1 locID: 109611004723200055 bcsId: 144 on Pipeline[ Id: a6f33c92-47f3-4bcf-8c55-0543fc7274b5, Nodes: 8b7f16e2-5fb9-442f-a717-cc893c5795e0{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}0005597f-3053-4b02-96b8-efe2de95313b{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}4cf3df89-7b36-4576-a18a-5d0c57ddb620{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:4cf3df89-7b36-4576-a18a-5d0c57ddb620, CreationTimestamp2022-04-08T11:48:59.048Z[UTC]]. Failed nodes: [0005597f-3053-4b02-96b8-efe2de95313b{ip: null, host: null, ports: [], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
scm3.org_1   | 2022-04-08 11:48:57,968 [9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: a76fa8e1-27b1-4e30-acd2-3b267e60a22d, Nodes: 8b7f16e2-5fb9-442f-a717-cc893c5795e0{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-04-08T11:48:56.511Z[UTC]].
scm3.org_1   | 2022-04-08 11:48:57,974 [9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-04-08 11:48:58,031 [9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 8c48fa47-1e15-404a-9159-e49e3da5df9c, Nodes: 0005597f-3053-4b02-96b8-efe2de95313b{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-04-08T11:48:57.726Z[UTC]].
scm3.org_1   | 2022-04-08 11:48:58,034 [9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om1_1        | 2022-04-08 11:58:01,918 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm3.org_1   | 2022-04-08 11:48:58,818 [IPC Server handler 63 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/4cf3df89-7b36-4576-a18a-5d0c57ddb620
recon_1      | 	... 35 more
scm1.org_1   | 2022-04-08 11:48:31,345 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33340
scm1.org_1   | 2022-04-08 11:48:31,525 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm3.org_1   | 2022-04-08 11:48:58,819 [IPC Server handler 63 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 4cf3df89-7b36-4576-a18a-5d0c57ddb620{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 936508841118, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-04-08 11:54:36,340 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34300
scm1.org_1   | 2022-04-08 11:48:31,526 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn 1e89468786a9, UUID: 4cf3df89-7b36-4576-a18a-5d0c57ddb620
scm1.org_1   | 2022-04-08 11:48:31,763 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om1_1        | 2022-04-08 11:58:01,920 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:58:01,922 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
recon_1      | 2022-04-08 11:54:36,368 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 11:54:36,447 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:60372
om1_1        | 2022-04-08 11:58:01,930 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:58:01,966 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:58:01,979 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:58:04,560 [IPC Server handler 59 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm3.org_1   | 2022-04-08 11:48:58,820 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm3.org_1   | 2022-04-08 11:48:58,821 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
om1_1        | 2022-04-08 11:58:04,575 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:58:05,191 [IPC Server handler 71 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm1.org_1   | 2022-04-08 11:48:33,713 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42514
scm1.org_1   | 2022-04-08 11:48:33,822 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
recon_1      | 2022-04-08 11:54:36,456 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 11:54:36,464 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36714
scm1.org_1   | 2022-04-08 11:48:35,760 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:47096
scm1.org_1   | 2022-04-08 11:48:35,791 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
om1_1        | 2022-04-08 11:58:05,195 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm3.org_1   | 2022-04-08 11:48:58,821 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm3.org_1   | 2022-04-08 11:48:58,821 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm3.org_1   | 2022-04-08 11:48:58,821 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm3.org_1   | 2022-04-08 11:48:58,821 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
scm3.org_1   | 2022-04-08 11:48:58,821 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm3.org_1   | 2022-04-08 11:48:58,991 [9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: cfd3e9b8-6c85-4577-8ecd-7af890cf2706, Nodes: 4cf3df89-7b36-4576-a18a-5d0c57ddb620{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-04-08T11:48:58.915Z[UTC]].
scm3.org_1   | 2022-04-08 11:48:58,991 [9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-04-08 11:48:59,159 [9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: a6f33c92-47f3-4bcf-8c55-0543fc7274b5, Nodes: 8b7f16e2-5fb9-442f-a717-cc893c5795e0{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}0005597f-3053-4b02-96b8-efe2de95313b{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}4cf3df89-7b36-4576-a18a-5d0c57ddb620{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-04-08T11:48:59.048Z[UTC]].
scm3.org_1   | 2022-04-08 11:48:59,160 [9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-04-08 11:48:59,330 [9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: d7bff567-93ff-485c-a104-bc074898d12a, Nodes: 0005597f-3053-4b02-96b8-efe2de95313b{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}4cf3df89-7b36-4576-a18a-5d0c57ddb620{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}8b7f16e2-5fb9-442f-a717-cc893c5795e0{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-04-08T11:48:59.171Z[UTC]].
scm3.org_1   | 2022-04-08 11:48:59,330 [9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-04-08 11:49:02,098 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: cfd3e9b8-6c85-4577-8ecd-7af890cf2706, Nodes: 4cf3df89-7b36-4576-a18a-5d0c57ddb620{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:4cf3df89-7b36-4576-a18a-5d0c57ddb620, CreationTimestamp2022-04-08T11:48:58.915Z[UTC]] moved to OPEN state
scm1.org_1   | 2022-04-08 11:48:35,829 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for om om2, UUID: 43c25a0a-cbe2-4f8f-87b4-6b5c7d4d0ede
scm3.org_1   | 2022-04-08 11:49:02,351 [9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-04-08 11:49:03,130 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
om1_1        | 2022-04-08 11:58:05,197 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:58:05,200 [IPC Server handler 67 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm1.org_1   | 2022-04-08 11:48:36,169 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
recon_1      | 2022-04-08 11:54:36,534 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 11:55:06,391 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34476
recon_1      | 2022-04-08 11:55:06,472 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:60544
recon_1      | 2022-04-08 11:55:06,481 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36890
recon_1      | 2022-04-08 11:55:06,485 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 11:55:06,493 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 11:55:06,588 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm1.org_1   | 2022-04-08 11:48:36,447 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:40098
recon_1      | 2022-04-08 11:55:33,644 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-04-08 11:55:33,644 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-04-08 11:55:33,690 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
scm1.org_1   | 2022-04-08 11:48:36,499 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-04-08 11:58:05,763 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:58:05,766 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:58:05,768 [IPC Server handler 46 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:58:05,776 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:58:05,777 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:58:05,785 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm1.org_1   | 2022-04-08 11:48:36,502 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for om om1, UUID: ecff06fd-f6b2-4711-acf8-eb4234935b65
scm1.org_1   | 2022-04-08 11:48:36,744 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om1_1        | 2022-04-08 11:58:05,795 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:58:08,361 [IPC Server handler 95 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:58:08,378 [IPC Server handler 81 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:58:08,986 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:58:08,988 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:58:08,989 [IPC Server handler 43 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:58:08,992 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:58:09,573 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:58:09,575 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:58:09,578 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:58:09,579 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:58:10,151 [IPC Server handler 71 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:58:10,154 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:58:11,387 [IPC Server handler 81 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:58:11,390 [IPC Server handler 65 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:58:11,391 [IPC Server handler 73 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:58:11,396 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:58:11,397 [IPC Server handler 63 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:58:14,596 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43438
om1_1        | 2022-04-08 11:58:14,616 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:58:17,590 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:58:17,593 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:58:17,600 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-5420801628 of layout LEGACY in volume: s3v
om1_1        | 2022-04-08 11:58:18,199 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:58:18,201 [IPC Server handler 67 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:58:18,203 [IPC Server handler 68 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:58:33,838 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:35377
scm3.org_1   | 2022-04-08 11:49:08,132 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
scm3.org_1   | 2022-04-08 11:49:09,280 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm3.org_1   | 2022-04-08 11:49:10,748 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45264
scm1.org_1   | 2022-04-08 11:48:37,571 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:55074
scm1.org_1   | 2022-04-08 11:48:37,588 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-04-08 11:48:37,588 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for om om3, UUID: d078aee7-755e-4695-954b-78f9ef4019f8
scm3.org_1   | 2022-04-08 11:49:10,840 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 11:49:10,842 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: a6f33c92-47f3-4bcf-8c55-0543fc7274b5, Nodes: 8b7f16e2-5fb9-442f-a717-cc893c5795e0{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}0005597f-3053-4b02-96b8-efe2de95313b{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}4cf3df89-7b36-4576-a18a-5d0c57ddb620{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:4cf3df89-7b36-4576-a18a-5d0c57ddb620, CreationTimestamp2022-04-08T11:48:59.048Z[UTC]] moved to OPEN state
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
scm3.org_1   | 2022-04-08 11:49:11,239 [9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
scm3.org_1   | 2022-04-08 11:49:11,578 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm3.org_1   | 2022-04-08 11:49:11,579 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
scm3.org_1   | 2022-04-08 11:49:11,579 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm3.org_1   | 2022-04-08 11:49:11,580 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm3.org_1   | 2022-04-08 11:49:11,580 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
scm3.org_1   | 2022-04-08 11:49:11,580 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm3.org_1   | 2022-04-08 11:49:11,580 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
scm3.org_1   | 2022-04-08 11:49:28,146 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37932
scm3.org_1   | 2022-04-08 11:49:28,174 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 11:49:28,176 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: a76fa8e1-27b1-4e30-acd2-3b267e60a22d, Nodes: 8b7f16e2-5fb9-442f-a717-cc893c5795e0{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:8b7f16e2-5fb9-442f-a717-cc893c5795e0, CreationTimestamp2022-04-08T11:48:56.511Z[UTC]] moved to OPEN state
scm3.org_1   | 2022-04-08 11:49:28,605 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45342
scm3.org_1   | 2022-04-08 11:49:28,655 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 11:49:28,660 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 8c48fa47-1e15-404a-9159-e49e3da5df9c, Nodes: 0005597f-3053-4b02-96b8-efe2de95313b{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:0005597f-3053-4b02-96b8-efe2de95313b, CreationTimestamp2022-04-08T11:48:57.726Z[UTC]] moved to OPEN state
scm3.org_1   | 2022-04-08 11:49:41,653 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46128
scm3.org_1   | 2022-04-08 11:49:41,690 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 11:49:47,265 [9ebec731-0724-46e8-adb1-25fbc2c43c85@group-A2EA220FD69F-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 109611004723200000.
scm3.org_1   | 2022-04-08 11:49:47,744 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37994
scm3.org_1   | 2022-04-08 11:49:47,790 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 11:49:51,086 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45408
scm3.org_1   | 2022-04-08 11:49:51,151 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 11:50:20,739 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46254
scm3.org_1   | 2022-04-08 11:50:20,774 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 11:50:21,034 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45510
scm1.org_1   | 2022-04-08 11:48:37,676 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om1_1        | 2022-04-08 11:58:33,848 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:59:19,235 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:39289
om1_1        | 2022-04-08 11:59:19,253 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 11:59:19,253 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:59:19,256 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm1.org_1   | 2022-04-08 11:48:38,014 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52830
scm1.org_1   | 2022-04-08 11:48:38,051 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-04-08 11:48:38,570 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:47898
scm1.org_1   | 2022-04-08 11:48:38,603 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-04-08 11:48:42,308 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33380
scm1.org_1   | 2022-04-08 11:48:42,355 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-04-08 11:48:51,617 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:43974
scm1.org_1   | 2022-04-08 11:48:51,652 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 11:48:54,019 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55640
scm1.org_1   | 2022-04-08 11:48:54,180 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 11:48:55,968 [IPC Server handler 99 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/0005597f-3053-4b02-96b8-efe2de95313b
scm1.org_1   | 2022-04-08 11:48:56,126 [IPC Server handler 2 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/8b7f16e2-5fb9-442f-a717-cc893c5795e0
scm1.org_1   | 2022-04-08 11:48:56,167 [IPC Server handler 2 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 8b7f16e2-5fb9-442f-a717-cc893c5795e0{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 932981906868, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm1.org_1   | 2022-04-08 11:48:56,184 [IPC Server handler 99 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 0005597f-3053-4b02-96b8-efe2de95313b{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 933750048452, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm1.org_1   | 2022-04-08 11:48:56,261 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm1.org_1   | 2022-04-08 11:48:56,267 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm1.org_1   | 2022-04-08 11:48:56,365 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
scm1.org_1   | 2022-04-08 11:48:56,485 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
scm1.org_1   | 2022-04-08 11:48:56,670 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=a76fa8e1-27b1-4e30-acd2-3b267e60a22d to datanode:8b7f16e2-5fb9-442f-a717-cc893c5795e0
scm1.org_1   | 2022-04-08 11:48:57,192 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$437/0x0000000840547c40@b21cbbf] WARN util.JvmPauseMonitor: JvmPauseMonitor-088c2e91-0545-411d-8d31-8415832ed844: Detected pause in JVM or host machine (eg GC): pause of approximately 133289579ns.
scm1.org_1   | GC pool 'ParNew' had collection(s): count=1 time=161ms
scm1.org_1   | 2022-04-08 11:48:57,317 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43134
scm1.org_1   | 2022-04-08 11:48:57,445 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 11:48:57,610 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: a76fa8e1-27b1-4e30-acd2-3b267e60a22d, Nodes: 8b7f16e2-5fb9-442f-a717-cc893c5795e0{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-04-08T11:48:56.511Z[UTC]].
scm1.org_1   | 2022-04-08 11:48:57,672 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-04-08 11:48:57,726 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=8c48fa47-1e15-404a-9159-e49e3da5df9c to datanode:0005597f-3053-4b02-96b8-efe2de95313b
scm1.org_1   | 2022-04-08 11:48:57,855 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 8c48fa47-1e15-404a-9159-e49e3da5df9c, Nodes: 0005597f-3053-4b02-96b8-efe2de95313b{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-04-08T11:48:57.726Z[UTC]].
scm1.org_1   | 2022-04-08 11:48:57,858 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-04-08 11:48:58,878 [IPC Server handler 0 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/4cf3df89-7b36-4576-a18a-5d0c57ddb620
scm1.org_1   | 2022-04-08 11:48:58,905 [IPC Server handler 0 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 4cf3df89-7b36-4576-a18a-5d0c57ddb620{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 936508841118, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm1.org_1   | 2022-04-08 11:48:58,906 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm1.org_1   | 2022-04-08 11:48:58,915 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=cfd3e9b8-6c85-4577-8ecd-7af890cf2706 to datanode:4cf3df89-7b36-4576-a18a-5d0c57ddb620
scm1.org_1   | 2022-04-08 11:48:58,944 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
scm1.org_1   | 2022-04-08 11:48:58,944 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm1.org_1   | 2022-04-08 11:48:58,950 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm1.org_1   | 2022-04-08 11:48:58,951 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm1.org_1   | 2022-04-08 11:48:58,952 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
scm1.org_1   | 2022-04-08 11:48:58,953 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm1.org_1   | 2022-04-08 11:48:58,965 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: cfd3e9b8-6c85-4577-8ecd-7af890cf2706, Nodes: 4cf3df89-7b36-4576-a18a-5d0c57ddb620{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-04-08T11:48:58.915Z[UTC]].
scm1.org_1   | 2022-04-08 11:48:58,975 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-04-08 11:48:59,048 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=a6f33c92-47f3-4bcf-8c55-0543fc7274b5 to datanode:8b7f16e2-5fb9-442f-a717-cc893c5795e0
scm1.org_1   | 2022-04-08 11:48:59,067 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=a6f33c92-47f3-4bcf-8c55-0543fc7274b5 to datanode:0005597f-3053-4b02-96b8-efe2de95313b
scm1.org_1   | 2022-04-08 11:48:59,067 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=a6f33c92-47f3-4bcf-8c55-0543fc7274b5 to datanode:4cf3df89-7b36-4576-a18a-5d0c57ddb620
scm1.org_1   | 2022-04-08 11:48:59,149 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: a6f33c92-47f3-4bcf-8c55-0543fc7274b5, Nodes: 8b7f16e2-5fb9-442f-a717-cc893c5795e0{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}0005597f-3053-4b02-96b8-efe2de95313b{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}4cf3df89-7b36-4576-a18a-5d0c57ddb620{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-04-08T11:48:59.048Z[UTC]].
scm1.org_1   | 2022-04-08 11:48:59,169 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-04-08 11:48:59,171 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=d7bff567-93ff-485c-a104-bc074898d12a to datanode:0005597f-3053-4b02-96b8-efe2de95313b
scm1.org_1   | 2022-04-08 11:48:59,231 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=d7bff567-93ff-485c-a104-bc074898d12a to datanode:4cf3df89-7b36-4576-a18a-5d0c57ddb620
scm1.org_1   | 2022-04-08 11:48:59,232 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=d7bff567-93ff-485c-a104-bc074898d12a to datanode:8b7f16e2-5fb9-442f-a717-cc893c5795e0
scm1.org_1   | 2022-04-08 11:48:59,338 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: d7bff567-93ff-485c-a104-bc074898d12a, Nodes: 0005597f-3053-4b02-96b8-efe2de95313b{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}4cf3df89-7b36-4576-a18a-5d0c57ddb620{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}8b7f16e2-5fb9-442f-a717-cc893c5795e0{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-04-08T11:48:59.171Z[UTC]].
scm1.org_1   | 2022-04-08 11:48:59,340 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-04-08 11:48:59,342 [RatisPipelineUtilsThread - 0] INFO pipeline.PipelineManagerImpl: Pipeline: PipelineID=d7bff567-93ff-485c-a104-bc074898d12a contains same datanodes as previous pipelines: PipelineID=a6f33c92-47f3-4bcf-8c55-0543fc7274b5 nodeIds: 0005597f-3053-4b02-96b8-efe2de95313b, 4cf3df89-7b36-4576-a18a-5d0c57ddb620, 8b7f16e2-5fb9-442f-a717-cc893c5795e0
scm1.org_1   | 2022-04-08 11:49:01,944 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:35417
scm1.org_1   | 2022-04-08 11:49:01,954 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:44724
scm1.org_1   | 2022-04-08 11:49:01,974 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-04-08 11:49:02,044 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:44210
scm1.org_1   | 2022-04-08 11:49:02,174 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-04-08 11:49:02,178 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: cfd3e9b8-6c85-4577-8ecd-7af890cf2706, Nodes: 4cf3df89-7b36-4576-a18a-5d0c57ddb620{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:4cf3df89-7b36-4576-a18a-5d0c57ddb620, CreationTimestamp2022-04-08T11:48:58.915Z[UTC]] moved to OPEN state
scm1.org_1   | 2022-04-08 11:49:02,241 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-04-08 11:49:02,279 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-04-08 11:49:02,380 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2022-04-08 11:49:02,695 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:56134
scm1.org_1   | 2022-04-08 11:49:02,775 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-04-08 11:49:03,140 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2022-04-08 11:49:08,169 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2022-04-08 11:49:09,325 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
scm3.org_1   | 2022-04-08 11:50:21,079 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
om1_1        | 2022-04-08 11:59:19,260 [IPC Server handler 72 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:59:19,405 [IPC Server handler 63 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:59:20,046 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:59:20,050 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:59:20,052 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:59:20,054 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:59:20,642 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1        | 2022-04-08 11:59:20,644 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:59:20,646 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:59:20,665 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:59:21,279 [IPC Server handler 72 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:59:21,282 [IPC Server handler 66 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:59:21,283 [IPC Server handler 80 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:59:22,039 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:59:22,041 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:59:22,042 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:59:22,724 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:59:22,726 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:59:22,729 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:59:23,378 [IPC Server handler 95 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
scm3.org_1   | 2022-04-08 11:50:21,145 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38110
scm3.org_1   | 2022-04-08 11:50:21,159 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 11:50:50,760 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46348
scm3.org_1   | 2022-04-08 11:50:50,804 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 11:50:51,037 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38198
scm3.org_1   | 2022-04-08 11:50:51,082 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 11:50:51,086 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45602
scm3.org_1   | 2022-04-08 11:50:51,089 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2022-04-08 11:59:23,380 [IPC Server handler 81 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-04-08 11:55:36,342 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34586
recon_1      | 2022-04-08 11:55:36,390 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:60656
recon_1      | 2022-04-08 11:55:36,400 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 11:55:36,466 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37000
recon_1      | 2022-04-08 11:55:36,469 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 11:55:36,486 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 11:56:06,371 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34700
recon_1      | 2022-04-08 11:56:06,420 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 11:56:06,432 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:60766
recon_1      | 2022-04-08 11:56:06,459 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37106
recon_1      | 2022-04-08 11:56:06,464 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 11:56:06,498 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 11:56:33,694 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-04-08 11:56:33,694 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-04-08 11:56:33,777 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
scm1.org_1   | 2022-04-08 11:49:09,761 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42632
om1_1        | 2022-04-08 11:59:23,382 [IPC Server handler 65 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:59:23,988 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:59:23,990 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:59:23,992 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:59:24,059 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:59:24,744 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm3.org_1   | 2022-04-08 11:51:20,691 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46458
scm3.org_1   | 2022-04-08 11:51:20,722 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 11:51:21,038 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38308
scm3.org_1   | 2022-04-08 11:51:21,069 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45710
scm3.org_1   | 2022-04-08 11:51:21,097 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 11:51:21,130 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 11:51:50,756 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46554
scm3.org_1   | 2022-04-08 11:51:50,783 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 11:51:51,051 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45814
scm3.org_1   | 2022-04-08 11:51:51,098 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38406
scm3.org_1   | 2022-04-08 11:51:51,109 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 11:51:51,127 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2022-04-08 11:59:24,749 [IPC Server handler 46 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:59:24,751 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:59:24,752 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:59:25,358 [IPC Server handler 95 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:59:25,360 [IPC Server handler 81 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:59:25,363 [IPC Server handler 65 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:59:26,112 [IPC Server handler 42 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:59:26,114 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:59:26,115 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:59:26,120 [IPC Server handler 71 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:59:26,809 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm3.org_1   | 2022-04-08 11:52:20,726 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46660
scm3.org_1   | 2022-04-08 11:52:20,759 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 11:52:21,035 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38514
scm3.org_1   | 2022-04-08 11:52:21,074 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45920
scm3.org_1   | 2022-04-08 11:52:21,096 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2022-04-08 11:59:26,810 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:59:26,812 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:59:26,821 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:59:27,432 [IPC Server handler 97 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:59:27,434 [IPC Server handler 87 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:59:27,436 [IPC Server handler 96 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 11:59:33,880 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:44487
om1_1        | 2022-04-08 11:59:33,885 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 12:00:28,052 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:43529
om1_1        | 2022-04-08 12:00:28,057 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 12:00:28,058 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:00:28,062 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:00:28,108 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:00:33,910 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:38681
om1_1        | 2022-04-08 12:00:33,925 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 12:01:19,090 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:38423
om1_1        | 2022-04-08 12:01:19,092 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 12:01:19,093 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm3.org_1   | 2022-04-08 11:52:21,128 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 11:52:50,717 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46762
scm3.org_1   | 2022-04-08 11:52:50,728 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 11:52:51,001 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38608
scm3.org_1   | 2022-04-08 11:52:51,050 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46018
scm3.org_1   | 2022-04-08 11:52:51,091 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 11:52:51,110 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 11:52:59,155 [ReplicationMonitor] INFO container.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm3.org_1   | 2022-04-08 11:53:20,732 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46874
scm3.org_1   | 2022-04-08 11:53:20,744 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 11:53:21,029 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46128
scm3.org_1   | 2022-04-08 11:53:21,057 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38722
scm3.org_1   | 2022-04-08 11:53:21,072 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 11:53:21,093 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 11:53:50,703 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46972
scm3.org_1   | 2022-04-08 11:53:50,720 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 11:53:51,035 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38816
scm3.org_1   | 2022-04-08 11:53:51,057 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46228
scm3.org_1   | 2022-04-08 11:53:51,070 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2022-04-08 12:01:29,858 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:39271
om1_1        | 2022-04-08 12:01:29,874 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 12:01:29,875 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:01:29,880 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:01:29,884 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:01:33,953 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:46383
om1_1        | 2022-04-08 12:01:33,960 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2022-04-08 11:53:51,073 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 11:54:06,467 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47032
recon_1      | 	... 20 more
om1_1        | 2022-04-08 12:02:28,085 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:44209
om1_1        | 2022-04-08 12:02:28,088 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 12:02:28,089 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:02:30,316 [IPC Server handler 95 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:02:30,318 [IPC Server handler 81 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:02:30,320 [IPC Server handler 65 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:02:33,987 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:46083
om1_1        | 2022-04-08 12:02:33,991 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
om1_1        | 2022-04-08 12:03:29,076 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:41153
om1_1        | 2022-04-08 12:03:29,083 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 12:03:29,083 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:03:34,016 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:38715
om1_1        | 2022-04-08 12:03:34,028 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
scm1.org_1   | 2022-04-08 11:49:09,856 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
om1_1        | 2022-04-08 12:03:34,562 [IPC Server handler 84 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:03:34,564 [IPC Server handler 77 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:03:34,566 [IPC Server handler 86 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:04:27,549 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:42535
om1_1        | 2022-04-08 12:04:27,559 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 12:04:27,560 [IPC Server handler 84 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:04:27,564 [IPC Server handler 77 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:04:30,058 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:04:33,312 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44404
om1_1        | 2022-04-08 12:04:33,355 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 12:04:34,061 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:45621
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
om1_1        | 2022-04-08 12:04:34,068 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 12:04:37,451 [IPC Server handler 63 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:04:37,455 [IPC Server handler 87 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:04:37,464 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-0487653167 of layout LEGACY in volume: s3v
scm3.org_1   | 2022-04-08 11:54:06,473 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46286
scm3.org_1   | 2022-04-08 11:54:06,524 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 11:54:06,538 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
scm3.org_1   | 2022-04-08 11:54:06,547 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38896
om1_1        | 2022-04-08 12:04:38,276 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:04:38,278 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:04:38,280 [IPC Server handler 72 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:04:38,439 [IPC Server handler 73 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm3.org_1   | 2022-04-08 11:54:06,636 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
om1_1        | 2022-04-08 12:04:39,076 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm3.org_1   | 2022-04-08 11:54:36,373 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47204
scm3.org_1   | 2022-04-08 11:54:36,462 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 11:54:36,470 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46450
scm3.org_1   | 2022-04-08 11:54:36,477 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2022-04-08 12:04:39,079 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:04:39,082 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
scm1.org_1   | 2022-04-08 11:49:10,521 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:55190
scm1.org_1   | 2022-04-08 11:49:10,551 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-04-08 11:49:11,024 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:40228
scm1.org_1   | 2022-04-08 11:49:11,043 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-04-08 11:49:11,054 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:47230
scm1.org_1   | 2022-04-08 11:49:11,063 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55712
scm1.org_1   | 2022-04-08 11:49:11,073 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 11:49:11,075 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
om1_1        | 2022-04-08 12:04:39,179 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:04:39,811 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm1.org_1   | 2022-04-08 11:49:11,081 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: a6f33c92-47f3-4bcf-8c55-0543fc7274b5, Nodes: 8b7f16e2-5fb9-442f-a717-cc893c5795e0{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}0005597f-3053-4b02-96b8-efe2de95313b{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}4cf3df89-7b36-4576-a18a-5d0c57ddb620{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:4cf3df89-7b36-4576-a18a-5d0c57ddb620, CreationTimestamp2022-04-08T11:48:59.048Z[UTC]] moved to OPEN state
scm3.org_1   | 2022-04-08 11:54:36,499 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39060
om1_1        | 2022-04-08 12:04:39,813 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:04:39,814 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm1.org_1   | 2022-04-08 11:49:11,178 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
scm3.org_1   | 2022-04-08 11:54:36,547 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 11:55:06,390 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47378
scm3.org_1   | 2022-04-08 11:55:06,455 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46626
scm3.org_1   | 2022-04-08 11:55:06,463 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 11:55:06,487 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39236
scm3.org_1   | 2022-04-08 11:55:06,508 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 11:55:06,582 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2022-04-08 12:04:39,900 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm3.org_1   | 2022-04-08 11:55:36,349 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47490
scm3.org_1   | 2022-04-08 11:55:36,388 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46738
om1_1        | 2022-04-08 12:04:40,585 [IPC Server handler 94 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm3.org_1   | 2022-04-08 11:55:36,405 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 11:55:36,428 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 11:55:36,488 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39346
scm3.org_1   | 2022-04-08 11:55:36,496 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 11:56:06,365 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47596
scm3.org_1   | 2022-04-08 11:56:06,386 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46844
scm1.org_1   | 2022-04-08 11:49:11,186 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
scm1.org_1   | 2022-04-08 11:49:11,220 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm1.org_1   | 2022-04-08 11:49:11,220 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm1.org_1   | 2022-04-08 11:49:11,220 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
scm1.org_1   | 2022-04-08 11:49:11,220 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm1.org_1   | 2022-04-08 11:49:11,224 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
scm1.org_1   | 2022-04-08 11:49:11,224 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO container.ReplicationManager: Service ReplicationManager transitions to RUNNING.
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
scm1.org_1   | 2022-04-08 11:49:22,817 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42686
scm1.org_1   | 2022-04-08 11:49:22,878 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-04-08 11:49:28,161 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:44118
scm3.org_1   | 2022-04-08 11:56:06,396 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
om1_1        | 2022-04-08 12:04:40,589 [IPC Server handler 99 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:04:40,591 [IPC Server handler 69 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm3.org_1   | 2022-04-08 11:56:06,424 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-04-08 11:56:36,337 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34834
recon_1      | 2022-04-08 11:56:36,346 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm3.org_1   | 2022-04-08 11:56:06,470 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39456
recon_1      | 2022-04-08 11:56:36,417 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:60898
om1_1        | 2022-04-08 12:04:40,594 [IPC Server handler 78 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:04:41,639 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:04:41,641 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:04:41,650 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:04:41,671 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:04:41,700 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:04:41,716 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:s3v, Bucket:bucket-ozone-test-0487653167, Key:ozone-test-2108438619/multidelete/key=value/f4.
om1_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:146)
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:92)
scm3.org_1   | 2022-04-08 11:56:06,498 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
scm1.org_1   | 2022-04-08 11:49:28,185 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 11:49:28,186 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: a76fa8e1-27b1-4e30-acd2-3b267e60a22d, Nodes: 8b7f16e2-5fb9-442f-a717-cc893c5795e0{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:8b7f16e2-5fb9-442f-a717-cc893c5795e0, CreationTimestamp2022-04-08T11:48:56.511Z[UTC]] moved to OPEN state
scm1.org_1   | 2022-04-08 11:49:28,231 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:35731
scm1.org_1   | 2022-04-08 11:49:28,241 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-04-08 11:49:28,616 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55780
scm3.org_1   | 2022-04-08 11:56:36,385 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47730
scm3.org_1   | 2022-04-08 11:56:36,409 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46976
scm3.org_1   | 2022-04-08 11:56:36,443 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 11:56:36,467 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 11:56:36,474 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39586
recon_1      | 2022-04-08 11:56:36,477 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 11:56:36,495 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37240
recon_1      | 2022-04-08 11:56:36,515 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm3.org_1   | 2022-04-08 11:56:36,508 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm3.org_1   | 2022-04-08 11:57:06,369 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47864
scm3.org_1   | 2022-04-08 11:57:06,450 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:47108
scm3.org_1   | 2022-04-08 11:57:06,481 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39724
scm3.org_1   | 2022-04-08 11:57:06,498 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 11:57:06,541 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 11:49:28,668 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 11:49:28,676 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 8c48fa47-1e15-404a-9159-e49e3da5df9c, Nodes: 0005597f-3053-4b02-96b8-efe2de95313b{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:0005597f-3053-4b02-96b8-efe2de95313b, CreationTimestamp2022-04-08T11:48:57.726Z[UTC]] moved to OPEN state
scm1.org_1   | 2022-04-08 11:49:41,658 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43302
scm1.org_1   | 2022-04-08 11:49:41,688 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 11:49:46,981 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:56300
scm1.org_1   | 2022-04-08 11:49:46,988 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
recon_1      | 2022-04-08 11:57:06,388 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34960
recon_1      | 2022-04-08 11:57:06,445 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:32798
recon_1      | 2022-04-08 11:57:06,490 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37372
recon_1      | 2022-04-08 11:57:06,511 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm3.org_1   | 2022-04-08 11:57:06,560 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 2022-04-08 11:57:06,545 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 11:57:06,564 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm1.org_1   | 2022-04-08 11:49:47,065 [IPC Server handler 41 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for containerId, change lastId from 0 to 1000.
scm1.org_1   | 2022-04-08 11:49:47,248 [088c2e91-0545-411d-8d31-8415832ed844@group-A2EA220FD69F-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 109611004723200000.
recon_1      | 2022-04-08 11:57:33,779 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
om1_1        | 2022-04-08 12:04:42,743 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:04:42,745 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:04:42,747 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:04:42,749 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
recon_1      | 2022-04-08 11:57:33,779 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
scm3.org_1   | 2022-04-08 11:57:36,383 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48000
om1_1        | 2022-04-08 12:04:47,973 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44468
om1_1        | 2022-04-08 12:04:48,001 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
recon_1      | 2022-04-08 11:57:33,818 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
scm1.org_1   | 2022-04-08 11:49:47,331 [IPC Server handler 41 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for localId, change lastId from 109611004723200000 to 109611004723201000.
om1_1        | 2022-04-08 12:04:51,490 [IPC Server handler 96 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm3.org_1   | 2022-04-08 11:57:36,487 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39862
scm3.org_1   | 2022-04-08 11:57:36,490 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
om1_1        | 2022-04-08 12:04:51,493 [IPC Server handler 84 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm1.org_1   | 2022-04-08 11:49:47,634 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:44180
scm3.org_1   | 2022-04-08 11:57:36,494 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:47250
scm3.org_1   | 2022-04-08 11:57:36,514 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2022-04-08 12:04:51,500 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-2100108116 of layout LEGACY in volume: s3v
om1_1        | 2022-04-08 12:04:52,122 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:04:52,129 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
scm1.org_1   | 2022-04-08 11:49:47,719 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 11:57:36,527 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2022-04-08 12:04:52,136 [IPC Server handler 42 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:04:52,290 [IPC Server handler 80 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:04:52,999 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:04:53,001 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm3.org_1   | 2022-04-08 11:57:59,156 [ReplicationMonitor] INFO container.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm1.org_1   | 2022-04-08 11:49:47,720 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: d7bff567-93ff-485c-a104-bc074898d12a, Nodes: 0005597f-3053-4b02-96b8-efe2de95313b{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}4cf3df89-7b36-4576-a18a-5d0c57ddb620{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}8b7f16e2-5fb9-442f-a717-cc893c5795e0{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:8b7f16e2-5fb9-442f-a717-cc893c5795e0, CreationTimestamp2022-04-08T11:48:59.171Z[UTC]] moved to OPEN state
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
scm3.org_1   | 2022-04-08 11:58:06,402 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48126
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
scm1.org_1   | 2022-04-08 11:49:50,153 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33614
scm3.org_1   | 2022-04-08 11:58:06,423 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 11:58:06,454 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:47368
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
om1_1        | 2022-04-08 12:04:53,004 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:04:53,007 [IPC Server handler 43 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:04:53,774 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:04:53,775 [IPC Server handler 46 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:04:53,781 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:04:53,807 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:04:54,517 [IPC Server handler 77 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:04:54,520 [IPC Server handler 89 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:04:54,523 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 2022-04-08 12:04:54,525 [IPC Server handler 62 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:04:55,232 [IPC Server handler 67 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:04:55,234 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:04:55,237 [IPC Server handler 68 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:04:55,257 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:04:55,986 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:04:55,988 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm1.org_1   | 2022-04-08 11:49:50,175 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-04-08 11:49:50,381 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:48150
scm1.org_1   | 2022-04-08 11:49:50,395 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-04-08 11:49:50,526 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53086
scm1.org_1   | 2022-04-08 11:49:50,533 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-04-08 11:49:50,784 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:35659
scm1.org_1   | 2022-04-08 11:49:50,828 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-04-08 11:49:51,066 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55850
scm1.org_1   | 2022-04-08 11:49:51,101 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 11:49:59,336 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:56348
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm1.org_1   | 2022-04-08 11:49:59,340 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-04-08 11:50:09,685 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:56386
scm1.org_1   | 2022-04-08 11:50:09,693 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-04-08 11:50:20,753 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43428
scm1.org_1   | 2022-04-08 11:50:20,775 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 11:50:21,056 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55956
scm1.org_1   | 2022-04-08 11:50:21,087 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 11:58:06,472 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39980
scm3.org_1   | 2022-04-08 11:58:06,489 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 11:58:06,504 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 11:50:21,096 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:44292
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
om1_1        | 2022-04-08 12:04:55,989 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:04:55,999 [IPC Server handler 43 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
om1_1        | 2022-04-08 12:04:56,726 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
scm1.org_1   | 2022-04-08 11:50:21,157 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 11:50:33,817 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:35412
scm1.org_1   | 2022-04-08 11:50:33,822 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-04-08 11:50:50,785 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43514
scm1.org_1   | 2022-04-08 11:50:50,805 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 11:58:36,369 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48224
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm3.org_1   | 2022-04-08 11:58:36,426 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:47476
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
scm3.org_1   | 2022-04-08 11:58:36,430 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:40084
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
om1_1        | 2022-04-08 12:04:56,727 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:04:56,729 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:04:56,745 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm3.org_1   | 2022-04-08 11:58:36,441 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	... 19 more
om1_1        | 2022-04-08 12:04:57,368 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:04:57,370 [IPC Server handler 63 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:04:57,371 [IPC Server handler 73 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm3.org_1   | 2022-04-08 11:58:36,499 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
scm3.org_1   | 2022-04-08 11:58:36,513 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
scm1.org_1   | 2022-04-08 11:50:51,091 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56044
scm1.org_1   | 2022-04-08 11:50:51,094 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:44382
scm1.org_1   | 2022-04-08 11:50:51,099 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 11:59:06,376 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48290
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
scm3.org_1   | 2022-04-08 11:59:06,387 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:47534
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
scm3.org_1   | 2022-04-08 11:59:06,430 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
scm3.org_1   | 2022-04-08 11:59:06,465 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:40150
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
om1_1        | 2022-04-08 12:04:57,378 [IPC Server handler 97 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:04:58,012 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:04:58,015 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm3.org_1   | 2022-04-08 11:59:06,476 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2022-04-08 12:04:58,016 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:04:58,749 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:04:58,751 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:04:58,753 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:04:58,759 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm3.org_1   | 2022-04-08 11:59:06,503 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2022-04-08 12:04:59,556 [IPC Server handler 76 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:04:59,558 [IPC Server handler 70 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:04:59,560 [IPC Server handler 64 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:04:59,569 [IPC Server handler 92 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm3.org_1   | 2022-04-08 11:59:36,369 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48408
om1_1        | 2022-04-08 12:05:00,281 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:05:00,282 [IPC Server handler 66 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:05:00,284 [IPC Server handler 80 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:05:00,291 [IPC Server handler 72 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm3.org_1   | 2022-04-08 11:59:36,420 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:47652
om1_1        | 2022-04-08 12:05:00,981 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:05:00,984 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:05:00,986 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:05:00,994 [IPC Server handler 43 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm3.org_1   | 2022-04-08 11:59:36,436 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2022-04-08 12:05:01,679 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:05:01,681 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:05:01,683 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:05:01,693 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:05:02,384 [IPC Server handler 97 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm3.org_1   | 2022-04-08 11:59:36,469 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:40260
om1_1        | 2022-04-08 12:05:02,385 [IPC Server handler 87 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:05:02,401 [IPC Server handler 96 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:05:02,412 [IPC Server handler 84 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:05:03,107 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm3.org_1   | 2022-04-08 11:59:36,475 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2022-04-08 12:05:03,108 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:05:03,110 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:05:03,122 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:05:03,905 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm3.org_1   | 2022-04-08 11:59:36,482 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2022-04-08 12:05:03,909 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
scm1.org_1   | 2022-04-08 11:50:51,132 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 11:50:59,051 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:56544
scm1.org_1   | 2022-04-08 11:50:59,058 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm3.org_1   | 2022-04-08 12:00:06,493 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:47720
scm1.org_1   | 2022-04-08 11:51:18,042 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:56598
scm1.org_1   | 2022-04-08 11:51:18,055 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-04-08 11:51:18,102 [IPC Server handler 98 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for delTxnId, change lastId from 0 to 1000.
scm1.org_1   | 2022-04-08 11:51:20,740 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43628
scm3.org_1   | 2022-04-08 12:00:06,500 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:40324
scm1.org_1   | 2022-04-08 11:51:20,758 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 11:51:21,053 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:44490
scm1.org_1   | 2022-04-08 11:51:21,080 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56152
scm1.org_1   | 2022-04-08 11:51:21,105 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 12:00:06,503 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48472
scm1.org_1   | 2022-04-08 11:51:21,140 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 11:51:50,701 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43730
scm1.org_1   | 2022-04-08 11:51:50,782 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 11:51:51,040 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:44596
scm3.org_1   | 2022-04-08 12:00:06,517 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 11:51:51,066 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56254
scm3.org_1   | 2022-04-08 12:00:06,518 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 11:51:51,105 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 11:51:51,130 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 12:00:06,537 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 12:00:36,361 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48558
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
scm3.org_1   | 2022-04-08 12:00:36,434 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:40410
scm1.org_1   | 2022-04-08 11:51:57,768 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:56744
scm1.org_1   | 2022-04-08 11:51:57,774 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-04-08 11:52:06,689 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:35712
scm1.org_1   | 2022-04-08 11:52:06,700 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-04-08 11:52:12,764 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:56794
scm1.org_1   | 2022-04-08 11:52:12,770 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-04-08 11:52:15,068 [ReplicationMonitor] INFO container.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm1.org_1   | 2022-04-08 11:52:20,734 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43830
scm1.org_1   | 2022-04-08 11:52:20,770 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 11:52:21,070 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:44698
scm1.org_1   | 2022-04-08 11:52:21,112 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 11:52:21,147 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56358
scm1.org_1   | 2022-04-08 11:52:21,155 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 11:52:22,190 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:35788
scm1.org_1   | 2022-04-08 11:52:22,194 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-04-08 11:52:43,248 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:42671
scm1.org_1   | 2022-04-08 11:52:43,258 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-04-08 11:52:50,710 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43928
scm1.org_1   | 2022-04-08 11:52:50,726 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 11:52:51,015 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:44794
scm1.org_1   | 2022-04-08 11:52:51,052 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56456
scm1.org_1   | 2022-04-08 11:52:51,106 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 11:52:51,119 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 11:53:18,022 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:57014
scm1.org_1   | 2022-04-08 11:53:18,024 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-04-08 11:53:20,724 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44040
scm1.org_1   | 2022-04-08 11:53:20,744 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 11:53:21,081 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:44906
scm1.org_1   | 2022-04-08 11:53:21,092 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56568
scm1.org_1   | 2022-04-08 11:53:21,103 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 11:53:21,120 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 11:53:50,708 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44138
scm1.org_1   | 2022-04-08 11:53:50,725 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 11:53:51,109 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56666
scm1.org_1   | 2022-04-08 11:53:51,109 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:45006
scm1.org_1   | 2022-04-08 11:53:51,129 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 11:53:51,129 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2022-04-08 12:05:03,911 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:05:03,919 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:05:04,635 [IPC Server handler 86 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:05:04,637 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:05:04,639 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:05:05,266 [IPC Server handler 52 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:05:05,271 [IPC Server handler 85 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:05:05,273 [IPC Server handler 61 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:05:05,868 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:05:05,869 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:05:05,871 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:05:11,269 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44588
om1_1        | 2022-04-08 12:05:11,303 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 12:05:15,565 [IPC Server handler 64 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:05:15,567 [IPC Server handler 92 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:05:15,572 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-8208772603 of layout LEGACY in volume: s3v
om1_1        | 2022-04-08 12:05:31,081 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:33663
om1_1        | 2022-04-08 12:05:31,083 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-08 12:05:31,084 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 3ef16ff51954998c2cd524dcf3232b4a88d57131c99bd08d80f78999c74f8a23
om1_1        | 2022-04-08 12:05:34,118 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:33741
om1_1        | 2022-04-08 12:05:34,131 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-04-08 11:57:36,347 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35104
recon_1      | 2022-04-08 11:57:36,416 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:32936
recon_1      | 2022-04-08 11:57:36,443 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 11:57:36,444 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37510
recon_1      | 2022-04-08 11:57:36,451 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 11:57:36,476 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 11:57:43,093 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 2 milliseconds to process 0 existing database records.
recon_1      | 2022-04-08 11:57:43,097 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 4 milliseconds for processing 2 containers.
recon_1      | 2022-04-08 11:57:43,298 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 5 pipelines in house.
recon_1      | 2022-04-08 11:57:43,301 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 26 milliseconds.
recon_1      | 2022-04-08 11:58:06,342 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35224
scm1.org_1   | 2022-04-08 11:54:04,541 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:57180
scm1.org_1   | 2022-04-08 11:54:04,544 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-04-08 11:54:06,398 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44208
scm1.org_1   | 2022-04-08 11:54:06,577 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 11:54:06,598 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56726
scm1.org_1   | 2022-04-08 11:54:06,602 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 12:00:36,437 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 12:00:36,449 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:47802
scm3.org_1   | 2022-04-08 12:00:36,484 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 12:00:36,506 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 12:01:06,360 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48616
recon_1      | 2022-04-08 11:58:06,344 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 11:58:06,427 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33060
recon_1      | 2022-04-08 11:58:06,455 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37634
scm3.org_1   | 2022-04-08 12:01:06,366 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 12:01:06,464 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:40478
recon_1      | 2022-04-08 11:58:06,487 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 11:58:06,500 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 11:58:33,819 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
scm1.org_1   | 2022-04-08 11:54:06,606 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:45082
scm1.org_1   | 2022-04-08 11:54:06,608 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:43455
scm1.org_1   | 2022-04-08 11:54:06,622 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-04-08 11:54:06,649 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 11:54:10,889 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:36174
scm3.org_1   | 2022-04-08 12:01:06,466 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:47870
scm3.org_1   | 2022-04-08 12:01:06,482 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 12:01:06,492 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 12:01:36,351 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48700
scm3.org_1   | 2022-04-08 12:01:36,377 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 12:01:36,458 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:40562
recon_1      | 2022-04-08 11:58:33,819 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-04-08 11:58:33,858 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
scm1.org_1   | 2022-04-08 11:54:10,899 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-04-08 11:54:36,491 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44378
scm1.org_1   | 2022-04-08 11:54:36,499 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56892
scm1.org_1   | 2022-04-08 11:54:36,508 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:45246
scm3.org_1   | 2022-04-08 12:01:36,459 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:47948
scm3.org_1   | 2022-04-08 12:01:36,480 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 12:01:36,487 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 12:02:06,368 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48768
scm3.org_1   | 2022-04-08 12:02:06,411 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 12:02:06,432 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:40626
scm1.org_1   | 2022-04-08 11:54:36,508 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 11:54:36,510 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 11:54:36,532 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
scm1.org_1   | 2022-04-08 11:55:05,187 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:57524
scm1.org_1   | 2022-04-08 11:55:05,195 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-04-08 11:55:06,396 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:57066
scm3.org_1   | 2022-04-08 12:02:06,443 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:48016
scm3.org_1   | 2022-04-08 12:02:06,458 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 12:02:06,472 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 12:02:36,351 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48852
scm3.org_1   | 2022-04-08 12:02:36,377 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 12:02:36,480 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:48098
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm1.org_1   | 2022-04-08 11:55:06,437 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:45420
scm1.org_1   | 2022-04-08 11:55:06,449 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44552
scm1.org_1   | 2022-04-08 11:55:06,475 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 11:55:06,553 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 11:55:06,573 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
scm3.org_1   | 2022-04-08 12:02:36,493 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:40710
scm3.org_1   | 2022-04-08 12:02:36,499 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 12:02:36,505 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 11:55:23,199 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:57610
scm1.org_1   | 2022-04-08 11:55:23,201 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-04-08 11:55:36,367 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44664
scm1.org_1   | 2022-04-08 11:55:36,437 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 11:55:36,454 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:57184
scm1.org_1   | 2022-04-08 11:55:36,465 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:45532
scm3.org_1   | 2022-04-08 12:02:59,156 [ReplicationMonitor] INFO container.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm3.org_1   | 2022-04-08 12:03:06,355 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48912
scm3.org_1   | 2022-04-08 12:03:06,415 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 12:03:06,435 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:40774
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
scm1.org_1   | 2022-04-08 11:55:36,471 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 12:03:06,453 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:48162
scm3.org_1   | 2022-04-08 12:03:06,461 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 12:03:06,488 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
scm3.org_1   | 2022-04-08 12:03:36,382 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48992
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm1.org_1   | 2022-04-08 11:55:36,490 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 11:55:38,845 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:36606
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
scm3.org_1   | 2022-04-08 12:03:36,453 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 12:03:36,456 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:40860
scm1.org_1   | 2022-04-08 11:55:38,857 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
scm1.org_1   | 2022-04-08 11:56:06,360 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44766
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
scm3.org_1   | 2022-04-08 12:03:36,478 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:48244
scm3.org_1   | 2022-04-08 12:03:36,495 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 12:03:36,522 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 12:04:06,397 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:48302
scm3.org_1   | 2022-04-08 12:04:06,399 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49056
scm1.org_1   | 2022-04-08 11:56:06,439 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:45640
scm1.org_1   | 2022-04-08 11:56:06,440 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
scm1.org_1   | 2022-04-08 11:56:06,451 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:57286
scm1.org_1   | 2022-04-08 11:56:06,455 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 11:56:06,487 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 11:56:18,039 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:57816
scm1.org_1   | 2022-04-08 11:56:18,045 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
scm3.org_1   | 2022-04-08 12:04:06,433 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:40916
scm3.org_1   | 2022-04-08 12:04:06,460 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
scm1.org_1   | 2022-04-08 11:56:28,853 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:36790
scm3.org_1   | 2022-04-08 12:04:06,469 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 11:56:28,859 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-04-08 11:56:36,386 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44900
scm3.org_1   | 2022-04-08 12:04:06,484 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 12:04:36,357 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49146
scm1.org_1   | 2022-04-08 11:56:36,408 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:57426
scm3.org_1   | 2022-04-08 12:04:36,390 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:48398
scm3.org_1   | 2022-04-08 12:04:36,456 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:41006
scm3.org_1   | 2022-04-08 12:04:36,463 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 12:04:36,492 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 12:04:36,503 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 12:05:06,389 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49288
scm3.org_1   | 2022-04-08 12:05:06,419 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 12:05:06,427 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:48530
scm3.org_1   | 2022-04-08 12:05:06,444 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 11:56:36,418 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 11:56:36,436 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 11:56:36,457 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:45780
scm1.org_1   | 2022-04-08 11:56:36,478 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 11:56:39,324 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:36854
scm1.org_1   | 2022-04-08 11:56:39,329 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-04-08 11:56:55,525 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:36916
scm1.org_1   | 2022-04-08 11:56:55,530 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-04-08 11:57:06,431 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45030
scm1.org_1   | 2022-04-08 11:57:06,442 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:57558
scm1.org_1   | 2022-04-08 11:57:06,492 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:45906
scm1.org_1   | 2022-04-08 11:57:06,510 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 11:57:06,549 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 11:57:06,570 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 11:57:14,257 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:37020
scm3.org_1   | 2022-04-08 12:05:06,472 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:41140
scm3.org_1   | 2022-04-08 12:05:06,478 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
scm3.org_1   | 2022-04-08 12:05:36,447 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49378
scm3.org_1   | 2022-04-08 12:05:36,458 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:48624
scm3.org_1   | 2022-04-08 12:05:36,459 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-08 12:05:36,482 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
scm1.org_1   | 2022-04-08 11:57:14,265 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-04-08 11:57:15,071 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 3 milliseconds for processing 2 containers.
scm1.org_1   | 2022-04-08 11:57:36,389 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45170
scm1.org_1   | 2022-04-08 11:57:36,457 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 11:57:36,476 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:57690
scm1.org_1   | 2022-04-08 11:57:36,482 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:46048
scm3.org_1   | 2022-04-08 12:05:36,519 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:41230
scm3.org_1   | 2022-04-08 12:05:36,525 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
scm1.org_1   | 2022-04-08 11:57:36,509 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 11:57:36,526 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 11:57:43,288 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:41363
scm1.org_1   | 2022-04-08 11:57:43,292 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-04-08 11:58:36,344 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35326
scm1.org_1   | 2022-04-08 11:57:58,107 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:58240
scm1.org_1   | 2022-04-08 11:57:58,113 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-04-08 11:58:01,942 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:37200
scm1.org_1   | 2022-04-08 11:58:01,955 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-04-08 11:58:06,359 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45292
scm1.org_1   | 2022-04-08 11:58:06,410 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 11:58:06,420 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:57814
scm1.org_1   | 2022-04-08 11:58:06,485 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:46166
scm1.org_1   | 2022-04-08 11:58:06,489 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 2022-04-08 11:58:36,433 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37734
recon_1      | 2022-04-08 11:58:36,443 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 11:58:36,470 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33162
recon_1      | 2022-04-08 11:58:36,485 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 11:58:36,500 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 11:59:06,355 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35388
recon_1      | 2022-04-08 11:59:06,430 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33226
scm1.org_1   | 2022-04-08 11:58:06,511 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 2022-04-08 11:59:06,451 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 11:59:06,467 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 11:59:06,470 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37798
recon_1      | 2022-04-08 11:59:06,510 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 11:59:33,860 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
scm1.org_1   | 2022-04-08 11:58:18,051 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:58342
scm1.org_1   | 2022-04-08 11:58:18,057 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-04-08 11:58:36,381 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45394
scm1.org_1   | 2022-04-08 11:58:36,401 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:57914
scm1.org_1   | 2022-04-08 11:58:36,444 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 11:58:36,456 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:46274
recon_1      | 2022-04-08 11:59:33,860 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-04-08 11:59:33,897 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
scm1.org_1   | 2022-04-08 11:58:36,474 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 11:58:36,504 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 11:59:06,408 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:57984
scm1.org_1   | 2022-04-08 11:59:06,456 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45458
scm1.org_1   | 2022-04-08 11:59:06,466 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:46332
scm1.org_1   | 2022-04-08 11:59:06,476 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
scm1.org_1   | 2022-04-08 11:59:06,505 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 11:59:06,512 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 11:59:19,277 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:58492
scm1.org_1   | 2022-04-08 11:59:19,284 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm1.org_1   | 2022-04-08 11:59:20,656 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:37444
scm1.org_1   | 2022-04-08 11:59:20,659 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm1.org_1   | 2022-04-08 11:59:36,396 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45574
scm1.org_1   | 2022-04-08 11:59:36,418 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58094
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
scm1.org_1   | 2022-04-08 11:59:36,447 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:46450
scm1.org_1   | 2022-04-08 11:59:36,456 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 11:59:36,468 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 11:59:36,483 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 12:00:06,516 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:46518
scm1.org_1   | 2022-04-08 12:00:06,526 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45642
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
scm1.org_1   | 2022-04-08 12:00:06,527 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58158
scm1.org_1   | 2022-04-08 12:00:06,530 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
scm1.org_1   | 2022-04-08 12:00:06,541 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 12:00:06,547 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 12:00:18,036 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:58670
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-04-08 11:59:36,349 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35504
scm1.org_1   | 2022-04-08 12:00:18,038 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-04-08 12:00:28,132 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:58682
scm1.org_1   | 2022-04-08 12:00:28,139 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-04-08 12:00:36,388 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58244
scm1.org_1   | 2022-04-08 12:00:36,441 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45724
scm1.org_1   | 2022-04-08 12:00:36,473 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 12:00:36,482 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:46602
scm1.org_1   | 2022-04-08 12:00:36,506 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 12:00:36,520 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 12:01:06,363 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45790
scm1.org_1   | 2022-04-08 12:01:06,380 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 12:01:06,391 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58308
scm1.org_1   | 2022-04-08 12:01:06,447 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 12:01:06,454 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:46662
scm1.org_1   | 2022-04-08 12:01:06,477 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 12:01:29,906 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:58830
scm1.org_1   | 2022-04-08 12:01:29,918 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-04-08 12:01:36,350 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45878
scm1.org_1   | 2022-04-08 12:01:36,375 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 12:01:36,426 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58394
scm1.org_1   | 2022-04-08 12:01:36,440 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:46746
scm1.org_1   | 2022-04-08 12:01:36,447 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 12:01:36,451 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 12:02:06,359 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45938
scm1.org_1   | 2022-04-08 12:02:06,399 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 12:02:06,433 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:46810
scm1.org_1   | 2022-04-08 12:02:06,438 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58456
scm1.org_1   | 2022-04-08 12:02:06,465 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 12:02:06,473 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 12:02:15,072 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 2 containers.
scm1.org_1   | 2022-04-08 12:02:30,341 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:58986
scm1.org_1   | 2022-04-08 12:02:30,345 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-04-08 12:02:36,376 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46020
scm1.org_1   | 2022-04-08 12:02:36,405 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 12:02:36,465 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58540
scm1.org_1   | 2022-04-08 12:02:36,468 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:46894
scm1.org_1   | 2022-04-08 12:02:36,476 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 12:02:36,486 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 12:02:43,352 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:37489
scm1.org_1   | 2022-04-08 12:02:43,354 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-04-08 12:03:06,430 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46090
scm1.org_1   | 2022-04-08 12:03:06,440 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 12:03:06,452 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58604
scm1.org_1   | 2022-04-08 12:03:06,455 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:46958
scm1.org_1   | 2022-04-08 12:03:06,470 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 12:03:06,487 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 12:03:34,589 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:59138
scm1.org_1   | 2022-04-08 12:03:34,607 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-04-08 12:03:36,378 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46162
scm1.org_1   | 2022-04-08 12:03:36,383 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 2022-04-08 11:59:36,351 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 11:59:36,400 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33342
recon_1      | 2022-04-08 11:59:36,446 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37918
recon_1      | 2022-04-08 11:59:36,474 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 11:59:36,483 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 12:00:06,414 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35566
recon_1      | 2022-04-08 12:00:06,423 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37980
recon_1      | 2022-04-08 12:00:06,428 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 12:00:06,431 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 12:00:06,438 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33404
recon_1      | 2022-04-08 12:00:06,446 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 12:00:33,898 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-04-08 12:00:33,898 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-04-08 12:00:33,937 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
scm1.org_1   | 2022-04-08 12:03:36,461 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47044
scm1.org_1   | 2022-04-08 12:03:36,502 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58682
scm1.org_1   | 2022-04-08 12:03:36,531 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 12:03:36,535 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 12:04:06,400 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58752
scm1.org_1   | 2022-04-08 12:04:06,432 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47102
scm1.org_1   | 2022-04-08 12:04:06,441 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46226
scm1.org_1   | 2022-04-08 12:04:06,456 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 12:04:06,469 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 12:04:06,479 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 12:04:18,044 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:59258
scm1.org_1   | 2022-04-08 12:04:18,051 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
scm1.org_1   | 2022-04-08 12:04:36,357 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46324
scm1.org_1   | 2022-04-08 12:04:36,438 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58838
scm1.org_1   | 2022-04-08 12:04:36,460 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 12:04:36,501 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47192
scm1.org_1   | 2022-04-08 12:04:36,514 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 12:04:36,530 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 12:04:38,288 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:59334
scm1.org_1   | 2022-04-08 12:04:38,296 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-04-08 12:04:52,149 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:59372
scm1.org_1   | 2022-04-08 12:04:52,157 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-04-08 12:04:55,247 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:38336
scm1.org_1   | 2022-04-08 12:04:55,248 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-04-08 12:05:06,388 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46454
scm1.org_1   | 2022-04-08 12:05:06,423 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 12:05:06,448 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58978
scm1.org_1   | 2022-04-08 12:05:06,475 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47334
scm1.org_1   | 2022-04-08 12:05:06,484 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 12:05:06,496 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 12:05:18,036 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:59494
scm1.org_1   | 2022-04-08 12:05:18,044 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-04-08 12:05:36,369 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46544
scm1.org_1   | 2022-04-08 12:05:36,430 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:59064
scm1.org_1   | 2022-04-08 12:05:36,436 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 12:05:36,438 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47424
scm1.org_1   | 2022-04-08 12:05:36,467 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-08 12:05:36,488 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 2022-04-08 12:00:36,363 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35654
recon_1      | 2022-04-08 12:00:36,412 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33492
recon_1      | 2022-04-08 12:00:36,461 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38064
recon_1      | 2022-04-08 12:00:36,480 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 12:00:36,508 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 12:00:36,517 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 12:01:06,350 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35720
recon_1      | 2022-04-08 12:01:06,366 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 12:01:06,415 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33554
recon_1      | 2022-04-08 12:01:06,446 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38128
recon_1      | 2022-04-08 12:01:06,460 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 12:01:06,475 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 12:01:33,939 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-04-08 12:01:33,939 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-04-08 12:01:33,975 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-04-08 12:01:36,341 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35802
recon_1      | 2022-04-08 12:01:36,370 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 12:01:36,403 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33640
recon_1      | 2022-04-08 12:01:36,407 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 12:01:36,441 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38216
recon_1      | 2022-04-08 12:01:36,478 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 12:02:06,342 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35870
recon_1      | 2022-04-08 12:02:06,388 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33702
recon_1      | 2022-04-08 12:02:06,397 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 12:02:06,446 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38280
recon_1      | 2022-04-08 12:02:06,464 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 12:02:06,477 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 12:02:33,975 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-04-08 12:02:33,976 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-04-08 12:02:34,001 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-04-08 12:02:36,352 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35954
recon_1      | 2022-04-08 12:02:36,393 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 12:02:36,437 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38364
recon_1      | 2022-04-08 12:02:36,451 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33788
recon_1      | 2022-04-08 12:02:36,456 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 12:02:36,468 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 12:02:43,100 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 3 milliseconds to process 0 existing database records.
recon_1      | 2022-04-08 12:02:43,105 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 5 milliseconds for processing 2 containers.
recon_1      | 2022-04-08 12:02:43,357 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 5 pipelines in house.
recon_1      | 2022-04-08 12:02:43,363 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 31 milliseconds.
recon_1      | 2022-04-08 12:03:06,345 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:36016
recon_1      | 2022-04-08 12:03:06,371 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 12:03:06,448 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33852
recon_1      | 2022-04-08 12:03:06,454 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38424
recon_1      | 2022-04-08 12:03:06,470 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 12:03:06,480 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 12:03:34,002 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-04-08 12:03:34,002 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-04-08 12:03:34,040 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-04-08 12:03:36,351 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:36094
recon_1      | 2022-04-08 12:03:36,366 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 12:03:36,420 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33928
recon_1      | 2022-04-08 12:03:36,450 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38514
recon_1      | 2022-04-08 12:03:36,466 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 12:03:36,524 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 12:04:06,389 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:36160
recon_1      | 2022-04-08 12:04:06,401 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33992
recon_1      | 2022-04-08 12:04:06,431 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38564
recon_1      | 2022-04-08 12:04:06,440 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 12:04:06,454 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 12:04:06,478 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 12:04:34,041 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-04-08 12:04:34,041 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-04-08 12:04:34,104 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-04-08 12:04:36,356 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:36248
recon_1      | 2022-04-08 12:04:36,420 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34084
recon_1      | 2022-04-08 12:04:36,462 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 12:04:36,484 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38662
recon_1      | 2022-04-08 12:04:36,508 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 12:04:36,523 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 12:05:06,346 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:36386
recon_1      | 2022-04-08 12:05:06,389 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 12:05:06,431 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38794
recon_1      | 2022-04-08 12:05:06,441 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34220
recon_1      | 2022-04-08 12:05:06,472 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 12:05:06,475 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 12:05:34,106 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-04-08 12:05:34,106 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-04-08 12:05:34,151 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at jdk.internal.reflect.GeneratedConstructorAccessor55.newInstance(Unknown Source)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-04-08 12:05:36,348 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:36474
recon_1      | 2022-04-08 12:05:36,350 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 12:05:36,390 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34310
recon_1      | 2022-04-08 12:05:36,416 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-08 12:05:36,435 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38886
recon_1      | 2022-04-08 12:05:36,464 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
