Attaching to ozonesecure-ha_recon_1, ozonesecure-ha_scm3.org_1, ozonesecure-ha_kms_1, ozonesecure-ha_datanode3_1, ozonesecure-ha_om2_1, ozonesecure-ha_scm2.org_1, ozonesecure-ha_s3g_1, ozonesecure-ha_om3_1, ozonesecure-ha_datanode1_1, ozonesecure-ha_kdc_1, ozonesecure-ha_om1_1, ozonesecure-ha_scm1.org_1, ozonesecure-ha_datanode2_1
datanode1_1  | Sleeping for 5 seconds
datanode1_1  | Waiting for the service scm3.org:9894
datanode1_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode1_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode1_1  | 2022-04-21 16:44:29,778 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode1_1  | /************************************************************
datanode1_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode1_1  | STARTUP_MSG:   host = 95934f1cb1a3/172.25.0.102
datanode1_1  | STARTUP_MSG:   args = []
datanode1_1  | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
datanode1_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.0.4.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.3.0-SNAPSHOT.jar
datanode1_1  | STARTUP_MSG:   build = https://github.com/apache/ozone/be5888b907ab03eaf5ec49e88bd592b9f9bd78c4 ; compiled by 'runner' on 2022-04-21T16:20Z
datanode1_1  | STARTUP_MSG:   java = 11.0.14.1
datanode1_1  | ************************************************************/
datanode1_1  | 2022-04-21 16:44:29,863 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode1_1  | 2022-04-21 16:44:31,729 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode1_1  | 2022-04-21 16:44:32,458 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode1_1  | 2022-04-21 16:44:33,437 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode1_1  | 2022-04-21 16:44:33,437 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode1_1  | 2022-04-21 16:44:34,400 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:95934f1cb1a3 ip:172.25.0.102
datanode1_1  | 2022-04-21 16:44:37,427 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/dn@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode1_1  | 2022-04-21 16:44:38,543 [main] INFO security.UserGroupInformation: Login successful for user dn/dn@EXAMPLE.COM using keytab file dn.keytab. Keytab auto renewal enabled : false
datanode1_1  | 2022-04-21 16:44:38,563 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
datanode1_1  | 2022-04-21 16:44:40,703 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
datanode1_1  | 2022-04-21 16:44:40,706 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode1_1  | 2022-04-21 16:44:40,715 [main] INFO client.DNCertificateClient: Certificate client init case: 0
datanode1_1  | 2022-04-21 16:44:40,717 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode1_1  | 2022-04-21 16:44:45,924 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
datanode1_1  | 2022-04-21 16:44:46,036 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.102,host:95934f1cb1a3
datanode1_1  | 2022-04-21 16:44:46,038 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode1_1  | 2022-04-21 16:44:46,044 [main] ERROR client.DNCertificateClient: Invalid domain 95934f1cb1a3
datanode1_1  | 2022-04-21 16:44:46,051 [main] INFO ozone.HddsDatanodeService: Creating csr for DN-> subject:root@95934f1cb1a3
datanode1_1  | 2022-04-21 16:44:51,096 [main] INFO client.DNCertificateClient: Loading certificate from location:/data/metadata/dn/certs.
datanode1_1  | 2022-04-21 16:44:51,182 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/952600664327.crt.
datanode1_1  | 2022-04-21 16:44:51,205 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/ROOTCA-1.crt.
datanode1_1  | 2022-04-21 16:44:51,236 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/CA-862887965327.crt.
datanode1_1  | 2022-04-21 16:44:51,236 [main] INFO ozone.HddsDatanodeService: Successfully stored SCM signed certificate, case:GETCERT.
datanode1_1  | 2022-04-21 16:44:51,350 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3), software layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3)
datanode1_1  | 2022-04-21 16:44:52,349 [main] INFO reflections.Reflections: Reflections took 762 ms to scan 2 urls, producing 87 keys and 176 values 
datanode1_1  | 2022-04-21 16:44:52,839 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 4
datanode1_1  | 2022-04-21 16:44:53,974 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode1_1  | 2022-04-21 16:44:54,020 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89311358976
datanode1_1  | 2022-04-21 16:44:54,048 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode1_1  | 2022-04-21 16:44:54,060 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode1_1  | 2022-04-21 16:44:54,236 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode1_1  | 2022-04-21 16:44:54,455 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode1_1  | 2022-04-21 16:44:54,468 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode1_1  | 2022-04-21 16:44:54,484 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode1_1  | 2022-04-21 16:44:54,487 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
datanode1_1  | 2022-04-21 16:44:54,492 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
datanode1_1  | 2022-04-21 16:44:54,712 [Thread-8] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode1_1  | 2022-04-21 16:44:54,718 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode1_1  | 2022-04-21 16:44:59,573 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for DNAudit to [].
datanode1_1  | 2022-04-21 16:45:01,213 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode1_1  | 2022-04-21 16:45:02,224 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode1_1  | 2022-04-21 16:45:02,950 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode1_1  | 2022-04-21 16:45:02,956 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode1_1  | 2022-04-21 16:45:02,957 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode1_1  | 2022-04-21 16:45:02,958 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode1_1  | 2022-04-21 16:45:02,976 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2022-04-21 16:45:02,977 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode1_1  | 2022-04-21 16:45:02,981 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode1_1  | 2022-04-21 16:45:09,669 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode1_1  | 2022-04-21 16:45:09,674 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode1_1  | 2022-04-21 16:45:09,698 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode1_1  | 2022-04-21 16:45:09,763 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode1_1  | 2022-04-21 16:45:10,722 [main] INFO server.XceiverServerGrpc: GrpcServer channel type EpollServerSocketChannel
datanode1_1  | 2022-04-21 16:45:11,841 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode1_1  | 2022-04-21 16:45:11,841 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode1_1  | 2022-04-21 16:45:11,841 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.datanode.http.auth.type = kerberos
datanode1_1  | 2022-04-21 16:45:12,067 [main] INFO util.log: Logging initialized @50236ms to org.eclipse.jetty.util.log.Slf4jLog
datanode1_1  | 2022-04-21 16:45:12,917 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode1_1  | 2022-04-21 16:45:12,960 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode1_1  | 2022-04-21 16:45:12,965 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode1_1  | 2022-04-21 16:45:12,967 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode1_1  | 2022-04-21 16:45:12,968 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode1_1  | 2022-04-21 16:45:12,979 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.datanode.http.auth.kerberos.principal keytabKey: hdds.datanode.http.auth.kerberos.keytab
datanode1_1  | 2022-04-21 16:45:13,231 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode1_1  | 2022-04-21 16:45:13,251 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
datanode1_1  | 2022-04-21 16:45:13,504 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode1_1  | 2022-04-21 16:45:13,508 [main] INFO server.session: No SessionScavenger set, using defaults
datanode1_1  | 2022-04-21 16:45:13,513 [main] INFO server.session: node0 Scavenging every 660000ms
datanode1_1  | 2022-04-21 16:45:13,674 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode1_1  | 2022-04-21 16:45:13,717 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@3638120f{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode1_1  | 2022-04-21 16:45:13,741 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4700064f{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode1_1  | 2022-04-21 16:45:14,408 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode1_1  | 2022-04-21 16:45:14,460 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@72364a40{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-857662937435854898/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode1_1  | 2022-04-21 16:45:14,530 [main] INFO server.AbstractConnector: Started ServerConnector@6f7e5e11{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode1_1  | 2022-04-21 16:45:14,539 [main] INFO server.Server: Started @52701ms
datanode1_1  | 2022-04-21 16:45:14,556 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode1_1  | 2022-04-21 16:45:14,557 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode1_1  | 2022-04-21 16:45:14,559 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode1_1  | 2022-04-21 16:45:14,575 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
datanode1_1  | 2022-04-21 16:45:14,685 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@703817e6] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode1_1  | 2022-04-21 16:45:15,232 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.25.0.115:9891
datanode1_1  | 2022-04-21 16:45:17,907 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode1_1  | 2022-04-21 16:45:17,922 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode1_1  | 2022-04-21 16:45:18,308 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 8694db2d-5e51-4888-b1e0-69ff67626e43
datanode1_1  | 2022-04-21 16:45:18,544 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO server.RaftServer: 8694db2d-5e51-4888-b1e0-69ff67626e43: start RPC server
datanode1_1  | 2022-04-21 16:45:18,556 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO server.GrpcService: 8694db2d-5e51-4888-b1e0-69ff67626e43: GrpcService started, listening on 9856
datanode1_1  | 2022-04-21 16:45:18,563 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO server.GrpcService: 8694db2d-5e51-4888-b1e0-69ff67626e43: GrpcService started, listening on 9857
datanode1_1  | 2022-04-21 16:45:18,564 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO server.GrpcService: 8694db2d-5e51-4888-b1e0-69ff67626e43: GrpcService started, listening on 9858
datanode1_1  | 2022-04-21 16:45:18,598 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 8694db2d-5e51-4888-b1e0-69ff67626e43 is started using port 9858 for RATIS
datanode1_1  | 2022-04-21 16:45:18,598 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 8694db2d-5e51-4888-b1e0-69ff67626e43 is started using port 9857 for RATIS_ADMIN
datanode1_1  | 2022-04-21 16:45:18,598 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 8694db2d-5e51-4888-b1e0-69ff67626e43 is started using port 9856 for RATIS_SERVER
datanode1_1  | 2022-04-21 16:45:18,607 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$352/0x00000008405b6840@5a59bff4] INFO util.JvmPauseMonitor: JvmPauseMonitor-8694db2d-5e51-4888-b1e0-69ff67626e43: Started
datanode1_1  | 2022-04-21 16:45:18,666 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode1_1  | 2022-04-21 16:45:18,666 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode1_1  | 2022-04-21 16:45:27,729 [grpc-default-executor-0] INFO server.RaftServer: 8694db2d-5e51-4888-b1e0-69ff67626e43: addNew group-0B8A33D7FC85:[0ef408af-3ea2-4044-bc54-ad0ae15d84f1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 8694db2d-5e51-4888-b1e0-69ff67626e43|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a9037631-20c7-49ff-8966-d11abf0c09e2|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1] returns group-0B8A33D7FC85:java.util.concurrent.CompletableFuture@bf40b7e[Not completed]
datanode2_1  | Sleeping for 5 seconds
datanode2_1  | Waiting for the service scm3.org:9894
datanode2_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode2_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode2_1  | 2022-04-21 16:44:29,347 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode2_1  | /************************************************************
datanode2_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode2_1  | STARTUP_MSG:   host = 2fbb6e549361/172.25.0.103
datanode2_1  | STARTUP_MSG:   args = []
datanode2_1  | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
datanode2_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.0.4.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.3.0-SNAPSHOT.jar
datanode2_1  | STARTUP_MSG:   build = https://github.com/apache/ozone/be5888b907ab03eaf5ec49e88bd592b9f9bd78c4 ; compiled by 'runner' on 2022-04-21T16:20Z
datanode2_1  | STARTUP_MSG:   java = 11.0.14.1
datanode2_1  | ************************************************************/
datanode2_1  | 2022-04-21 16:44:29,438 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode2_1  | 2022-04-21 16:44:30,900 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode2_1  | 2022-04-21 16:44:31,579 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode2_1  | 2022-04-21 16:44:32,587 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode2_1  | 2022-04-21 16:44:32,591 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode2_1  | 2022-04-21 16:44:33,629 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:2fbb6e549361 ip:172.25.0.103
datanode2_1  | 2022-04-21 16:44:36,474 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/dn@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode2_1  | 2022-04-21 16:44:37,580 [main] INFO security.UserGroupInformation: Login successful for user dn/dn@EXAMPLE.COM using keytab file dn.keytab. Keytab auto renewal enabled : false
datanode2_1  | 2022-04-21 16:44:37,581 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
datanode2_1  | 2022-04-21 16:44:39,748 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
datanode2_1  | 2022-04-21 16:44:39,753 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode2_1  | 2022-04-21 16:44:39,754 [main] INFO client.DNCertificateClient: Certificate client init case: 0
datanode2_1  | 2022-04-21 16:44:39,757 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode2_1  | 2022-04-21 16:44:45,724 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
datanode2_1  | 2022-04-21 16:44:45,809 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.103,host:2fbb6e549361
datanode2_1  | 2022-04-21 16:44:45,826 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode2_1  | 2022-04-21 16:44:45,851 [main] ERROR client.DNCertificateClient: Invalid domain 2fbb6e549361
datanode2_1  | 2022-04-21 16:44:45,855 [main] INFO ozone.HddsDatanodeService: Creating csr for DN-> subject:root@2fbb6e549361
datanode2_1  | 2022-04-21 16:44:50,998 [main] INFO client.DNCertificateClient: Loading certificate from location:/data/metadata/dn/certs.
datanode2_1  | 2022-04-21 16:44:51,101 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/ROOTCA-1.crt.
datanode2_1  | 2022-04-21 16:44:51,127 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/952295697655.crt.
datanode2_1  | 2022-04-21 16:44:51,160 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/CA-862887965327.crt.
datanode2_1  | 2022-04-21 16:44:51,160 [main] INFO ozone.HddsDatanodeService: Successfully stored SCM signed certificate, case:GETCERT.
datanode2_1  | 2022-04-21 16:44:51,230 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3), software layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3)
datanode2_1  | 2022-04-21 16:44:51,907 [main] INFO reflections.Reflections: Reflections took 545 ms to scan 2 urls, producing 87 keys and 176 values 
datanode2_1  | 2022-04-21 16:44:52,398 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 4
datanode2_1  | 2022-04-21 16:44:53,819 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode2_1  | 2022-04-21 16:44:53,873 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89311358976
datanode2_1  | 2022-04-21 16:44:53,894 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode2_1  | 2022-04-21 16:44:53,896 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode2_1  | 2022-04-21 16:44:54,121 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode2_1  | 2022-04-21 16:44:54,223 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode2_1  | 2022-04-21 16:44:54,225 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode2_1  | 2022-04-21 16:44:54,231 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode2_1  | 2022-04-21 16:44:54,232 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
datanode2_1  | 2022-04-21 16:44:54,233 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
datanode2_1  | 2022-04-21 16:44:54,453 [Thread-8] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode2_1  | 2022-04-21 16:44:54,459 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode2_1  | 2022-04-21 16:44:59,665 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for DNAudit to [].
datanode2_1  | 2022-04-21 16:45:01,185 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode2_1  | 2022-04-21 16:45:01,816 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode2_1  | 2022-04-21 16:45:02,909 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode2_1  | 2022-04-21 16:45:02,941 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode2_1  | 2022-04-21 16:45:02,941 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode2_1  | 2022-04-21 16:45:02,943 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode2_1  | 2022-04-21 16:45:02,957 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2022-04-21 16:45:02,958 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode2_1  | 2022-04-21 16:45:02,983 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode2_1  | 2022-04-21 16:45:08,716 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode2_1  | 2022-04-21 16:45:08,740 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode2_1  | 2022-04-21 16:45:08,745 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode2_1  | 2022-04-21 16:45:08,845 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2022-04-21 16:45:09,291 [main] INFO server.XceiverServerGrpc: GrpcServer channel type EpollServerSocketChannel
datanode1_1  | 2022-04-21 16:45:27,842 [pool-23-thread-1] INFO server.RaftServer$Division: 8694db2d-5e51-4888-b1e0-69ff67626e43: new RaftServerImpl for group-0B8A33D7FC85:[0ef408af-3ea2-4044-bc54-ad0ae15d84f1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 8694db2d-5e51-4888-b1e0-69ff67626e43|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a9037631-20c7-49ff-8966-d11abf0c09e2|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1] with ContainerStateMachine:uninitialized
datanode1_1  | 2022-04-21 16:45:27,845 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode1_1  | 2022-04-21 16:45:27,859 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode1_1  | 2022-04-21 16:45:27,860 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode1_1  | 2022-04-21 16:45:27,860 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode1_1  | 2022-04-21 16:45:27,860 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode1_1  | 2022-04-21 16:45:27,860 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode1_1  | 2022-04-21 16:45:27,861 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode1_1  | 2022-04-21 16:45:27,878 [pool-23-thread-1] INFO server.RaftServer$Division: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-0B8A33D7FC85: ConfigurationManager, init=-1: [0ef408af-3ea2-4044-bc54-ad0ae15d84f1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 8694db2d-5e51-4888-b1e0-69ff67626e43|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a9037631-20c7-49ff-8966-d11abf0c09e2|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1], old=null, confs=<EMPTY_MAP>
datanode1_1  | 2022-04-21 16:45:27,895 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode1_1  | 2022-04-21 16:45:27,915 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode1_1  | 2022-04-21 16:45:27,920 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode1_1  | 2022-04-21 16:45:27,923 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/a2956c20-9fda-4457-b767-0b8a33d7fc85 does not exist. Creating ...
datanode1_1  | 2022-04-21 16:45:27,950 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/a2956c20-9fda-4457-b767-0b8a33d7fc85/in_use.lock acquired by nodename 7@95934f1cb1a3
datanode1_1  | 2022-04-21 16:45:27,980 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/a2956c20-9fda-4457-b767-0b8a33d7fc85 has been successfully formatted.
datanode1_1  | 2022-04-21 16:45:28,015 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-0B8A33D7FC85: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode1_1  | 2022-04-21 16:45:28,040 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode1_1  | 2022-04-21 16:45:28,045 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode1_1  | 2022-04-21 16:45:28,117 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode1_1  | 2022-04-21 16:45:28,128 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2022-04-21 16:45:28,314 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2022-04-21 16:45:28,389 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode1_1  | 2022-04-21 16:45:28,392 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode1_1  | 2022-04-21 16:45:28,438 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 8694db2d-5e51-4888-b1e0-69ff67626e43@group-0B8A33D7FC85-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/a2956c20-9fda-4457-b767-0b8a33d7fc85
datanode1_1  | 2022-04-21 16:45:28,443 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode1_1  | 2022-04-21 16:45:28,447 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode1_1  | 2022-04-21 16:45:28,455 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2022-04-21 16:45:28,456 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode1_1  | 2022-04-21 16:45:28,457 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode1_1  | 2022-04-21 16:45:28,460 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode1_1  | 2022-04-21 16:45:28,464 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode1_1  | 2022-04-21 16:45:28,465 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode1_1  | 2022-04-21 16:45:28,510 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode1_1  | 2022-04-21 16:45:28,526 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode1_1  | 2022-04-21 16:45:28,567 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-0B8A33D7FC85-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode1_1  | 2022-04-21 16:45:28,567 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-0B8A33D7FC85-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode1_1  | 2022-04-21 16:45:28,601 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode1_1  | 2022-04-21 16:45:28,609 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode1_1  | 2022-04-21 16:45:28,630 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode1_1  | 2022-04-21 16:45:28,634 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode1_1  | 2022-04-21 16:45:28,652 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode1_1  | 2022-04-21 16:45:28,655 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode1_1  | 2022-04-21 16:45:28,807 [pool-23-thread-1] INFO server.RaftServer$Division: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-0B8A33D7FC85: start as a follower, conf=-1: [0ef408af-3ea2-4044-bc54-ad0ae15d84f1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 8694db2d-5e51-4888-b1e0-69ff67626e43|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a9037631-20c7-49ff-8966-d11abf0c09e2|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1], old=null
datanode1_1  | 2022-04-21 16:45:28,811 [pool-23-thread-1] INFO server.RaftServer$Division: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-0B8A33D7FC85: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode1_1  | 2022-04-21 16:45:28,821 [pool-23-thread-1] INFO impl.RoleInfo: 8694db2d-5e51-4888-b1e0-69ff67626e43: start 8694db2d-5e51-4888-b1e0-69ff67626e43@group-0B8A33D7FC85-FollowerState
datanode3_1  | Sleeping for 5 seconds
datanode3_1  | Waiting for the service scm3.org:9894
datanode3_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode3_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode3_1  | 2022-04-21 16:44:29,769 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode3_1  | /************************************************************
datanode3_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode3_1  | STARTUP_MSG:   host = 4703807bf00c/172.25.0.104
datanode3_1  | STARTUP_MSG:   args = []
datanode3_1  | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
datanode3_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.0.4.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.3.0-SNAPSHOT.jar
datanode3_1  | STARTUP_MSG:   build = https://github.com/apache/ozone/be5888b907ab03eaf5ec49e88bd592b9f9bd78c4 ; compiled by 'runner' on 2022-04-21T16:20Z
datanode3_1  | STARTUP_MSG:   java = 11.0.14.1
datanode3_1  | ************************************************************/
datanode3_1  | 2022-04-21 16:44:29,810 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode3_1  | 2022-04-21 16:44:31,809 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode3_1  | 2022-04-21 16:44:32,679 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode3_1  | 2022-04-21 16:44:33,714 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode3_1  | 2022-04-21 16:44:33,714 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode3_1  | 2022-04-21 16:44:34,687 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:4703807bf00c ip:172.25.0.104
datanode3_1  | 2022-04-21 16:44:38,028 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/dn@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode3_1  | 2022-04-21 16:44:39,002 [main] INFO security.UserGroupInformation: Login successful for user dn/dn@EXAMPLE.COM using keytab file dn.keytab. Keytab auto renewal enabled : false
datanode3_1  | 2022-04-21 16:44:39,002 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
datanode3_1  | 2022-04-21 16:44:41,150 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
datanode3_1  | 2022-04-21 16:44:41,151 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode3_1  | 2022-04-21 16:44:41,170 [main] INFO client.DNCertificateClient: Certificate client init case: 0
datanode3_1  | 2022-04-21 16:44:41,173 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode3_1  | 2022-04-21 16:44:46,911 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
datanode3_1  | 2022-04-21 16:44:46,982 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.104,host:4703807bf00c
datanode3_1  | 2022-04-21 16:44:46,982 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode3_1  | 2022-04-21 16:44:46,989 [main] ERROR client.DNCertificateClient: Invalid domain 4703807bf00c
datanode3_1  | 2022-04-21 16:44:46,993 [main] INFO ozone.HddsDatanodeService: Creating csr for DN-> subject:root@4703807bf00c
datanode3_1  | 2022-04-21 16:44:52,150 [main] INFO client.DNCertificateClient: Loading certificate from location:/data/metadata/dn/certs.
datanode3_1  | 2022-04-21 16:44:52,246 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/953699741549.crt.
datanode3_1  | 2022-04-21 16:44:52,265 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/ROOTCA-1.crt.
datanode3_1  | 2022-04-21 16:44:52,283 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/CA-862887965327.crt.
datanode3_1  | 2022-04-21 16:44:52,283 [main] INFO ozone.HddsDatanodeService: Successfully stored SCM signed certificate, case:GETCERT.
datanode3_1  | 2022-04-21 16:44:52,380 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3), software layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3)
datanode3_1  | 2022-04-21 16:44:53,270 [main] INFO reflections.Reflections: Reflections took 656 ms to scan 2 urls, producing 87 keys and 176 values 
datanode3_1  | 2022-04-21 16:44:53,813 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 4
datanode3_1  | 2022-04-21 16:44:54,742 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode3_1  | 2022-04-21 16:44:54,836 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89311358976
datanode3_1  | 2022-04-21 16:44:54,876 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode3_1  | 2022-04-21 16:44:54,877 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode3_1  | 2022-04-21 16:44:55,086 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode3_1  | 2022-04-21 16:44:55,224 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode3_1  | 2022-04-21 16:44:55,235 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode3_1  | 2022-04-21 16:44:55,250 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode3_1  | 2022-04-21 16:44:55,250 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
datanode3_1  | 2022-04-21 16:44:55,251 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
datanode3_1  | 2022-04-21 16:44:55,559 [Thread-8] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode3_1  | 2022-04-21 16:44:55,572 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode3_1  | 2022-04-21 16:45:00,554 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for DNAudit to [].
datanode3_1  | 2022-04-21 16:45:02,323 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode3_1  | 2022-04-21 16:45:02,938 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode3_1  | 2022-04-21 16:45:03,450 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode3_1  | 2022-04-21 16:45:03,456 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode3_1  | 2022-04-21 16:45:03,466 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode3_1  | 2022-04-21 16:45:03,467 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode3_1  | 2022-04-21 16:45:03,472 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2022-04-21 16:45:03,472 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode3_1  | 2022-04-21 16:45:03,476 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode3_1  | 2022-04-21 16:45:09,705 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode3_1  | 2022-04-21 16:45:09,762 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode3_1  | 2022-04-21 16:45:09,771 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode3_1  | 2022-04-21 16:45:09,829 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode1_1  | 2022-04-21 16:45:28,838 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-0B8A33D7FC85,id=8694db2d-5e51-4888-b1e0-69ff67626e43
datanode1_1  | 2022-04-21 16:45:29,884 [grpc-default-executor-0] INFO server.RaftServer$Division: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-0B8A33D7FC85: receive requestVote(ELECTION, a9037631-20c7-49ff-8966-d11abf0c09e2, group-0B8A33D7FC85, 1, (t:0, i:0))
datanode1_1  | 2022-04-21 16:45:29,896 [grpc-default-executor-0] INFO impl.VoteContext: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-0B8A33D7FC85-FOLLOWER: accept ELECTION from a9037631-20c7-49ff-8966-d11abf0c09e2: our priority 0 <= candidate's priority 1
datanode1_1  | 2022-04-21 16:45:29,900 [grpc-default-executor-0] INFO server.RaftServer$Division: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-0B8A33D7FC85: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:a9037631-20c7-49ff-8966-d11abf0c09e2
datanode1_1  | 2022-04-21 16:45:29,902 [grpc-default-executor-0] INFO impl.RoleInfo: 8694db2d-5e51-4888-b1e0-69ff67626e43: shutdown 8694db2d-5e51-4888-b1e0-69ff67626e43@group-0B8A33D7FC85-FollowerState
datanode1_1  | 2022-04-21 16:45:29,903 [8694db2d-5e51-4888-b1e0-69ff67626e43@group-0B8A33D7FC85-FollowerState] INFO impl.FollowerState: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-0B8A33D7FC85-FollowerState was interrupted: {}
datanode1_1  | java.lang.InterruptedException: sleep interrupted
datanode1_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode1_1  | 	at java.base/java.lang.Thread.sleep(Thread.java:334)
datanode1_1  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode1_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
datanode1_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode1_1  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
datanode1_1  | 2022-04-21 16:45:29,911 [grpc-default-executor-0] INFO impl.RoleInfo: 8694db2d-5e51-4888-b1e0-69ff67626e43: start 8694db2d-5e51-4888-b1e0-69ff67626e43@group-0B8A33D7FC85-FollowerState
datanode1_1  | 2022-04-21 16:45:29,950 [grpc-default-executor-0] INFO server.RaftServer$Division: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-0B8A33D7FC85 replies to ELECTION vote request: a9037631-20c7-49ff-8966-d11abf0c09e2<-8694db2d-5e51-4888-b1e0-69ff67626e43#0:OK-t1. Peer's state: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-0B8A33D7FC85:t1, leader=null, voted=a9037631-20c7-49ff-8966-d11abf0c09e2, raftlog=8694db2d-5e51-4888-b1e0-69ff67626e43@group-0B8A33D7FC85-SegmentedRaftLog:OPENED:c-1, conf=-1: [0ef408af-3ea2-4044-bc54-ad0ae15d84f1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 8694db2d-5e51-4888-b1e0-69ff67626e43|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a9037631-20c7-49ff-8966-d11abf0c09e2|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1], old=null
datanode1_1  | 2022-04-21 16:45:31,066 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-0B8A33D7FC85 with new leaderId: a9037631-20c7-49ff-8966-d11abf0c09e2
datanode1_1  | 2022-04-21 16:45:31,067 [grpc-default-executor-0] INFO server.RaftServer$Division: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-0B8A33D7FC85: change Leader from null to a9037631-20c7-49ff-8966-d11abf0c09e2 at term 1 for appendEntries, leader elected after 3026ms
datanode1_1  | 2022-04-21 16:45:31,237 [grpc-default-executor-0] INFO server.RaftServer$Division: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-0B8A33D7FC85: set configuration 0: [0ef408af-3ea2-4044-bc54-ad0ae15d84f1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 8694db2d-5e51-4888-b1e0-69ff67626e43|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a9037631-20c7-49ff-8966-d11abf0c09e2|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1], old=null
datanode1_1  | 2022-04-21 16:45:31,269 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-0B8A33D7FC85-SegmentedRaftLogWorker: Starting segment from index:0
datanode1_1  | 2022-04-21 16:45:31,746 [8694db2d-5e51-4888-b1e0-69ff67626e43@group-0B8A33D7FC85-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-0B8A33D7FC85-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/a2956c20-9fda-4457-b767-0b8a33d7fc85/current/log_inprogress_0
datanode1_1  | 2022-04-21 16:45:34,687 [grpc-default-executor-0] INFO server.RaftServer: 8694db2d-5e51-4888-b1e0-69ff67626e43: addNew group-F38EF2C5977C:[0ef408af-3ea2-4044-bc54-ad0ae15d84f1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 8694db2d-5e51-4888-b1e0-69ff67626e43|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a9037631-20c7-49ff-8966-d11abf0c09e2|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0] returns group-F38EF2C5977C:java.util.concurrent.CompletableFuture@551c9a3c[Not completed]
datanode1_1  | 2022-04-21 16:45:34,708 [pool-23-thread-1] INFO server.RaftServer$Division: 8694db2d-5e51-4888-b1e0-69ff67626e43: new RaftServerImpl for group-F38EF2C5977C:[0ef408af-3ea2-4044-bc54-ad0ae15d84f1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 8694db2d-5e51-4888-b1e0-69ff67626e43|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a9037631-20c7-49ff-8966-d11abf0c09e2|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0] with ContainerStateMachine:uninitialized
datanode1_1  | 2022-04-21 16:45:34,708 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode1_1  | 2022-04-21 16:45:34,708 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode1_1  | 2022-04-21 16:45:34,712 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode1_1  | 2022-04-21 16:45:34,712 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode1_1  | 2022-04-21 16:45:34,712 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode1_1  | 2022-04-21 16:45:34,712 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode1_1  | 2022-04-21 16:45:34,712 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode1_1  | 2022-04-21 16:45:34,713 [pool-23-thread-1] INFO server.RaftServer$Division: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C: ConfigurationManager, init=-1: [0ef408af-3ea2-4044-bc54-ad0ae15d84f1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 8694db2d-5e51-4888-b1e0-69ff67626e43|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a9037631-20c7-49ff-8966-d11abf0c09e2|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null, confs=<EMPTY_MAP>
datanode1_1  | 2022-04-21 16:45:34,713 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode1_1  | 2022-04-21 16:45:34,713 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode1_1  | 2022-04-21 16:45:34,717 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode1_1  | 2022-04-21 16:45:34,717 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/f5f2ffbc-fc63-4015-9163-f38ef2c5977c does not exist. Creating ...
datanode1_1  | 2022-04-21 16:45:34,724 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/f5f2ffbc-fc63-4015-9163-f38ef2c5977c/in_use.lock acquired by nodename 7@95934f1cb1a3
datanode1_1  | 2022-04-21 16:45:34,733 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/f5f2ffbc-fc63-4015-9163-f38ef2c5977c has been successfully formatted.
datanode1_1  | 2022-04-21 16:45:34,794 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-F38EF2C5977C: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode1_1  | 2022-04-21 16:45:34,795 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode1_1  | 2022-04-21 16:45:34,796 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode1_1  | 2022-04-21 16:45:34,803 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode1_1  | 2022-04-21 16:45:34,803 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2022-04-21 16:45:34,804 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2022-04-21 16:45:34,807 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode1_1  | 2022-04-21 16:45:34,824 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode1_1  | 2022-04-21 16:45:34,830 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/f5f2ffbc-fc63-4015-9163-f38ef2c5977c
datanode1_1  | 2022-04-21 16:45:34,830 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode1_1  | 2022-04-21 16:45:34,830 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode1_1  | 2022-04-21 16:45:34,830 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2022-04-21 16:45:34,830 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode1_1  | 2022-04-21 16:45:34,830 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode1_1  | 2022-04-21 16:45:34,835 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode1_1  | 2022-04-21 16:45:34,836 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode1_1  | 2022-04-21 16:45:34,836 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode1_1  | 2022-04-21 16:45:34,839 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode1_1  | 2022-04-21 16:45:34,840 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode1_1  | 2022-04-21 16:45:34,852 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode1_1  | 2022-04-21 16:45:34,853 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode1_1  | 2022-04-21 16:45:34,859 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode1_1  | 2022-04-21 16:45:34,868 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode1_1  | 2022-04-21 16:45:34,907 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode1_1  | 2022-04-21 16:45:34,923 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode1_1  | 2022-04-21 16:45:34,923 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode1_1  | 2022-04-21 16:45:34,924 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode1_1  | 2022-04-21 16:45:34,931 [pool-23-thread-1] INFO server.RaftServer$Division: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C: start as a follower, conf=-1: [0ef408af-3ea2-4044-bc54-ad0ae15d84f1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 8694db2d-5e51-4888-b1e0-69ff67626e43|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a9037631-20c7-49ff-8966-d11abf0c09e2|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-04-21 16:45:34,938 [pool-23-thread-1] INFO server.RaftServer$Division: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode1_1  | 2022-04-21 16:45:34,939 [pool-23-thread-1] INFO impl.RoleInfo: 8694db2d-5e51-4888-b1e0-69ff67626e43: start 8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C-FollowerState
datanode1_1  | 2022-04-21 16:45:34,948 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F38EF2C5977C,id=8694db2d-5e51-4888-b1e0-69ff67626e43
datanode1_1  | 2022-04-21 16:45:39,014 [grpc-default-executor-0] INFO server.RaftServer$Division: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C: receive requestVote(ELECTION, a9037631-20c7-49ff-8966-d11abf0c09e2, group-F38EF2C5977C, 1, (t:0, i:0))
datanode1_1  | 2022-04-21 16:45:39,015 [grpc-default-executor-0] INFO impl.VoteContext: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C-FOLLOWER: accept ELECTION from a9037631-20c7-49ff-8966-d11abf0c09e2: our priority 0 <= candidate's priority 0
datanode1_1  | 2022-04-21 16:45:39,016 [grpc-default-executor-0] INFO server.RaftServer$Division: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:a9037631-20c7-49ff-8966-d11abf0c09e2
datanode1_1  | 2022-04-21 16:45:39,016 [grpc-default-executor-0] INFO impl.RoleInfo: 8694db2d-5e51-4888-b1e0-69ff67626e43: shutdown 8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C-FollowerState
datanode1_1  | 2022-04-21 16:45:39,016 [grpc-default-executor-0] INFO impl.RoleInfo: 8694db2d-5e51-4888-b1e0-69ff67626e43: start 8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C-FollowerState
datanode1_1  | 2022-04-21 16:45:39,016 [8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C-FollowerState] INFO impl.FollowerState: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C-FollowerState was interrupted: {}
datanode1_1  | java.lang.InterruptedException: sleep interrupted
datanode1_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode1_1  | 	at java.base/java.lang.Thread.sleep(Thread.java:334)
datanode1_1  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode2_1  | 2022-04-21 16:45:10,410 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode2_1  | 2022-04-21 16:45:10,415 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode2_1  | 2022-04-21 16:45:10,419 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.datanode.http.auth.type = kerberos
datanode2_1  | 2022-04-21 16:45:10,715 [main] INFO util.log: Logging initialized @49335ms to org.eclipse.jetty.util.log.Slf4jLog
datanode2_1  | 2022-04-21 16:45:11,510 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode2_1  | 2022-04-21 16:45:11,552 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode2_1  | 2022-04-21 16:45:11,561 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode2_1  | 2022-04-21 16:45:11,568 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode2_1  | 2022-04-21 16:45:11,569 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode2_1  | 2022-04-21 16:45:11,593 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.datanode.http.auth.kerberos.principal keytabKey: hdds.datanode.http.auth.kerberos.keytab
datanode2_1  | 2022-04-21 16:45:11,876 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode2_1  | 2022-04-21 16:45:11,879 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
datanode2_1  | 2022-04-21 16:45:12,086 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode2_1  | 2022-04-21 16:45:12,116 [main] INFO server.session: No SessionScavenger set, using defaults
datanode2_1  | 2022-04-21 16:45:12,128 [main] INFO server.session: node0 Scavenging every 660000ms
datanode2_1  | 2022-04-21 16:45:12,283 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode2_1  | 2022-04-21 16:45:12,299 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@56c26b21{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode2_1  | 2022-04-21 16:45:12,330 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@76fdd5f1{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode2_1  | 2022-04-21 16:45:12,984 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode2_1  | 2022-04-21 16:45:13,063 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@736af6f3{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-12422767903660972271/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode2_1  | 2022-04-21 16:45:13,134 [main] INFO server.AbstractConnector: Started ServerConnector@56c39949{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode2_1  | 2022-04-21 16:45:13,144 [main] INFO server.Server: Started @51764ms
datanode2_1  | 2022-04-21 16:45:13,177 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode2_1  | 2022-04-21 16:45:13,178 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode2_1  | 2022-04-21 16:45:13,180 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode2_1  | 2022-04-21 16:45:13,195 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
datanode2_1  | 2022-04-21 16:45:13,397 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5425213] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode2_1  | 2022-04-21 16:45:13,969 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.25.0.115:9891
datanode2_1  | 2022-04-21 16:45:17,983 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode2_1  | 2022-04-21 16:45:17,994 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode2_1  | 2022-04-21 16:45:18,534 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis a9037631-20c7-49ff-8966-d11abf0c09e2
datanode2_1  | 2022-04-21 16:45:18,672 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.RaftServer: a9037631-20c7-49ff-8966-d11abf0c09e2: start RPC server
datanode2_1  | 2022-04-21 16:45:18,697 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.GrpcService: a9037631-20c7-49ff-8966-d11abf0c09e2: GrpcService started, listening on 9856
datanode2_1  | 2022-04-21 16:45:18,708 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.GrpcService: a9037631-20c7-49ff-8966-d11abf0c09e2: GrpcService started, listening on 9857
datanode2_1  | 2022-04-21 16:45:18,724 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.GrpcService: a9037631-20c7-49ff-8966-d11abf0c09e2: GrpcService started, listening on 9858
datanode2_1  | 2022-04-21 16:45:18,767 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis a9037631-20c7-49ff-8966-d11abf0c09e2 is started using port 9858 for RATIS
datanode2_1  | 2022-04-21 16:45:18,779 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis a9037631-20c7-49ff-8966-d11abf0c09e2 is started using port 9857 for RATIS_ADMIN
datanode2_1  | 2022-04-21 16:45:18,779 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis a9037631-20c7-49ff-8966-d11abf0c09e2 is started using port 9856 for RATIS_SERVER
datanode2_1  | 2022-04-21 16:45:18,780 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$351/0x00000008405b6c40@76d3a596] INFO util.JvmPauseMonitor: JvmPauseMonitor-a9037631-20c7-49ff-8966-d11abf0c09e2: Started
datanode2_1  | 2022-04-21 16:45:18,825 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode2_1  | 2022-04-21 16:45:18,826 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode2_1  | 2022-04-21 16:45:22,505 [Command processor thread] INFO server.RaftServer: a9037631-20c7-49ff-8966-d11abf0c09e2: addNew group-0B8A33D7FC85:[0ef408af-3ea2-4044-bc54-ad0ae15d84f1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 8694db2d-5e51-4888-b1e0-69ff67626e43|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, a9037631-20c7-49ff-8966-d11abf0c09e2|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1] returns group-0B8A33D7FC85:java.util.concurrent.CompletableFuture@10f049d8[Not completed]
datanode2_1  | 2022-04-21 16:45:22,643 [pool-23-thread-1] INFO server.RaftServer$Division: a9037631-20c7-49ff-8966-d11abf0c09e2: new RaftServerImpl for group-0B8A33D7FC85:[0ef408af-3ea2-4044-bc54-ad0ae15d84f1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 8694db2d-5e51-4888-b1e0-69ff67626e43|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, a9037631-20c7-49ff-8966-d11abf0c09e2|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1] with ContainerStateMachine:uninitialized
datanode2_1  | 2022-04-21 16:45:22,653 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode2_1  | 2022-04-21 16:45:22,682 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode2_1  | 2022-04-21 16:45:22,682 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode2_1  | 2022-04-21 16:45:22,682 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode2_1  | 2022-04-21 16:45:22,682 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode2_1  | 2022-04-21 16:45:22,682 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode2_1  | 2022-04-21 16:45:22,685 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | 2022-04-21 16:45:22,718 [pool-23-thread-1] INFO server.RaftServer$Division: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85: ConfigurationManager, init=-1: [0ef408af-3ea2-4044-bc54-ad0ae15d84f1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 8694db2d-5e51-4888-b1e0-69ff67626e43|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, a9037631-20c7-49ff-8966-d11abf0c09e2|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode2_1  | 2022-04-21 16:45:22,730 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2022-04-21 16:45:22,756 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode2_1  | 2022-04-21 16:45:22,766 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode2_1  | 2022-04-21 16:45:22,781 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/a2956c20-9fda-4457-b767-0b8a33d7fc85 does not exist. Creating ...
datanode2_1  | 2022-04-21 16:45:22,825 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/a2956c20-9fda-4457-b767-0b8a33d7fc85/in_use.lock acquired by nodename 7@2fbb6e549361
datanode2_1  | 2022-04-21 16:45:22,860 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/a2956c20-9fda-4457-b767-0b8a33d7fc85 has been successfully formatted.
datanode2_1  | 2022-04-21 16:45:22,894 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-0B8A33D7FC85: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode2_1  | 2022-04-21 16:45:22,908 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode2_1  | 2022-04-21 16:45:22,963 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode2_1  | 2022-04-21 16:45:23,125 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode2_1  | 2022-04-21 16:45:23,125 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2022-04-21 16:45:23,278 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2022-04-21 16:45:23,326 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode2_1  | 2022-04-21 16:45:23,336 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode2_1  | 2022-04-21 16:45:23,366 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/a2956c20-9fda-4457-b767-0b8a33d7fc85
datanode2_1  | 2022-04-21 16:45:23,385 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode2_1  | 2022-04-21 16:45:23,386 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode2_1  | 2022-04-21 16:45:23,388 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2022-04-21 16:45:23,388 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode2_1  | 2022-04-21 16:45:23,391 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode2_1  | 2022-04-21 16:45:23,399 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode2_1  | 2022-04-21 16:45:23,399 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode2_1  | 2022-04-21 16:45:23,403 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode2_1  | 2022-04-21 16:45:23,480 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode2_1  | 2022-04-21 16:45:23,481 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode2_1  | 2022-04-21 16:45:23,523 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode2_1  | 2022-04-21 16:45:23,523 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode2_1  | 2022-04-21 16:45:23,553 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode2_1  | 2022-04-21 16:45:23,560 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode2_1  | 2022-04-21 16:45:23,560 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode2_1  | 2022-04-21 16:45:23,561 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode2_1  | 2022-04-21 16:45:23,571 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode2_1  | 2022-04-21 16:45:23,571 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode2_1  | 2022-04-21 16:45:23,771 [pool-23-thread-1] INFO server.RaftServer$Division: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85: start as a follower, conf=-1: [0ef408af-3ea2-4044-bc54-ad0ae15d84f1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 8694db2d-5e51-4888-b1e0-69ff67626e43|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, a9037631-20c7-49ff-8966-d11abf0c09e2|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1], old=null
datanode2_1  | 2022-04-21 16:45:23,776 [pool-23-thread-1] INFO server.RaftServer$Division: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode2_1  | 2022-04-21 16:45:23,795 [pool-23-thread-1] INFO impl.RoleInfo: a9037631-20c7-49ff-8966-d11abf0c09e2: start a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85-FollowerState
datanode2_1  | 2022-04-21 16:45:23,824 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-0B8A33D7FC85,id=a9037631-20c7-49ff-8966-d11abf0c09e2
datanode2_1  | 2022-04-21 16:45:23,914 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=a2956c20-9fda-4457-b767-0b8a33d7fc85
datanode2_1  | 2022-04-21 16:45:28,943 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85-FollowerState] INFO impl.FollowerState: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5158741420ns, electionTimeout:5122ms
datanode2_1  | 2022-04-21 16:45:28,944 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85-FollowerState] INFO impl.RoleInfo: a9037631-20c7-49ff-8966-d11abf0c09e2: shutdown a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85-FollowerState
datanode2_1  | 2022-04-21 16:45:28,944 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85-FollowerState] INFO server.RaftServer$Division: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode2_1  | 2022-04-21 16:45:28,951 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode2_1  | 2022-04-21 16:45:28,951 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85-FollowerState] INFO impl.RoleInfo: a9037631-20c7-49ff-8966-d11abf0c09e2: start a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85-LeaderElection1
datanode2_1  | 2022-04-21 16:45:28,996 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85-LeaderElection1] INFO impl.LeaderElection: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [0ef408af-3ea2-4044-bc54-ad0ae15d84f1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 8694db2d-5e51-4888-b1e0-69ff67626e43|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, a9037631-20c7-49ff-8966-d11abf0c09e2|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1], old=null
datanode2_1  | 2022-04-21 16:45:30,006 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85-LeaderElection1] INFO impl.LeaderElection: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85-LeaderElection1: ELECTION PASSED received 1 response(s) and 0 exception(s):
datanode2_1  | 2022-04-21 16:45:30,012 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85-LeaderElection1] INFO impl.LeaderElection:   Response 0: a9037631-20c7-49ff-8966-d11abf0c09e2<-8694db2d-5e51-4888-b1e0-69ff67626e43#0:OK-t1
datanode2_1  | 2022-04-21 16:45:30,019 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85-LeaderElection1] INFO impl.LeaderElection: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85-LeaderElection1 ELECTION round 0: result PASSED
datanode2_1  | 2022-04-21 16:45:30,023 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85-LeaderElection1] INFO impl.RoleInfo: a9037631-20c7-49ff-8966-d11abf0c09e2: shutdown a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85-LeaderElection1
datanode2_1  | 2022-04-21 16:45:30,029 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85-LeaderElection1] INFO server.RaftServer$Division: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode2_1  | 2022-04-21 16:45:30,029 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-0B8A33D7FC85 with new leaderId: a9037631-20c7-49ff-8966-d11abf0c09e2
datanode2_1  | 2022-04-21 16:45:30,054 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85-LeaderElection1] INFO server.RaftServer$Division: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85: change Leader from null to a9037631-20c7-49ff-8966-d11abf0c09e2 at term 1 for becomeLeader, leader elected after 7121ms
datanode2_1  | 2022-04-21 16:45:30,079 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode2_1  | 2022-04-21 16:45:30,219 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode2_1  | 2022-04-21 16:45:30,230 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode2_1  | 2022-04-21 16:45:30,280 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode2_1  | 2022-04-21 16:45:30,293 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode2_1  | 2022-04-21 16:45:30,294 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode2_1  | 2022-04-21 16:45:30,356 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode2_1  | 2022-04-21 16:45:30,395 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode2_1  | 2022-04-21 16:45:30,453 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode2_1  | 2022-04-21 16:45:30,468 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2022-04-21 16:45:30,469 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode2_1  | 2022-04-21 16:45:30,489 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85-LeaderElection1] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode2_1  | 2022-04-21 16:45:30,492 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode2_1  | 2022-04-21 16:45:30,493 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | 2022-04-21 16:45:30,513 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode2_1  | 2022-04-21 16:45:30,523 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2022-04-21 16:45:30,524 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode2_1  | 2022-04-21 16:45:30,524 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85-LeaderElection1] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode2_1  | 2022-04-21 16:45:30,535 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode2_1  | 2022-04-21 16:45:30,536 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | 2022-04-21 16:45:30,547 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85-LeaderElection1] INFO impl.RoleInfo: a9037631-20c7-49ff-8966-d11abf0c09e2: start a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85-LeaderStateImpl
datanode1_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
datanode1_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode1_1  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
kdc_1        | Apr 21 16:42:57 kdc krb5kdc[7](info): Loaded
kdc_1        | Apr 21 16:42:57 kdc krb5kdc[7](Error): preauth spake failed to initialize: No SPAKE preauth groups configured
kdc_1        | Apr 21 16:42:57 kdc krb5kdc[7](info): setting up network...
kdc_1        | Apr 21 16:42:57 kdc krb5kdc[7](info): setsockopt(8,IPV6_V6ONLY,1) worked
kdc_1        | Apr 21 16:42:57 kdc krb5kdc[7](info): setsockopt(10,IPV6_V6ONLY,1) worked
kdc_1        | Apr 21 16:42:57 kdc krb5kdc[7](info): set up 4 sockets
kdc_1        | Apr 21 16:42:57 kdc krb5kdc[7](info): commencing operation
kdc_1        | krb5kdc: starting...
kdc_1        | Apr 21 16:43:00 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1650559380, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 21 16:43:07 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1650559387, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 21 16:43:09 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.114: ISSUE: authtime 1650559389, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, s3g/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 21 16:43:13 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.115: ISSUE: authtime 1650559393, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, recon/recon@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 21 16:43:23 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.117: ISSUE: authtime 1650559403, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 21 16:43:30 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.116: ISSUE: authtime 1650559410, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 21 16:43:35 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: ISSUE: authtime 1650559393, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, recon/recon@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Apr 21 16:43:36 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1650559403, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Apr 21 16:43:38 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559387, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Apr 21 16:43:42 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1650559422, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 21 16:43:53 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559422, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Apr 21 16:43:55 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.117: ISSUE: authtime 1650559435, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 21 16:43:57 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1650559437, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 21 16:44:03 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1650559435, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Apr 21 16:44:05 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559437, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Apr 21 16:44:06 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.118: ISSUE: authtime 1650559446, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 21 16:44:07 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.118: ISSUE: authtime 1650559446, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
datanode3_1  | 2022-04-21 16:45:10,467 [main] INFO server.XceiverServerGrpc: GrpcServer channel type EpollServerSocketChannel
datanode3_1  | 2022-04-21 16:45:12,080 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode3_1  | 2022-04-21 16:45:12,080 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode3_1  | 2022-04-21 16:45:12,080 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.datanode.http.auth.type = kerberos
datanode3_1  | 2022-04-21 16:45:12,285 [main] INFO util.log: Logging initialized @50410ms to org.eclipse.jetty.util.log.Slf4jLog
datanode3_1  | 2022-04-21 16:45:13,138 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode3_1  | 2022-04-21 16:45:13,173 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode3_1  | 2022-04-21 16:45:13,193 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode3_1  | 2022-04-21 16:45:13,193 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode3_1  | 2022-04-21 16:45:13,193 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode3_1  | 2022-04-21 16:45:13,232 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.datanode.http.auth.kerberos.principal keytabKey: hdds.datanode.http.auth.kerberos.keytab
datanode3_1  | 2022-04-21 16:45:13,457 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode3_1  | 2022-04-21 16:45:13,458 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
datanode3_1  | 2022-04-21 16:45:13,688 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode3_1  | 2022-04-21 16:45:13,697 [main] INFO server.session: No SessionScavenger set, using defaults
datanode3_1  | 2022-04-21 16:45:13,699 [main] INFO server.session: node0 Scavenging every 660000ms
datanode3_1  | 2022-04-21 16:45:13,816 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode3_1  | 2022-04-21 16:45:13,840 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@3993cecb{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode3_1  | 2022-04-21 16:45:13,872 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@3380313d{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode3_1  | 2022-04-21 16:45:14,501 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode3_1  | 2022-04-21 16:45:14,573 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@1b48784a{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-14324544177954459243/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode3_1  | 2022-04-21 16:45:14,660 [main] INFO server.AbstractConnector: Started ServerConnector@e8ce5b1{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode3_1  | 2022-04-21 16:45:14,660 [main] INFO server.Server: Started @52785ms
datanode3_1  | 2022-04-21 16:45:14,671 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode3_1  | 2022-04-21 16:45:14,672 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode3_1  | 2022-04-21 16:45:14,687 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode3_1  | 2022-04-21 16:45:14,705 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
datanode3_1  | 2022-04-21 16:45:14,828 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@22f13b4a] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode3_1  | 2022-04-21 16:45:15,421 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.25.0.115:9891
datanode3_1  | 2022-04-21 16:45:17,866 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode3_1  | 2022-04-21 16:45:17,886 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode3_1  | 2022-04-21 16:45:18,393 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 0ef408af-3ea2-4044-bc54-ad0ae15d84f1
datanode3_1  | 2022-04-21 16:45:18,535 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO server.RaftServer: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1: start RPC server
datanode3_1  | 2022-04-21 16:45:18,561 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO server.GrpcService: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1: GrpcService started, listening on 9856
datanode3_1  | 2022-04-21 16:45:18,588 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO server.GrpcService: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1: GrpcService started, listening on 9857
datanode3_1  | 2022-04-21 16:45:18,594 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO server.GrpcService: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1: GrpcService started, listening on 9858
datanode3_1  | 2022-04-21 16:45:18,651 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 0ef408af-3ea2-4044-bc54-ad0ae15d84f1 is started using port 9858 for RATIS
datanode3_1  | 2022-04-21 16:45:18,652 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 0ef408af-3ea2-4044-bc54-ad0ae15d84f1 is started using port 9857 for RATIS_ADMIN
datanode3_1  | 2022-04-21 16:45:18,652 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 0ef408af-3ea2-4044-bc54-ad0ae15d84f1 is started using port 9856 for RATIS_SERVER
datanode3_1  | 2022-04-21 16:45:18,652 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$351/0x00000008405b6c40@4d15dc8f] INFO util.JvmPauseMonitor: JvmPauseMonitor-0ef408af-3ea2-4044-bc54-ad0ae15d84f1: Started
datanode3_1  | 2022-04-21 16:45:18,762 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode3_1  | 2022-04-21 16:45:18,771 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode3_1  | 2022-04-21 16:45:31,643 [grpc-default-executor-0] WARN server.GrpcServerProtocolService: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1: Failed requestVote a9037631-20c7-49ff-8966-d11abf0c09e2->0ef408af-3ea2-4044-bc54-ad0ae15d84f1#0
datanode3_1  | org.apache.ratis.protocol.exceptions.GroupMismatchException: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1: group-0B8A33D7FC85 not found.
datanode3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:147)
datanode3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:339)
datanode3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:348)
datanode3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:343)
datanode3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.requestVote(RaftServerProxy.java:548)
datanode3_1  | 	at org.apache.ratis.grpc.server.GrpcServerProtocolService.requestVote(GrpcServerProtocolService.java:172)
datanode3_1  | 	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$MethodHandlers.invoke(RaftServerProtocolServiceGrpc.java:394)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:182)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.PartialForwardingServerCallListener.onHalfClose(PartialForwardingServerCallListener.java:35)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onHalfClose(ForwardingServerCallListener.java:23)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode3_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode3_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode3_1  | 	at java.base/java.lang.Thread.run(Thread.java:829)
datanode3_1  | 2022-04-21 16:45:31,868 [grpc-default-executor-1] INFO server.RaftServer: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1: addNew group-0B8A33D7FC85:[0ef408af-3ea2-4044-bc54-ad0ae15d84f1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 8694db2d-5e51-4888-b1e0-69ff67626e43|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a9037631-20c7-49ff-8966-d11abf0c09e2|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1] returns group-0B8A33D7FC85:java.util.concurrent.CompletableFuture@2ed91cab[Not completed]
datanode3_1  | 2022-04-21 16:45:32,060 [pool-23-thread-1] INFO server.RaftServer$Division: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1: new RaftServerImpl for group-0B8A33D7FC85:[0ef408af-3ea2-4044-bc54-ad0ae15d84f1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 8694db2d-5e51-4888-b1e0-69ff67626e43|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a9037631-20c7-49ff-8966-d11abf0c09e2|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1] with ContainerStateMachine:uninitialized
datanode3_1  | 2022-04-21 16:45:32,072 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode3_1  | 2022-04-21 16:45:32,082 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode3_1  | 2022-04-21 16:45:32,082 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode3_1  | 2022-04-21 16:45:32,083 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode3_1  | 2022-04-21 16:45:32,083 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode3_1  | 2022-04-21 16:45:32,083 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode3_1  | 2022-04-21 16:45:32,085 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2022-04-21 16:45:32,109 [pool-23-thread-1] INFO server.RaftServer$Division: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-0B8A33D7FC85: ConfigurationManager, init=-1: [0ef408af-3ea2-4044-bc54-ad0ae15d84f1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 8694db2d-5e51-4888-b1e0-69ff67626e43|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a9037631-20c7-49ff-8966-d11abf0c09e2|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1], old=null, confs=<EMPTY_MAP>
datanode3_1  | 2022-04-21 16:45:32,117 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode3_1  | 2022-04-21 16:45:32,121 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode3_1  | 2022-04-21 16:45:32,142 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode3_1  | 2022-04-21 16:45:32,144 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/a2956c20-9fda-4457-b767-0b8a33d7fc85 does not exist. Creating ...
datanode3_1  | 2022-04-21 16:45:32,164 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/a2956c20-9fda-4457-b767-0b8a33d7fc85/in_use.lock acquired by nodename 7@4703807bf00c
datanode3_1  | 2022-04-21 16:45:32,232 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/a2956c20-9fda-4457-b767-0b8a33d7fc85 has been successfully formatted.
datanode3_1  | 2022-04-21 16:45:32,322 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-0B8A33D7FC85: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode3_1  | 2022-04-21 16:45:32,327 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode3_1  | 2022-04-21 16:45:32,345 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode3_1  | 2022-04-21 16:45:32,384 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode3_1  | 2022-04-21 16:45:32,388 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2022-04-21 16:45:39,020 [grpc-default-executor-0] INFO server.RaftServer$Division: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C replies to ELECTION vote request: a9037631-20c7-49ff-8966-d11abf0c09e2<-8694db2d-5e51-4888-b1e0-69ff67626e43#0:OK-t1. Peer's state: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C:t1, leader=null, voted=a9037631-20c7-49ff-8966-d11abf0c09e2, raftlog=8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C-SegmentedRaftLog:OPENED:c-1, conf=-1: [0ef408af-3ea2-4044-bc54-ad0ae15d84f1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 8694db2d-5e51-4888-b1e0-69ff67626e43|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a9037631-20c7-49ff-8966-d11abf0c09e2|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-04-21 16:45:44,247 [grpc-default-executor-0] INFO server.RaftServer$Division: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C: receive requestVote(ELECTION, a9037631-20c7-49ff-8966-d11abf0c09e2, group-F38EF2C5977C, 2, (t:0, i:0))
datanode1_1  | 2022-04-21 16:45:44,247 [grpc-default-executor-0] INFO impl.VoteContext: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C-FOLLOWER: accept ELECTION from a9037631-20c7-49ff-8966-d11abf0c09e2: our priority 0 <= candidate's priority 0
datanode1_1  | 2022-04-21 16:45:44,248 [grpc-default-executor-0] INFO server.RaftServer$Division: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:a9037631-20c7-49ff-8966-d11abf0c09e2
datanode1_1  | 2022-04-21 16:45:44,248 [grpc-default-executor-0] INFO impl.RoleInfo: 8694db2d-5e51-4888-b1e0-69ff67626e43: shutdown 8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C-FollowerState
datanode1_1  | 2022-04-21 16:45:44,248 [8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C-FollowerState] INFO impl.FollowerState: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C-FollowerState was interrupted: {}
datanode1_1  | java.lang.InterruptedException: sleep interrupted
datanode1_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode1_1  | 	at java.base/java.lang.Thread.sleep(Thread.java:334)
datanode1_1  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode1_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
datanode1_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode1_1  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
datanode1_1  | 2022-04-21 16:45:44,249 [grpc-default-executor-0] INFO impl.RoleInfo: 8694db2d-5e51-4888-b1e0-69ff67626e43: start 8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C-FollowerState
datanode1_1  | 2022-04-21 16:45:44,253 [grpc-default-executor-0] INFO server.RaftServer$Division: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C replies to ELECTION vote request: a9037631-20c7-49ff-8966-d11abf0c09e2<-8694db2d-5e51-4888-b1e0-69ff67626e43#0:OK-t2. Peer's state: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C:t2, leader=null, voted=a9037631-20c7-49ff-8966-d11abf0c09e2, raftlog=8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C-SegmentedRaftLog:OPENED:c-1, conf=-1: [0ef408af-3ea2-4044-bc54-ad0ae15d84f1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 8694db2d-5e51-4888-b1e0-69ff67626e43|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a9037631-20c7-49ff-8966-d11abf0c09e2|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-04-21 16:45:45,275 [grpc-default-executor-0] INFO server.RaftServer$Division: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C: receive requestVote(ELECTION, 0ef408af-3ea2-4044-bc54-ad0ae15d84f1, group-F38EF2C5977C, 2, (t:0, i:0))
datanode1_1  | 2022-04-21 16:45:45,275 [grpc-default-executor-0] INFO impl.VoteContext: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C-FOLLOWER: reject ELECTION from 0ef408af-3ea2-4044-bc54-ad0ae15d84f1: already has voted for a9037631-20c7-49ff-8966-d11abf0c09e2 at current term 2
datanode1_1  | 2022-04-21 16:45:45,275 [grpc-default-executor-0] INFO server.RaftServer$Division: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C replies to ELECTION vote request: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1<-8694db2d-5e51-4888-b1e0-69ff67626e43#0:FAIL-t2. Peer's state: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C:t2, leader=null, voted=a9037631-20c7-49ff-8966-d11abf0c09e2, raftlog=8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C-SegmentedRaftLog:OPENED:c-1, conf=-1: [0ef408af-3ea2-4044-bc54-ad0ae15d84f1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 8694db2d-5e51-4888-b1e0-69ff67626e43|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a9037631-20c7-49ff-8966-d11abf0c09e2|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-04-21 16:45:49,397 [grpc-default-executor-0] INFO server.RaftServer$Division: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C: receive requestVote(ELECTION, a9037631-20c7-49ff-8966-d11abf0c09e2, group-F38EF2C5977C, 3, (t:0, i:0))
datanode1_1  | 2022-04-21 16:45:49,397 [grpc-default-executor-0] INFO impl.VoteContext: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C-FOLLOWER: accept ELECTION from a9037631-20c7-49ff-8966-d11abf0c09e2: our priority 0 <= candidate's priority 0
datanode1_1  | 2022-04-21 16:45:49,397 [grpc-default-executor-0] INFO server.RaftServer$Division: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C: changes role from  FOLLOWER to FOLLOWER at term 3 for candidate:a9037631-20c7-49ff-8966-d11abf0c09e2
datanode1_1  | 2022-04-21 16:45:49,397 [grpc-default-executor-0] INFO impl.RoleInfo: 8694db2d-5e51-4888-b1e0-69ff67626e43: shutdown 8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C-FollowerState
datanode1_1  | 2022-04-21 16:45:49,398 [8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C-FollowerState] INFO impl.FollowerState: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C-FollowerState was interrupted: {}
datanode1_1  | java.lang.InterruptedException: sleep interrupted
datanode1_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode1_1  | 	at java.base/java.lang.Thread.sleep(Thread.java:334)
datanode1_1  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode1_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
datanode1_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode1_1  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
datanode1_1  | 2022-04-21 16:45:49,399 [grpc-default-executor-0] INFO impl.RoleInfo: 8694db2d-5e51-4888-b1e0-69ff67626e43: start 8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C-FollowerState
datanode1_1  | 2022-04-21 16:45:49,403 [grpc-default-executor-0] INFO server.RaftServer$Division: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C replies to ELECTION vote request: a9037631-20c7-49ff-8966-d11abf0c09e2<-8694db2d-5e51-4888-b1e0-69ff67626e43#0:OK-t3. Peer's state: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C:t3, leader=null, voted=a9037631-20c7-49ff-8966-d11abf0c09e2, raftlog=8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C-SegmentedRaftLog:OPENED:c-1, conf=-1: [0ef408af-3ea2-4044-bc54-ad0ae15d84f1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 8694db2d-5e51-4888-b1e0-69ff67626e43|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a9037631-20c7-49ff-8966-d11abf0c09e2|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-04-21 16:45:51,668 [Command processor thread] INFO server.RaftServer: 8694db2d-5e51-4888-b1e0-69ff67626e43: addNew group-63989FD6333F:[8694db2d-5e51-4888-b1e0-69ff67626e43|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1] returns group-63989FD6333F:java.util.concurrent.CompletableFuture@47a6e4f8[Not completed]
kdc_1        | Apr 21 16:44:10 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1650559450, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 21 16:44:15 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.118: ISSUE: authtime 1650559455, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 21 16:44:17 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559450, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Apr 21 16:44:21 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.118: ISSUE: authtime 1650559455, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Apr 21 16:44:21 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1650559461, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 21 16:44:37 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.103: ISSUE: authtime 1650559477, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 21 16:44:38 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.102: ISSUE: authtime 1650559478, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 21 16:44:38 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.104: ISSUE: authtime 1650559478, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 21 16:44:41 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.113: ISSUE: authtime 1650559481, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 21 16:44:42 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.111: ISSUE: authtime 1650559482, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 21 16:44:42 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.112: ISSUE: authtime 1650559482, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 21 16:44:45 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.113: ISSUE: authtime 1650559481, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Apr 21 16:44:45 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.112: ISSUE: authtime 1650559482, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Apr 21 16:44:46 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.111: ISSUE: authtime 1650559482, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Apr 21 16:44:49 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.103: ISSUE: authtime 1650559477, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Apr 21 16:44:49 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.102: ISSUE: authtime 1650559478, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Apr 21 16:44:50 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.104: ISSUE: authtime 1650559478, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Apr 21 16:44:54 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559461, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Apr 21 16:45:02 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1650559502, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 21 16:45:15 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.103: ISSUE: authtime 1650559477, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for recon/recon@EXAMPLE.COM
datanode1_1  | 2022-04-21 16:45:51,671 [pool-23-thread-1] INFO server.RaftServer$Division: 8694db2d-5e51-4888-b1e0-69ff67626e43: new RaftServerImpl for group-63989FD6333F:[8694db2d-5e51-4888-b1e0-69ff67626e43|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1] with ContainerStateMachine:uninitialized
datanode1_1  | 2022-04-21 16:45:51,680 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode1_1  | 2022-04-21 16:45:51,681 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode1_1  | 2022-04-21 16:45:51,681 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode1_1  | 2022-04-21 16:45:51,681 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode1_1  | 2022-04-21 16:45:51,681 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode1_1  | 2022-04-21 16:45:51,681 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode1_1  | 2022-04-21 16:45:51,681 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode1_1  | 2022-04-21 16:45:51,681 [pool-23-thread-1] INFO server.RaftServer$Division: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-63989FD6333F: ConfigurationManager, init=-1: [8694db2d-5e51-4888-b1e0-69ff67626e43|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode1_1  | 2022-04-21 16:45:51,681 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode1_1  | 2022-04-21 16:45:51,682 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode1_1  | 2022-04-21 16:45:51,682 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode1_1  | 2022-04-21 16:45:51,682 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/39b933e3-a932-4461-b956-63989fd6333f does not exist. Creating ...
datanode1_1  | 2022-04-21 16:45:51,684 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/39b933e3-a932-4461-b956-63989fd6333f/in_use.lock acquired by nodename 7@95934f1cb1a3
datanode1_1  | 2022-04-21 16:45:51,685 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/39b933e3-a932-4461-b956-63989fd6333f has been successfully formatted.
datanode1_1  | 2022-04-21 16:45:51,686 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-63989FD6333F: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode1_1  | 2022-04-21 16:45:51,686 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode1_1  | 2022-04-21 16:45:51,686 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode1_1  | 2022-04-21 16:45:51,686 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode1_1  | 2022-04-21 16:45:51,687 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2022-04-21 16:45:51,687 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2022-04-21 16:45:51,687 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode1_1  | 2022-04-21 16:45:51,687 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode1_1  | 2022-04-21 16:45:51,687 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 8694db2d-5e51-4888-b1e0-69ff67626e43@group-63989FD6333F-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/39b933e3-a932-4461-b956-63989fd6333f
datanode1_1  | 2022-04-21 16:45:51,687 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode1_1  | 2022-04-21 16:45:51,688 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode1_1  | 2022-04-21 16:45:51,688 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2022-04-21 16:45:51,688 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode1_1  | 2022-04-21 16:45:51,688 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode1_1  | 2022-04-21 16:45:51,688 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode1_1  | 2022-04-21 16:45:51,688 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode1_1  | 2022-04-21 16:45:51,688 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode1_1  | 2022-04-21 16:45:51,689 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode1_1  | 2022-04-21 16:45:51,691 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode1_1  | 2022-04-21 16:45:51,697 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-63989FD6333F-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode1_1  | 2022-04-21 16:45:51,697 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-63989FD6333F-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode1_1  | 2022-04-21 16:45:51,698 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode1_1  | 2022-04-21 16:45:51,698 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode1_1  | 2022-04-21 16:45:51,698 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode1_1  | 2022-04-21 16:45:51,698 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode1_1  | 2022-04-21 16:45:51,698 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode1_1  | 2022-04-21 16:45:51,698 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode1_1  | 2022-04-21 16:45:51,699 [pool-23-thread-1] INFO server.RaftServer$Division: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-63989FD6333F: start as a follower, conf=-1: [8694db2d-5e51-4888-b1e0-69ff67626e43|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1], old=null
datanode1_1  | 2022-04-21 16:45:51,699 [pool-23-thread-1] INFO server.RaftServer$Division: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-63989FD6333F: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode1_1  | 2022-04-21 16:45:51,700 [pool-23-thread-1] INFO impl.RoleInfo: 8694db2d-5e51-4888-b1e0-69ff67626e43: start 8694db2d-5e51-4888-b1e0-69ff67626e43@group-63989FD6333F-FollowerState
datanode1_1  | 2022-04-21 16:45:51,701 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-63989FD6333F,id=8694db2d-5e51-4888-b1e0-69ff67626e43
datanode1_1  | 2022-04-21 16:45:51,702 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=39b933e3-a932-4461-b956-63989fd6333f
datanode1_1  | 2022-04-21 16:45:51,703 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=39b933e3-a932-4461-b956-63989fd6333f.
datanode3_1  | 2022-04-21 16:45:32,405 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2022-04-21 16:45:32,537 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode3_1  | 2022-04-21 16:45:32,539 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode3_1  | 2022-04-21 16:45:32,659 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-0B8A33D7FC85-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/a2956c20-9fda-4457-b767-0b8a33d7fc85
datanode3_1  | 2022-04-21 16:45:32,660 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode3_1  | 2022-04-21 16:45:32,666 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode3_1  | 2022-04-21 16:45:32,666 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2022-04-21 16:45:32,673 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode3_1  | 2022-04-21 16:45:32,689 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode3_1  | 2022-04-21 16:45:32,707 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode3_1  | 2022-04-21 16:45:32,711 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode3_1  | 2022-04-21 16:45:32,716 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode3_1  | 2022-04-21 16:45:32,848 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode3_1  | 2022-04-21 16:45:32,853 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode2_1  | 2022-04-21 16:45:30,617 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85-SegmentedRaftLogWorker: Starting segment from index:0
datanode2_1  | 2022-04-21 16:45:30,936 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85-LeaderElection1] INFO server.RaftServer$Division: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85: set configuration 0: [0ef408af-3ea2-4044-bc54-ad0ae15d84f1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 8694db2d-5e51-4888-b1e0-69ff67626e43|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a9037631-20c7-49ff-8966-d11abf0c09e2|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1], old=null
datanode2_1  | 2022-04-21 16:45:31,478 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/a2956c20-9fda-4457-b767-0b8a33d7fc85/current/log_inprogress_0
datanode2_1  | 2022-04-21 16:45:33,468 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=a2956c20-9fda-4457-b767-0b8a33d7fc85.
datanode2_1  | 2022-04-21 16:45:33,469 [Command processor thread] INFO server.RaftServer: a9037631-20c7-49ff-8966-d11abf0c09e2: addNew group-A5405A44EB65:[a9037631-20c7-49ff-8966-d11abf0c09e2|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1] returns group-A5405A44EB65:java.util.concurrent.CompletableFuture@4aae7f8[Not completed]
datanode2_1  | 2022-04-21 16:45:33,471 [pool-23-thread-1] INFO server.RaftServer$Division: a9037631-20c7-49ff-8966-d11abf0c09e2: new RaftServerImpl for group-A5405A44EB65:[a9037631-20c7-49ff-8966-d11abf0c09e2|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1] with ContainerStateMachine:uninitialized
datanode2_1  | 2022-04-21 16:45:33,471 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode2_1  | 2022-04-21 16:45:33,472 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode2_1  | 2022-04-21 16:45:33,472 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode2_1  | 2022-04-21 16:45:33,472 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode2_1  | 2022-04-21 16:45:33,472 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode2_1  | 2022-04-21 16:45:33,472 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode2_1  | 2022-04-21 16:45:33,472 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | 2022-04-21 16:45:33,472 [pool-23-thread-1] INFO server.RaftServer$Division: a9037631-20c7-49ff-8966-d11abf0c09e2@group-A5405A44EB65: ConfigurationManager, init=-1: [a9037631-20c7-49ff-8966-d11abf0c09e2|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode2_1  | 2022-04-21 16:45:33,473 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2022-04-21 16:45:33,473 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode2_1  | 2022-04-21 16:45:33,473 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode2_1  | 2022-04-21 16:45:33,473 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/72e20438-e2a5-4ad3-9b38-a5405a44eb65 does not exist. Creating ...
datanode2_1  | 2022-04-21 16:45:33,483 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/72e20438-e2a5-4ad3-9b38-a5405a44eb65/in_use.lock acquired by nodename 7@2fbb6e549361
datanode2_1  | 2022-04-21 16:45:33,485 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/72e20438-e2a5-4ad3-9b38-a5405a44eb65 has been successfully formatted.
datanode2_1  | 2022-04-21 16:45:33,486 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-A5405A44EB65: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode2_1  | 2022-04-21 16:45:33,486 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode2_1  | 2022-04-21 16:45:33,486 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode2_1  | 2022-04-21 16:45:33,487 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode2_1  | 2022-04-21 16:45:33,487 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2022-04-21 16:45:33,487 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2022-04-21 16:45:33,531 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode2_1  | 2022-04-21 16:45:33,531 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode2_1  | 2022-04-21 16:45:33,532 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new a9037631-20c7-49ff-8966-d11abf0c09e2@group-A5405A44EB65-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/72e20438-e2a5-4ad3-9b38-a5405a44eb65
datanode2_1  | 2022-04-21 16:45:33,532 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode2_1  | 2022-04-21 16:45:33,532 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode2_1  | 2022-04-21 16:45:33,532 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2022-04-21 16:45:33,532 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode2_1  | 2022-04-21 16:45:33,545 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode2_1  | 2022-04-21 16:45:33,574 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode2_1  | 2022-04-21 16:45:33,584 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode2_1  | 2022-04-21 16:45:33,587 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode2_1  | 2022-04-21 16:45:33,592 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode2_1  | 2022-04-21 16:45:33,597 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode2_1  | 2022-04-21 16:45:33,607 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: a9037631-20c7-49ff-8966-d11abf0c09e2@group-A5405A44EB65-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode2_1  | 2022-04-21 16:45:33,627 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: a9037631-20c7-49ff-8966-d11abf0c09e2@group-A5405A44EB65-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode2_1  | 2022-04-21 16:45:33,637 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode2_1  | 2022-04-21 16:45:33,641 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode2_1  | 2022-04-21 16:45:33,641 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode1_1  | 2022-04-21 16:45:54,541 [grpc-default-executor-0] INFO server.RaftServer$Division: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C: receive requestVote(ELECTION, a9037631-20c7-49ff-8966-d11abf0c09e2, group-F38EF2C5977C, 4, (t:0, i:0))
datanode1_1  | 2022-04-21 16:45:54,541 [grpc-default-executor-0] INFO impl.VoteContext: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C-FOLLOWER: accept ELECTION from a9037631-20c7-49ff-8966-d11abf0c09e2: our priority 0 <= candidate's priority 0
datanode1_1  | 2022-04-21 16:45:54,541 [grpc-default-executor-0] INFO server.RaftServer$Division: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C: changes role from  FOLLOWER to FOLLOWER at term 4 for candidate:a9037631-20c7-49ff-8966-d11abf0c09e2
datanode1_1  | 2022-04-21 16:45:54,542 [grpc-default-executor-0] INFO impl.RoleInfo: 8694db2d-5e51-4888-b1e0-69ff67626e43: shutdown 8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C-FollowerState
datanode1_1  | 2022-04-21 16:45:54,542 [8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C-FollowerState] INFO impl.FollowerState: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C-FollowerState was interrupted: {}
datanode1_1  | java.lang.InterruptedException: sleep interrupted
datanode1_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode1_1  | 	at java.base/java.lang.Thread.sleep(Thread.java:334)
datanode1_1  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode1_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
datanode1_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode1_1  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
datanode1_1  | 2022-04-21 16:45:54,543 [grpc-default-executor-0] INFO impl.RoleInfo: 8694db2d-5e51-4888-b1e0-69ff67626e43: start 8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C-FollowerState
datanode1_1  | 2022-04-21 16:45:54,547 [grpc-default-executor-0] INFO server.RaftServer$Division: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C replies to ELECTION vote request: a9037631-20c7-49ff-8966-d11abf0c09e2<-8694db2d-5e51-4888-b1e0-69ff67626e43#0:OK-t4. Peer's state: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C:t4, leader=null, voted=a9037631-20c7-49ff-8966-d11abf0c09e2, raftlog=8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C-SegmentedRaftLog:OPENED:c-1, conf=-1: [0ef408af-3ea2-4044-bc54-ad0ae15d84f1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 8694db2d-5e51-4888-b1e0-69ff67626e43|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a9037631-20c7-49ff-8966-d11abf0c09e2|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-04-21 16:45:56,760 [8694db2d-5e51-4888-b1e0-69ff67626e43@group-63989FD6333F-FollowerState] INFO impl.FollowerState: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-63989FD6333F-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5060359496ns, electionTimeout:5057ms
datanode1_1  | 2022-04-21 16:45:56,761 [8694db2d-5e51-4888-b1e0-69ff67626e43@group-63989FD6333F-FollowerState] INFO impl.RoleInfo: 8694db2d-5e51-4888-b1e0-69ff67626e43: shutdown 8694db2d-5e51-4888-b1e0-69ff67626e43@group-63989FD6333F-FollowerState
datanode1_1  | 2022-04-21 16:45:56,761 [8694db2d-5e51-4888-b1e0-69ff67626e43@group-63989FD6333F-FollowerState] INFO server.RaftServer$Division: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-63989FD6333F: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode1_1  | 2022-04-21 16:45:56,769 [8694db2d-5e51-4888-b1e0-69ff67626e43@group-63989FD6333F-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode1_1  | 2022-04-21 16:45:56,770 [8694db2d-5e51-4888-b1e0-69ff67626e43@group-63989FD6333F-FollowerState] INFO impl.RoleInfo: 8694db2d-5e51-4888-b1e0-69ff67626e43: start 8694db2d-5e51-4888-b1e0-69ff67626e43@group-63989FD6333F-LeaderElection1
datanode1_1  | 2022-04-21 16:45:56,777 [8694db2d-5e51-4888-b1e0-69ff67626e43@group-63989FD6333F-LeaderElection1] INFO impl.LeaderElection: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-63989FD6333F-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [8694db2d-5e51-4888-b1e0-69ff67626e43|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1], old=null
datanode1_1  | 2022-04-21 16:45:56,778 [8694db2d-5e51-4888-b1e0-69ff67626e43@group-63989FD6333F-LeaderElection1] INFO impl.LeaderElection: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-63989FD6333F-LeaderElection1 ELECTION round 0: result PASSED (term=1)
datanode1_1  | 2022-04-21 16:45:56,779 [8694db2d-5e51-4888-b1e0-69ff67626e43@group-63989FD6333F-LeaderElection1] INFO impl.RoleInfo: 8694db2d-5e51-4888-b1e0-69ff67626e43: shutdown 8694db2d-5e51-4888-b1e0-69ff67626e43@group-63989FD6333F-LeaderElection1
datanode1_1  | 2022-04-21 16:45:56,779 [8694db2d-5e51-4888-b1e0-69ff67626e43@group-63989FD6333F-LeaderElection1] INFO server.RaftServer$Division: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-63989FD6333F: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode1_1  | 2022-04-21 16:45:56,779 [8694db2d-5e51-4888-b1e0-69ff67626e43@group-63989FD6333F-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-63989FD6333F with new leaderId: 8694db2d-5e51-4888-b1e0-69ff67626e43
datanode1_1  | 2022-04-21 16:45:56,812 [8694db2d-5e51-4888-b1e0-69ff67626e43@group-63989FD6333F-LeaderElection1] INFO server.RaftServer$Division: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-63989FD6333F: change Leader from null to 8694db2d-5e51-4888-b1e0-69ff67626e43 at term 1 for becomeLeader, leader elected after 5093ms
datanode1_1  | 2022-04-21 16:45:56,819 [8694db2d-5e51-4888-b1e0-69ff67626e43@group-63989FD6333F-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode1_1  | 2022-04-21 16:45:56,861 [8694db2d-5e51-4888-b1e0-69ff67626e43@group-63989FD6333F-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode1_1  | 2022-04-21 16:45:56,873 [8694db2d-5e51-4888-b1e0-69ff67626e43@group-63989FD6333F-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode1_1  | 2022-04-21 16:45:56,900 [8694db2d-5e51-4888-b1e0-69ff67626e43@group-63989FD6333F-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode1_1  | 2022-04-21 16:45:56,900 [8694db2d-5e51-4888-b1e0-69ff67626e43@group-63989FD6333F-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode1_1  | 2022-04-21 16:45:56,900 [8694db2d-5e51-4888-b1e0-69ff67626e43@group-63989FD6333F-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode1_1  | 2022-04-21 16:45:56,916 [8694db2d-5e51-4888-b1e0-69ff67626e43@group-63989FD6333F-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode1_1  | 2022-04-21 16:45:56,920 [8694db2d-5e51-4888-b1e0-69ff67626e43@group-63989FD6333F-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode1_1  | 2022-04-21 16:45:56,929 [8694db2d-5e51-4888-b1e0-69ff67626e43@group-63989FD6333F-LeaderElection1] INFO impl.RoleInfo: 8694db2d-5e51-4888-b1e0-69ff67626e43: start 8694db2d-5e51-4888-b1e0-69ff67626e43@group-63989FD6333F-LeaderStateImpl
datanode1_1  | 2022-04-21 16:45:56,952 [8694db2d-5e51-4888-b1e0-69ff67626e43@group-63989FD6333F-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-63989FD6333F-SegmentedRaftLogWorker: Starting segment from index:0
datanode1_1  | 2022-04-21 16:45:56,955 [8694db2d-5e51-4888-b1e0-69ff67626e43@group-63989FD6333F-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-63989FD6333F-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/39b933e3-a932-4461-b956-63989fd6333f/current/log_inprogress_0
datanode3_1  | 2022-04-21 16:45:32,908 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-0B8A33D7FC85-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode3_1  | 2022-04-21 16:45:32,913 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-0B8A33D7FC85-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode3_1  | 2022-04-21 16:45:32,927 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode3_1  | 2022-04-21 16:45:32,938 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode3_1  | 2022-04-21 16:45:32,942 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode3_1  | 2022-04-21 16:45:32,946 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode3_1  | 2022-04-21 16:45:32,948 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode3_1  | 2022-04-21 16:45:32,954 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode3_1  | 2022-04-21 16:45:33,161 [pool-23-thread-1] INFO server.RaftServer$Division: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-0B8A33D7FC85: start as a follower, conf=-1: [0ef408af-3ea2-4044-bc54-ad0ae15d84f1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 8694db2d-5e51-4888-b1e0-69ff67626e43|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a9037631-20c7-49ff-8966-d11abf0c09e2|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1], old=null
datanode3_1  | 2022-04-21 16:45:33,185 [pool-23-thread-1] INFO server.RaftServer$Division: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-0B8A33D7FC85: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode3_1  | 2022-04-21 16:45:33,196 [pool-23-thread-1] INFO impl.RoleInfo: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1: start 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-0B8A33D7FC85-FollowerState
datanode3_1  | 2022-04-21 16:45:33,230 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-0B8A33D7FC85,id=0ef408af-3ea2-4044-bc54-ad0ae15d84f1
datanode3_1  | 2022-04-21 16:45:34,053 [grpc-default-executor-1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-0B8A33D7FC85 with new leaderId: a9037631-20c7-49ff-8966-d11abf0c09e2
datanode3_1  | 2022-04-21 16:45:34,059 [grpc-default-executor-1] INFO server.RaftServer$Division: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-0B8A33D7FC85: change Leader from null to a9037631-20c7-49ff-8966-d11abf0c09e2 at term 1 for appendEntries, leader elected after 1726ms
datanode3_1  | 2022-04-21 16:45:34,095 [grpc-default-executor-1] INFO server.RaftServer$Division: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-0B8A33D7FC85: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
datanode3_1  | 2022-04-21 16:45:34,099 [grpc-default-executor-1] INFO server.RaftServer$Division: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-0B8A33D7FC85: inconsistency entries. Reply:a9037631-20c7-49ff-8966-d11abf0c09e2<-0ef408af-3ea2-4044-bc54-ad0ae15d84f1#3:FAIL-t0,INCONSISTENCY,nextIndex=0,followerCommit=-1
datanode3_1  | 2022-04-21 16:45:34,206 [grpc-default-executor-1] INFO server.RaftServer$Division: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-0B8A33D7FC85: set configuration 0: [0ef408af-3ea2-4044-bc54-ad0ae15d84f1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 8694db2d-5e51-4888-b1e0-69ff67626e43|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a9037631-20c7-49ff-8966-d11abf0c09e2|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1], old=null
datanode3_1  | 2022-04-21 16:45:34,227 [grpc-default-executor-1] INFO segmented.SegmentedRaftLogWorker: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-0B8A33D7FC85-SegmentedRaftLogWorker: Starting segment from index:0
datanode3_1  | 2022-04-21 16:45:34,717 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-0B8A33D7FC85-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-0B8A33D7FC85-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/a2956c20-9fda-4457-b767-0b8a33d7fc85/current/log_inprogress_0
datanode3_1  | 2022-04-21 16:45:35,472 [grpc-default-executor-1] INFO server.RaftServer: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1: addNew group-F38EF2C5977C:[0ef408af-3ea2-4044-bc54-ad0ae15d84f1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 8694db2d-5e51-4888-b1e0-69ff67626e43|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a9037631-20c7-49ff-8966-d11abf0c09e2|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0] returns group-F38EF2C5977C:java.util.concurrent.CompletableFuture@317a9cf[Not completed]
datanode3_1  | 2022-04-21 16:45:35,474 [pool-23-thread-1] INFO server.RaftServer$Division: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1: new RaftServerImpl for group-F38EF2C5977C:[0ef408af-3ea2-4044-bc54-ad0ae15d84f1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 8694db2d-5e51-4888-b1e0-69ff67626e43|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a9037631-20c7-49ff-8966-d11abf0c09e2|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0] with ContainerStateMachine:uninitialized
datanode3_1  | 2022-04-21 16:45:35,478 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode3_1  | 2022-04-21 16:45:35,480 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode3_1  | 2022-04-21 16:45:35,482 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode3_1  | 2022-04-21 16:45:35,482 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode3_1  | 2022-04-21 16:45:35,482 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode3_1  | 2022-04-21 16:45:35,482 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode3_1  | 2022-04-21 16:45:35,482 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2022-04-21 16:45:35,491 [pool-23-thread-1] INFO server.RaftServer$Division: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C: ConfigurationManager, init=-1: [0ef408af-3ea2-4044-bc54-ad0ae15d84f1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 8694db2d-5e51-4888-b1e0-69ff67626e43|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a9037631-20c7-49ff-8966-d11abf0c09e2|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null, confs=<EMPTY_MAP>
datanode3_1  | 2022-04-21 16:45:35,491 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode3_1  | 2022-04-21 16:45:35,491 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode3_1  | 2022-04-21 16:45:35,496 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode3_1  | 2022-04-21 16:45:35,497 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/f5f2ffbc-fc63-4015-9163-f38ef2c5977c does not exist. Creating ...
datanode3_1  | 2022-04-21 16:45:35,499 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/f5f2ffbc-fc63-4015-9163-f38ef2c5977c/in_use.lock acquired by nodename 7@4703807bf00c
datanode3_1  | 2022-04-21 16:45:35,502 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/f5f2ffbc-fc63-4015-9163-f38ef2c5977c has been successfully formatted.
datanode3_1  | 2022-04-21 16:45:35,519 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-F38EF2C5977C: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode3_1  | 2022-04-21 16:45:35,520 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode3_1  | 2022-04-21 16:45:35,523 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode3_1  | 2022-04-21 16:45:35,523 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode3_1  | 2022-04-21 16:45:35,524 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2022-04-21 16:45:35,524 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2022-04-21 16:45:35,524 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode3_1  | 2022-04-21 16:45:35,524 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode3_1  | 2022-04-21 16:45:35,529 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/f5f2ffbc-fc63-4015-9163-f38ef2c5977c
datanode3_1  | 2022-04-21 16:45:35,529 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode3_1  | 2022-04-21 16:45:35,531 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode3_1  | 2022-04-21 16:45:35,531 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2022-04-21 16:45:35,532 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode3_1  | 2022-04-21 16:45:35,532 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode3_1  | 2022-04-21 16:45:35,533 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode3_1  | 2022-04-21 16:45:35,539 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode3_1  | 2022-04-21 16:45:35,539 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode3_1  | 2022-04-21 16:45:35,550 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode3_1  | 2022-04-21 16:45:35,552 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode3_1  | 2022-04-21 16:45:35,555 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode3_1  | 2022-04-21 16:45:35,556 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode3_1  | 2022-04-21 16:45:35,556 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode3_1  | 2022-04-21 16:45:35,557 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode3_1  | 2022-04-21 16:45:35,557 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode3_1  | 2022-04-21 16:45:35,557 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode3_1  | 2022-04-21 16:45:35,557 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode3_1  | 2022-04-21 16:45:35,562 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode3_1  | 2022-04-21 16:45:35,571 [pool-23-thread-1] INFO server.RaftServer$Division: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C: start as a follower, conf=-1: [0ef408af-3ea2-4044-bc54-ad0ae15d84f1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 8694db2d-5e51-4888-b1e0-69ff67626e43|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a9037631-20c7-49ff-8966-d11abf0c09e2|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-04-21 16:45:35,572 [pool-23-thread-1] INFO server.RaftServer$Division: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode3_1  | 2022-04-21 16:45:35,575 [pool-23-thread-1] INFO impl.RoleInfo: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1: start 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-FollowerState
datanode3_1  | 2022-04-21 16:45:35,577 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F38EF2C5977C,id=0ef408af-3ea2-4044-bc54-ad0ae15d84f1
datanode3_1  | 2022-04-21 16:45:38,980 [grpc-default-executor-1] INFO server.RaftServer$Division: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C: receive requestVote(ELECTION, a9037631-20c7-49ff-8966-d11abf0c09e2, group-F38EF2C5977C, 1, (t:0, i:0))
datanode3_1  | 2022-04-21 16:45:38,982 [grpc-default-executor-1] INFO impl.VoteContext: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-FOLLOWER: reject ELECTION from a9037631-20c7-49ff-8966-d11abf0c09e2: our priority 1 > candidate's priority 0
datanode3_1  | 2022-04-21 16:45:38,982 [grpc-default-executor-1] INFO server.RaftServer$Division: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:a9037631-20c7-49ff-8966-d11abf0c09e2
datanode3_1  | 2022-04-21 16:45:38,982 [grpc-default-executor-1] INFO impl.RoleInfo: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1: shutdown 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-FollowerState
kdc_1        | Apr 21 16:45:17 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.102: ISSUE: authtime 1650559478, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for recon/recon@EXAMPLE.COM
kdc_1        | Apr 21 16:45:17 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.104: ISSUE: authtime 1650559478, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for recon/recon@EXAMPLE.COM
kdc_1        | Apr 21 16:45:21 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.111: ISSUE: authtime 1650559521, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 21 16:45:22 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.113: ISSUE: authtime 1650559522, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 21 16:45:23 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.112: ISSUE: authtime 1650559523, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 21 16:45:24 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.111: ISSUE: authtime 1650559521, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Apr 21 16:45:26 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.112: ISSUE: authtime 1650559523, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Apr 21 16:45:26 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.113: ISSUE: authtime 1650559522, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Apr 21 16:45:30 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559502, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Apr 21 16:45:35 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1650559535, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 21 16:45:45 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: ISSUE: authtime 1650559393, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, recon/recon@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:45:50 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559535, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Apr 21 16:45:52 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1650559552, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 21 16:45:57 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559552, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:45:57 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Apr 21 16:45:57 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Apr 21 16:45:58 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Apr 21 16:45:58 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Apr 21 16:46:00 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1650559560, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 21 16:46:11 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559560, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:46:23 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559560, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:46:28 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559560, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:46:33 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559560, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:46:40 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559560, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:46:46 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559560, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:46:51 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559560, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:46:56 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559560, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:46:58 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Apr 21 16:46:58 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Apr 21 16:47:10 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559560, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:47:14 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559560, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:47:18 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559560, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:47:22 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559560, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:47:31 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559560, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:47:35 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559560, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:47:39 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559560, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:47:43 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559560, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode1_1  | 2022-04-21 16:45:56,970 [8694db2d-5e51-4888-b1e0-69ff67626e43@group-63989FD6333F-LeaderElection1] INFO server.RaftServer$Division: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-63989FD6333F: set configuration 0: [8694db2d-5e51-4888-b1e0-69ff67626e43|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1], old=null
datanode1_1  | 2022-04-21 16:45:59,731 [grpc-default-executor-0] INFO server.RaftServer$Division: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C: receive requestVote(ELECTION, 0ef408af-3ea2-4044-bc54-ad0ae15d84f1, group-F38EF2C5977C, 5, (t:0, i:0))
datanode1_1  | 2022-04-21 16:45:59,731 [grpc-default-executor-0] INFO impl.VoteContext: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C-FOLLOWER: accept ELECTION from 0ef408af-3ea2-4044-bc54-ad0ae15d84f1: our priority 0 <= candidate's priority 1
datanode1_1  | 2022-04-21 16:45:59,732 [grpc-default-executor-0] INFO server.RaftServer$Division: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C: changes role from  FOLLOWER to FOLLOWER at term 5 for candidate:0ef408af-3ea2-4044-bc54-ad0ae15d84f1
datanode1_1  | 2022-04-21 16:45:59,732 [grpc-default-executor-0] INFO impl.RoleInfo: 8694db2d-5e51-4888-b1e0-69ff67626e43: shutdown 8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C-FollowerState
datanode1_1  | 2022-04-21 16:45:59,732 [8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C-FollowerState] INFO impl.FollowerState: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C-FollowerState was interrupted: {}
datanode1_1  | java.lang.InterruptedException: sleep interrupted
datanode1_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode1_1  | 	at java.base/java.lang.Thread.sleep(Thread.java:334)
datanode1_1  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode1_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
datanode1_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode1_1  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
datanode1_1  | 2022-04-21 16:45:59,733 [grpc-default-executor-0] INFO impl.RoleInfo: 8694db2d-5e51-4888-b1e0-69ff67626e43: start 8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C-FollowerState
datanode1_1  | 2022-04-21 16:45:59,738 [grpc-default-executor-0] INFO server.RaftServer$Division: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C replies to ELECTION vote request: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1<-8694db2d-5e51-4888-b1e0-69ff67626e43#0:OK-t5. Peer's state: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C:t5, leader=null, voted=0ef408af-3ea2-4044-bc54-ad0ae15d84f1, raftlog=8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C-SegmentedRaftLog:OPENED:c-1, conf=-1: [0ef408af-3ea2-4044-bc54-ad0ae15d84f1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 8694db2d-5e51-4888-b1e0-69ff67626e43|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a9037631-20c7-49ff-8966-d11abf0c09e2|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-04-21 16:45:59,786 [grpc-default-executor-0] INFO server.RaftServer$Division: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C: receive requestVote(ELECTION, a9037631-20c7-49ff-8966-d11abf0c09e2, group-F38EF2C5977C, 5, (t:0, i:0))
datanode1_1  | 2022-04-21 16:45:59,787 [grpc-default-executor-0] INFO impl.VoteContext: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C-FOLLOWER: reject ELECTION from a9037631-20c7-49ff-8966-d11abf0c09e2: already has voted for 0ef408af-3ea2-4044-bc54-ad0ae15d84f1 at current term 5
datanode1_1  | 2022-04-21 16:45:59,787 [grpc-default-executor-0] INFO server.RaftServer$Division: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C replies to ELECTION vote request: a9037631-20c7-49ff-8966-d11abf0c09e2<-8694db2d-5e51-4888-b1e0-69ff67626e43#0:FAIL-t5. Peer's state: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C:t5, leader=null, voted=0ef408af-3ea2-4044-bc54-ad0ae15d84f1, raftlog=8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C-SegmentedRaftLog:OPENED:c-1, conf=-1: [0ef408af-3ea2-4044-bc54-ad0ae15d84f1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 8694db2d-5e51-4888-b1e0-69ff67626e43|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a9037631-20c7-49ff-8966-d11abf0c09e2|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-04-21 16:46:00,211 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-F38EF2C5977C with new leaderId: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1
datanode1_1  | 2022-04-21 16:46:00,211 [grpc-default-executor-0] INFO server.RaftServer$Division: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C: change Leader from null to 0ef408af-3ea2-4044-bc54-ad0ae15d84f1 at term 5 for appendEntries, leader elected after 25415ms
datanode1_1  | 2022-04-21 16:46:00,306 [grpc-default-executor-0] INFO server.RaftServer$Division: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C: set configuration 0: [0ef408af-3ea2-4044-bc54-ad0ae15d84f1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 8694db2d-5e51-4888-b1e0-69ff67626e43|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a9037631-20c7-49ff-8966-d11abf0c09e2|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-04-21 16:46:00,307 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C-SegmentedRaftLogWorker: Starting segment from index:0
datanode1_1  | 2022-04-21 16:46:00,309 [8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 8694db2d-5e51-4888-b1e0-69ff67626e43@group-F38EF2C5977C-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/f5f2ffbc-fc63-4015-9163-f38ef2c5977c/current/log_inprogress_0
datanode1_1  | 2022-04-21 16:46:16,549 [ChunkWriter-1-0] INFO client.DNCertificateClient: Getting certificate with certSerialId:960208477648.
datanode3_1  | 2022-04-21 16:45:38,983 [grpc-default-executor-1] INFO impl.RoleInfo: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1: start 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-FollowerState
datanode3_1  | 2022-04-21 16:45:38,983 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-FollowerState] INFO impl.FollowerState: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-FollowerState was interrupted: {}
datanode3_1  | java.lang.InterruptedException: sleep interrupted
datanode3_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode3_1  | 	at java.base/java.lang.Thread.sleep(Thread.java:334)
datanode3_1  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode3_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
datanode3_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode3_1  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
kms_1        | Sleeping for 5 seconds
kms_1        | WARNING: /opt/hadoop/temp does not exist. Creating.
kdc_1        | Apr 21 16:47:47 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559560, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:47:50 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559560, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:47:54 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559560, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:47:58 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Apr 21 16:47:58 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Apr 21 16:47:58 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559560, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:48:02 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559560, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:48:03 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1650559683, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 21 16:48:06 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559683, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:48:10 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559683, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:48:11 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1650559691, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 21 16:48:14 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559691, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:48:18 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559691, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:48:21 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559691, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:48:28 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559691, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:48:31 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1650559711, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 21 16:48:34 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559711, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:48:43 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559711, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:48:46 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1650559726, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 21 16:48:49 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559726, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:48:53 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559726, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:48:54 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1650559734, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 21 16:48:58 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Apr 21 16:48:58 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Apr 21 16:48:58 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559734, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:49:02 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559734, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:49:03 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1650559743, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 21 16:49:06 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559743, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:49:07 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1650559747, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 21 16:49:10 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559747, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:49:11 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1650559751, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 21 16:49:14 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559751, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:49:18 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559751, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:49:22 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559751, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:49:26 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559751, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode2_1  | 2022-04-21 16:45:33,641 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode2_1  | 2022-04-21 16:45:33,641 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode2_1  | 2022-04-21 16:45:33,642 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode2_1  | 2022-04-21 16:45:33,646 [pool-23-thread-1] INFO server.RaftServer$Division: a9037631-20c7-49ff-8966-d11abf0c09e2@group-A5405A44EB65: start as a follower, conf=-1: [a9037631-20c7-49ff-8966-d11abf0c09e2|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1], old=null
datanode2_1  | 2022-04-21 16:45:33,657 [pool-23-thread-1] INFO server.RaftServer$Division: a9037631-20c7-49ff-8966-d11abf0c09e2@group-A5405A44EB65: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode2_1  | 2022-04-21 16:45:33,658 [pool-23-thread-1] INFO impl.RoleInfo: a9037631-20c7-49ff-8966-d11abf0c09e2: start a9037631-20c7-49ff-8966-d11abf0c09e2@group-A5405A44EB65-FollowerState
datanode2_1  | 2022-04-21 16:45:33,665 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A5405A44EB65,id=a9037631-20c7-49ff-8966-d11abf0c09e2
datanode2_1  | 2022-04-21 16:45:33,668 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=72e20438-e2a5-4ad3-9b38-a5405a44eb65
datanode2_1  | 2022-04-21 16:45:33,668 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=72e20438-e2a5-4ad3-9b38-a5405a44eb65.
datanode2_1  | 2022-04-21 16:45:33,669 [Command processor thread] INFO server.RaftServer: a9037631-20c7-49ff-8966-d11abf0c09e2: addNew group-F38EF2C5977C:[0ef408af-3ea2-4044-bc54-ad0ae15d84f1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 8694db2d-5e51-4888-b1e0-69ff67626e43|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, a9037631-20c7-49ff-8966-d11abf0c09e2|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0] returns group-F38EF2C5977C:java.util.concurrent.CompletableFuture@2f2dca9c[Not completed]
datanode2_1  | 2022-04-21 16:45:33,676 [pool-23-thread-1] INFO server.RaftServer$Division: a9037631-20c7-49ff-8966-d11abf0c09e2: new RaftServerImpl for group-F38EF2C5977C:[0ef408af-3ea2-4044-bc54-ad0ae15d84f1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 8694db2d-5e51-4888-b1e0-69ff67626e43|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, a9037631-20c7-49ff-8966-d11abf0c09e2|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0] with ContainerStateMachine:uninitialized
datanode2_1  | 2022-04-21 16:45:33,694 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode2_1  | 2022-04-21 16:45:33,695 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode2_1  | 2022-04-21 16:45:33,696 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode2_1  | 2022-04-21 16:45:33,696 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode2_1  | 2022-04-21 16:45:33,696 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode2_1  | 2022-04-21 16:45:33,696 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode2_1  | 2022-04-21 16:45:33,699 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | 2022-04-21 16:45:33,700 [pool-23-thread-1] INFO server.RaftServer$Division: a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C: ConfigurationManager, init=-1: [0ef408af-3ea2-4044-bc54-ad0ae15d84f1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 8694db2d-5e51-4888-b1e0-69ff67626e43|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, a9037631-20c7-49ff-8966-d11abf0c09e2|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0], old=null, confs=<EMPTY_MAP>
datanode2_1  | 2022-04-21 16:45:33,700 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2022-04-21 16:45:33,702 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode2_1  | 2022-04-21 16:45:33,737 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode2_1  | 2022-04-21 16:45:33,738 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/f5f2ffbc-fc63-4015-9163-f38ef2c5977c does not exist. Creating ...
datanode2_1  | 2022-04-21 16:45:33,747 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/f5f2ffbc-fc63-4015-9163-f38ef2c5977c/in_use.lock acquired by nodename 7@2fbb6e549361
datanode2_1  | 2022-04-21 16:45:33,757 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/f5f2ffbc-fc63-4015-9163-f38ef2c5977c has been successfully formatted.
datanode2_1  | 2022-04-21 16:45:33,757 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-F38EF2C5977C: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode2_1  | 2022-04-21 16:45:33,758 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode2_1  | 2022-04-21 16:45:33,777 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode2_1  | 2022-04-21 16:45:33,778 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode2_1  | 2022-04-21 16:45:33,778 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2022-04-21 16:45:33,779 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2022-04-21 16:45:33,788 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode2_1  | 2022-04-21 16:45:33,822 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode2_1  | 2022-04-21 16:45:33,822 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/f5f2ffbc-fc63-4015-9163-f38ef2c5977c
datanode2_1  | 2022-04-21 16:45:33,849 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode2_1  | 2022-04-21 16:45:33,850 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode2_1  | 2022-04-21 16:45:33,850 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2022-04-21 16:45:33,850 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode2_1  | 2022-04-21 16:45:33,850 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode2_1  | 2022-04-21 16:45:33,850 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode2_1  | 2022-04-21 16:45:33,851 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode2_1  | 2022-04-21 16:45:33,851 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode2_1  | 2022-04-21 16:45:33,854 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode2_1  | 2022-04-21 16:45:33,860 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode2_1  | 2022-04-21 16:45:33,862 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode2_1  | 2022-04-21 16:45:33,865 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode2_1  | 2022-04-21 16:45:33,866 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode2_1  | 2022-04-21 16:45:33,870 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode2_1  | 2022-04-21 16:45:33,872 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode2_1  | 2022-04-21 16:45:33,872 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode2_1  | 2022-04-21 16:45:33,873 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode2_1  | 2022-04-21 16:45:33,877 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode2_1  | 2022-04-21 16:45:33,878 [pool-23-thread-1] INFO server.RaftServer$Division: a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C: start as a follower, conf=-1: [0ef408af-3ea2-4044-bc54-ad0ae15d84f1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 8694db2d-5e51-4888-b1e0-69ff67626e43|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, a9037631-20c7-49ff-8966-d11abf0c09e2|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0], old=null
datanode2_1  | 2022-04-21 16:45:33,882 [pool-23-thread-1] INFO server.RaftServer$Division: a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode2_1  | 2022-04-21 16:45:33,882 [pool-23-thread-1] INFO impl.RoleInfo: a9037631-20c7-49ff-8966-d11abf0c09e2: start a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-FollowerState
datanode2_1  | 2022-04-21 16:45:33,883 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F38EF2C5977C,id=a9037631-20c7-49ff-8966-d11abf0c09e2
datanode2_1  | 2022-04-21 16:45:33,900 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=f5f2ffbc-fc63-4015-9163-f38ef2c5977c
datanode2_1  | 2022-04-21 16:45:34,165 [grpc-default-executor-0] INFO leader.FollowerInfo: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1: nextIndex: updateUnconditionally 1 -> 0
datanode2_1  | 2022-04-21 16:45:35,625 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=f5f2ffbc-fc63-4015-9163-f38ef2c5977c.
datanode2_1  | 2022-04-21 16:45:38,820 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-A5405A44EB65-FollowerState] INFO impl.FollowerState: a9037631-20c7-49ff-8966-d11abf0c09e2@group-A5405A44EB65-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5162149447ns, electionTimeout:5151ms
datanode2_1  | 2022-04-21 16:45:38,820 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-A5405A44EB65-FollowerState] INFO impl.RoleInfo: a9037631-20c7-49ff-8966-d11abf0c09e2: shutdown a9037631-20c7-49ff-8966-d11abf0c09e2@group-A5405A44EB65-FollowerState
datanode2_1  | 2022-04-21 16:45:38,821 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-A5405A44EB65-FollowerState] INFO server.RaftServer$Division: a9037631-20c7-49ff-8966-d11abf0c09e2@group-A5405A44EB65: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode2_1  | 2022-04-21 16:45:38,821 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-A5405A44EB65-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode2_1  | 2022-04-21 16:45:38,821 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-A5405A44EB65-FollowerState] INFO impl.RoleInfo: a9037631-20c7-49ff-8966-d11abf0c09e2: start a9037631-20c7-49ff-8966-d11abf0c09e2@group-A5405A44EB65-LeaderElection2
datanode2_1  | 2022-04-21 16:45:38,829 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-A5405A44EB65-LeaderElection2] INFO impl.LeaderElection: a9037631-20c7-49ff-8966-d11abf0c09e2@group-A5405A44EB65-LeaderElection2 ELECTION round 0: submit vote requests at term 1 for -1: [a9037631-20c7-49ff-8966-d11abf0c09e2|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1], old=null
datanode2_1  | 2022-04-21 16:45:38,829 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-A5405A44EB65-LeaderElection2] INFO impl.LeaderElection: a9037631-20c7-49ff-8966-d11abf0c09e2@group-A5405A44EB65-LeaderElection2 ELECTION round 0: result PASSED (term=1)
datanode2_1  | 2022-04-21 16:45:38,829 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-A5405A44EB65-LeaderElection2] INFO impl.RoleInfo: a9037631-20c7-49ff-8966-d11abf0c09e2: shutdown a9037631-20c7-49ff-8966-d11abf0c09e2@group-A5405A44EB65-LeaderElection2
datanode2_1  | 2022-04-21 16:45:38,829 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-A5405A44EB65-LeaderElection2] INFO server.RaftServer$Division: a9037631-20c7-49ff-8966-d11abf0c09e2@group-A5405A44EB65: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode2_1  | 2022-04-21 16:45:38,830 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-A5405A44EB65-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-A5405A44EB65 with new leaderId: a9037631-20c7-49ff-8966-d11abf0c09e2
datanode2_1  | 2022-04-21 16:45:38,846 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-A5405A44EB65-LeaderElection2] INFO server.RaftServer$Division: a9037631-20c7-49ff-8966-d11abf0c09e2@group-A5405A44EB65: change Leader from null to a9037631-20c7-49ff-8966-d11abf0c09e2 at term 1 for becomeLeader, leader elected after 5343ms
datanode2_1  | 2022-04-21 16:45:38,846 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-A5405A44EB65-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode2_1  | 2022-04-21 16:45:38,847 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-A5405A44EB65-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode2_1  | 2022-04-21 16:45:38,847 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-A5405A44EB65-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode2_1  | 2022-04-21 16:45:38,847 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-A5405A44EB65-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode2_1  | 2022-04-21 16:45:38,851 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-A5405A44EB65-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode2_1  | 2022-04-21 16:45:38,855 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-A5405A44EB65-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode2_1  | 2022-04-21 16:45:38,857 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-A5405A44EB65-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode2_1  | 2022-04-21 16:45:38,857 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-A5405A44EB65-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
kdc_1        | Apr 21 16:49:30 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559751, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:49:34 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559751, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:49:35 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1650559775, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 21 16:49:38 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559775, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:49:42 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559775, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:49:46 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559775, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:49:50 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559775, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:49:51 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1650559791, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 21 16:49:51 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1650559791, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 21 16:49:54 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559791, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:49:55 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1650559795, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 21 16:49:55 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1650559795, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 21 16:49:58 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Apr 21 16:49:58 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Apr 21 16:49:58 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559795, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:49:59 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1650559799, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 21 16:49:59 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1650559799, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 21 16:50:02 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559799, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:50:06 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559799, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:50:07 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1650559807, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 21 16:50:10 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559807, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:50:14 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559807, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:50:18 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559807, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:50:22 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559807, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:50:22 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1650559822, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 21 16:50:26 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559822, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:50:30 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559822, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:50:36 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559822, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:50:39 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1650559839, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 21 16:50:42 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559839, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:50:46 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559839, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:50:50 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559839, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:50:58 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Apr 21 16:50:58 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Apr 21 16:51:19 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1650559879, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 21 16:51:21 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559879, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:51:26 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.114: ISSUE: authtime 1650559389, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, s3g/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:51:27 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1650559887, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 21 16:51:30 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559887, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:51:43 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1650559903, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 21 16:51:46 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559903, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:51:58 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Apr 21 16:51:58 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Apr 21 16:52:15 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1650559935, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 21 16:52:17 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559935, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:52:24 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1650559944, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 21 16:52:27 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559944, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:52:33 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1650559953, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 21 16:52:35 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559953, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:52:41 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1650559961, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 21 16:52:43 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559961, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:52:50 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559961, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:52:53 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1650559973, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 21 16:52:56 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650559973, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:52:58 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Apr 21 16:52:58 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Apr 21 16:53:58 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Apr 21 16:53:58 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Apr 21 16:54:58 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Apr 21 16:54:58 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Apr 21 16:55:58 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Apr 21 16:55:58 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Apr 21 16:56:58 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Apr 21 16:56:58 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Apr 21 16:57:30 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1650560250, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 21 16:57:35 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650560250, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:57:58 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Apr 21 16:57:58 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Apr 21 16:58:58 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Apr 21 16:58:58 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Apr 21 16:59:50 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1650560390, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
datanode2_1  | 2022-04-21 16:45:38,857 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-A5405A44EB65-LeaderElection2] INFO impl.RoleInfo: a9037631-20c7-49ff-8966-d11abf0c09e2: start a9037631-20c7-49ff-8966-d11abf0c09e2@group-A5405A44EB65-LeaderStateImpl
datanode2_1  | 2022-04-21 16:45:38,858 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-A5405A44EB65-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: a9037631-20c7-49ff-8966-d11abf0c09e2@group-A5405A44EB65-SegmentedRaftLogWorker: Starting segment from index:0
datanode2_1  | 2022-04-21 16:45:38,879 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-A5405A44EB65-LeaderElection2] INFO server.RaftServer$Division: a9037631-20c7-49ff-8966-d11abf0c09e2@group-A5405A44EB65: set configuration 0: [a9037631-20c7-49ff-8966-d11abf0c09e2|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1], old=null
datanode2_1  | 2022-04-21 16:45:38,903 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-A5405A44EB65-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: a9037631-20c7-49ff-8966-d11abf0c09e2@group-A5405A44EB65-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/72e20438-e2a5-4ad3-9b38-a5405a44eb65/current/log_inprogress_0
datanode2_1  | 2022-04-21 16:45:38,956 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-FollowerState] INFO impl.FollowerState: a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5074236786ns, electionTimeout:5071ms
datanode2_1  | 2022-04-21 16:45:38,957 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-FollowerState] INFO impl.RoleInfo: a9037631-20c7-49ff-8966-d11abf0c09e2: shutdown a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-FollowerState
datanode2_1  | 2022-04-21 16:45:38,957 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-FollowerState] INFO server.RaftServer$Division: a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode2_1  | 2022-04-21 16:45:38,957 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode2_1  | 2022-04-21 16:45:38,957 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-FollowerState] INFO impl.RoleInfo: a9037631-20c7-49ff-8966-d11abf0c09e2: start a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-LeaderElection3
datanode2_1  | 2022-04-21 16:45:38,974 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-LeaderElection3] INFO impl.LeaderElection: a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-LeaderElection3 ELECTION round 0: submit vote requests at term 1 for -1: [0ef408af-3ea2-4044-bc54-ad0ae15d84f1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 8694db2d-5e51-4888-b1e0-69ff67626e43|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, a9037631-20c7-49ff-8966-d11abf0c09e2|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0], old=null
datanode2_1  | 2022-04-21 16:45:39,028 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-LeaderElection3] INFO impl.LeaderElection: a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-LeaderElection3: ELECTION REJECTED received 1 response(s) and 0 exception(s):
datanode2_1  | 2022-04-21 16:45:39,029 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-LeaderElection3] INFO impl.LeaderElection:   Response 0: a9037631-20c7-49ff-8966-d11abf0c09e2<-0ef408af-3ea2-4044-bc54-ad0ae15d84f1#0:FAIL-t1
datanode2_1  | 2022-04-21 16:45:39,030 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-LeaderElection3] INFO impl.LeaderElection: a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-LeaderElection3 ELECTION round 0: result REJECTED
datanode2_1  | 2022-04-21 16:45:39,030 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-LeaderElection3] INFO server.RaftServer$Division: a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
datanode2_1  | 2022-04-21 16:45:39,031 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-LeaderElection3] INFO impl.RoleInfo: a9037631-20c7-49ff-8966-d11abf0c09e2: shutdown a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-LeaderElection3
datanode2_1  | 2022-04-21 16:45:39,031 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-LeaderElection3] INFO impl.RoleInfo: a9037631-20c7-49ff-8966-d11abf0c09e2: start a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-FollowerState
datanode2_1  | 2022-04-21 16:45:44,230 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-FollowerState] INFO impl.FollowerState: a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5198817194ns, electionTimeout:5198ms
datanode2_1  | 2022-04-21 16:45:44,230 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-FollowerState] INFO impl.RoleInfo: a9037631-20c7-49ff-8966-d11abf0c09e2: shutdown a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-FollowerState
datanode2_1  | 2022-04-21 16:45:44,230 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-FollowerState] INFO server.RaftServer$Division: a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
datanode2_1  | 2022-04-21 16:45:44,231 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode2_1  | 2022-04-21 16:45:44,231 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-FollowerState] INFO impl.RoleInfo: a9037631-20c7-49ff-8966-d11abf0c09e2: start a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-LeaderElection4
datanode2_1  | 2022-04-21 16:45:44,238 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-LeaderElection4] INFO impl.LeaderElection: a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-LeaderElection4 ELECTION round 0: submit vote requests at term 2 for -1: [0ef408af-3ea2-4044-bc54-ad0ae15d84f1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 8694db2d-5e51-4888-b1e0-69ff67626e43|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, a9037631-20c7-49ff-8966-d11abf0c09e2|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0], old=null
datanode2_1  | 2022-04-21 16:45:44,270 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-LeaderElection4] INFO impl.LeaderElection: a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-LeaderElection4: ELECTION REJECTED received 2 response(s) and 0 exception(s):
datanode2_1  | 2022-04-21 16:45:44,271 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-LeaderElection4] INFO impl.LeaderElection:   Response 0: a9037631-20c7-49ff-8966-d11abf0c09e2<-0ef408af-3ea2-4044-bc54-ad0ae15d84f1#0:FAIL-t2
datanode2_1  | 2022-04-21 16:45:44,272 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-LeaderElection4] INFO impl.LeaderElection:   Response 1: a9037631-20c7-49ff-8966-d11abf0c09e2<-8694db2d-5e51-4888-b1e0-69ff67626e43#0:OK-t2
datanode2_1  | 2022-04-21 16:45:44,272 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-LeaderElection4] INFO impl.LeaderElection: a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-LeaderElection4 ELECTION round 0: result REJECTED
datanode2_1  | 2022-04-21 16:45:44,272 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-LeaderElection4] INFO server.RaftServer$Division: a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C: changes role from CANDIDATE to FOLLOWER at term 2 for REJECTED
datanode2_1  | 2022-04-21 16:45:44,272 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-LeaderElection4] INFO impl.RoleInfo: a9037631-20c7-49ff-8966-d11abf0c09e2: shutdown a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-LeaderElection4
datanode2_1  | 2022-04-21 16:45:44,272 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-LeaderElection4] INFO impl.RoleInfo: a9037631-20c7-49ff-8966-d11abf0c09e2: start a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-FollowerState
datanode2_1  | 2022-04-21 16:45:45,373 [grpc-default-executor-0] INFO server.RaftServer$Division: a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C: receive requestVote(ELECTION, 0ef408af-3ea2-4044-bc54-ad0ae15d84f1, group-F38EF2C5977C, 2, (t:0, i:0))
datanode2_1  | 2022-04-21 16:45:45,377 [grpc-default-executor-0] INFO impl.VoteContext: a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-FOLLOWER: reject ELECTION from 0ef408af-3ea2-4044-bc54-ad0ae15d84f1: already has voted for a9037631-20c7-49ff-8966-d11abf0c09e2 at current term 2
datanode2_1  | 2022-04-21 16:45:45,420 [grpc-default-executor-0] INFO server.RaftServer$Division: a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C replies to ELECTION vote request: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1<-a9037631-20c7-49ff-8966-d11abf0c09e2#0:FAIL-t2. Peer's state: a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C:t2, leader=null, voted=a9037631-20c7-49ff-8966-d11abf0c09e2, raftlog=a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-SegmentedRaftLog:OPENED:c-1, conf=-1: [0ef408af-3ea2-4044-bc54-ad0ae15d84f1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 8694db2d-5e51-4888-b1e0-69ff67626e43|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, a9037631-20c7-49ff-8966-d11abf0c09e2|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0], old=null
datanode2_1  | 2022-04-21 16:45:49,384 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-FollowerState] INFO impl.FollowerState: a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5111304411ns, electionTimeout:5080ms
datanode2_1  | 2022-04-21 16:45:49,384 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-FollowerState] INFO impl.RoleInfo: a9037631-20c7-49ff-8966-d11abf0c09e2: shutdown a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-FollowerState
datanode2_1  | 2022-04-21 16:45:49,384 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-FollowerState] INFO server.RaftServer$Division: a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C: changes role from  FOLLOWER to CANDIDATE at term 2 for changeToCandidate
datanode2_1  | 2022-04-21 16:45:49,384 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode2_1  | 2022-04-21 16:45:49,384 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-FollowerState] INFO impl.RoleInfo: a9037631-20c7-49ff-8966-d11abf0c09e2: start a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-LeaderElection5
datanode2_1  | 2022-04-21 16:45:49,391 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-LeaderElection5] INFO impl.LeaderElection: a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-LeaderElection5 ELECTION round 0: submit vote requests at term 3 for -1: [0ef408af-3ea2-4044-bc54-ad0ae15d84f1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 8694db2d-5e51-4888-b1e0-69ff67626e43|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, a9037631-20c7-49ff-8966-d11abf0c09e2|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0], old=null
datanode2_1  | 2022-04-21 16:45:49,430 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-LeaderElection5] INFO impl.LeaderElection: a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-LeaderElection5: ELECTION REJECTED received 2 response(s) and 0 exception(s):
datanode2_1  | 2022-04-21 16:45:49,430 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-LeaderElection5] INFO impl.LeaderElection:   Response 0: a9037631-20c7-49ff-8966-d11abf0c09e2<-0ef408af-3ea2-4044-bc54-ad0ae15d84f1#0:FAIL-t3
datanode2_1  | 2022-04-21 16:45:49,430 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-LeaderElection5] INFO impl.LeaderElection:   Response 1: a9037631-20c7-49ff-8966-d11abf0c09e2<-8694db2d-5e51-4888-b1e0-69ff67626e43#0:OK-t3
datanode2_1  | 2022-04-21 16:45:49,430 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-LeaderElection5] INFO impl.LeaderElection: a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-LeaderElection5 ELECTION round 0: result REJECTED
datanode2_1  | 2022-04-21 16:45:49,430 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-LeaderElection5] INFO server.RaftServer$Division: a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C: changes role from CANDIDATE to FOLLOWER at term 3 for REJECTED
datanode2_1  | 2022-04-21 16:45:49,432 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-LeaderElection5] INFO impl.RoleInfo: a9037631-20c7-49ff-8966-d11abf0c09e2: shutdown a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-LeaderElection5
datanode2_1  | 2022-04-21 16:45:49,432 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-LeaderElection5] INFO impl.RoleInfo: a9037631-20c7-49ff-8966-d11abf0c09e2: start a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-FollowerState
datanode2_1  | 2022-04-21 16:45:54,514 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-FollowerState] INFO impl.FollowerState: a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5081783588ns, electionTimeout:5065ms
datanode2_1  | 2022-04-21 16:45:54,515 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-FollowerState] INFO impl.RoleInfo: a9037631-20c7-49ff-8966-d11abf0c09e2: shutdown a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-FollowerState
datanode2_1  | 2022-04-21 16:45:54,515 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-FollowerState] INFO server.RaftServer$Division: a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C: changes role from  FOLLOWER to CANDIDATE at term 3 for changeToCandidate
datanode2_1  | 2022-04-21 16:45:54,515 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode2_1  | 2022-04-21 16:45:54,515 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-FollowerState] INFO impl.RoleInfo: a9037631-20c7-49ff-8966-d11abf0c09e2: start a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-LeaderElection6
datanode2_1  | 2022-04-21 16:45:54,518 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-LeaderElection6] INFO impl.LeaderElection: a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-LeaderElection6 ELECTION round 0: submit vote requests at term 4 for -1: [0ef408af-3ea2-4044-bc54-ad0ae15d84f1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 8694db2d-5e51-4888-b1e0-69ff67626e43|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, a9037631-20c7-49ff-8966-d11abf0c09e2|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0], old=null
datanode2_1  | 2022-04-21 16:45:54,550 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-LeaderElection6] INFO impl.LeaderElection: a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-LeaderElection6: ELECTION REJECTED received 1 response(s) and 0 exception(s):
datanode2_1  | 2022-04-21 16:45:54,550 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-LeaderElection6] INFO impl.LeaderElection:   Response 0: a9037631-20c7-49ff-8966-d11abf0c09e2<-0ef408af-3ea2-4044-bc54-ad0ae15d84f1#0:FAIL-t4
datanode2_1  | 2022-04-21 16:45:54,550 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-LeaderElection6] INFO impl.LeaderElection: a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-LeaderElection6 ELECTION round 0: result REJECTED
datanode2_1  | 2022-04-21 16:45:54,556 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-LeaderElection6] INFO server.RaftServer$Division: a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C: changes role from CANDIDATE to FOLLOWER at term 4 for REJECTED
datanode2_1  | 2022-04-21 16:45:54,556 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-LeaderElection6] INFO impl.RoleInfo: a9037631-20c7-49ff-8966-d11abf0c09e2: shutdown a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-LeaderElection6
om1_1        | Sleeping for 5 seconds
om1_1        | Waiting for the service scm3.org:9894
om1_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om1_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om1_1        | 2022-04-21 16:44:30,524 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om1_1        | /************************************************************
om1_1        | STARTUP_MSG: Starting OzoneManager
om1_1        | STARTUP_MSG:   host = om1/172.25.0.111
om1_1        | STARTUP_MSG:   args = [--init]
om1_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
datanode2_1  | 2022-04-21 16:45:54,556 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-LeaderElection6] INFO impl.RoleInfo: a9037631-20c7-49ff-8966-d11abf0c09e2: start a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-FollowerState
datanode2_1  | 2022-04-21 16:45:59,727 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-FollowerState] INFO impl.FollowerState: a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5170833136ns, electionTimeout:5170ms
datanode2_1  | 2022-04-21 16:45:59,728 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-FollowerState] INFO impl.RoleInfo: a9037631-20c7-49ff-8966-d11abf0c09e2: shutdown a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-FollowerState
datanode2_1  | 2022-04-21 16:45:59,728 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-FollowerState] INFO server.RaftServer$Division: a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C: changes role from  FOLLOWER to CANDIDATE at term 4 for changeToCandidate
datanode2_1  | 2022-04-21 16:45:59,730 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode2_1  | 2022-04-21 16:45:59,730 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-FollowerState] INFO impl.RoleInfo: a9037631-20c7-49ff-8966-d11abf0c09e2: start a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-LeaderElection7
datanode2_1  | 2022-04-21 16:45:59,738 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-LeaderElection7] INFO impl.LeaderElection: a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-LeaderElection7 ELECTION round 0: submit vote requests at term 5 for -1: [0ef408af-3ea2-4044-bc54-ad0ae15d84f1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 8694db2d-5e51-4888-b1e0-69ff67626e43|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, a9037631-20c7-49ff-8966-d11abf0c09e2|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0], old=null
datanode2_1  | 2022-04-21 16:45:59,797 [grpc-default-executor-0] INFO server.RaftServer$Division: a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C: receive requestVote(ELECTION, 0ef408af-3ea2-4044-bc54-ad0ae15d84f1, group-F38EF2C5977C, 5, (t:0, i:0))
datanode2_1  | 2022-04-21 16:45:59,797 [grpc-default-executor-0] INFO impl.VoteContext: a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-CANDIDATE: reject ELECTION from 0ef408af-3ea2-4044-bc54-ad0ae15d84f1: already has voted for a9037631-20c7-49ff-8966-d11abf0c09e2 at current term 5
datanode2_1  | 2022-04-21 16:45:59,797 [grpc-default-executor-0] INFO server.RaftServer$Division: a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C replies to ELECTION vote request: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1<-a9037631-20c7-49ff-8966-d11abf0c09e2#0:FAIL-t5. Peer's state: a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C:t5, leader=null, voted=a9037631-20c7-49ff-8966-d11abf0c09e2, raftlog=a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-SegmentedRaftLog:OPENED:c-1, conf=-1: [0ef408af-3ea2-4044-bc54-ad0ae15d84f1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 8694db2d-5e51-4888-b1e0-69ff67626e43|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, a9037631-20c7-49ff-8966-d11abf0c09e2|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0], old=null
datanode2_1  | 2022-04-21 16:45:59,823 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-LeaderElection7] INFO impl.LeaderElection: a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-LeaderElection7: ELECTION REJECTED received 2 response(s) and 0 exception(s):
datanode2_1  | 2022-04-21 16:45:59,830 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-LeaderElection7] INFO impl.LeaderElection:   Response 0: a9037631-20c7-49ff-8966-d11abf0c09e2<-0ef408af-3ea2-4044-bc54-ad0ae15d84f1#0:FAIL-t5
datanode2_1  | 2022-04-21 16:45:59,830 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-LeaderElection7] INFO impl.LeaderElection:   Response 1: a9037631-20c7-49ff-8966-d11abf0c09e2<-8694db2d-5e51-4888-b1e0-69ff67626e43#0:FAIL-t5
datanode2_1  | 2022-04-21 16:45:59,830 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-LeaderElection7] INFO impl.LeaderElection: a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-LeaderElection7 ELECTION round 0: result REJECTED
datanode2_1  | 2022-04-21 16:45:59,830 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-LeaderElection7] INFO server.RaftServer$Division: a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C: changes role from CANDIDATE to FOLLOWER at term 5 for REJECTED
datanode2_1  | 2022-04-21 16:45:59,831 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-LeaderElection7] INFO impl.RoleInfo: a9037631-20c7-49ff-8966-d11abf0c09e2: shutdown a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-LeaderElection7
datanode2_1  | 2022-04-21 16:45:59,831 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-LeaderElection7] INFO impl.RoleInfo: a9037631-20c7-49ff-8966-d11abf0c09e2: start a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-FollowerState
datanode2_1  | 2022-04-21 16:46:00,263 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-F38EF2C5977C with new leaderId: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1
om1_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.0.4.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om1_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/be5888b907ab03eaf5ec49e88bd592b9f9bd78c4 ; compiled by 'runner' on 2022-04-21T16:20Z
om1_1        | STARTUP_MSG:   java = 11.0.14.1
om1_1        | ************************************************************/
om1_1        | 2022-04-21 16:44:30,661 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om1_1        | 2022-04-21 16:44:38,192 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
om1_1        | 2022-04-21 16:44:40,685 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om1_1        | 2022-04-21 16:44:41,277 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om1, RPC Address: om1:9862 and Ratis port: 9872
om1_1        | 2022-04-21 16:44:41,280 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om1: om1
om1_1        | 2022-04-21 16:44:41,283 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om1: om1
om1_1        | 2022-04-21 16:44:42,422 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om1_1        | 2022-04-21 16:44:42,441 [main] INFO om.OzoneManager: Ozone Manager login successful.
om1_1        | 2022-04-21 16:44:42,537 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2022-04-21 16:44:46,800 [main] INFO om.OzoneManager: Initializing secure OzoneManager.
om1_1        | 2022-04-21 16:44:50,077 [main] ERROR client.OMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
om1_1        | 2022-04-21 16:44:50,077 [main] INFO client.OMCertificateClient: Certificate client init case: 0
om1_1        | 2022-04-21 16:44:50,105 [main] INFO client.OMCertificateClient: Creating keypair for client as keypair and certificate not found.
om1_1        | 2022-04-21 16:44:54,783 [main] INFO om.OzoneManager: Init response: GETCERT
om1_1        | 2022-04-21 16:44:54,950 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.111,host:om1
om1_1        | 2022-04-21 16:44:54,961 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
om1_1        | 2022-04-21 16:44:54,969 [main] ERROR client.OMCertificateClient: Invalid domain om1
om1_1        | 2022-04-21 16:44:54,981 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om1_1        | 2022-04-21 16:44:54,989 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om1, RPC Address: om1:9862 and Ratis port: 9872
om1_1        | 2022-04-21 16:44:54,989 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om1: om1
om1_1        | 2022-04-21 16:44:54,990 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om1: om1
om1_1        | 2022-04-21 16:44:54,994 [main] INFO om.OzoneManager: Creating csr for OM->dns:om1,ip:172.25.0.111,scmId:e8ea6b57-c3ba-42bd-9807-0913ca4228d7,clusterId:CID-37768e1b-cb4c-49da-b09f-824fabcc98dc,subject:om1
om1_1        | 2022-04-21 16:44:55,930 [main] INFO om.OzoneManager: OzoneManager ports added:[name: "RPC"
om1_1        | value: 9862
om1_1        | ]
om1_1        | 2022-04-21 16:44:58,112 [main] INFO om.OzoneManager: Successfully stored SCM signed certificate.
om1_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-37768e1b-cb4c-49da-b09f-824fabcc98dc;layoutVersion=1
om1_1        | 2022-04-21 16:44:58,204 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om1_1        | /************************************************************
om1_1        | SHUTDOWN_MSG: Shutting down OzoneManager at om1/172.25.0.111
om1_1        | ************************************************************/
om1_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om1_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om1_1        | 2022-04-21 16:45:08,042 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om1_1        | /************************************************************
om1_1        | STARTUP_MSG: Starting OzoneManager
om1_1        | STARTUP_MSG:   host = om1/172.25.0.111
om1_1        | STARTUP_MSG:   args = []
om1_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
datanode3_1  | 2022-04-21 16:45:39,004 [grpc-default-executor-1] INFO server.RaftServer$Division: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C replies to ELECTION vote request: a9037631-20c7-49ff-8966-d11abf0c09e2<-0ef408af-3ea2-4044-bc54-ad0ae15d84f1#0:FAIL-t1. Peer's state: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C:t1, leader=null, voted=null, raftlog=0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-SegmentedRaftLog:OPENED:c-1, conf=-1: [0ef408af-3ea2-4044-bc54-ad0ae15d84f1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 8694db2d-5e51-4888-b1e0-69ff67626e43|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a9037631-20c7-49ff-8966-d11abf0c09e2|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-04-21 16:45:44,034 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-FollowerState] INFO impl.FollowerState: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5050805029ns, electionTimeout:5031ms
datanode3_1  | 2022-04-21 16:45:44,034 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-FollowerState] INFO impl.RoleInfo: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1: shutdown 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-FollowerState
datanode3_1  | 2022-04-21 16:45:44,035 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-FollowerState] INFO server.RaftServer$Division: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
datanode3_1  | 2022-04-21 16:45:44,037 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode3_1  | 2022-04-21 16:45:44,038 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-FollowerState] INFO impl.RoleInfo: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1: start 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-LeaderElection1
datanode3_1  | 2022-04-21 16:45:44,062 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-LeaderElection1] INFO impl.LeaderElection: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-LeaderElection1 ELECTION round 0: submit vote requests at term 2 for -1: [0ef408af-3ea2-4044-bc54-ad0ae15d84f1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 8694db2d-5e51-4888-b1e0-69ff67626e43|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a9037631-20c7-49ff-8966-d11abf0c09e2|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-04-21 16:45:44,253 [grpc-default-executor-1] INFO server.RaftServer$Division: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C: receive requestVote(ELECTION, a9037631-20c7-49ff-8966-d11abf0c09e2, group-F38EF2C5977C, 2, (t:0, i:0))
datanode3_1  | 2022-04-21 16:45:44,254 [grpc-default-executor-1] INFO impl.VoteContext: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-CANDIDATE: reject ELECTION from a9037631-20c7-49ff-8966-d11abf0c09e2: already has voted for 0ef408af-3ea2-4044-bc54-ad0ae15d84f1 at current term 2
datanode3_1  | 2022-04-21 16:45:44,262 [grpc-default-executor-1] INFO server.RaftServer$Division: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C replies to ELECTION vote request: a9037631-20c7-49ff-8966-d11abf0c09e2<-0ef408af-3ea2-4044-bc54-ad0ae15d84f1#0:FAIL-t2. Peer's state: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C:t2, leader=null, voted=0ef408af-3ea2-4044-bc54-ad0ae15d84f1, raftlog=0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-SegmentedRaftLog:OPENED:c-1, conf=-1: [0ef408af-3ea2-4044-bc54-ad0ae15d84f1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 8694db2d-5e51-4888-b1e0-69ff67626e43|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a9037631-20c7-49ff-8966-d11abf0c09e2|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-04-21 16:45:45,461 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-LeaderElection1] INFO impl.LeaderElection: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-LeaderElection1: ELECTION REJECTED received 2 response(s) and 0 exception(s):
datanode3_1  | 2022-04-21 16:45:45,476 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-LeaderElection1] INFO impl.LeaderElection:   Response 0: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1<-8694db2d-5e51-4888-b1e0-69ff67626e43#0:FAIL-t2
datanode3_1  | 2022-04-21 16:45:45,476 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-LeaderElection1] INFO impl.LeaderElection:   Response 1: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1<-a9037631-20c7-49ff-8966-d11abf0c09e2#0:FAIL-t2
datanode3_1  | 2022-04-21 16:45:45,476 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-LeaderElection1] INFO impl.LeaderElection: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-LeaderElection1 ELECTION round 0: result REJECTED
datanode3_1  | 2022-04-21 16:45:45,477 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-LeaderElection1] INFO server.RaftServer$Division: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C: changes role from CANDIDATE to FOLLOWER at term 2 for REJECTED
datanode3_1  | 2022-04-21 16:45:45,478 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-LeaderElection1] INFO impl.RoleInfo: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1: shutdown 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-LeaderElection1
datanode3_1  | 2022-04-21 16:45:45,478 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-LeaderElection1] INFO impl.RoleInfo: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1: start 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-FollowerState
datanode3_1  | 2022-04-21 16:45:49,411 [grpc-default-executor-1] INFO server.RaftServer$Division: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C: receive requestVote(ELECTION, a9037631-20c7-49ff-8966-d11abf0c09e2, group-F38EF2C5977C, 3, (t:0, i:0))
datanode3_1  | 2022-04-21 16:45:49,412 [grpc-default-executor-1] INFO impl.VoteContext: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-FOLLOWER: reject ELECTION from a9037631-20c7-49ff-8966-d11abf0c09e2: our priority 1 > candidate's priority 0
datanode3_1  | 2022-04-21 16:45:49,412 [grpc-default-executor-1] INFO server.RaftServer$Division: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C: changes role from  FOLLOWER to FOLLOWER at term 3 for candidate:a9037631-20c7-49ff-8966-d11abf0c09e2
datanode3_1  | 2022-04-21 16:45:49,412 [grpc-default-executor-1] INFO impl.RoleInfo: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1: shutdown 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-FollowerState
datanode3_1  | 2022-04-21 16:45:49,412 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-FollowerState] INFO impl.FollowerState: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-FollowerState was interrupted: {}
datanode3_1  | java.lang.InterruptedException: sleep interrupted
datanode3_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode3_1  | 	at java.base/java.lang.Thread.sleep(Thread.java:334)
datanode3_1  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode3_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
datanode3_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode3_1  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
datanode3_1  | 2022-04-21 16:45:49,413 [grpc-default-executor-1] INFO impl.RoleInfo: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1: start 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-FollowerState
om2_1        | Sleeping for 5 seconds
om2_1        | Waiting for the service scm3.org:9894
om2_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om2_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om2_1        | 2022-04-21 16:44:30,120 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om2_1        | /************************************************************
om2_1        | STARTUP_MSG: Starting OzoneManager
om2_1        | STARTUP_MSG:   host = om2/172.25.0.112
om2_1        | STARTUP_MSG:   args = [--init]
om2_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
datanode2_1  | 2022-04-21 16:46:00,265 [grpc-default-executor-0] INFO server.RaftServer$Division: a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C: change Leader from null to 0ef408af-3ea2-4044-bc54-ad0ae15d84f1 at term 5 for appendEntries, leader elected after 26505ms
datanode2_1  | 2022-04-21 16:46:00,313 [grpc-default-executor-0] INFO server.RaftServer$Division: a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C: set configuration 0: [0ef408af-3ea2-4044-bc54-ad0ae15d84f1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 8694db2d-5e51-4888-b1e0-69ff67626e43|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a9037631-20c7-49ff-8966-d11abf0c09e2|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode2_1  | 2022-04-21 16:46:00,314 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-SegmentedRaftLogWorker: Starting segment from index:0
datanode2_1  | 2022-04-21 16:46:00,320 [a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: a9037631-20c7-49ff-8966-d11abf0c09e2@group-F38EF2C5977C-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/f5f2ffbc-fc63-4015-9163-f38ef2c5977c/current/log_inprogress_0
datanode2_1  | 2022-04-21 16:46:16,689 [ChunkWriter-1-0] INFO client.DNCertificateClient: Getting certificate with certSerialId:960208477648.
datanode2_1  | 2022-04-21 16:46:34,167 [java.util.concurrent.ThreadPoolExecutor$Worker@3fc301c[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4,entriesCount=1,lastEntry=(t:1, i:0)
datanode2_1  | 2022-04-21 16:48:25,114 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=261,entriesCount=1,lastEntry=(t:1, i:1)
datanode2_1  | 2022-04-21 16:48:25,136 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=262,entriesCount=1,lastEntry=(t:1, i:2)
datanode2_1  | 2022-04-21 16:48:25,294 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=263,entriesCount=1,lastEntry=(t:1, i:3)
datanode2_1  | 2022-04-21 16:49:37,204 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=542,entriesCount=1,lastEntry=(t:1, i:4)
datanode2_1  | 2022-04-21 16:49:37,213 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=543,entriesCount=1,lastEntry=(t:1, i:5)
datanode2_1  | 2022-04-21 16:49:37,230 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=545,entriesCount=1,lastEntry=(t:1, i:6)
datanode2_1  | 2022-04-21 16:49:37,254 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=547,entriesCount=1,lastEntry=(t:1, i:7)
datanode2_1  | 2022-04-21 16:52:39,653 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=869,entriesCount=1,lastEntry=(t:1, i:8)
datanode2_1  | 2022-04-21 16:52:39,674 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=870,entriesCount=1,lastEntry=(t:1, i:9)
datanode2_1  | 2022-04-21 16:52:39,687 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=871,entriesCount=1,lastEntry=(t:1, i:10)
datanode2_1  | 2022-04-21 16:52:39,710 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=872,entriesCount=1,lastEntry=(t:1, i:11)
datanode2_1  | 2022-04-21 16:52:50,045 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1124,entriesCount=1,lastEntry=(t:1, i:12)
datanode2_1  | 2022-04-21 16:52:50,046 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1125,entriesCount=1,lastEntry=(t:1, i:13)
datanode2_1  | 2022-04-21 16:52:50,049 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1126,entriesCount=1,lastEntry=(t:1, i:14)
datanode2_1  | 2022-04-21 16:52:50,059 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1127,entriesCount=1,lastEntry=(t:1, i:15)
datanode2_1  | 2022-04-21 16:52:52,674 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1379,entriesCount=1,lastEntry=(t:1, i:16)
datanode2_1  | 2022-04-21 16:52:52,694 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1380,entriesCount=1,lastEntry=(t:1, i:17)
kdc_1        | Apr 21 16:59:55 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650560390, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 16:59:58 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Apr 21 16:59:58 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Apr 21 17:00:15 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1650560415, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 21 17:00:20 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650560415, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 17:00:32 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1650560432, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 21 17:00:35 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650560432, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 17:00:56 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1650560456, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 21 17:00:58 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Apr 21 17:00:58 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Apr 21 17:01:02 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1650560456, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Apr 21 17:01:05 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1650560465, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Apr 21 17:01:05 kdc krb5kdc[7](info): TGS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1650560465, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for HTTP/s3g@EXAMPLE.COM
om2_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.0.4.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om2_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/be5888b907ab03eaf5ec49e88bd592b9f9bd78c4 ; compiled by 'runner' on 2022-04-21T16:20Z
om2_1        | STARTUP_MSG:   java = 11.0.14.1
om2_1        | ************************************************************/
om2_1        | 2022-04-21 16:44:30,261 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om2_1        | 2022-04-21 16:44:37,902 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
om2_1        | 2022-04-21 16:44:40,654 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om2_1        | 2022-04-21 16:44:41,245 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om2, RPC Address: om2:9862 and Ratis port: 9872
om2_1        | 2022-04-21 16:44:41,245 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om2: om2
om2_1        | 2022-04-21 16:44:41,245 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om2: om2
om2_1        | 2022-04-21 16:44:42,706 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om2_1        | 2022-04-21 16:44:42,706 [main] INFO om.OzoneManager: Ozone Manager login successful.
om2_1        | 2022-04-21 16:44:42,783 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2022-04-21 16:44:46,123 [main] INFO om.OzoneManager: Initializing secure OzoneManager.
om2_1        | 2022-04-21 16:44:48,901 [main] ERROR client.OMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
om2_1        | 2022-04-21 16:44:48,901 [main] INFO client.OMCertificateClient: Certificate client init case: 0
om2_1        | 2022-04-21 16:44:48,917 [main] INFO client.OMCertificateClient: Creating keypair for client as keypair and certificate not found.
om2_1        | 2022-04-21 16:44:56,483 [main] INFO om.OzoneManager: Init response: GETCERT
om2_1        | 2022-04-21 16:44:56,774 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.112,host:om2
om2_1        | 2022-04-21 16:44:56,788 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
om2_1        | 2022-04-21 16:44:56,830 [main] ERROR client.OMCertificateClient: Invalid domain om2
om2_1        | 2022-04-21 16:44:56,831 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om2_1        | 2022-04-21 16:44:56,835 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om2, RPC Address: om2:9862 and Ratis port: 9872
om2_1        | 2022-04-21 16:44:56,836 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om2: om2
om2_1        | 2022-04-21 16:44:56,839 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om2: om2
om2_1        | 2022-04-21 16:44:56,842 [main] INFO om.OzoneManager: Creating csr for OM->dns:om2,ip:172.25.0.112,scmId:e8ea6b57-c3ba-42bd-9807-0913ca4228d7,clusterId:CID-37768e1b-cb4c-49da-b09f-824fabcc98dc,subject:om2
om2_1        | 2022-04-21 16:44:57,826 [main] INFO om.OzoneManager: OzoneManager ports added:[name: "RPC"
om2_1        | value: 9862
om2_1        | ]
om2_1        | 2022-04-21 16:44:59,510 [main] INFO om.OzoneManager: Successfully stored SCM signed certificate.
om2_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-37768e1b-cb4c-49da-b09f-824fabcc98dc;layoutVersion=1
om2_1        | 2022-04-21 16:44:59,698 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om2_1        | /************************************************************
om2_1        | SHUTDOWN_MSG: Shutting down OzoneManager at om2/172.25.0.112
om2_1        | ************************************************************/
om2_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om2_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om2_1        | 2022-04-21 16:45:09,462 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om2_1        | /************************************************************
om2_1        | STARTUP_MSG: Starting OzoneManager
om2_1        | STARTUP_MSG:   host = om2/172.25.0.112
om2_1        | STARTUP_MSG:   args = []
om2_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om2_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.0.4.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om2_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/be5888b907ab03eaf5ec49e88bd592b9f9bd78c4 ; compiled by 'runner' on 2022-04-21T16:20Z
om2_1        | STARTUP_MSG:   java = 11.0.14.1
om2_1        | ************************************************************/
om2_1        | 2022-04-21 16:45:09,588 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om2_1        | 2022-04-21 16:45:16,424 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
om2_1        | 2022-04-21 16:45:19,640 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om2_1        | 2022-04-21 16:45:20,143 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om2, RPC Address: om2:9862 and Ratis port: 9872
om2_1        | 2022-04-21 16:45:20,144 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om2: om2
om2_1        | 2022-04-21 16:45:20,144 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om2: om2
om2_1        | 2022-04-21 16:45:20,257 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2022-04-21 16:45:20,534 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = ERASURE_CODED_STORAGE_SUPPORT (version = 1), software layout = ERASURE_CODED_STORAGE_SUPPORT (version = 1)
datanode3_1  | 2022-04-21 16:45:49,417 [grpc-default-executor-1] INFO server.RaftServer$Division: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C replies to ELECTION vote request: a9037631-20c7-49ff-8966-d11abf0c09e2<-0ef408af-3ea2-4044-bc54-ad0ae15d84f1#0:FAIL-t3. Peer's state: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C:t3, leader=null, voted=null, raftlog=0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-SegmentedRaftLog:OPENED:c-1, conf=-1: [0ef408af-3ea2-4044-bc54-ad0ae15d84f1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 8694db2d-5e51-4888-b1e0-69ff67626e43|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a9037631-20c7-49ff-8966-d11abf0c09e2|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode2_1  | 2022-04-21 16:52:52,697 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1381,entriesCount=1,lastEntry=(t:1, i:18)
datanode2_1  | 2022-04-21 16:52:52,711 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1383,entriesCount=1,lastEntry=(t:1, i:19)
datanode2_1  | 2022-04-21 16:52:55,517 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1631,entriesCount=1,lastEntry=(t:1, i:20)
datanode2_1  | 2022-04-21 16:52:55,559 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1632,entriesCount=1,lastEntry=(t:1, i:21)
datanode2_1  | 2022-04-21 16:52:55,559 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1633,entriesCount=1,lastEntry=(t:1, i:22)
datanode2_1  | 2022-04-21 16:52:55,566 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1634,entriesCount=1,lastEntry=(t:1, i:23)
datanode2_1  | 2022-04-21 16:52:59,089 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1887,entriesCount=1,lastEntry=(t:1, i:24)
datanode3_1  | 2022-04-21 16:45:51,829 [Command processor thread] INFO server.RaftServer: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1: addNew group-24D42BA70F8F:[0ef408af-3ea2-4044-bc54-ad0ae15d84f1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1] returns group-24D42BA70F8F:java.util.concurrent.CompletableFuture@34b9baf4[Not completed]
om1_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.0.4.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om1_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/be5888b907ab03eaf5ec49e88bd592b9f9bd78c4 ; compiled by 'runner' on 2022-04-21T16:20Z
datanode3_1  | 2022-04-21 16:45:51,832 [pool-23-thread-1] INFO server.RaftServer$Division: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1: new RaftServerImpl for group-24D42BA70F8F:[0ef408af-3ea2-4044-bc54-ad0ae15d84f1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1] with ContainerStateMachine:uninitialized
datanode2_1  | 2022-04-21 16:52:59,238 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1888,entriesCount=1,lastEntry=(t:1, i:25)
datanode2_1  | 2022-04-21 16:52:59,248 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1889,entriesCount=1,lastEntry=(t:1, i:26)
datanode2_1  | 2022-04-21 16:52:59,447 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1890,entriesCount=1,lastEntry=(t:1, i:27)
datanode2_1  | 2022-04-21 16:52:59,540 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1899,entriesCount=1,lastEntry=(t:1, i:28)
datanode2_1  | 2022-04-21 16:52:59,554 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1900,entriesCount=1,lastEntry=(t:1, i:29)
datanode2_1  | 2022-04-21 16:53:02,627 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2152,entriesCount=1,lastEntry=(t:1, i:30)
datanode2_1  | 2022-04-21 16:53:02,642 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2153,entriesCount=1,lastEntry=(t:1, i:31)
datanode2_1  | 2022-04-21 16:53:02,770 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2154,entriesCount=1,lastEntry=(t:1, i:32)
datanode2_1  | 2022-04-21 16:53:02,793 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2156,entriesCount=1,lastEntry=(t:1, i:33)
datanode2_1  | 2022-04-21 16:53:02,977 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2166,entriesCount=1,lastEntry=(t:1, i:34)
datanode2_1  | 2022-04-21 16:53:03,030 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2170,entriesCount=1,lastEntry=(t:1, i:35)
datanode3_1  | 2022-04-21 16:45:51,836 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode3_1  | 2022-04-21 16:45:51,836 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode3_1  | 2022-04-21 16:45:51,836 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode3_1  | 2022-04-21 16:45:51,837 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode3_1  | 2022-04-21 16:45:51,837 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode3_1  | 2022-04-21 16:45:51,837 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode3_1  | 2022-04-21 16:45:51,837 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2022-04-21 16:45:51,837 [pool-23-thread-1] INFO server.RaftServer$Division: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-24D42BA70F8F: ConfigurationManager, init=-1: [0ef408af-3ea2-4044-bc54-ad0ae15d84f1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode3_1  | 2022-04-21 16:45:51,837 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2022-04-21 16:53:03,049 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2173,entriesCount=1,lastEntry=(t:1, i:36)
datanode2_1  | 2022-04-21 16:53:03,245 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2192,entriesCount=1,lastEntry=(t:1, i:37)
datanode2_1  | 2022-04-21 16:53:03,339 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2200,entriesCount=1,lastEntry=(t:1, i:38)
datanode2_1  | 2022-04-21 16:53:03,346 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2201,entriesCount=1,lastEntry=(t:1, i:39)
datanode2_1  | 2022-04-21 16:53:07,231 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2454,entriesCount=1,lastEntry=(t:1, i:40)
datanode3_1  | 2022-04-21 16:45:51,838 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode3_1  | 2022-04-21 16:45:51,838 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode3_1  | 2022-04-21 16:45:51,838 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/d5d7df1a-3895-4b52-8476-24d42ba70f8f does not exist. Creating ...
datanode2_1  | 2022-04-21 16:53:07,656 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2455,entriesCount=1,lastEntry=(t:1, i:41)
datanode3_1  | 2022-04-21 16:45:51,840 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/d5d7df1a-3895-4b52-8476-24d42ba70f8f/in_use.lock acquired by nodename 7@4703807bf00c
datanode3_1  | 2022-04-21 16:45:51,855 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/d5d7df1a-3895-4b52-8476-24d42ba70f8f has been successfully formatted.
datanode3_1  | 2022-04-21 16:45:51,857 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-24D42BA70F8F: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode3_1  | 2022-04-21 16:45:51,917 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode3_1  | 2022-04-21 16:45:51,919 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode2_1  | 2022-04-21 16:53:07,847 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2465,entriesCount=1,lastEntry=(t:1, i:42)
datanode2_1  | 2022-04-21 16:53:07,995 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2479,entriesCount=1,lastEntry=(t:1, i:43)
datanode2_1  | 2022-04-21 16:53:08,103 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2489,entriesCount=1,lastEntry=(t:1, i:44)
datanode2_1  | 2022-04-21 16:53:08,114 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2491,entriesCount=1,lastEntry=(t:1, i:45)
datanode2_1  | 2022-04-21 16:53:08,161 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2496,entriesCount=1,lastEntry=(t:1, i:46)
datanode3_1  | 2022-04-21 16:45:51,920 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode3_1  | 2022-04-21 16:45:51,922 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2022-04-21 16:53:08,175 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2498,entriesCount=1,lastEntry=(t:1, i:47)
datanode2_1  | 2022-04-21 16:53:11,013 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2745,entriesCount=1,lastEntry=(t:1, i:48)
datanode2_1  | 2022-04-21 16:53:11,384 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2746,entriesCount=1,lastEntry=(t:1, i:49)
datanode2_1  | 2022-04-21 16:53:11,487 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2753,entriesCount=1,lastEntry=(t:1, i:50)
datanode2_1  | 2022-04-21 16:53:11,661 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2760,entriesCount=1,lastEntry=(t:1, i:51)
datanode2_1  | 2022-04-21 16:53:11,682 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2762,entriesCount=1,lastEntry=(t:1, i:52)
datanode3_1  | 2022-04-21 16:45:51,925 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2022-04-21 16:53:11,714 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2766,entriesCount=1,lastEntry=(t:1, i:53)
datanode2_1  | 2022-04-21 16:53:11,714 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2767,entriesCount=1,lastEntry=(t:1, i:54)
om2_1        | 2022-04-21 16:45:22,329 [main] INFO reflections.Reflections: Reflections took 1410 ms to scan 1 urls, producing 101 keys and 277 values [using 2 cores]
om3_1        | Sleeping for 5 seconds
om3_1        | Waiting for the service scm3.org:9894
om3_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om3_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om3_1        | 2022-04-21 16:44:29,610 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om3_1        | /************************************************************
om3_1        | STARTUP_MSG: Starting OzoneManager
om3_1        | STARTUP_MSG:   host = om3/172.25.0.113
om1_1        | STARTUP_MSG:   java = 11.0.14.1
om1_1        | ************************************************************/
om1_1        | 2022-04-21 16:45:08,131 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om1_1        | 2022-04-21 16:45:14,646 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
om1_1        | 2022-04-21 16:45:16,063 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om1_1        | 2022-04-21 16:45:17,216 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om1, RPC Address: om1:9862 and Ratis port: 9872
om1_1        | 2022-04-21 16:45:17,271 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om1: om1
om1_1        | 2022-04-21 16:45:17,274 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om1: om1
om1_1        | 2022-04-21 16:45:17,456 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2022-04-21 16:45:17,829 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = ERASURE_CODED_STORAGE_SUPPORT (version = 1), software layout = ERASURE_CODED_STORAGE_SUPPORT (version = 1)
om1_1        | 2022-04-21 16:45:19,532 [main] INFO reflections.Reflections: Reflections took 1188 ms to scan 1 urls, producing 101 keys and 277 values [using 2 cores]
om1_1        | 2022-04-21 16:45:21,539 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om1_1        | 2022-04-21 16:45:21,584 [main] INFO om.OzoneManager: Ozone Manager login successful.
om1_1        | 2022-04-21 16:45:21,588 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2022-04-21 16:45:27,776 [main] INFO client.OMCertificateClient: Loading certificate from location:/data/metadata/om/certs.
om1_1        | 2022-04-21 16:45:28,341 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/ROOTCA-1.crt.
om1_1        | 2022-04-21 16:45:28,354 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/960208477648.crt.
om1_1        | 2022-04-21 16:45:28,358 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/CA-862887965327.crt.
om1_1        | 2022-04-21 16:45:28,679 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2022-04-21 16:45:29,499 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om1_1        | 2022-04-21 16:45:29,506 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om1_1        | 2022-04-21 16:45:30,566 [main] INFO security.OzoneSecretStore: Loaded 0 tokens
om1_1        | 2022-04-21 16:45:30,576 [main] INFO security.OzoneDelegationTokenSecretManager: Loading token state into token manager.
om1_1        | 2022-04-21 16:45:31,234 [main] INFO om.OzoneManager: Created Volume s3v With Owner root required for S3Gateway operations.
om1_1        | 2022-04-21 16:45:31,811 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om1_1        | 2022-04-21 16:45:31,865 [main] WARN utils.OzoneManagerRatisUtils: ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
om1_1        | 2022-04-21 16:45:31,981 [main] INFO snapshot.OzoneManagerSnapshotProvider: Initializing OM Snapshot Provider
om1_1        | 2022-04-21 16:45:32,954 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om1_1        | 2022-04-21 16:45:33,041 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om1_1        | 2022-04-21 16:45:33,288 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with groupID: id1 and peers: om1:9872, om3:9872, om2:9872
om1_1        | 2022-04-21 16:45:33,342 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
om1_1        | 2022-04-21 16:45:34,809 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
om2_1        | 2022-04-21 16:45:23,489 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om2_1        | 2022-04-21 16:45:23,495 [main] INFO om.OzoneManager: Ozone Manager login successful.
datanode3_1  | 2022-04-21 16:45:51,926 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode2_1  | 2022-04-21 16:53:11,726 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2769,entriesCount=1,lastEntry=(t:1, i:55)
datanode2_1  | 2022-04-21 16:54:06,165 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3041,entriesCount=1,lastEntry=(t:1, i:56)
datanode2_1  | 2022-04-21 16:54:06,187 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3042,entriesCount=1,lastEntry=(t:1, i:57)
datanode2_1  | 2022-04-21 16:54:06,208 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3043,entriesCount=1,lastEntry=(t:1, i:58)
datanode2_1  | 2022-04-21 16:54:06,265 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3044,entriesCount=1,lastEntry=(t:1, i:59)
datanode2_1  | 2022-04-21 16:54:06,271 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3045,entriesCount=1,lastEntry=(t:1, i:60)
datanode2_1  | 2022-04-21 16:54:06,286 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3047,entriesCount=1,lastEntry=(t:1, i:61)
datanode2_1  | 2022-04-21 16:54:09,715 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3300,entriesCount=1,lastEntry=(t:1, i:62)
datanode2_1  | 2022-04-21 16:54:09,736 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3301,entriesCount=1,lastEntry=(t:1, i:63)
datanode2_1  | 2022-04-21 16:54:09,757 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3302,entriesCount=1,lastEntry=(t:1, i:64)
datanode2_1  | 2022-04-21 16:54:09,903 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3303,entriesCount=1,lastEntry=(t:1, i:65)
datanode3_1  | 2022-04-21 16:45:51,927 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode3_1  | 2022-04-21 16:45:51,932 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-24D42BA70F8F-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/d5d7df1a-3895-4b52-8476-24d42ba70f8f
datanode3_1  | 2022-04-21 16:45:51,935 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode3_1  | 2022-04-21 16:45:51,935 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode3_1  | 2022-04-21 16:45:51,935 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2022-04-21 16:45:51,936 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode3_1  | 2022-04-21 16:45:51,936 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om2_1        | 2022-04-21 16:45:23,496 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2022-04-21 16:45:29,644 [main] INFO client.OMCertificateClient: Loading certificate from location:/data/metadata/om/certs.
om2_1        | 2022-04-21 16:45:30,714 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/ROOTCA-1.crt.
om2_1        | 2022-04-21 16:45:30,734 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/961640954884.crt.
om2_1        | 2022-04-21 16:45:30,762 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/CA-862887965327.crt.
om2_1        | 2022-04-21 16:45:31,030 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | STARTUP_MSG:   args = [--init]
om3_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om3_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.0.4.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om3_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/be5888b907ab03eaf5ec49e88bd592b9f9bd78c4 ; compiled by 'runner' on 2022-04-21T16:20Z
om3_1        | STARTUP_MSG:   java = 11.0.14.1
datanode3_1  | 2022-04-21 16:45:51,936 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode3_1  | 2022-04-21 16:45:51,936 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode3_1  | 2022-04-21 16:45:51,953 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode3_1  | 2022-04-21 16:45:51,982 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode3_1  | 2022-04-21 16:45:52,007 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode3_1  | 2022-04-21 16:45:52,008 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-24D42BA70F8F-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode3_1  | 2022-04-21 16:45:52,012 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-24D42BA70F8F-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om2_1        | 2022-04-21 16:45:31,975 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om2_1        | 2022-04-21 16:45:32,001 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om2_1        | 2022-04-21 16:45:33,029 [main] INFO security.OzoneSecretStore: Loaded 0 tokens
om2_1        | 2022-04-21 16:45:33,030 [main] INFO security.OzoneDelegationTokenSecretManager: Loading token state into token manager.
om2_1        | 2022-04-21 16:45:33,840 [main] INFO om.OzoneManager: Created Volume s3v With Owner root required for S3Gateway operations.
datanode2_1  | 2022-04-21 16:54:09,904 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3304,entriesCount=1,lastEntry=(t:1, i:66)
datanode2_1  | 2022-04-21 16:54:09,904 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3305,entriesCount=1,lastEntry=(t:1, i:67)
om3_1        | ************************************************************/
om3_1        | 2022-04-21 16:44:29,766 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om3_1        | 2022-04-21 16:44:37,179 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
om3_1        | 2022-04-21 16:44:40,111 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om3_1        | 2022-04-21 16:44:40,936 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om3, RPC Address: om3:9862 and Ratis port: 9872
om3_1        | 2022-04-21 16:44:40,936 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om3: om3
om3_1        | 2022-04-21 16:44:40,936 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om3: om3
om1_1        | 2022-04-21 16:45:35,481 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
om3_1        | 2022-04-21 16:44:42,098 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om3_1        | 2022-04-21 16:44:42,107 [main] INFO om.OzoneManager: Ozone Manager login successful.
om3_1        | 2022-04-21 16:44:42,170 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2022-04-21 16:44:45,693 [main] INFO om.OzoneManager: Initializing secure OzoneManager.
om3_1        | 2022-04-21 16:44:48,868 [main] ERROR client.OMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
om3_1        | 2022-04-21 16:44:48,868 [main] INFO client.OMCertificateClient: Certificate client init case: 0
om3_1        | 2022-04-21 16:44:48,870 [main] INFO client.OMCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode2_1  | 2022-04-21 16:54:13,967 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3555,entriesCount=1,lastEntry=(t:1, i:68)
datanode2_1  | 2022-04-21 16:54:14,052 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3556,entriesCount=1,lastEntry=(t:1, i:69)
datanode2_1  | 2022-04-21 16:54:14,097 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3557,entriesCount=1,lastEntry=(t:1, i:70)
datanode2_1  | 2022-04-21 16:54:14,108 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3558,entriesCount=1,lastEntry=(t:1, i:71)
datanode2_1  | 2022-04-21 16:54:14,128 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3560,entriesCount=1,lastEntry=(t:1, i:72)
datanode2_1  | 2022-04-21 16:54:14,142 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3562,entriesCount=1,lastEntry=(t:1, i:73)
datanode3_1  | 2022-04-21 16:45:52,016 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode3_1  | 2022-04-21 16:45:52,024 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode3_1  | 2022-04-21 16:45:52,027 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode3_1  | 2022-04-21 16:45:52,028 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode3_1  | 2022-04-21 16:45:52,028 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode3_1  | 2022-04-21 16:45:52,028 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode3_1  | 2022-04-21 16:45:52,029 [pool-23-thread-1] INFO server.RaftServer$Division: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-24D42BA70F8F: start as a follower, conf=-1: [0ef408af-3ea2-4044-bc54-ad0ae15d84f1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
om2_1        | 2022-04-21 16:45:34,048 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om2_1        | 2022-04-21 16:45:34,049 [main] WARN utils.OzoneManagerRatisUtils: ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
om2_1        | 2022-04-21 16:45:34,113 [main] INFO snapshot.OzoneManagerSnapshotProvider: Initializing OM Snapshot Provider
om2_1        | 2022-04-21 16:45:35,326 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om2_1        | 2022-04-21 16:45:35,367 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om2_1        | 2022-04-21 16:45:35,649 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with groupID: id1 and peers: om2:9872, om1:9872, om3:9872
om2_1        | 2022-04-21 16:45:35,701 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
om2_1        | 2022-04-21 16:45:36,589 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode2_1  | 2022-04-21 16:54:17,377 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3816,entriesCount=1,lastEntry=(t:1, i:74)
datanode2_1  | 2022-04-21 16:54:17,383 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3817,entriesCount=1,lastEntry=(t:1, i:75)
datanode2_1  | 2022-04-21 16:54:17,407 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3818,entriesCount=1,lastEntry=(t:1, i:76)
datanode2_1  | 2022-04-21 16:54:17,407 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3822,entriesCount=1,lastEntry=(t:1, i:77)
datanode2_1  | 2022-04-21 16:54:22,893 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4074,entriesCount=1,lastEntry=(t:1, i:78)
datanode2_1  | 2022-04-21 16:54:22,912 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4075,entriesCount=1,lastEntry=(t:1, i:79)
datanode2_1  | 2022-04-21 16:54:22,917 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4076,entriesCount=1,lastEntry=(t:1, i:80)
datanode2_1  | 2022-04-21 16:54:22,920 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4078,entriesCount=1,lastEntry=(t:1, i:81)
datanode2_1  | 2022-04-21 16:54:26,185 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4323,entriesCount=1,lastEntry=(t:1, i:82)
datanode2_1  | 2022-04-21 16:54:26,197 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4324,entriesCount=1,lastEntry=(t:1, i:83)
datanode2_1  | 2022-04-21 16:54:26,202 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4325,entriesCount=1,lastEntry=(t:1, i:84)
datanode3_1  | 2022-04-21 16:45:52,032 [pool-23-thread-1] INFO server.RaftServer$Division: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-24D42BA70F8F: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode3_1  | 2022-04-21 16:45:52,036 [pool-23-thread-1] INFO impl.RoleInfo: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1: start 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-24D42BA70F8F-FollowerState
datanode3_1  | 2022-04-21 16:45:52,042 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-24D42BA70F8F,id=0ef408af-3ea2-4044-bc54-ad0ae15d84f1
datanode3_1  | 2022-04-21 16:45:52,047 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=d5d7df1a-3895-4b52-8476-24d42ba70f8f
datanode3_1  | 2022-04-21 16:45:52,048 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=d5d7df1a-3895-4b52-8476-24d42ba70f8f.
om2_1        | 2022-04-21 16:45:36,872 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
om2_1        | 2022-04-21 16:45:36,880 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om3_1        | 2022-04-21 16:44:57,917 [main] INFO om.OzoneManager: Init response: GETCERT
om3_1        | 2022-04-21 16:44:58,353 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.113,host:om3
om3_1        | 2022-04-21 16:44:58,362 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
om3_1        | 2022-04-21 16:44:58,384 [main] ERROR client.OMCertificateClient: Invalid domain om3
om3_1        | 2022-04-21 16:44:58,400 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om3_1        | 2022-04-21 16:44:58,408 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om3, RPC Address: om3:9862 and Ratis port: 9872
om3_1        | 2022-04-21 16:44:58,420 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om3: om3
om3_1        | 2022-04-21 16:44:58,420 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om3: om3
om2_1        | 2022-04-21 16:45:36,881 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
om2_1        | 2022-04-21 16:45:36,882 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om2_1        | 2022-04-21 16:45:36,882 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om2_1        | 2022-04-21 16:45:36,884 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om2_1        | 2022-04-21 16:45:36,901 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om2_1        | 2022-04-21 16:45:36,904 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om2_1        | 2022-04-21 16:45:36,906 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om2_1        | 2022-04-21 16:45:39,232 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om2_1        | 2022-04-21 16:45:39,234 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om2_1        | 2022-04-21 16:45:39,234 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om2_1        | 2022-04-21 16:45:39,323 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om2_1        | 2022-04-21 16:45:39,374 [main] INFO server.RaftServer: om2: addNew group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] returns group-562213E44849:java.util.concurrent.CompletableFuture@54a2ff94[Not completed]
om2_1        | 2022-04-21 16:45:39,374 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om2_1        | 2022-04-21 16:45:39,579 [pool-24-thread-1] INFO server.RaftServer$Division: om2: new RaftServerImpl for group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] with OzoneManagerStateMachine:uninitialized
om1_1        | 2022-04-21 16:45:35,484 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om1_1        | 2022-04-21 16:45:35,498 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
om1_1        | 2022-04-21 16:45:35,498 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om1_1        | 2022-04-21 16:45:35,498 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om1_1        | 2022-04-21 16:45:35,499 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om1_1        | 2022-04-21 16:45:35,503 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2022-04-21 16:45:54,526 [grpc-default-executor-1] INFO server.RaftServer$Division: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C: receive requestVote(ELECTION, a9037631-20c7-49ff-8966-d11abf0c09e2, group-F38EF2C5977C, 4, (t:0, i:0))
datanode3_1  | 2022-04-21 16:45:54,528 [grpc-default-executor-1] INFO impl.VoteContext: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-FOLLOWER: reject ELECTION from a9037631-20c7-49ff-8966-d11abf0c09e2: our priority 1 > candidate's priority 0
datanode3_1  | 2022-04-21 16:45:54,528 [grpc-default-executor-1] INFO server.RaftServer$Division: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C: changes role from  FOLLOWER to FOLLOWER at term 4 for candidate:a9037631-20c7-49ff-8966-d11abf0c09e2
datanode3_1  | 2022-04-21 16:45:54,529 [grpc-default-executor-1] INFO impl.RoleInfo: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1: shutdown 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-FollowerState
datanode3_1  | 2022-04-21 16:45:54,529 [grpc-default-executor-1] INFO impl.RoleInfo: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1: start 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-FollowerState
datanode3_1  | 2022-04-21 16:45:54,529 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-FollowerState] INFO impl.FollowerState: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-FollowerState was interrupted: {}
datanode2_1  | 2022-04-21 16:54:26,241 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4330,entriesCount=1,lastEntry=(t:1, i:85)
datanode2_1  | 2022-04-21 16:54:32,282 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4581,entriesCount=1,lastEntry=(t:1, i:86)
datanode2_1  | 2022-04-21 16:54:32,305 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4582,entriesCount=1,lastEntry=(t:1, i:87)
datanode2_1  | 2022-04-21 16:54:32,342 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4583,entriesCount=1,lastEntry=(t:1, i:88)
datanode2_1  | 2022-04-21 16:54:32,495 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4584,entriesCount=1,lastEntry=(t:1, i:89)
datanode2_1  | 2022-04-21 16:54:32,495 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4585,entriesCount=1,lastEntry=(t:1, i:90)
datanode2_1  | 2022-04-21 16:54:32,514 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4586,entriesCount=1,lastEntry=(t:1, i:91)
datanode2_1  | 2022-04-21 16:54:44,573 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4838,entriesCount=1,lastEntry=(t:1, i:92)
datanode2_1  | 2022-04-21 16:54:44,601 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4839,entriesCount=1,lastEntry=(t:1, i:93)
om1_1        | 2022-04-21 16:45:35,508 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om3_1        | 2022-04-21 16:44:58,428 [main] INFO om.OzoneManager: Creating csr for OM->dns:om3,ip:172.25.0.113,scmId:e8ea6b57-c3ba-42bd-9807-0913ca4228d7,clusterId:CID-37768e1b-cb4c-49da-b09f-824fabcc98dc,subject:om3
om3_1        | 2022-04-21 16:44:59,267 [main] INFO om.OzoneManager: OzoneManager ports added:[name: "RPC"
om3_1        | value: 9862
om3_1        | ]
datanode3_1  | java.lang.InterruptedException: sleep interrupted
datanode3_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode3_1  | 	at java.base/java.lang.Thread.sleep(Thread.java:334)
datanode3_1  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode3_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
datanode3_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode3_1  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
om1_1        | 2022-04-21 16:45:35,508 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om1_1        | 2022-04-21 16:45:37,580 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om1_1        | 2022-04-21 16:45:37,585 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om1_1        | 2022-04-21 16:45:37,586 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om1_1        | 2022-04-21 16:45:37,625 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om1_1        | 2022-04-21 16:45:37,656 [main] INFO server.RaftServer: om1: addNew group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] returns group-562213E44849:java.util.concurrent.CompletableFuture@16fa28eb[Not completed]
om3_1        | 2022-04-21 16:45:00,490 [main] INFO om.OzoneManager: Successfully stored SCM signed certificate.
om3_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-37768e1b-cb4c-49da-b09f-824fabcc98dc;layoutVersion=1
om3_1        | 2022-04-21 16:45:00,634 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om3_1        | /************************************************************
om3_1        | SHUTDOWN_MSG: Shutting down OzoneManager at om3/172.25.0.113
om3_1        | ************************************************************/
datanode2_1  | 2022-04-21 16:54:44,604 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4840,entriesCount=1,lastEntry=(t:1, i:94)
datanode2_1  | 2022-04-21 16:54:44,657 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4841,entriesCount=1,lastEntry=(t:1, i:95)
datanode2_1  | 2022-04-21 16:54:44,675 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4843,entriesCount=1,lastEntry=(t:1, i:96)
datanode2_1  | 2022-04-21 16:54:44,683 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4844,entriesCount=1,lastEntry=(t:1, i:97)
datanode2_1  | 2022-04-21 16:54:47,959 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5097,entriesCount=1,lastEntry=(t:1, i:98)
datanode2_1  | 2022-04-21 16:54:47,960 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5098,entriesCount=1,lastEntry=(t:1, i:99)
datanode2_1  | 2022-04-21 16:54:47,975 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5099,entriesCount=1,lastEntry=(t:1, i:100)
om1_1        | 2022-04-21 16:45:37,656 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om1_1        | 2022-04-21 16:45:37,762 [pool-24-thread-1] INFO server.RaftServer$Division: om1: new RaftServerImpl for group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] with OzoneManagerStateMachine:uninitialized
datanode3_1  | 2022-04-21 16:45:54,536 [grpc-default-executor-1] INFO server.RaftServer$Division: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C replies to ELECTION vote request: a9037631-20c7-49ff-8966-d11abf0c09e2<-0ef408af-3ea2-4044-bc54-ad0ae15d84f1#0:FAIL-t4. Peer's state: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C:t4, leader=null, voted=null, raftlog=0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-SegmentedRaftLog:OPENED:c-1, conf=-1: [0ef408af-3ea2-4044-bc54-ad0ae15d84f1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 8694db2d-5e51-4888-b1e0-69ff67626e43|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a9037631-20c7-49ff-8966-d11abf0c09e2|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-04-21 16:45:57,225 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-24D42BA70F8F-FollowerState] INFO impl.FollowerState: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-24D42BA70F8F-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5190779048ns, electionTimeout:5182ms
datanode3_1  | 2022-04-21 16:45:57,226 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-24D42BA70F8F-FollowerState] INFO impl.RoleInfo: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1: shutdown 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-24D42BA70F8F-FollowerState
datanode3_1  | 2022-04-21 16:45:57,227 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-24D42BA70F8F-FollowerState] INFO server.RaftServer$Division: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-24D42BA70F8F: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode3_1  | 2022-04-21 16:45:57,227 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-24D42BA70F8F-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode3_1  | 2022-04-21 16:45:57,227 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-24D42BA70F8F-FollowerState] INFO impl.RoleInfo: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1: start 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-24D42BA70F8F-LeaderElection2
om2_1        | 2022-04-21 16:45:39,628 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om2_1        | 2022-04-21 16:45:39,646 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om2_1        | 2022-04-21 16:45:39,646 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om2_1        | 2022-04-21 16:45:39,647 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om2_1        | 2022-04-21 16:45:39,647 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om2_1        | 2022-04-21 16:45:39,648 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om2_1        | 2022-04-21 16:45:39,648 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om2_1        | 2022-04-21 16:45:39,701 [pool-24-thread-1] INFO server.RaftServer$Division: om2@group-562213E44849: ConfigurationManager, init=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null, confs=<EMPTY_MAP>
om2_1        | 2022-04-21 16:45:39,708 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om2_1        | 2022-04-21 16:45:39,830 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om3_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om3_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om3_1        | 2022-04-21 16:45:10,225 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om3_1        | /************************************************************
om3_1        | STARTUP_MSG: Starting OzoneManager
om3_1        | STARTUP_MSG:   host = om3/172.25.0.113
om1_1        | 2022-04-21 16:45:37,782 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om1_1        | 2022-04-21 16:45:37,787 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om1_1        | 2022-04-21 16:45:37,794 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om1_1        | 2022-04-21 16:45:37,795 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om1_1        | 2022-04-21 16:45:37,802 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om1_1        | 2022-04-21 16:45:37,810 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om1_1        | 2022-04-21 16:45:37,811 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | 2022-04-21 16:54:47,976 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5100,entriesCount=1,lastEntry=(t:1, i:101)
datanode2_1  | 2022-04-21 16:54:54,938 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5351,entriesCount=1,lastEntry=(t:1, i:102)
datanode2_1  | 2022-04-21 16:54:55,034 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5352,entriesCount=1,lastEntry=(t:1, i:103)
datanode2_1  | 2022-04-21 16:54:55,229 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5353,entriesCount=1,lastEntry=(t:1, i:104)
datanode2_1  | 2022-04-21 16:54:55,229 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5354,entriesCount=1,lastEntry=(t:1, i:105)
datanode2_1  | 2022-04-21 16:54:55,467 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5355,entriesCount=1,lastEntry=(t:1, i:106)
om3_1        | STARTUP_MSG:   args = []
om3_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om3_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.0.4.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om3_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/be5888b907ab03eaf5ec49e88bd592b9f9bd78c4 ; compiled by 'runner' on 2022-04-21T16:20Z
om3_1        | STARTUP_MSG:   java = 11.0.14.1
datanode3_1  | 2022-04-21 16:45:57,234 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-24D42BA70F8F-LeaderElection2] INFO impl.LeaderElection: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-24D42BA70F8F-LeaderElection2 ELECTION round 0: submit vote requests at term 1 for -1: [0ef408af-3ea2-4044-bc54-ad0ae15d84f1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode3_1  | 2022-04-21 16:45:57,234 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-24D42BA70F8F-LeaderElection2] INFO impl.LeaderElection: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-24D42BA70F8F-LeaderElection2 ELECTION round 0: result PASSED (term=1)
datanode3_1  | 2022-04-21 16:45:57,234 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-24D42BA70F8F-LeaderElection2] INFO impl.RoleInfo: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1: shutdown 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-24D42BA70F8F-LeaderElection2
datanode3_1  | 2022-04-21 16:45:57,234 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-24D42BA70F8F-LeaderElection2] INFO server.RaftServer$Division: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-24D42BA70F8F: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode3_1  | 2022-04-21 16:45:57,234 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-24D42BA70F8F-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-24D42BA70F8F with new leaderId: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1
datanode3_1  | 2022-04-21 16:45:57,234 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-24D42BA70F8F-LeaderElection2] INFO server.RaftServer$Division: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-24D42BA70F8F: change Leader from null to 0ef408af-3ea2-4044-bc54-ad0ae15d84f1 at term 1 for becomeLeader, leader elected after 5317ms
om1_1        | 2022-04-21 16:45:37,843 [pool-24-thread-1] INFO server.RaftServer$Division: om1@group-562213E44849: ConfigurationManager, init=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null, confs=<EMPTY_MAP>
om1_1        | 2022-04-21 16:45:37,863 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om1_1        | 2022-04-21 16:45:37,904 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om1_1        | 2022-04-21 16:45:37,914 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
om1_1        | 2022-04-21 16:45:37,925 [pool-24-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 does not exist. Creating ...
om1_1        | 2022-04-21 16:45:38,039 [pool-24-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/in_use.lock acquired by nodename 7@om1
om1_1        | 2022-04-21 16:45:38,212 [pool-24-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 has been successfully formatted.
om1_1        | 2022-04-21 16:45:38,241 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om2_1        | 2022-04-21 16:45:39,831 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
om2_1        | 2022-04-21 16:45:39,852 [pool-24-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 does not exist. Creating ...
om2_1        | 2022-04-21 16:45:39,937 [pool-24-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/in_use.lock acquired by nodename 8@om2
om2_1        | 2022-04-21 16:45:40,115 [pool-24-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 has been successfully formatted.
om2_1        | 2022-04-21 16:45:40,130 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om2_1        | 2022-04-21 16:45:40,156 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode2_1  | 2022-04-21 16:54:55,468 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5356,entriesCount=1,lastEntry=(t:1, i:107)
datanode2_1  | 2022-04-21 16:54:55,468 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5357,entriesCount=1,lastEntry=(t:1, i:108)
datanode2_1  | 2022-04-21 16:54:55,708 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5375,entriesCount=1,lastEntry=(t:1, i:109)
datanode2_1  | 2022-04-21 16:54:55,798 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5383,entriesCount=1,lastEntry=(t:1, i:110)
datanode2_1  | 2022-04-21 16:54:55,913 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5394,entriesCount=1,lastEntry=(t:1, i:111)
datanode2_1  | 2022-04-21 16:54:56,063 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5407,entriesCount=1,lastEntry=(t:1, i:112)
datanode2_1  | 2022-04-21 16:55:03,777 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5664,entriesCount=1,lastEntry=(t:1, i:113)
scm2.org_1   | Sleeping for 5 seconds
scm2.org_1   | Waiting for the service scm1.org:9894
scm2.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm2.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm2.org_1   | 2022-04-21 16:43:23,332 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm2.org_1   | /************************************************************
om3_1        | ************************************************************/
om3_1        | 2022-04-21 16:45:10,316 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om3_1        | 2022-04-21 16:45:16,761 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
om3_1        | 2022-04-21 16:45:19,235 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om3_1        | 2022-04-21 16:45:20,196 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om3, RPC Address: om3:9862 and Ratis port: 9872
datanode3_1  | 2022-04-21 16:45:57,236 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-24D42BA70F8F-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode3_1  | 2022-04-21 16:45:57,240 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-24D42BA70F8F-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode3_1  | 2022-04-21 16:45:57,241 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-24D42BA70F8F-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode3_1  | 2022-04-21 16:45:57,278 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-24D42BA70F8F-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
om2_1        | 2022-04-21 16:45:40,199 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om2_1        | 2022-04-21 16:45:40,236 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om2_1        | 2022-04-21 16:45:40,597 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om2_1        | 2022-04-21 16:45:40,742 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om1_1        | 2022-04-21 16:45:38,262 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om1_1        | 2022-04-21 16:45:38,357 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om1_1        | 2022-04-21 16:45:38,383 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om1_1        | 2022-04-21 16:45:38,634 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om1_1        | 2022-04-21 16:45:38,698 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om1_1        | 2022-04-21 16:45:38,698 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode2_1  | 2022-04-21 16:55:03,860 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5665,entriesCount=1,lastEntry=(t:1, i:114)
datanode2_1  | 2022-04-21 16:55:03,871 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5666,entriesCount=1,lastEntry=(t:1, i:115)
datanode2_1  | 2022-04-21 16:55:03,929 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5667,entriesCount=1,lastEntry=(t:1, i:116)
datanode2_1  | 2022-04-21 16:55:03,935 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5668,entriesCount=1,lastEntry=(t:1, i:117)
datanode2_1  | 2022-04-21 16:55:03,936 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5669,entriesCount=1,lastEntry=(t:1, i:118)
datanode2_1  | 2022-04-21 16:55:11,075 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5922,entriesCount=1,lastEntry=(t:1, i:119)
datanode2_1  | 2022-04-21 16:55:11,236 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5923,entriesCount=1,lastEntry=(t:1, i:120)
scm2.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm2.org_1   | STARTUP_MSG:   host = scm2.org/172.25.0.117
scm2.org_1   | STARTUP_MSG:   args = [--bootstrap]
scm2.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
scm2.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.0.4.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
om3_1        | 2022-04-21 16:45:20,203 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om3: om3
om3_1        | 2022-04-21 16:45:20,204 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om3: om3
om3_1        | 2022-04-21 16:45:20,301 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2022-04-21 16:45:20,518 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = ERASURE_CODED_STORAGE_SUPPORT (version = 1), software layout = ERASURE_CODED_STORAGE_SUPPORT (version = 1)
om3_1        | 2022-04-21 16:45:21,971 [main] INFO reflections.Reflections: Reflections took 1160 ms to scan 1 urls, producing 101 keys and 277 values [using 2 cores]
om3_1        | 2022-04-21 16:45:23,208 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
datanode3_1  | 2022-04-21 16:45:57,278 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-24D42BA70F8F-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode3_1  | 2022-04-21 16:45:57,279 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-24D42BA70F8F-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode3_1  | 2022-04-21 16:45:57,293 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-24D42BA70F8F-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode3_1  | 2022-04-21 16:45:57,300 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-24D42BA70F8F-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode3_1  | 2022-04-21 16:45:57,302 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-24D42BA70F8F-LeaderElection2] INFO impl.RoleInfo: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1: start 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-24D42BA70F8F-LeaderStateImpl
om2_1        | 2022-04-21 16:45:40,744 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om2_1        | 2022-04-21 16:45:40,816 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: new om2@group-562213E44849-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849
om2_1        | 2022-04-21 16:45:40,817 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om2_1        | 2022-04-21 16:45:40,817 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om2_1        | 2022-04-21 16:45:40,833 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om2_1        | 2022-04-21 16:45:40,834 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om2_1        | 2022-04-21 16:45:40,844 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om2_1        | 2022-04-21 16:45:40,856 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om2_1        | 2022-04-21 16:45:40,856 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om1_1        | 2022-04-21 16:45:38,719 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: new om1@group-562213E44849-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849
om1_1        | 2022-04-21 16:45:38,730 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om1_1        | 2022-04-21 16:45:38,732 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm2.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/be5888b907ab03eaf5ec49e88bd592b9f9bd78c4 ; compiled by 'runner' on 2022-04-21T16:20Z
datanode2_1  | 2022-04-21 16:55:11,246 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5924,entriesCount=1,lastEntry=(t:1, i:121)
datanode2_1  | 2022-04-21 16:55:11,262 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5925,entriesCount=1,lastEntry=(t:1, i:122)
om1_1        | 2022-04-21 16:45:38,745 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om1_1        | 2022-04-21 16:45:38,748 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om3_1        | 2022-04-21 16:45:23,210 [main] INFO om.OzoneManager: Ozone Manager login successful.
om3_1        | 2022-04-21 16:45:23,211 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2022-04-21 16:45:29,731 [main] INFO client.OMCertificateClient: Loading certificate from location:/data/metadata/om/certs.
om3_1        | 2022-04-21 16:45:30,419 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/ROOTCA-1.crt.
om3_1        | 2022-04-21 16:45:30,430 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/962729036934.crt.
om3_1        | 2022-04-21 16:45:30,456 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/CA-862887965327.crt.
om3_1        | 2022-04-21 16:45:30,812 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2022-04-21 16:45:31,893 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
datanode3_1  | 2022-04-21 16:45:57,314 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-24D42BA70F8F-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-24D42BA70F8F-SegmentedRaftLogWorker: Starting segment from index:0
datanode3_1  | 2022-04-21 16:45:57,323 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-24D42BA70F8F-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-24D42BA70F8F-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/d5d7df1a-3895-4b52-8476-24d42ba70f8f/current/log_inprogress_0
datanode3_1  | 2022-04-21 16:45:57,336 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-24D42BA70F8F-LeaderElection2] INFO server.RaftServer$Division: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-24D42BA70F8F: set configuration 0: [0ef408af-3ea2-4044-bc54-ad0ae15d84f1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1], old=null
datanode3_1  | 2022-04-21 16:45:59,714 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-FollowerState] INFO impl.FollowerState: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5185385718ns, electionTimeout:5183ms
datanode3_1  | 2022-04-21 16:45:59,714 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-FollowerState] INFO impl.RoleInfo: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1: shutdown 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-FollowerState
datanode3_1  | 2022-04-21 16:45:59,715 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-FollowerState] INFO server.RaftServer$Division: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C: changes role from  FOLLOWER to CANDIDATE at term 4 for changeToCandidate
scm2.org_1   | STARTUP_MSG:   java = 11.0.14.1
scm2.org_1   | ************************************************************/
scm2.org_1   | 2022-04-21 16:43:23,349 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm2.org_1   | 2022-04-21 16:43:23,459 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm2.org_1   | 2022-04-21 16:43:23,459 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm2.org_1   | 2022-04-21 16:43:23,497 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm2, RPC Address: scm2.org:9894 and Ratis port: 9894
scm2.org_1   | 2022-04-21 16:43:23,498 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm2: scm2.org
datanode2_1  | 2022-04-21 16:55:11,278 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5927,entriesCount=1,lastEntry=(t:1, i:123)
datanode2_1  | 2022-04-21 16:55:11,498 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5950,entriesCount=1,lastEntry=(t:1, i:124)
datanode2_1  | 2022-04-21 16:55:11,509 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5952,entriesCount=1,lastEntry=(t:1, i:125)
datanode2_1  | 2022-04-21 16:55:11,513 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5953,entriesCount=1,lastEntry=(t:1, i:126)
datanode2_1  | 2022-04-21 16:55:17,430 [java.util.concurrent.ThreadPoolExecutor$Worker@37050c99[State = -1, empty queue]] WARN server.GrpcLogAppender: a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85->0ef408af-3ea2-4044-bc54-ad0ae15d84f1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=6207,entriesCount=1,lastEntry=(t:1, i:127)
datanode2_1  | 2022-04-21 16:57:18,286 [Thread-623] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-70F5B9EC736E->a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85, cid=136, seq=0, Watch-ALL_COMMITTED(130), Message:<EMPTY>, reply=RaftClientReply:client-70F5B9EC736E->a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85, cid=136, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 136 and log index 130 is not yet replicated to ALL_COMMITTED, logIndex=130, commits[a9037631-20c7-49ff-8966-d11abf0c09e2:c146, 0ef408af-3ea2-4044-bc54-ad0ae15d84f1:c127, 8694db2d-5e51-4888-b1e0-69ff67626e43:c146]
datanode2_1  | 2022-04-21 16:58:19,282 [Thread-660] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-4B2E33D36359->a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85, cid=142, seq=0, Watch-ALL_COMMITTED(139), Message:<EMPTY>, reply=RaftClientReply:client-4B2E33D36359->a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85, cid=142, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 142 and log index 139 is not yet replicated to ALL_COMMITTED, logIndex=139, commits[a9037631-20c7-49ff-8966-d11abf0c09e2:c150, 0ef408af-3ea2-4044-bc54-ad0ae15d84f1:c127, 8694db2d-5e51-4888-b1e0-69ff67626e43:c150]
datanode2_1  | 2022-04-21 16:59:26,282 [Thread-711] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-431F46E155D9->a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85, cid=157, seq=0, Watch-ALL_COMMITTED(144), Message:<EMPTY>, reply=RaftClientReply:client-431F46E155D9->a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85, cid=157, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 157 and log index 144 is not yet replicated to ALL_COMMITTED, logIndex=144, commits[a9037631-20c7-49ff-8966-d11abf0c09e2:c154, 0ef408af-3ea2-4044-bc54-ad0ae15d84f1:c127, 8694db2d-5e51-4888-b1e0-69ff67626e43:c154]
datanode2_1  | 2022-04-21 17:00:41,282 [Thread-778] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-8E7FFC69C7C2->a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85, cid=162, seq=0, Watch-ALL_COMMITTED(148), Message:<EMPTY>, reply=RaftClientReply:client-8E7FFC69C7C2->a9037631-20c7-49ff-8966-d11abf0c09e2@group-0B8A33D7FC85, cid=162, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 162 and log index 148 is not yet replicated to ALL_COMMITTED, logIndex=148, commits[a9037631-20c7-49ff-8966-d11abf0c09e2:c154, 0ef408af-3ea2-4044-bc54-ad0ae15d84f1:c127, 8694db2d-5e51-4888-b1e0-69ff67626e43:c154]
om1_1        | 2022-04-21 16:45:38,758 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om1_1        | 2022-04-21 16:45:38,768 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om1_1        | 2022-04-21 16:45:38,800 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om1_1        | 2022-04-21 16:45:38,801 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om1_1        | 2022-04-21 16:45:38,909 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om1_1        | 2022-04-21 16:45:38,909 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om1_1        | 2022-04-21 16:45:38,966 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
om2_1        | 2022-04-21 16:45:40,875 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om2_1        | 2022-04-21 16:45:40,980 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om2_1        | 2022-04-21 16:45:40,986 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om2_1        | 2022-04-21 16:45:41,014 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
om2_1        | 2022-04-21 16:45:41,014 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om2_1        | 2022-04-21 16:45:41,026 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om2_1        | 2022-04-21 16:45:41,029 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
datanode3_1  | 2022-04-21 16:45:59,715 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode3_1  | 2022-04-21 16:45:59,715 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-FollowerState] INFO impl.RoleInfo: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1: start 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-LeaderElection3
datanode3_1  | 2022-04-21 16:45:59,721 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-LeaderElection3] INFO impl.LeaderElection: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-LeaderElection3 ELECTION round 0: submit vote requests at term 5 for -1: [0ef408af-3ea2-4044-bc54-ad0ae15d84f1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 8694db2d-5e51-4888-b1e0-69ff67626e43|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a9037631-20c7-49ff-8966-d11abf0c09e2|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-04-21 16:45:59,819 [grpc-default-executor-1] INFO server.RaftServer$Division: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C: receive requestVote(ELECTION, a9037631-20c7-49ff-8966-d11abf0c09e2, group-F38EF2C5977C, 5, (t:0, i:0))
datanode3_1  | 2022-04-21 16:45:59,819 [grpc-default-executor-1] INFO impl.VoteContext: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-CANDIDATE: reject ELECTION from a9037631-20c7-49ff-8966-d11abf0c09e2: already has voted for 0ef408af-3ea2-4044-bc54-ad0ae15d84f1 at current term 5
datanode3_1  | 2022-04-21 16:45:59,819 [grpc-default-executor-1] INFO server.RaftServer$Division: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C replies to ELECTION vote request: a9037631-20c7-49ff-8966-d11abf0c09e2<-0ef408af-3ea2-4044-bc54-ad0ae15d84f1#0:FAIL-t5. Peer's state: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C:t5, leader=null, voted=0ef408af-3ea2-4044-bc54-ad0ae15d84f1, raftlog=0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-SegmentedRaftLog:OPENED:c-1, conf=-1: [0ef408af-3ea2-4044-bc54-ad0ae15d84f1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 8694db2d-5e51-4888-b1e0-69ff67626e43|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a9037631-20c7-49ff-8966-d11abf0c09e2|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-04-21 16:45:59,821 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-LeaderElection3] INFO impl.LeaderElection: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-LeaderElection3: ELECTION PASSED received 1 response(s) and 0 exception(s):
scm2.org_1   | 2022-04-21 16:43:23,505 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2022-04-21 16:43:23,682 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
om3_1        | 2022-04-21 16:45:31,896 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om3_1        | 2022-04-21 16:45:33,106 [main] INFO security.OzoneSecretStore: Loaded 0 tokens
om3_1        | 2022-04-21 16:45:33,106 [main] INFO security.OzoneDelegationTokenSecretManager: Loading token state into token manager.
om3_1        | 2022-04-21 16:45:33,754 [main] INFO om.OzoneManager: Created Volume s3v With Owner root required for S3Gateway operations.
om3_1        | 2022-04-21 16:45:34,661 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om3_1        | 2022-04-21 16:45:34,673 [main] WARN utils.OzoneManagerRatisUtils: ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
om3_1        | 2022-04-21 16:45:34,882 [main] INFO snapshot.OzoneManagerSnapshotProvider: Initializing OM Snapshot Provider
scm2.org_1   | 2022-04-21 16:43:23,683 [main] INFO server.StorageContainerManager: SCM login successful.
scm2.org_1   | 2022-04-21 16:43:25,951 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm2.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863 after 1 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-04-21 16:43:27,954 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-04-21 16:43:29,955 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm1.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863 after 3 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-04-21 16:43:31,957 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm2.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863 after 4 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-04-21 16:43:33,960 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
om1_1        | 2022-04-21 16:45:38,966 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om2_1        | 2022-04-21 16:45:41,033 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om2_1        | 2022-04-21 16:45:41,034 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om2_1        | 2022-04-21 16:45:41,035 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
om3_1        | 2022-04-21 16:45:35,749 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm3.org_1   | Sleeping for 5 seconds
scm3.org_1   | Waiting for the service scm2.org:9894
om2_1        | 2022-04-21 16:45:41,045 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode3_1  | 2022-04-21 16:45:59,841 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-LeaderElection3] INFO impl.LeaderElection:   Response 0: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1<-8694db2d-5e51-4888-b1e0-69ff67626e43#0:OK-t5
datanode3_1  | 2022-04-21 16:45:59,841 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-LeaderElection3] INFO impl.LeaderElection: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-LeaderElection3 ELECTION round 0: result PASSED
datanode3_1  | 2022-04-21 16:45:59,842 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-LeaderElection3] INFO impl.RoleInfo: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1: shutdown 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-LeaderElection3
datanode3_1  | 2022-04-21 16:45:59,842 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-LeaderElection3] INFO server.RaftServer$Division: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C: changes role from CANDIDATE to LEADER at term 5 for changeToLeader
recon_1      | Sleeping for 5 seconds
recon_1      | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om2_1        | 2022-04-21 16:45:41,847 [main] INFO reflections.Reflections: Reflections took 1732 ms to scan 7 urls, producing 20 keys and 355 values [using 2 cores]
om2_1        | 2022-04-21 16:45:42,899 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om2_1        | 2022-04-21 16:45:42,936 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om2_1        | 2022-04-21 16:45:43,488 [Listener at om2/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om2_1        | 2022-04-21 16:45:43,563 [Listener at om2/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om2_1        | 2022-04-21 16:45:43,564 [Listener at om2/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om2_1        | 2022-04-21 16:45:43,784 [Listener at om2/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om2/172.25.0.112:9862
om2_1        | 2022-04-21 16:45:43,787 [Listener at om2/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om2 at port 9872
datanode3_1  | 2022-04-21 16:45:59,842 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-LeaderElection3] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-F38EF2C5977C with new leaderId: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1
datanode3_1  | 2022-04-21 16:45:59,842 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-LeaderElection3] INFO server.RaftServer$Division: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C: change Leader from null to 0ef408af-3ea2-4044-bc54-ad0ae15d84f1 at term 5 for becomeLeader, leader elected after 24322ms
datanode3_1  | 2022-04-21 16:45:59,842 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode3_1  | 2022-04-21 16:45:59,843 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode3_1  | 2022-04-21 16:45:59,843 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode3_1  | 2022-04-21 16:45:59,843 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode3_1  | 2022-04-21 16:45:59,850 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode3_1  | 2022-04-21 16:45:59,850 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode3_1  | 2022-04-21 16:45:59,851 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode3_1  | 2022-04-21 16:45:59,851 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
om1_1        | 2022-04-21 16:45:39,017 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om1_1        | 2022-04-21 16:45:39,027 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om1_1        | 2022-04-21 16:45:39,036 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om1_1        | 2022-04-21 16:45:39,127 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om1_1        | 2022-04-21 16:45:39,142 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
om1_1        | 2022-04-21 16:45:39,143 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om1_1        | 2022-04-21 16:45:40,340 [main] INFO reflections.Reflections: Reflections took 2230 ms to scan 7 urls, producing 20 keys and 355 values [using 2 cores]
om1_1        | 2022-04-21 16:45:41,367 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om1_1        | 2022-04-21 16:45:41,403 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om1_1        | 2022-04-21 16:45:42,091 [Listener at om1/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm2.org_1   | 2022-04-21 16:43:36,277 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:e8ea6b57-c3ba-42bd-9807-0913ca4228d7 is not the leader. Could not determine the leader node.
scm2.org_1   | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
scm2.org_1   | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
scm2.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:109)
scm2.org_1   | 	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:14202)
scm2.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
scm2.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
scm2.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
scm2.org_1   | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
scm2.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
om2_1        | 2022-04-21 16:45:43,792 [Listener at om2/9862] INFO server.RaftServer$Division: om2@group-562213E44849: start as a follower, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om2_1        | 2022-04-21 16:45:43,796 [Listener at om2/9862] INFO server.RaftServer$Division: om2@group-562213E44849: changes role from      null to FOLLOWER at term 0 for startAsFollower
om2_1        | 2022-04-21 16:45:43,802 [Listener at om2/9862] INFO impl.RoleInfo: om2: start om2@group-562213E44849-FollowerState
om2_1        | 2022-04-21 16:45:43,815 [Listener at om2/9862] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-562213E44849,id=om2
datanode3_1  | 2022-04-21 16:45:59,959 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode3_1  | 2022-04-21 16:45:59,961 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2022-04-21 16:45:59,962 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
om2_1        | 2022-04-21 16:45:43,848 [Listener at om2/9862] INFO server.RaftServer: om2: start RPC server
om2_1        | 2022-04-21 16:45:44,088 [Listener at om2/9862] INFO server.GrpcService: om2: GrpcService started, listening on 9872
datanode3_1  | 2022-04-21 16:45:59,965 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-LeaderElection3] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode3_1  | 2022-04-21 16:45:59,965 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode3_1  | 2022-04-21 16:45:59,965 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2022-04-21 16:45:59,974 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode3_1  | 2022-04-21 16:45:59,995 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2022-04-21 16:46:00,000 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode3_1  | 2022-04-21 16:46:00,000 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-LeaderElection3] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode3_1  | 2022-04-21 16:46:00,000 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode3_1  | 2022-04-21 16:46:00,011 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om3_1        | 2022-04-21 16:45:35,823 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om3_1        | 2022-04-21 16:45:35,980 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with groupID: id1 and peers: om3:9872, om1:9872, om2:9872
om3_1        | 2022-04-21 16:45:36,037 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
om3_1        | 2022-04-21 16:45:37,106 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
om3_1        | 2022-04-21 16:45:37,356 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
om3_1        | 2022-04-21 16:45:37,364 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om3_1        | 2022-04-21 16:45:37,368 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
om3_1        | 2022-04-21 16:45:37,371 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om3_1        | 2022-04-21 16:45:37,371 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om3_1        | 2022-04-21 16:45:37,374 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om3_1        | 2022-04-21 16:45:37,403 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om3_1        | 2022-04-21 16:45:37,408 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om3_1        | 2022-04-21 16:45:37,417 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om3_1        | 2022-04-21 16:45:39,468 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om3_1        | 2022-04-21 16:45:39,477 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om3_1        | 2022-04-21 16:45:39,477 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om3_1        | 2022-04-21 16:45:39,526 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om3_1        | 2022-04-21 16:45:39,552 [main] INFO server.RaftServer: om3: addNew group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] returns group-562213E44849:java.util.concurrent.CompletableFuture@6fe43257[Not completed]
om3_1        | 2022-04-21 16:45:39,552 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om3_1        | 2022-04-21 16:45:39,638 [pool-24-thread-1] INFO server.RaftServer$Division: om3: new RaftServerImpl for group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] with OzoneManagerStateMachine:uninitialized
om3_1        | 2022-04-21 16:45:39,657 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om3_1        | 2022-04-21 16:45:39,659 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om3_1        | 2022-04-21 16:45:39,659 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om3_1        | 2022-04-21 16:45:39,662 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om3_1        | 2022-04-21 16:45:39,663 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om3_1        | 2022-04-21 16:45:39,664 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om3_1        | 2022-04-21 16:45:39,666 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om3_1        | 2022-04-21 16:45:39,675 [pool-24-thread-1] INFO server.RaftServer$Division: om3@group-562213E44849: ConfigurationManager, init=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null, confs=<EMPTY_MAP>
om3_1        | 2022-04-21 16:45:39,675 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om3_1        | 2022-04-21 16:45:39,688 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om3_1        | 2022-04-21 16:45:39,689 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
om3_1        | 2022-04-21 16:45:39,692 [pool-24-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 does not exist. Creating ...
om3_1        | 2022-04-21 16:45:39,747 [pool-24-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/in_use.lock acquired by nodename 6@om3
om3_1        | 2022-04-21 16:45:40,000 [pool-24-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 has been successfully formatted.
om3_1        | 2022-04-21 16:45:40,028 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om3_1        | 2022-04-21 16:45:40,030 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om1_1        | 2022-04-21 16:45:42,159 [Listener at om1/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om1_1        | 2022-04-21 16:45:42,161 [Listener at om1/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om1_1        | 2022-04-21 16:45:42,402 [Listener at om1/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om1/172.25.0.111:9862
om1_1        | 2022-04-21 16:45:42,405 [Listener at om1/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om1 at port 9872
om1_1        | 2022-04-21 16:45:42,415 [Listener at om1/9862] INFO server.RaftServer$Division: om1@group-562213E44849: start as a follower, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1        | 2022-04-21 16:45:42,420 [Listener at om1/9862] INFO server.RaftServer$Division: om1@group-562213E44849: changes role from      null to FOLLOWER at term 0 for startAsFollower
om1_1        | 2022-04-21 16:45:42,428 [Listener at om1/9862] INFO impl.RoleInfo: om1: start om1@group-562213E44849-FollowerState
om1_1        | 2022-04-21 16:45:42,442 [Listener at om1/9862] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-562213E44849,id=om1
om1_1        | 2022-04-21 16:45:42,480 [Listener at om1/9862] INFO server.RaftServer: om1: start RPC server
om1_1        | 2022-04-21 16:45:42,712 [Listener at om1/9862] INFO server.GrpcService: om1: GrpcService started, listening on 9872
om1_1        | 2022-04-21 16:45:42,729 [Listener at om1/9862] INFO om.OzoneManager: Starting OM block token secret manager
om1_1        | 2022-04-21 16:45:42,732 [Listener at om1/9862] INFO security.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
om1_1        | 2022-04-21 16:45:42,733 [Listener at om1/9862] INFO om.OzoneManager: Starting OM delegation token secret manager
om1_1        | 2022-04-21 16:45:42,735 [Listener at om1/9862] INFO security.OzoneDelegationTokenSecretManager: Updating the current master key for generating tokens
om1_1        | 2022-04-21 16:45:42,736 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$412/0x00000008405e7c40@418422c3] INFO util.JvmPauseMonitor: JvmPauseMonitor-om1: Started
om1_1        | 2022-04-21 16:45:42,744 [Listener at om1/9862] INFO om.OzoneManager: Version File has different layout version (1) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
om1_1        | 2022-04-21 16:45:42,748 [Thread[Thread-17,5,main]] INFO security.OzoneDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
om1_1        | 2022-04-21 16:45:43,020 [Listener at om1/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om1_1        | 2022-04-21 16:45:43,022 [Listener at om1/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
om1_1        | 2022-04-21 16:45:43,023 [Listener at om1/9862] INFO http.BaseHttpServer: HttpAuthType: ozone.om.http.auth.type = kerberos
om1_1        | 2022-04-21 16:45:43,119 [Listener at om1/9862] INFO util.log: Logging initialized @43974ms to org.eclipse.jetty.util.log.Slf4jLog
om2_1        | 2022-04-21 16:45:44,095 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$412/0x00000008405e7040@1c8a2bec] INFO util.JvmPauseMonitor: JvmPauseMonitor-om2: Started
om2_1        | 2022-04-21 16:45:44,096 [Listener at om2/9862] INFO om.OzoneManager: Starting OM block token secret manager
om2_1        | 2022-04-21 16:45:44,096 [Listener at om2/9862] INFO security.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
scm3.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm3.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm3.org_1   | 2022-04-21 16:44:06,389 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm3.org_1   | /************************************************************
scm3.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm3.org_1   | STARTUP_MSG:   host = scm3.org/172.25.0.118
scm3.org_1   | STARTUP_MSG:   args = [--bootstrap]
scm3.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
scm3.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.0.4.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm3.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/be5888b907ab03eaf5ec49e88bd592b9f9bd78c4 ; compiled by 'runner' on 2022-04-21T16:20Z
scm3.org_1   | STARTUP_MSG:   java = 11.0.14.1
scm3.org_1   | ************************************************************/
scm3.org_1   | 2022-04-21 16:44:06,414 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm3.org_1   | 2022-04-21 16:44:06,647 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm3.org_1   | 2022-04-21 16:44:06,650 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm3.org_1   | 2022-04-21 16:44:06,755 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm3, RPC Address: scm3.org:9894 and Ratis port: 9894
scm3.org_1   | 2022-04-21 16:44:06,765 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm3: scm3.org
scm3.org_1   | 2022-04-21 16:44:06,779 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm3.org_1   | 2022-04-21 16:44:07,025 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm3.org_1   | 2022-04-21 16:44:07,025 [main] INFO server.StorageContainerManager: SCM login successful.
scm3.org_1   | 2022-04-21 16:44:07,419 [main] INFO ha.HASecurityUtils: Initializing secure StorageContainerManager.
scm3.org_1   | 2022-04-21 16:44:07,800 [main] ERROR client.SCMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
scm3.org_1   | 2022-04-21 16:44:07,801 [main] INFO client.SCMCertificateClient: Certificate client init case: 0
scm3.org_1   | 2022-04-21 16:44:07,802 [main] INFO client.SCMCertificateClient: Creating keypair for client as keypair and certificate not found.
scm3.org_1   | 2022-04-21 16:44:08,417 [main] INFO ha.HASecurityUtils: Init response: GETCERT
scm2.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
scm2.org_1   | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm2.org_1   | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm2.org_1   | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
scm2.org_1   | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
scm2.org_1   | , while invoking $Proxy15.send over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863 after 6 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-04-21 16:43:38,279 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm2.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863 after 7 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-04-21 16:43:40,281 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 8 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-04-21 16:43:42,512 [main] INFO ha.HASecurityUtils: Initializing secure StorageContainerManager.
scm2.org_1   | 2022-04-21 16:43:43,560 [main] ERROR client.SCMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
scm2.org_1   | 2022-04-21 16:43:43,565 [main] INFO client.SCMCertificateClient: Certificate client init case: 0
scm2.org_1   | 2022-04-21 16:43:43,577 [main] INFO client.SCMCertificateClient: Creating keypair for client as keypair and certificate not found.
om2_1        | 2022-04-21 16:45:44,098 [Listener at om2/9862] INFO om.OzoneManager: Starting OM delegation token secret manager
om2_1        | 2022-04-21 16:45:44,098 [Listener at om2/9862] INFO security.OzoneDelegationTokenSecretManager: Updating the current master key for generating tokens
datanode3_1  | 2022-04-21 16:46:00,034 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-LeaderElection3] INFO impl.RoleInfo: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1: start 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-LeaderStateImpl
om2_1        | 2022-04-21 16:45:44,129 [Listener at om2/9862] INFO om.OzoneManager: Version File has different layout version (1) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
om2_1        | 2022-04-21 16:45:44,132 [Thread[Thread-17,5,main]] INFO security.OzoneDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
om2_1        | 2022-04-21 16:45:44,411 [Listener at om2/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om2_1        | 2022-04-21 16:45:44,411 [Listener at om2/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
om2_1        | 2022-04-21 16:45:44,411 [Listener at om2/9862] INFO http.BaseHttpServer: HttpAuthType: ozone.om.http.auth.type = kerberos
om2_1        | 2022-04-21 16:45:44,582 [Listener at om2/9862] INFO util.log: Logging initialized @43800ms to org.eclipse.jetty.util.log.Slf4jLog
om2_1        | 2022-04-21 16:45:45,121 [Listener at om2/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
recon_1      | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
recon_1      | 2022-04-21 16:43:08,723 [main] INFO recon.ReconServer: STARTUP_MSG: 
recon_1      | /************************************************************
recon_1      | STARTUP_MSG: Starting ReconServer
recon_1      | STARTUP_MSG:   host = recon/172.25.0.115
recon_1      | STARTUP_MSG:   args = []
recon_1      | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
datanode3_1  | 2022-04-21 16:46:00,035 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-LeaderElection3] INFO segmented.SegmentedRaftLogWorker: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-SegmentedRaftLogWorker: Starting segment from index:0
om1_1        | 2022-04-21 16:45:43,535 [Listener at om1/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om1_1        | 2022-04-21 16:45:43,547 [Listener at om1/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om1_1        | 2022-04-21 16:45:43,556 [Listener at om1/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context ozoneManager
datanode3_1  | 2022-04-21 16:46:00,044 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/f5f2ffbc-fc63-4015-9163-f38ef2c5977c/current/log_inprogress_0
datanode3_1  | 2022-04-21 16:46:00,134 [0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C-LeaderElection3] INFO server.RaftServer$Division: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1@group-F38EF2C5977C: set configuration 0: [0ef408af-3ea2-4044-bc54-ad0ae15d84f1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 8694db2d-5e51-4888-b1e0-69ff67626e43|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a9037631-20c7-49ff-8966-d11abf0c09e2|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-04-21 16:46:16,347 [ChunkWriter-1-0] INFO client.DNCertificateClient: Getting certificate with certSerialId:960208477648.
om2_1        | 2022-04-21 16:45:45,161 [Listener at om2/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm2.org_1   | 2022-04-21 16:43:45,270 [main] INFO ha.HASecurityUtils: Init response: GETCERT
scm2.org_1   | 2022-04-21 16:43:45,362 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.117,host:scm2.org
scm2.org_1   | 2022-04-21 16:43:45,363 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm2.org_1   | 2022-04-21 16:43:45,368 [main] INFO ha.HASecurityUtils: Creating csr for SCM->hostName:scm2.org,scmId:d794df5a-ece1-4828-94ba-97e720366f72,clusterId:CID-37768e1b-cb4c-49da-b09f-824fabcc98dc,subject:scm-sub@scm2.org
scm2.org_1   | 2022-04-21 16:43:48,576 [main] INFO ha.HASecurityUtils: Successfully stored SCM signed certificate.
om2_1        | 2022-04-21 16:45:45,176 [Listener at om2/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context ozoneManager
om2_1        | 2022-04-21 16:45:45,176 [Listener at om2/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
om2_1        | 2022-04-21 16:45:45,178 [Listener at om2/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
om2_1        | 2022-04-21 16:45:45,211 [Listener at om2/9862] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.om.http.auth.kerberos.principal keytabKey: ozone.om.http.auth.kerberos.keytab
om2_1        | 2022-04-21 16:45:45,435 [Listener at om2/9862] INFO http.HttpServer2: Jetty bound to port 9874
om2_1        | 2022-04-21 16:45:45,438 [Listener at om2/9862] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
om1_1        | 2022-04-21 16:45:43,569 [Listener at om1/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
om1_1        | 2022-04-21 16:45:43,571 [Listener at om1/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
om1_1        | 2022-04-21 16:45:43,588 [Listener at om1/9862] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.om.http.auth.kerberos.principal keytabKey: ozone.om.http.auth.kerberos.keytab
om1_1        | 2022-04-21 16:45:43,795 [Listener at om1/9862] INFO http.HttpServer2: Jetty bound to port 9874
om1_1        | 2022-04-21 16:45:43,798 [Listener at om1/9862] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
scm2.org_1   | 2022-04-21 16:43:48,617 [main] INFO server.StorageContainerManager: SCM BootStrap  is successful for ClusterID CID-37768e1b-cb4c-49da-b09f-824fabcc98dc, SCMID d794df5a-ece1-4828-94ba-97e720366f72
scm2.org_1   | 2022-04-21 16:43:48,623 [main] INFO server.StorageContainerManager: Primary SCM Node ID e8ea6b57-c3ba-42bd-9807-0913ca4228d7
scm2.org_1   | 2022-04-21 16:43:48,708 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm2.org_1   | /************************************************************
scm2.org_1   | SHUTDOWN_MSG: Shutting down StorageContainerManager at scm2.org/172.25.0.117
scm2.org_1   | ************************************************************/
scm2.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm2.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om2_1        | 2022-04-21 16:45:45,602 [Listener at om2/9862] INFO server.session: DefaultSessionIdManager workerName=node0
scm3.org_1   | 2022-04-21 16:44:08,484 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.118,host:scm3.org
scm3.org_1   | 2022-04-21 16:44:08,484 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm3.org_1   | 2022-04-21 16:44:08,488 [main] INFO ha.HASecurityUtils: Creating csr for SCM->hostName:scm3.org,scmId:9446a705-8bb9-4eda-8998-a3a4fb23e316,clusterId:CID-37768e1b-cb4c-49da-b09f-824fabcc98dc,subject:scm-sub@scm3.org
scm3.org_1   | 2022-04-21 16:44:09,206 [main] INFO ha.HASecurityUtils: Successfully stored SCM signed certificate.
scm3.org_1   | 2022-04-21 16:44:09,280 [main] INFO server.StorageContainerManager: SCM BootStrap  is successful for ClusterID CID-37768e1b-cb4c-49da-b09f-824fabcc98dc, SCMID 9446a705-8bb9-4eda-8998-a3a4fb23e316
scm3.org_1   | 2022-04-21 16:44:09,280 [main] INFO server.StorageContainerManager: Primary SCM Node ID e8ea6b57-c3ba-42bd-9807-0913ca4228d7
scm3.org_1   | 2022-04-21 16:44:09,370 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
om2_1        | 2022-04-21 16:45:45,619 [Listener at om2/9862] INFO server.session: No SessionScavenger set, using defaults
om2_1        | 2022-04-21 16:45:45,624 [Listener at om2/9862] INFO server.session: node0 Scavenging every 600000ms
om2_1        | 2022-04-21 16:45:45,734 [Listener at om2/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om2_1        | 2022-04-21 16:45:45,749 [Listener at om2/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@70382eb1{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om2_1        | 2022-04-21 16:45:45,752 [Listener at om2/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@21624bde{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om2_1        | 2022-04-21 16:45:46,143 [Listener at om2/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
recon_1      | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.6.1.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.6.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/aopalliance-1.0.jar:/opt/hadoop/share/ozone/lib/sqlite-jdbc-3.25.2.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guice-4.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.ws.rs-api-2.1.6.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-2.33.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.33.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.3.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/guice-multibindings-4.0.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/bonecp-0.8.0.RELEASE.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jakarta.validation-api-2.0.2.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.33.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-tools-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.33.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.33.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jooq-3.11.10.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.5.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.33.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.3.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/spring-beans-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/derby-10.14.2.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.0.4.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/spring-core-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/jooq-codegen-3.11.10.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/spring-tx-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/jersey-entity-filtering-2.33.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/guice-assistedinject-4.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-media-json-jackson-2.33.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/guice-servlet-4.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/guice-bridge-2.5.0.jar:/opt/hadoop/share/ozone/lib/jooq-meta-3.11.10.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/ozone-reconcodegen-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.33.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/spring-jdbc-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/spring-jcl-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-recon-1.3.0-SNAPSHOT.jar
recon_1      | STARTUP_MSG:   build = https://github.com/apache/ozone/be5888b907ab03eaf5ec49e88bd592b9f9bd78c4 ; compiled by 'runner' on 2022-04-21T16:20Z
recon_1      | STARTUP_MSG:   java = 11.0.14.1
recon_1      | ************************************************************/
recon_1      | 2022-04-21 16:43:08,772 [main] INFO recon.ReconServer: registered UNIX signal handlers for [TERM, HUP, INT]
om1_1        | 2022-04-21 16:45:43,931 [Listener at om1/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om1_1        | 2022-04-21 16:45:43,936 [Listener at om1/9862] INFO server.session: No SessionScavenger set, using defaults
om1_1        | 2022-04-21 16:45:43,938 [Listener at om1/9862] INFO server.session: node0 Scavenging every 600000ms
om1_1        | 2022-04-21 16:45:43,998 [Listener at om1/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om1_1        | 2022-04-21 16:45:44,003 [Listener at om1/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@723c6a25{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm2.org_1   | 2022-04-21 16:43:52,202 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm2.org_1   | /************************************************************
scm2.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm2.org_1   | STARTUP_MSG:   host = scm2.org/172.25.0.117
scm2.org_1   | STARTUP_MSG:   args = []
scm2.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
scm2.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.0.4.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm2.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/be5888b907ab03eaf5ec49e88bd592b9f9bd78c4 ; compiled by 'runner' on 2022-04-21T16:20Z
om3_1        | 2022-04-21 16:45:40,135 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om3_1        | 2022-04-21 16:45:40,139 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om3_1        | 2022-04-21 16:45:40,313 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om2_1        | 2022-04-21 16:45:46,191 [Listener at om2/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@4c368165{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-ozone-manager-1_3_0-SNAPSHOT_jar-_-any-9696578326358949718/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/ozoneManager}
om2_1        | 2022-04-21 16:45:46,227 [Listener at om2/9862] INFO server.AbstractConnector: Started ServerConnector@5ce0b14f{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
om2_1        | 2022-04-21 16:45:46,227 [Listener at om2/9862] INFO server.Server: Started @45445ms
om2_1        | 2022-04-21 16:45:46,235 [Listener at om2/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om1_1        | 2022-04-21 16:45:44,008 [Listener at om1/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@70382eb1{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om3_1        | 2022-04-21 16:45:40,504 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om2_1        | 2022-04-21 16:45:46,235 [Listener at om2/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om2_1        | 2022-04-21 16:45:46,240 [Listener at om2/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om2_1        | 2022-04-21 16:45:46,241 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om2_1        | 2022-04-21 16:45:46,242 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
scm3.org_1   | /************************************************************
scm3.org_1   | SHUTDOWN_MSG: Shutting down StorageContainerManager at scm3.org/172.25.0.118
scm3.org_1   | ************************************************************/
scm3.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm3.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm3.org_1   | 2022-04-21 16:44:12,924 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm3.org_1   | /************************************************************
scm3.org_1   | STARTUP_MSG: Starting StorageContainerManager
recon_1      | 2022-04-21 16:43:10,870 [main] INFO reflections.Reflections: Reflections took 86 ms to scan 1 urls, producing 13 keys and 35 values 
recon_1      | 2022-04-21 16:43:12,754 [main] INFO recon.ReconServer: Initializing Recon server...
recon_1      | 2022-04-21 16:43:12,911 [main] INFO recon.ReconServer: Ozone security is enabled. Attempting login for Recon service. Principal: recon/recon@EXAMPLE.COM, keytab: /etc/security/keytabs/recon.keytab
recon_1      | 2022-04-21 16:43:13,378 [main] INFO security.UserGroupInformation: Login successful for user recon/recon@EXAMPLE.COM using keytab file recon.keytab. Keytab auto renewal enabled : false
recon_1      | 2022-04-21 16:43:13,378 [main] INFO recon.ReconServer: Recon login successful.
recon_1      | 2022-04-21 16:43:13,378 [main] INFO recon.ReconServer: Initializing secure Recon.
recon_1      | 2022-04-21 16:43:14,739 [main] ERROR client.ReconCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
om1_1        | 2022-04-21 16:45:44,456 [Listener at om1/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
recon_1      | 2022-04-21 16:43:14,740 [main] INFO client.ReconCertificateClient: Certificate client init case: 0
recon_1      | 2022-04-21 16:43:14,748 [main] INFO client.ReconCertificateClient: Creating keypair for client as keypair and certificate not found.
recon_1      | 2022-04-21 16:43:16,586 [main] INFO recon.ReconServer: Init response: GETCERT
recon_1      | 2022-04-21 16:43:16,633 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.115,host:recon
recon_1      | 2022-04-21 16:43:16,633 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
recon_1      | 2022-04-21 16:43:16,639 [main] ERROR client.ReconCertificateClient: Invalid domain recon
recon_1      | 2022-04-21 16:43:16,873 [main] INFO recon.ReconServer: Creating CSR for Recon.
recon_1      | 2022-04-21 16:43:19,694 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm2.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9961 after 1 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-21 16:43:21,696 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm3.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9961 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-21 16:43:23,698 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm1.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9961 after 3 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-21 16:43:25,699 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm2.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9961 after 4 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-21 16:43:27,701 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm3.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9961 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-21 16:43:29,703 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm1.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9961 after 6 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-21 16:43:31,704 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm2.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9961 after 7 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-21 16:43:33,706 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm3.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9961 after 8 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-21 16:43:36,283 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:e8ea6b57-c3ba-42bd-9807-0913ca4228d7 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
recon_1      | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
recon_1      | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:93)
recon_1      | 	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:16080)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy39.submitRequest over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9961 after 9 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-21 16:43:38,284 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm2.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9961 after 10 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-21 16:43:40,286 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm3.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9961 after 11 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-21 16:43:43,284 [main] INFO recon.ReconServer: Successfully stored SCM signed certificate, case:GETCERT.
recon_1      | 2022-04-21 16:43:43,863 [main] INFO persistence.DefaultDataSourceProvider: JDBC Url for Recon : jdbc:derby:/data/metadata/recon/ozone_recon_derby.db 
recon_1      | 2022-04-21 16:43:46,484 [main] INFO codegen.SqlDbUtils: Created derby database at jdbc:derby:/data/metadata/recon/ozone_recon_derby.db.
recon_1      | WARNING: An illegal reflective access operation has occurred
recon_1      | WARNING: Illegal reflective access by org.jooq.tools.reflect.Reflect (file:/opt/hadoop/share/ozone/lib/jooq-3.11.10.jar) to constructor java.lang.invoke.MethodHandles$Lookup(java.lang.Class)
recon_1      | WARNING: Please consider reporting this to the maintainers of org.jooq.tools.reflect.Reflect
recon_1      | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
recon_1      | WARNING: All illegal access operations will be denied in a future release
recon_1      | 2022-04-21 16:43:47,187 [main] INFO persistence.DefaultDataSourceProvider: JDBC Url for Recon : jdbc:derby:/data/metadata/recon/ozone_recon_derby.db 
recon_1      | 2022-04-21 16:43:47,226 [main] INFO codegen.SqlDbUtils: Created derby database at jdbc:derby:/data/metadata/recon/ozone_recon_derby.db.
recon_1      | 2022-04-21 16:43:47,227 [main] INFO recon.ReconServer: Creating Recon Schema.
recon_1      | 2022-04-21 16:43:48,956 [main] INFO http.BaseHttpServer: Starting Web-server for recon at: http://0.0.0.0:9888
recon_1      | 2022-04-21 16:43:48,957 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
recon_1      | 2022-04-21 16:43:48,957 [main] INFO http.BaseHttpServer: HttpAuthType: ozone.recon.http.auth.type = kerberos
recon_1      | 2022-04-21 16:43:48,979 [main] INFO util.log: Logging initialized @43926ms to org.eclipse.jetty.util.log.Slf4jLog
recon_1      | 2022-04-21 16:43:49,175 [main] WARN http.HttpRequestLog: Jetty request log can only be enabled using Log4j
recon_1      | 2022-04-21 16:43:49,205 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
recon_1      | 2022-04-21 16:43:49,221 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context recon
recon_1      | 2022-04-21 16:43:49,221 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
recon_1      | 2022-04-21 16:43:49,221 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
recon_1      | 2022-04-21 16:43:49,231 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.recon.http.auth.kerberos.principal keytabKey: ozone.recon.http.auth.kerberos.keytab
recon_1      | 2022-04-21 16:43:49,610 [main] INFO tasks.ReconTaskControllerImpl: Registered task ContainerKeyMapperTask with controller.
recon_1      | 2022-04-21 16:43:50,143 [main] INFO tasks.ReconTaskControllerImpl: Registered task FileSizeCountTask with controller.
recon_1      | 2022-04-21 16:43:50,160 [main] INFO tasks.ReconTaskControllerImpl: Registered task TableCountTask with controller.
recon_1      | 2022-04-21 16:43:50,175 [main] INFO tasks.ReconTaskControllerImpl: Registered task NSSummaryTask with controller.
recon_1      | 2022-04-21 16:43:50,214 [main] INFO ozone.OmUtils: Using OzoneManager ServiceID 'id1'.
recon_1      | 2022-04-21 16:43:51,848 [main] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 2022-04-21 16:43:52,363 [main] WARN recon.ReconUtils: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 2022-04-21 16:43:52,432 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar!/network-topology-default.xml]
recon_1      | 2022-04-21 16:43:52,434 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
recon_1      | 2022-04-21 16:43:52,665 [main] WARN db.DBStoreBuilder: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2022-04-21 16:45:44,534 [Listener at om1/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@ecd7bee{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-ozone-manager-1_3_0-SNAPSHOT_jar-_-any-15711535414001436408/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/ozoneManager}
om1_1        | 2022-04-21 16:45:44,591 [Listener at om1/9862] INFO server.AbstractConnector: Started ServerConnector@f019e01{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
scm3.org_1   | STARTUP_MSG:   host = scm3.org/172.25.0.118
scm3.org_1   | STARTUP_MSG:   args = []
scm3.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
scm3.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.0.4.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm2.org_1   | STARTUP_MSG:   java = 11.0.14.1
scm2.org_1   | ************************************************************/
scm2.org_1   | 2022-04-21 16:43:52,236 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm2.org_1   | 2022-04-21 16:43:52,495 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
s3g_1        | Sleeping for 5 seconds
s3g_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
s3g_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
s3g_1        | 2022-04-21 16:43:09,908 [main] INFO security.UserGroupInformation: Login successful for user s3g/s3g@EXAMPLE.COM using keytab file s3g.keytab. Keytab auto renewal enabled : false
s3g_1        | 2022-04-21 16:43:09,915 [main] INFO s3.Gateway: S3Gateway login successful.
s3g_1        | 2022-04-21 16:43:10,145 [main] INFO http.BaseHttpServer: Starting Web-server for s3gateway at: http://0.0.0.0:9878
om2_1        | 2022-04-21 16:45:46,479 [Listener at om2/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted will not move to trash
s3g_1        | 2022-04-21 16:43:10,145 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
s3g_1        | 2022-04-21 16:43:10,145 [main] INFO http.BaseHttpServer: HttpAuthType: ozone.s3g.http.auth.type = kerberos
s3g_1        | 2022-04-21 16:43:10,214 [main] INFO util.log: Logging initialized @5301ms to org.eclipse.jetty.util.log.Slf4jLog
s3g_1        | 2022-04-21 16:43:10,567 [main] INFO http.HttpRequestLog: Http request log for http.requests.s3gateway is not defined
s3g_1        | 2022-04-21 16:43:10,597 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
s3g_1        | 2022-04-21 16:43:10,599 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context s3gateway
s3g_1        | 2022-04-21 16:43:10,599 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
s3g_1        | 2022-04-21 16:43:10,599 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
s3g_1        | 2022-04-21 16:43:10,619 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.s3g.http.auth.kerberos.principal keytabKey: ozone.s3g.http.auth.kerberos.keytab
om2_1        | 2022-04-21 16:45:46,513 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@88432f5] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om2_1        | 2022-04-21 16:45:46,777 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:43223
scm3.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/be5888b907ab03eaf5ec49e88bd592b9f9bd78c4 ; compiled by 'runner' on 2022-04-21T16:20Z
scm3.org_1   | STARTUP_MSG:   java = 11.0.14.1
scm3.org_1   | ************************************************************/
scm3.org_1   | 2022-04-21 16:44:12,949 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm3.org_1   | 2022-04-21 16:44:13,164 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm3.org_1   | 2022-04-21 16:44:13,164 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm3.org_1   | 2022-04-21 16:44:13,269 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm3, RPC Address: scm3.org:9894 and Ratis port: 9894
scm3.org_1   | 2022-04-21 16:44:13,269 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm3: scm3.org
scm3.org_1   | 2022-04-21 16:44:13,342 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm3.org_1   | 2022-04-21 16:44:13,400 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3), software layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3)
scm3.org_1   | 2022-04-21 16:44:13,888 [main] INFO reflections.Reflections: Reflections took 241 ms to scan 3 urls, producing 105 keys and 220 values 
s3g_1        | 2022-04-21 16:43:10,932 [main] INFO s3.Gateway: STARTUP_MSG: 
s3g_1        | /************************************************************
scm3.org_1   | 2022-04-21 16:44:14,915 [main] INFO client.SCMCertificateClient: Loading certificate from location:/data/metadata/scm/sub-ca/certs.
scm3.org_1   | 2022-04-21 16:44:15,069 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/911489842852.crt.
scm3.org_1   | 2022-04-21 16:44:15,074 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/CA-1.crt.
scm3.org_1   | 2022-04-21 16:44:15,086 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/certificate.crt.
scm3.org_1   | 2022-04-21 16:44:15,350 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm3.org_1   | 2022-04-21 16:44:15,350 [main] INFO server.StorageContainerManager: SCM login successful.
scm3.org_1   | 2022-04-21 16:44:15,424 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
s3g_1        | STARTUP_MSG: Starting Gateway
s3g_1        | STARTUP_MSG:   host = s3g/172.25.0.114
scm3.org_1   | 2022-04-21 16:44:15,810 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm3.org_1   | 2022-04-21 16:44:16,114 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar!/network-topology-default.xml]
scm3.org_1   | 2022-04-21 16:44:16,116 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm3.org_1   | 2022-04-21 16:44:16,225 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm3.org_1   | 2022-04-21 16:44:16,304 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:9446a705-8bb9-4eda-8998-a3a4fb23e316
scm3.org_1   | 2022-04-21 16:44:16,549 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
scm3.org_1   | 2022-04-21 16:44:16,689 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
scm3.org_1   | 2022-04-21 16:44:16,690 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm3.org_1   | 2022-04-21 16:44:16,690 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
scm3.org_1   | 2022-04-21 16:44:16,690 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm3.org_1   | 2022-04-21 16:44:16,690 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm3.org_1   | 2022-04-21 16:44:16,691 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
scm3.org_1   | 2022-04-21 16:44:16,697 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm3.org_1   | 2022-04-21 16:44:16,697 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm3.org_1   | 2022-04-21 16:44:16,698 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm3.org_1   | 2022-04-21 16:44:17,574 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
scm3.org_1   | 2022-04-21 16:44:17,576 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
s3g_1        | STARTUP_MSG:   args = []
scm3.org_1   | 2022-04-21 16:44:17,576 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
s3g_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
s3g_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.6.1.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.6.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.interceptor-api-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/javax.el-api-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jakarta.ws.rs-api-2.1.6.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jackson-dataformat-xml-2.13.2.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.33.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.3.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/cdi-api-1.2.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.validation-api-2.0.2.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.33.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.33.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.33.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.5.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.33.jar:/opt/hadoop/share/ozone/lib/jersey-cdi1x-2.33.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.3.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.0.4.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.33.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.3.0-SNAPSHOT.jar
s3g_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/be5888b907ab03eaf5ec49e88bd592b9f9bd78c4 ; compiled by 'runner' on 2022-04-21T16:20Z
s3g_1        | STARTUP_MSG:   java = 11.0.14.1
s3g_1        | ************************************************************/
s3g_1        | 2022-04-21 16:43:10,949 [main] INFO s3.Gateway: registered UNIX signal handlers for [TERM, HUP, INT]
s3g_1        | 2022-04-21 16:43:10,999 [main] INFO s3.Gateway: Starting Ozone S3 gateway
s3g_1        | 2022-04-21 16:43:11,024 [main] INFO http.HttpServer2: Jetty bound to port 9878
s3g_1        | 2022-04-21 16:43:11,025 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
s3g_1        | 2022-04-21 16:43:11,102 [main] INFO server.session: DefaultSessionIdManager workerName=node0
s3g_1        | 2022-04-21 16:43:11,113 [main] INFO server.session: No SessionScavenger set, using defaults
s3g_1        | 2022-04-21 16:43:11,115 [main] INFO server.session: node0 Scavenging every 660000ms
s3g_1        | 2022-04-21 16:43:11,226 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/s3g@EXAMPLE.COM
s3g_1        | 2022-04-21 16:43:11,291 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@45be7cd5{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
s3g_1        | 2022-04-21 16:43:11,300 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@bcec031{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
s3g_1        | WARNING: An illegal reflective access operation has occurred
s3g_1        | WARNING: Illegal reflective access by org.jboss.weld.util.reflection.Formats (file:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar) to constructor com.sun.org.apache.bcel.internal.classfile.ClassParser(java.io.InputStream,java.lang.String)
s3g_1        | WARNING: Please consider reporting this to the maintainers of org.jboss.weld.util.reflection.Formats
s3g_1        | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
s3g_1        | WARNING: All illegal access operations will be denied in a future release
s3g_1        | 2022-04-21 16:43:17,393 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/s3g@EXAMPLE.COM
scm3.org_1   | 2022-04-21 16:44:17,602 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
om1_1        | 2022-04-21 16:45:44,591 [Listener at om1/9862] INFO server.Server: Started @45446ms
om1_1        | 2022-04-21 16:45:44,602 [Listener at om1/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om1_1        | 2022-04-21 16:45:44,602 [Listener at om1/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om1_1        | 2022-04-21 16:45:44,616 [Listener at om1/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om1_1        | 2022-04-21 16:45:44,616 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm2.org_1   | 2022-04-21 16:43:52,499 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm2.org_1   | 2022-04-21 16:43:52,704 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm2, RPC Address: scm2.org:9894 and Ratis port: 9894
scm2.org_1   | 2022-04-21 16:43:52,706 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm2: scm2.org
scm2.org_1   | 2022-04-21 16:43:52,828 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2022-04-21 16:43:52,879 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3), software layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3)
scm2.org_1   | 2022-04-21 16:43:53,622 [main] INFO reflections.Reflections: Reflections took 358 ms to scan 3 urls, producing 105 keys and 220 values 
scm2.org_1   | 2022-04-21 16:43:55,030 [main] INFO client.SCMCertificateClient: Loading certificate from location:/data/metadata/scm/sub-ca/certs.
scm2.org_1   | 2022-04-21 16:43:55,187 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/888876518588.crt.
scm2.org_1   | 2022-04-21 16:43:55,194 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/CA-1.crt.
scm2.org_1   | 2022-04-21 16:43:55,199 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/certificate.crt.
scm2.org_1   | 2022-04-21 16:43:55,468 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm2.org_1   | 2022-04-21 16:43:55,468 [main] INFO server.StorageContainerManager: SCM login successful.
scm3.org_1   | 2022-04-21 16:44:17,620 [main] INFO server.RaftServer: 9446a705-8bb9-4eda-8998-a3a4fb23e316: addNew group-824FABCC98DC:[] returns group-824FABCC98DC:java.util.concurrent.CompletableFuture@482a58c7[Not completed]
scm3.org_1   | 2022-04-21 16:44:17,682 [pool-14-thread-1] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316: new RaftServerImpl for group-824FABCC98DC:[] with SCMStateMachine:uninitialized
scm1.org_1   | Sleeping for 5 seconds
scm1.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm1.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm1.org_1   | 2022-04-21 16:43:10,229 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm1.org_1   | /************************************************************
scm1.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm1.org_1   | STARTUP_MSG:   host = scm1.org/172.25.0.116
scm3.org_1   | 2022-04-21 16:44:17,694 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm3.org_1   | 2022-04-21 16:44:17,699 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
recon_1      | 2022-04-21 16:43:53,052 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3), software layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3)
recon_1      | 2022-04-21 16:43:53,148 [main] INFO reflections.Reflections: Reflections took 90 ms to scan 3 urls, producing 105 keys and 220 values 
recon_1      | 2022-04-21 16:43:53,297 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
recon_1      | 2022-04-21 16:43:53,413 [main] INFO node.SCMNodeManager: Entering startup safe mode.
recon_1      | 2022-04-21 16:43:53,434 [main] INFO scm.ReconNodeManager: Loaded 0 nodes from node DB.
om1_1        | 2022-04-21 16:45:44,780 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om1_1        | 2022-04-21 16:45:45,276 [Listener at om1/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted will not move to trash
scm3.org_1   | 2022-04-21 16:44:17,700 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm2.org_1   | 2022-04-21 16:43:55,496 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
s3g_1        | Apr 21, 2022 4:43:19 PM org.glassfish.jersey.internal.Errors logErrors
s3g_1        | WARNING: The following warnings have been detected: WARNING: A HTTP GET method, public javax.ws.rs.core.Response org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.get(java.lang.String,java.lang.String,java.lang.String,int,java.lang.String,java.io.InputStream) throws java.io.IOException,org.apache.hadoop.ozone.s3.exception.OS3Exception, should not consume any entity.
scm1.org_1   | STARTUP_MSG:   args = [--init]
scm1.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om1_1        | 2022-04-21 16:45:45,361 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6f8aecd3] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om3_1        | 2022-04-21 16:45:40,515 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om3_1        | 2022-04-21 16:45:40,586 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: new om3@group-562213E44849-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849
scm2.org_1   | 2022-04-21 16:43:55,802 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2022-04-21 16:43:56,196 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar!/network-topology-default.xml]
scm2.org_1   | 2022-04-21 16:43:56,196 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm2.org_1   | 2022-04-21 16:43:56,332 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm2.org_1   | 2022-04-21 16:43:56,375 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:d794df5a-ece1-4828-94ba-97e720366f72
scm2.org_1   | 2022-04-21 16:43:56,719 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
scm2.org_1   | 2022-04-21 16:43:57,032 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
om2_1        | 2022-04-21 16:45:46,781 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-04-21 16:45:48,875 [om2@group-562213E44849-FollowerState] INFO impl.FollowerState: om2@group-562213E44849-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5072939501ns, electionTimeout:5053ms
om2_1        | 2022-04-21 16:45:48,877 [om2@group-562213E44849-FollowerState] INFO impl.RoleInfo: om2: shutdown om2@group-562213E44849-FollowerState
om3_1        | 2022-04-21 16:45:40,587 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om3_1        | 2022-04-21 16:45:40,587 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
recon_1      | 2022-04-21 16:43:53,450 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
recon_1      | 2022-04-21 16:43:53,602 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm2.org_1   | 2022-04-21 16:43:57,033 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm2.org_1   | 2022-04-21 16:43:57,033 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
om1_1        | 2022-04-21 16:45:45,500 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:35705
om1_1        | 2022-04-21 16:45:45,542 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-04-21 16:45:40,610 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
s3g_1        | 
s3g_1        | 2022-04-21 16:43:19,253 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@59d5c537{s3gateway,/,file:///tmp/jetty-0_0_0_0-9878-ozone-s3gateway-1_3_0-SNAPSHOT_jar-_-any-9807396101188197762/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.3.0-SNAPSHOT.jar!/webapps/s3gateway}
s3g_1        | 2022-04-21 16:43:19,263 [main] INFO server.AbstractConnector: Started ServerConnector@37f21974{HTTP/1.1, (http/1.1)}{0.0.0.0:9878}
s3g_1        | 2022-04-21 16:43:19,263 [main] INFO server.Server: Started @14351ms
s3g_1        | 2022-04-21 16:43:19,265 [main] INFO http.BaseHttpServer: HTTP server of s3gateway listening at http://0.0.0.0:9878
s3g_1        | 2022-04-21 16:43:19,412 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
s3g_1        | 2022-04-21 16:43:19,430 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm2.org_1   | 2022-04-21 16:43:57,040 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
om1_1        | 2022-04-21 16:45:47,642 [om1@group-562213E44849-FollowerState] INFO impl.FollowerState: om1@group-562213E44849-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5214522080ns, electionTimeout:5196ms
om1_1        | 2022-04-21 16:45:47,644 [om1@group-562213E44849-FollowerState] INFO impl.RoleInfo: om1: shutdown om1@group-562213E44849-FollowerState
scm1.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.0.4.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm1.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/be5888b907ab03eaf5ec49e88bd592b9f9bd78c4 ; compiled by 'runner' on 2022-04-21T16:20Z
scm2.org_1   | 2022-04-21 16:43:57,040 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm2.org_1   | 2022-04-21 16:43:57,051 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
om2_1        | 2022-04-21 16:45:48,878 [om2@group-562213E44849-FollowerState] INFO server.RaftServer$Division: om2@group-562213E44849: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
om2_1        | 2022-04-21 16:45:48,881 [om2@group-562213E44849-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om2_1        | 2022-04-21 16:45:48,883 [om2@group-562213E44849-FollowerState] INFO impl.RoleInfo: om2: start om2@group-562213E44849-LeaderElection1
om1_1        | 2022-04-21 16:45:47,645 [om1@group-562213E44849-FollowerState] INFO server.RaftServer$Division: om1@group-562213E44849: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
om1_1        | 2022-04-21 16:45:47,647 [om1@group-562213E44849-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
scm1.org_1   | STARTUP_MSG:   java = 11.0.14.1
scm3.org_1   | 2022-04-21 16:44:17,700 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm3.org_1   | 2022-04-21 16:44:17,700 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm3.org_1   | 2022-04-21 16:44:17,700 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
scm3.org_1   | 2022-04-21 16:44:17,700 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm3.org_1   | 2022-04-21 16:44:17,720 [pool-14-thread-1] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
scm3.org_1   | 2022-04-21 16:44:17,721 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
om2_1        | 2022-04-21 16:45:48,911 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om2@group-562213E44849-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om2_1        | 2022-04-21 16:45:50,470 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-562213E44849: receive requestVote(ELECTION, om1, group-562213E44849, 1, (t:0, i:~))
scm1.org_1   | ************************************************************/
scm1.org_1   | 2022-04-21 16:43:10,270 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
s3g_1        | 2022-04-21 16:43:19,430 [main] INFO impl.MetricsSystemImpl: S3Gateway metrics system started
s3g_1        | 2022-04-21 16:43:19,442 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm2.org_1   | 2022-04-21 16:43:57,052 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om2_1        | 2022-04-21 16:45:50,489 [grpc-default-executor-0] INFO impl.VoteContext: om2@group-562213E44849-CANDIDATE: reject ELECTION from om1: already has voted for om2 at current term 1
om2_1        | 2022-04-21 16:45:50,506 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-562213E44849 replies to ELECTION vote request: om1<-om2#0:FAIL-t1. Peer's state: om2@group-562213E44849:t1, leader=null, voted=om2, raftlog=om2@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om2_1        | 2022-04-21 16:45:50,570 [grpc-default-executor-3] INFO server.RaftServer$Division: om2@group-562213E44849: receive requestVote(ELECTION, om3, group-562213E44849, 1, (t:0, i:~))
scm1.org_1   | 2022-04-21 16:43:10,786 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
s3g_1        | 2022-04-21 16:43:19,442 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
s3g_1        | 2022-04-21 16:51:25,691 [qtp440736059-22] INFO audit.AuditLogger: Refresh DebugCmdSet for S3GAudit to [].
om2_1        | 2022-04-21 16:45:50,628 [grpc-default-executor-3] INFO impl.VoteContext: om2@group-562213E44849-CANDIDATE: reject ELECTION from om3: already has voted for om2 at current term 1
om2_1        | 2022-04-21 16:45:50,629 [grpc-default-executor-3] INFO server.RaftServer$Division: om2@group-562213E44849 replies to ELECTION vote request: om3<-om2#0:FAIL-t1. Peer's state: om2@group-562213E44849:t1, leader=null, voted=om2, raftlog=om2@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
scm1.org_1   | 2022-04-21 16:43:11,064 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm3.org_1   | 2022-04-21 16:44:17,724 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm3.org_1   | 2022-04-21 16:44:17,725 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
om2_1        | 2022-04-21 16:45:50,940 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om2@group-562213E44849-LeaderElection1: ELECTION REJECTED received 2 response(s) and 0 exception(s):
s3g_1        | 2022-04-21 16:51:25,715 [qtp440736059-22] INFO ozone.OmUtils: Using OzoneManager ServiceID 'id1'.
om3_1        | 2022-04-21 16:45:40,610 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om3_1        | 2022-04-21 16:45:40,610 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
recon_1      | 2022-04-21 16:43:53,714 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om2_1        | 2022-04-21 16:45:50,941 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 0: om2<-om1#0:FAIL-t1
om1_1        | 2022-04-21 16:45:47,648 [om1@group-562213E44849-FollowerState] INFO impl.RoleInfo: om1: start om1@group-562213E44849-LeaderElection1
om1_1        | 2022-04-21 16:45:47,665 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1        | 2022-04-21 16:45:50,605 [grpc-default-executor-1] INFO server.RaftServer$Division: om1@group-562213E44849: receive requestVote(ELECTION, om3, group-562213E44849, 1, (t:0, i:~))
om1_1        | 2022-04-21 16:45:50,606 [grpc-default-executor-1] INFO impl.VoteContext: om1@group-562213E44849-CANDIDATE: reject ELECTION from om3: already has voted for om1 at current term 1
om1_1        | 2022-04-21 16:45:50,630 [grpc-default-executor-1] INFO server.RaftServer$Division: om1@group-562213E44849 replies to ELECTION vote request: om3<-om1#0:FAIL-t1. Peer's state: om1@group-562213E44849:t1, leader=null, voted=om1, raftlog=om1@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1        | 2022-04-21 16:45:50,700 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection1: ELECTION REJECTED received 2 response(s) and 0 exception(s):
om1_1        | 2022-04-21 16:45:50,700 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 0: om1<-om3#0:FAIL-t1
om1_1        | 2022-04-21 16:45:50,700 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 1: om1<-om2#0:FAIL-t1
om1_1        | 2022-04-21 16:45:50,700 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection1 ELECTION round 0: result REJECTED
om1_1        | 2022-04-21 16:45:50,703 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServer$Division: om1@group-562213E44849: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
om2_1        | 2022-04-21 16:45:50,941 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 1: om2<-om3#0:FAIL-t1
om1_1        | 2022-04-21 16:45:50,708 [om1@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om1: shutdown om1@group-562213E44849-LeaderElection1
om1_1        | 2022-04-21 16:45:50,709 [om1@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om1: start om1@group-562213E44849-FollowerState
s3g_1        | 2022-04-21 16:51:27,051 [qtp440736059-22] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-1938307693, with testuser as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
scm2.org_1   | 2022-04-21 16:43:57,054 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm2.org_1   | 2022-04-21 16:43:57,054 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
om3_1        | 2022-04-21 16:45:40,635 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om3_1        | 2022-04-21 16:45:40,635 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm1.org_1   | 2022-04-21 16:43:11,064 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm3.org_1   | 2022-04-21 16:44:17,726 [pool-14-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/37768e1b-cb4c-49da-b09f-824fabcc98dc does not exist. Creating ...
scm3.org_1   | 2022-04-21 16:44:17,750 [pool-14-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/37768e1b-cb4c-49da-b09f-824fabcc98dc/in_use.lock acquired by nodename 7@scm3.org
recon_1      | 2022-04-21 16:43:53,754 [Socket Reader #1 for port 9891] INFO ipc.Server: Starting Socket Reader #1 for port 9891
recon_1      | 2022-04-21 16:43:53,885 [Listener at 0.0.0.0/9891] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
recon_1      | 2022-04-21 16:43:54,189 [Listener at 0.0.0.0/9891] INFO recon.ReconServer: Recon server initialized successfully!
scm2.org_1   | 2022-04-21 16:43:58,381 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
s3g_1        | 2022-04-21 16:51:27,093 [qtp440736059-22] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-1938307693
om2_1        | 2022-04-21 16:45:50,941 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om2@group-562213E44849-LeaderElection1 ELECTION round 0: result REJECTED
om2_1        | 2022-04-21 16:45:50,942 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServer$Division: om2@group-562213E44849: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
om2_1        | 2022-04-21 16:45:50,942 [om2@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om2: shutdown om2@group-562213E44849-LeaderElection1
om2_1        | 2022-04-21 16:45:50,942 [om2@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om2: start om2@group-562213E44849-FollowerState
om2_1        | 2022-04-21 16:45:55,810 [grpc-default-executor-3] INFO server.RaftServer$Division: om2@group-562213E44849: receive requestVote(ELECTION, om1, group-562213E44849, 2, (t:0, i:~))
om2_1        | 2022-04-21 16:45:55,812 [grpc-default-executor-3] INFO impl.VoteContext: om2@group-562213E44849-FOLLOWER: accept ELECTION from om1: our priority 0 <= candidate's priority 0
om2_1        | 2022-04-21 16:45:55,812 [grpc-default-executor-3] INFO server.RaftServer$Division: om2@group-562213E44849: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:om1
scm1.org_1   | 2022-04-21 16:43:11,359 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm1, RPC Address: scm1.org:9894 and Ratis port: 9894
scm1.org_1   | 2022-04-21 16:43:11,377 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm1: scm1.org
scm1.org_1   | 2022-04-21 16:43:11,415 [main] INFO ha.HASecurityUtils: Initializing secure StorageContainerManager.
scm1.org_1   | 2022-04-21 16:43:13,997 [main] ERROR client.SCMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
scm1.org_1   | 2022-04-21 16:43:13,997 [main] INFO client.SCMCertificateClient: Certificate client init case: 0
scm2.org_1   | 2022-04-21 16:43:58,391 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm3.org_1   | 2022-04-21 16:44:17,801 [pool-14-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/37768e1b-cb4c-49da-b09f-824fabcc98dc has been successfully formatted.
scm3.org_1   | 2022-04-21 16:44:17,824 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm1.org_1   | 2022-04-21 16:43:14,020 [main] INFO client.SCMCertificateClient: Creating keypair for client as keypair and certificate not found.
om3_1        | 2022-04-21 16:45:40,647 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om3_1        | 2022-04-21 16:45:40,747 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om3_1        | 2022-04-21 16:45:40,757 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om3_1        | 2022-04-21 16:45:40,825 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm1.org_1   | 2022-04-21 16:43:16,673 [main] INFO ha.HASecurityUtils: Init response: GETCERT
recon_1      | 2022-04-21 16:43:54,196 [Listener at 0.0.0.0/9891] INFO recon.ReconServer: Starting Recon server
s3g_1        | 2022-04-21 16:51:33,787 [qtp440736059-20] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-3093588181, with testuser as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-04-21 16:51:33,810 [qtp440736059-20] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-3093588181
om1_1        | 2022-04-21 16:45:50,927 [grpc-default-executor-1] INFO server.RaftServer$Division: om1@group-562213E44849: receive requestVote(ELECTION, om2, group-562213E44849, 1, (t:0, i:~))
om1_1        | 2022-04-21 16:45:50,927 [grpc-default-executor-1] INFO impl.VoteContext: om1@group-562213E44849-FOLLOWER: reject ELECTION from om2: already has voted for om1 at current term 1
om1_1        | 2022-04-21 16:45:50,928 [grpc-default-executor-1] INFO server.RaftServer$Division: om1@group-562213E44849 replies to ELECTION vote request: om2<-om1#0:FAIL-t1. Peer's state: om1@group-562213E44849:t1, leader=null, voted=om1, raftlog=om1@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
recon_1      | 2022-04-21 16:43:54,411 [Listener at 0.0.0.0/9891] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om3_1        | 2022-04-21 16:45:40,825 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om3_1        | 2022-04-21 16:45:40,881 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om3_1        | 2022-04-21 16:45:40,892 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om3_1        | 2022-04-21 16:45:40,893 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om3_1        | 2022-04-21 16:45:40,893 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om3_1        | 2022-04-21 16:45:40,944 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
om3_1        | 2022-04-21 16:45:40,947 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om3_1        | 2022-04-21 16:45:41,630 [main] INFO reflections.Reflections: Reflections took 1590 ms to scan 7 urls, producing 20 keys and 355 values [using 2 cores]
om3_1        | 2022-04-21 16:45:42,586 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om3_1        | 2022-04-21 16:45:42,652 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om1_1        | 2022-04-21 16:45:55,777 [om1@group-562213E44849-FollowerState] INFO impl.FollowerState: om1@group-562213E44849-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5067697430ns, electionTimeout:5021ms
om1_1        | 2022-04-21 16:45:55,777 [om1@group-562213E44849-FollowerState] INFO impl.RoleInfo: om1: shutdown om1@group-562213E44849-FollowerState
om1_1        | 2022-04-21 16:45:55,778 [om1@group-562213E44849-FollowerState] INFO server.RaftServer$Division: om1@group-562213E44849: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
om1_1        | 2022-04-21 16:45:55,778 [om1@group-562213E44849-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om1_1        | 2022-04-21 16:45:55,779 [om1@group-562213E44849-FollowerState] INFO impl.RoleInfo: om1: start om1@group-562213E44849-LeaderElection2
om1_1        | 2022-04-21 16:45:55,785 [om1@group-562213E44849-LeaderElection2] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection2 ELECTION round 0: submit vote requests at term 2 for -1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1        | 2022-04-21 16:45:55,838 [om1@group-562213E44849-LeaderElection2] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection2: ELECTION PASSED received 1 response(s) and 0 exception(s):
om1_1        | 2022-04-21 16:45:55,855 [om1@group-562213E44849-LeaderElection2] INFO impl.LeaderElection:   Response 0: om1<-om2#0:OK-t2
om1_1        | 2022-04-21 16:45:55,856 [om1@group-562213E44849-LeaderElection2] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection2 ELECTION round 0: result PASSED
om1_1        | 2022-04-21 16:45:55,857 [om1@group-562213E44849-LeaderElection2] INFO impl.RoleInfo: om1: shutdown om1@group-562213E44849-LeaderElection2
om1_1        | 2022-04-21 16:45:55,857 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServer$Division: om1@group-562213E44849: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
om1_1        | 2022-04-21 16:45:55,857 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServer$Division: om1@group-562213E44849: change Leader from null to om1 at term 2 for becomeLeader, leader elected after 17615ms
om1_1        | 2022-04-21 16:45:55,871 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
om1_1        | 2022-04-21 16:45:55,880 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
om1_1        | 2022-04-21 16:45:55,882 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
om1_1        | 2022-04-21 16:45:55,895 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
om1_1        | 2022-04-21 16:45:55,895 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
om1_1        | 2022-04-21 16:45:55,896 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
om1_1        | 2022-04-21 16:45:55,906 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
om1_1        | 2022-04-21 16:45:55,923 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
om1_1        | 2022-04-21 16:45:55,954 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
om1_1        | 2022-04-21 16:45:55,958 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om1_1        | 2022-04-21 16:45:55,960 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
om1_1        | 2022-04-21 16:45:55,981 [om1@group-562213E44849-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
om1_1        | 2022-04-21 16:45:55,991 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om1_1        | 2022-04-21 16:45:55,991 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om1_1        | 2022-04-21 16:45:56,000 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
om1_1        | 2022-04-21 16:45:56,004 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om1_1        | 2022-04-21 16:45:56,004 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
om1_1        | 2022-04-21 16:45:56,005 [om1@group-562213E44849-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
om1_1        | 2022-04-21 16:45:56,005 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om1_1        | 2022-04-21 16:45:56,005 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om1_1        | 2022-04-21 16:45:56,012 [om1@group-562213E44849-LeaderElection2] INFO impl.RoleInfo: om1: start om1@group-562213E44849-LeaderStateImpl
om1_1        | 2022-04-21 16:45:56,063 [om1@group-562213E44849-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: Starting segment from index:0
om1_1        | 2022-04-21 16:45:56,144 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServer$Division: om1@group-562213E44849: set configuration 0: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om1_1        | 2022-04-21 16:45:56,338 [om1@group-562213E44849-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/current/log_inprogress_0
om1_1        | 2022-04-21 16:45:56,752 [om1@group-562213E44849-StateMachineUpdater] INFO ratis.OzoneManagerStateMachine: Received Configuration change notification from Ratis. New Peer list:
om1_1        | [id: "om1"
om1_1        | address: "om1:9872"
om1_1        | , id: "om3"
om1_1        | address: "om3:9872"
om1_1        | , id: "om2"
scm3.org_1   | 2022-04-21 16:44:17,829 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm3.org_1   | 2022-04-21 16:44:17,853 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm3.org_1   | 2022-04-21 16:44:17,853 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm3.org_1   | 2022-04-21 16:44:17,909 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm3.org_1   | 2022-04-21 16:44:17,923 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm3.org_1   | 2022-04-21 16:44:17,923 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
scm3.org_1   | 2022-04-21 16:44:17,955 [pool-14-thread-1] INFO segmented.SegmentedRaftLogWorker: new 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/37768e1b-cb4c-49da-b09f-824fabcc98dc
scm3.org_1   | 2022-04-21 16:44:17,956 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
scm3.org_1   | 2022-04-21 16:44:17,956 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm3.org_1   | 2022-04-21 16:44:17,957 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm3.org_1   | 2022-04-21 16:44:17,957 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
scm3.org_1   | 2022-04-21 16:44:17,958 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
s3g_1        | 2022-04-21 16:51:34,986 [qtp440736059-23] WARN impl.MetricsSystemImpl: S3Gateway metrics system already initialized!
s3g_1        | 2022-04-21 16:51:35,278 [qtp440736059-23] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
s3g_1        | 2022-04-21 16:51:49,309 [qtp440736059-20] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-1324058591, with testuser as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-04-21 16:51:49,327 [qtp440736059-20] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-1324058591
s3g_1        | 2022-04-21 16:51:49,868 [qtp440736059-19] INFO rpc.RpcClient: Creating Bucket: s3v/ozone-test-iivwcokihe, with testuser as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-04-21 16:51:49,896 [qtp440736059-19] INFO endpoint.BucketEndpoint: Location is /ozone-test-iivwcokihe
s3g_1        | 2022-04-21 16:52:05,974 [qtp440736059-22] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-miyukjhjbq, with testuser as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-04-21 16:52:05,993 [qtp440736059-22] INFO endpoint.BucketEndpoint: Location is /bucket-miyukjhjbq
s3g_1        | 2022-04-21 16:52:21,063 [qtp440736059-22] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-4268886784, with testuser as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-04-21 16:52:21,075 [qtp440736059-22] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-4268886784
s3g_1        | 2022-04-21 16:52:21,681 [qtp440736059-22] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-1890813946, with testuser as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-04-21 16:52:21,702 [qtp440736059-22] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-1890813946
s3g_1        | 2022-04-21 16:52:22,310 [qtp440736059-23] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-8475151662, with testuser as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-04-21 16:52:22,329 [qtp440736059-23] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-8475151662
s3g_1        | 2022-04-21 16:52:22,937 [qtp440736059-23] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-8475151662, with testuser as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-04-21 16:52:22,960 [qtp440736059-23] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-8475151662
s3g_1        | 2022-04-21 16:52:30,675 [qtp440736059-23] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-9441853734, with testuser as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-04-21 16:52:30,688 [qtp440736059-23] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-9441853734
scm2.org_1   | 2022-04-21 16:43:58,392 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm2.org_1   | 2022-04-21 16:43:58,425 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm2.org_1   | 2022-04-21 16:43:58,453 [main] INFO server.RaftServer: d794df5a-ece1-4828-94ba-97e720366f72: addNew group-824FABCC98DC:[] returns group-824FABCC98DC:java.util.concurrent.CompletableFuture@482a58c7[Not completed]
scm2.org_1   | 2022-04-21 16:43:58,520 [pool-14-thread-1] INFO server.RaftServer$Division: d794df5a-ece1-4828-94ba-97e720366f72: new RaftServerImpl for group-824FABCC98DC:[] with SCMStateMachine:uninitialized
scm2.org_1   | 2022-04-21 16:43:58,540 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm2.org_1   | 2022-04-21 16:43:58,547 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm2.org_1   | 2022-04-21 16:43:58,548 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm2.org_1   | 2022-04-21 16:43:58,549 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm2.org_1   | 2022-04-21 16:43:58,549 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm2.org_1   | 2022-04-21 16:43:58,549 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
scm2.org_1   | 2022-04-21 16:43:58,550 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm2.org_1   | 2022-04-21 16:43:58,554 [pool-14-thread-1] INFO server.RaftServer$Division: d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
scm2.org_1   | 2022-04-21 16:43:58,564 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm2.org_1   | 2022-04-21 16:43:58,584 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm2.org_1   | 2022-04-21 16:43:58,588 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
scm2.org_1   | 2022-04-21 16:43:58,590 [pool-14-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/37768e1b-cb4c-49da-b09f-824fabcc98dc does not exist. Creating ...
scm2.org_1   | 2022-04-21 16:43:58,630 [pool-14-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/37768e1b-cb4c-49da-b09f-824fabcc98dc/in_use.lock acquired by nodename 8@scm2.org
scm2.org_1   | 2022-04-21 16:43:58,675 [pool-14-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/37768e1b-cb4c-49da-b09f-824fabcc98dc has been successfully formatted.
scm2.org_1   | 2022-04-21 16:43:58,698 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm1.org_1   | 2022-04-21 16:43:19,848 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.116,host:scm1.org
scm1.org_1   | 2022-04-21 16:43:19,848 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm1.org_1   | 2022-04-21 16:43:20,083 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.116,host:scm1.org
scm1.org_1   | 2022-04-21 16:43:20,083 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
om2_1        | 2022-04-21 16:45:55,812 [grpc-default-executor-3] INFO impl.RoleInfo: om2: shutdown om2@group-562213E44849-FollowerState
om2_1        | 2022-04-21 16:45:55,814 [grpc-default-executor-3] INFO impl.RoleInfo: om2: start om2@group-562213E44849-FollowerState
om2_1        | 2022-04-21 16:45:55,813 [om2@group-562213E44849-FollowerState] INFO impl.FollowerState: om2@group-562213E44849-FollowerState was interrupted: {}
om2_1        | java.lang.InterruptedException: sleep interrupted
om2_1        | 	at java.base/java.lang.Thread.sleep(Native Method)
om2_1        | 	at java.base/java.lang.Thread.sleep(Thread.java:334)
om2_1        | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
om2_1        | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
om2_1        | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
om2_1        | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
om2_1        | 2022-04-21 16:45:55,821 [grpc-default-executor-3] INFO server.RaftServer$Division: om2@group-562213E44849 replies to ELECTION vote request: om1<-om2#0:OK-t2. Peer's state: om2@group-562213E44849:t2, leader=null, voted=om1, raftlog=om2@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om2_1        | 2022-04-21 16:45:56,203 [grpc-default-executor-3] INFO server.RaftServer$Division: om2@group-562213E44849: change Leader from null to om1 at term 2 for appendEntries, leader elected after 16073ms
om2_1        | 2022-04-21 16:45:56,303 [grpc-default-executor-3] INFO server.RaftServer$Division: om2@group-562213E44849: set configuration 0: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om2_1        | 2022-04-21 16:45:56,337 [grpc-default-executor-3] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: Starting segment from index:0
om2_1        | 2022-04-21 16:45:56,708 [om2@group-562213E44849-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/current/log_inprogress_0
om2_1        | 2022-04-21 16:45:59,477 [om2@group-562213E44849-StateMachineUpdater] INFO ratis.OzoneManagerStateMachine: Received Configuration change notification from Ratis. New Peer list:
om2_1        | [id: "om1"
om2_1        | address: "om1:9872"
om2_1        | , id: "om3"
recon_1      | 2022-04-21 16:43:54,471 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
recon_1      | 2022-04-21 16:43:54,471 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Recon metrics system started
recon_1      | 2022-04-21 16:43:54,963 [Listener at 0.0.0.0/9891] INFO http.HttpServer2: Jetty bound to port 9888
recon_1      | 2022-04-21 16:43:54,964 [Listener at 0.0.0.0/9891] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
recon_1      | 2022-04-21 16:43:55,012 [Listener at 0.0.0.0/9891] INFO server.session: DefaultSessionIdManager workerName=node0
recon_1      | 2022-04-21 16:43:55,013 [Listener at 0.0.0.0/9891] INFO server.session: No SessionScavenger set, using defaults
recon_1      | 2022-04-21 16:43:55,014 [Listener at 0.0.0.0/9891] INFO server.session: node0 Scavenging every 600000ms
recon_1      | 2022-04-21 16:43:55,063 [Listener at 0.0.0.0/9891] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/recon.keytab, for principal HTTP/recon@EXAMPLE.COM
recon_1      | 2022-04-21 16:43:55,065 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5bb90b89{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
recon_1      | 2022-04-21 16:43:55,072 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7e44f989{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-recon-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
recon_1      | 2022-04-21 16:43:55,751 [Listener at 0.0.0.0/9891] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/recon.keytab, for principal HTTP/recon@EXAMPLE.COM
recon_1      | 2022-04-21 16:43:55,765 [Listener at 0.0.0.0/9891] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/recon.keytab, for principal HTTP/recon@EXAMPLE.COM
recon_1      | 2022-04-21 16:43:59,371 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@1dd2c22a{recon,/,file:///tmp/jetty-0_0_0_0-9888-ozone-recon-1_3_0-SNAPSHOT_jar-_-any-11520452322086288007/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-recon-1.3.0-SNAPSHOT.jar!/webapps/recon}
recon_1      | 2022-04-21 16:43:59,398 [Listener at 0.0.0.0/9891] INFO server.AbstractConnector: Started ServerConnector@304cad3a{HTTP/1.1, (http/1.1)}{0.0.0.0:9888}
recon_1      | 2022-04-21 16:43:59,399 [Listener at 0.0.0.0/9891] INFO server.Server: Started @54346ms
recon_1      | 2022-04-21 16:43:59,407 [Listener at 0.0.0.0/9891] INFO impl.MetricsSinkAdapter: Sink prometheus started
recon_1      | 2022-04-21 16:43:59,408 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Registered sink prometheus
recon_1      | 2022-04-21 16:43:59,409 [Listener at 0.0.0.0/9891] INFO http.BaseHttpServer: HTTP server of recon listening at http://0.0.0.0:9888
recon_1      | 2022-04-21 16:43:59,410 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Starting Ozone Manager Service Provider.
recon_1      | 2022-04-21 16:43:59,441 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Registered OmDeltaRequest task 
recon_1      | 2022-04-21 16:43:59,469 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Registered OmSnapshotRequest task 
recon_1      | 2022-04-21 16:43:59,470 [Listener at 0.0.0.0/9891] INFO recovery.ReconOmMetadataManagerImpl: Starting ReconOMMetadataManagerImpl
recon_1      | 2022-04-21 16:43:59,470 [Listener at 0.0.0.0/9891] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 2022-04-21 16:43:59,493 [Listener at 0.0.0.0/9891] INFO tasks.ReconTaskControllerImpl: Starting Recon Task Controller.
recon_1      | 2022-04-21 16:43:59,503 [Listener at 0.0.0.0/9891] INFO scm.ReconStorageContainerManagerFacade: Recon ScmDatanodeProtocol RPC server is listening at /0.0.0.0:9891
recon_1      | 2022-04-21 16:44:00,074 [Listener at 0.0.0.0/9891] INFO scm.ReconStorageContainerManagerFacade: Obtained 0 pipelines from SCM.
recon_1      | 2022-04-21 16:44:00,074 [Listener at 0.0.0.0/9891] INFO scm.ReconPipelineManager: Recon has 0 pipelines in house.
recon_1      | 2022-04-21 16:44:00,075 [Listener at 0.0.0.0/9891] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9891
recon_1      | 2022-04-21 16:44:00,076 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
recon_1      | 2022-04-21 16:44:00,078 [IPC Server listener on 9891] INFO ipc.Server: IPC Server listener on 9891: starting
recon_1      | 2022-04-21 16:44:00,125 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Registered ContainerHealthTask task 
scm1.org_1   | 2022-04-21 16:43:20,091 [main] INFO ha.HASecurityUtils: Creating csr for SCM->hostName:scm1.org,scmId:e8ea6b57-c3ba-42bd-9807-0913ca4228d7,clusterId:CID-37768e1b-cb4c-49da-b09f-824fabcc98dc,subject:scm-sub@scm1.org
scm1.org_1   | 2022-04-21 16:43:20,205 [main] INFO ha.HASecurityUtils: Successfully stored SCM signed certificate.
scm1.org_1   | 2022-04-21 16:43:20,435 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
scm1.org_1   | 2022-04-21 16:43:20,551 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
scm1.org_1   | 2022-04-21 16:43:20,552 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
om3_1        | 2022-04-21 16:45:43,212 [Listener at om3/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om3_1        | 2022-04-21 16:45:43,278 [Listener at om3/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om3_1        | 2022-04-21 16:45:43,278 [Listener at om3/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om3_1        | 2022-04-21 16:45:43,491 [Listener at om3/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om3/172.25.0.113:9862
om3_1        | 2022-04-21 16:45:43,491 [Listener at om3/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om3 at port 9872
scm1.org_1   | 2022-04-21 16:43:20,552 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
scm1.org_1   | 2022-04-21 16:43:20,553 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2022-04-21 16:43:20,555 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2022-04-21 16:43:20,556 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
scm1.org_1   | 2022-04-21 16:43:20,560 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2022-04-21 16:43:20,561 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm1.org_1   | 2022-04-21 16:43:20,561 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm1.org_1   | 2022-04-21 16:43:20,889 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
scm1.org_1   | 2022-04-21 16:43:20,898 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm1.org_1   | 2022-04-21 16:43:20,898 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm1.org_1   | 2022-04-21 16:43:20,923 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm1.org_1   | 2022-04-21 16:43:20,930 [main] INFO server.RaftServer: e8ea6b57-c3ba-42bd-9807-0913ca4228d7: addNew group-824FABCC98DC:[e8ea6b57-c3ba-42bd-9807-0913ca4228d7|rpc:scm1.org:9894|priority:0] returns group-824FABCC98DC:java.util.concurrent.CompletableFuture@2a8a4e0c[Not completed]
scm1.org_1   | 2022-04-21 16:43:20,981 [pool-2-thread-1] INFO server.RaftServer$Division: e8ea6b57-c3ba-42bd-9807-0913ca4228d7: new RaftServerImpl for group-824FABCC98DC:[e8ea6b57-c3ba-42bd-9807-0913ca4228d7|rpc:scm1.org:9894|priority:0] with SCMStateMachine:uninitialized
scm1.org_1   | 2022-04-21 16:43:20,984 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm1.org_1   | 2022-04-21 16:43:20,984 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm1.org_1   | 2022-04-21 16:43:20,984 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm1.org_1   | 2022-04-21 16:43:20,984 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm1.org_1   | 2022-04-21 16:43:20,984 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm1.org_1   | 2022-04-21 16:43:20,984 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
scm1.org_1   | 2022-04-21 16:43:20,985 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm1.org_1   | 2022-04-21 16:43:20,989 [pool-2-thread-1] INFO server.RaftServer$Division: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC: ConfigurationManager, init=-1: [e8ea6b57-c3ba-42bd-9807-0913ca4228d7|rpc:scm1.org:9894|priority:0], old=null, confs=<EMPTY_MAP>
scm1.org_1   | 2022-04-21 16:43:20,990 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm1.org_1   | 2022-04-21 16:43:20,993 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm1.org_1   | 2022-04-21 16:43:20,994 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
scm1.org_1   | 2022-04-21 16:43:20,995 [pool-2-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/37768e1b-cb4c-49da-b09f-824fabcc98dc does not exist. Creating ...
scm1.org_1   | 2022-04-21 16:43:21,023 [pool-2-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/37768e1b-cb4c-49da-b09f-824fabcc98dc/in_use.lock acquired by nodename 93@scm1.org
scm1.org_1   | 2022-04-21 16:43:21,040 [pool-2-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/37768e1b-cb4c-49da-b09f-824fabcc98dc has been successfully formatted.
scm1.org_1   | 2022-04-21 16:43:21,044 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm1.org_1   | 2022-04-21 16:43:21,045 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm1.org_1   | 2022-04-21 16:43:21,056 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm1.org_1   | 2022-04-21 16:43:21,056 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2022-04-21 16:43:21,064 [pool-2-thread-1] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm3.org_1   | 2022-04-21 16:44:17,964 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm3.org_1   | 2022-04-21 16:44:17,964 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm3.org_1   | 2022-04-21 16:44:17,964 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm3.org_1   | 2022-04-21 16:44:17,982 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
scm3.org_1   | 2022-04-21 16:44:17,983 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
scm3.org_1   | 2022-04-21 16:44:17,989 [pool-14-thread-1] INFO segmented.SegmentedRaftLogWorker: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm3.org_1   | 2022-04-21 16:44:17,989 [pool-14-thread-1] INFO segmented.SegmentedRaftLogWorker: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm3.org_1   | 2022-04-21 16:44:17,992 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om3_1        | 2022-04-21 16:45:43,493 [Listener at om3/9862] INFO server.RaftServer$Division: om3@group-562213E44849: start as a follower, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
s3g_1        | 2022-04-21 16:52:31,286 [qtp440736059-22] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-4686250488, with testuser as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-04-21 16:52:31,301 [qtp440736059-22] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-4686250488
om3_1        | 2022-04-21 16:45:43,502 [Listener at om3/9862] INFO server.RaftServer$Division: om3@group-562213E44849: changes role from      null to FOLLOWER at term 0 for startAsFollower
om3_1        | 2022-04-21 16:45:43,506 [Listener at om3/9862] INFO impl.RoleInfo: om3: start om3@group-562213E44849-FollowerState
om3_1        | 2022-04-21 16:45:43,514 [Listener at om3/9862] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-562213E44849,id=om3
om3_1        | 2022-04-21 16:45:43,568 [Listener at om3/9862] INFO server.RaftServer: om3: start RPC server
s3g_1        | 2022-04-21 16:52:39,139 [qtp440736059-22] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-5308852827, with testuser as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-04-21 16:52:39,156 [qtp440736059-22] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-5308852827
s3g_1        | 2022-04-21 16:52:46,721 [qtp440736059-22] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-5640325463, with testuser as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-04-21 16:52:46,737 [qtp440736059-22] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-5640325463
s3g_1        | 2022-04-21 16:52:52,509 [qtp440736059-22] ERROR signature.AuthorizationV4HeaderParser: AWS access id shouldn't be empty. credential:/20220421/us-west-1/s3/aws4_request
scm2.org_1   | 2022-04-21 16:43:58,711 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm2.org_1   | 2022-04-21 16:43:58,741 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm2.org_1   | 2022-04-21 16:43:58,743 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm2.org_1   | 2022-04-21 16:43:58,780 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm2.org_1   | 2022-04-21 16:43:58,805 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm2.org_1   | 2022-04-21 16:43:58,817 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om2_1        | address: "om3:9872"
om2_1        | , id: "om2"
scm3.org_1   | 2022-04-21 16:44:17,993 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
scm3.org_1   | 2022-04-21 16:44:17,994 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
scm3.org_1   | 2022-04-21 16:44:17,994 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm3.org_1   | 2022-04-21 16:44:17,996 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
scm3.org_1   | 2022-04-21 16:44:17,996 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm3.org_1   | 2022-04-21 16:44:18,026 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
om3_1        | 2022-04-21 16:45:43,759 [Listener at om3/9862] INFO server.GrpcService: om3: GrpcService started, listening on 9872
om3_1        | 2022-04-21 16:45:43,770 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$412/0x00000008405e7040@140db646] INFO util.JvmPauseMonitor: JvmPauseMonitor-om3: Started
om3_1        | 2022-04-21 16:45:43,776 [Listener at om3/9862] INFO om.OzoneManager: Starting OM block token secret manager
om3_1        | 2022-04-21 16:45:43,776 [Listener at om3/9862] INFO security.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
om3_1        | 2022-04-21 16:45:43,778 [Listener at om3/9862] INFO om.OzoneManager: Starting OM delegation token secret manager
om3_1        | 2022-04-21 16:45:43,778 [Listener at om3/9862] INFO security.OzoneDelegationTokenSecretManager: Updating the current master key for generating tokens
om3_1        | 2022-04-21 16:45:43,806 [Listener at om3/9862] INFO om.OzoneManager: Version File has different layout version (1) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
om3_1        | 2022-04-21 16:45:43,806 [Thread[Thread-17,5,main]] INFO security.OzoneDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
om3_1        | 2022-04-21 16:45:44,015 [Listener at om3/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om3_1        | 2022-04-21 16:45:44,016 [Listener at om3/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
om3_1        | 2022-04-21 16:45:44,017 [Listener at om3/9862] INFO http.BaseHttpServer: HttpAuthType: ozone.om.http.auth.type = kerberos
om3_1        | 2022-04-21 16:45:44,210 [Listener at om3/9862] INFO util.log: Logging initialized @42208ms to org.eclipse.jetty.util.log.Slf4jLog
om3_1        | 2022-04-21 16:45:44,776 [Listener at om3/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om3_1        | 2022-04-21 16:45:44,783 [Listener at om3/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om2_1        | address: "om2:9872"
om2_1        | ]
om2_1        | 2022-04-21 16:46:13,239 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:vol1 for user:testuser
om2_1        | 2022-04-21 16:46:13,321 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket1 of layout LEGACY in volume: vol1
om2_1        | 2022-04-21 16:46:28,858 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ombg0 of layout LEGACY in volume: vol1
om2_1        | 2022-04-21 16:46:46,900 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ombr0 of layout LEGACY in volume: vol1
om2_1        | 2022-04-21 16:47:11,048 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:00630-source for user:testuser
om2_1        | 2022-04-21 16:47:15,231 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:00630-target for user:testuser
om2_1        | 2022-04-21 16:47:19,236 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: readable-bucket of layout OBJECT_STORE in volume: 00630-source
s3g_1        | Apr 21, 2022 4:52:52 PM org.glassfish.jersey.internal.Errors logErrors
s3g_1        | WARNING: The following warnings have been detected: WARNING: Unknown HK2 failure detected:
s3g_1        | MultiException stack 1 of 1
s3g_1        | javax.ws.rs.WebApplicationException: The authorization header you provided is invalid.
s3g_1        | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.wrapOS3Exception(OzoneClientProducer.java:146)
s3g_1        | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getSignature(OzoneClientProducer.java:106)
s3g_1        | 	at jdk.internal.reflect.GeneratedMethodAccessor19.invoke(Unknown Source)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
scm3.org_1   | 2022-04-21 16:44:18,027 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
scm3.org_1   | 2022-04-21 16:44:18,028 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
scm3.org_1   | 2022-04-21 16:44:18,206 [main] INFO ha.SequenceIdGenerator: upgrade localId to 109611004723200000
scm3.org_1   | 2022-04-21 16:44:18,206 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
scm3.org_1   | 2022-04-21 16:44:18,210 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
scm3.org_1   | 2022-04-21 16:44:18,218 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
scm3.org_1   | 2022-04-21 16:44:18,270 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm3.org_1   | 2022-04-21 16:44:18,294 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm3.org_1   | 2022-04-21 16:44:18,333 [main] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
scm3.org_1   | 2022-04-21 16:44:18,371 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
scm3.org_1   | 2022-04-21 16:44:18,372 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
scm3.org_1   | 2022-04-21 16:44:18,379 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
scm2.org_1   | 2022-04-21 16:43:58,823 [pool-14-thread-1] INFO segmented.SegmentedRaftLogWorker: new d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/37768e1b-cb4c-49da-b09f-824fabcc98dc
scm2.org_1   | 2022-04-21 16:43:58,832 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
scm2.org_1   | 2022-04-21 16:43:58,833 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm2.org_1   | 2022-04-21 16:43:58,834 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm2.org_1   | 2022-04-21 16:43:58,834 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
scm2.org_1   | 2022-04-21 16:43:58,835 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm2.org_1   | 2022-04-21 16:43:58,841 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm2.org_1   | 2022-04-21 16:43:58,841 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm2.org_1   | 2022-04-21 16:43:58,842 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
recon_1      | 2022-04-21 16:44:00,125 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Starting ContainerHealthTask Thread.
recon_1      | 2022-04-21 16:44:00,138 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Registered PipelineSyncTask task 
recon_1      | 2022-04-21 16:44:00,147 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Starting PipelineSyncTask Thread.
recon_1      | 2022-04-21 16:44:00,188 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 0 pipelines in house.
recon_1      | 2022-04-21 16:44:00,194 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 30 milliseconds.
recon_1      | 2022-04-21 16:44:19,496 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-04-21 16:44:19,496 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-04-21 16:44:19,571 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-21 16:44:19,574 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-21 16:44:21,576 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 3 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-21 16:44:21,580 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 4 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-21 16:44:21,581 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
om2_1        | 2022-04-21 16:47:31,945 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: unreadable-bucket of layout OBJECT_STORE in volume: 00630-source
om2_1        | 2022-04-21 16:47:36,314 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: readable-link of layout LEGACY in volume: 00630-target
om2_1        | 2022-04-21 16:47:40,119 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: unreadable-link of layout LEGACY in volume: 00630-target
om2_1        | 2022-04-21 16:47:43,934 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link-to-unreadable-bucket of layout LEGACY in volume: 00630-target
om2_1        | 2022-04-21 16:48:07,375 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: dangling-link of layout LEGACY in volume: 00630-target
om2_1        | 2022-04-21 16:48:15,107 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link1 of layout LEGACY in volume: 00630-target
om2_1        | 2022-04-21 16:48:18,744 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket1 of layout OBJECT_STORE in volume: 00630-source
om2_1        | 2022-04-21 16:49:39,113 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link2 of layout LEGACY in volume: 00630-target
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
s3g_1        | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1        | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1        | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
s3g_1        | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1        | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
om3_1        | 2022-04-21 16:45:44,793 [Listener at om3/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context ozoneManager
om3_1        | 2022-04-21 16:45:44,793 [Listener at om3/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
scm2.org_1   | 2022-04-21 16:43:58,901 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
scm2.org_1   | 2022-04-21 16:43:58,902 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
scm2.org_1   | 2022-04-21 16:43:58,934 [pool-14-thread-1] INFO segmented.SegmentedRaftLogWorker: d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm3.org_1   | 2022-04-21 16:44:18,379 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
scm3.org_1   | 2022-04-21 16:44:18,420 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
scm3.org_1   | 2022-04-21 16:44:18,437 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
scm3.org_1   | 2022-04-21 16:44:18,459 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
scm3.org_1   | 2022-04-21 16:44:18,470 [main] INFO container.ReplicationManager: Starting Replication Monitor Thread.
scm3.org_1   | 2022-04-21 16:44:18,479 [ReplicationMonitor] INFO container.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm3.org_1   | 2022-04-21 16:44:18,486 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
scm3.org_1   | 2022-04-21 16:44:18,489 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
om3_1        | 2022-04-21 16:45:44,793 [Listener at om3/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
om3_1        | 2022-04-21 16:45:44,812 [Listener at om3/9862] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.om.http.auth.kerberos.principal keytabKey: ozone.om.http.auth.kerberos.keytab
om3_1        | 2022-04-21 16:45:45,040 [Listener at om3/9862] INFO http.HttpServer2: Jetty bound to port 9874
om3_1        | 2022-04-21 16:45:45,044 [Listener at om3/9862] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
om3_1        | 2022-04-21 16:45:45,364 [Listener at om3/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om3_1        | 2022-04-21 16:45:45,367 [Listener at om3/9862] INFO server.session: No SessionScavenger set, using defaults
om1_1        | address: "om2:9872"
om1_1        | ]
om1_1        | 2022-04-21 16:45:57,109 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39144
om1_1        | 2022-04-21 16:45:57,154 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 16:46:11,800 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39184
om1_1        | 2022-04-21 16:46:11,834 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2022-04-21 16:43:58,936 [pool-14-thread-1] INFO segmented.SegmentedRaftLogWorker: d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm2.org_1   | 2022-04-21 16:43:58,953 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm2.org_1   | 2022-04-21 16:43:58,954 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
scm2.org_1   | 2022-04-21 16:43:58,955 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
scm2.org_1   | 2022-04-21 16:43:58,956 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm2.org_1   | 2022-04-21 16:43:58,965 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
om2_1        | 2022-04-21 16:49:42,942 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:link2 in volume:00630-target
om2_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om2_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:204)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:514)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:317)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1        | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1        | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1        | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1        | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1        | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1        | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1        | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1        | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
scm1.org_1   | 2022-04-21 16:43:21,194 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm1.org_1   | 2022-04-21 16:43:21,216 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm1.org_1   | 2022-04-21 16:43:21,217 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
recon_1      | 2022-04-21 16:44:23,585 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 6 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-21 16:44:23,587 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 7 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-21 16:44:23,588 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 8 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-21 16:44:25,591 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 9 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-21 16:44:25,592 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 10 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-21 16:44:25,593 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 11 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-21 16:44:27,594 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 12 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-21 16:44:27,596 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 13 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-21 16:44:27,597 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 14 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-21 16:44:29,599 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 15 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-21 16:44:29,600 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 16 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-21 16:44:29,600 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 17 failover attempts. Trying to failover after sleeping for 2000ms.
scm1.org_1   | 2022-04-21 16:43:21,222 [pool-2-thread-1] INFO segmented.SegmentedRaftLogWorker: new e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/37768e1b-cb4c-49da-b09f-824fabcc98dc
om3_1        | 2022-04-21 16:45:45,369 [Listener at om3/9862] INFO server.session: node0 Scavenging every 660000ms
om1_1        | 2022-04-21 16:46:12,665 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:vol1 for user:testuser
om1_1        | 2022-04-21 16:46:12,933 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket1 of layout LEGACY in volume: vol1
om1_1        | 2022-04-21 16:46:23,099 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39232
om1_1        | 2022-04-21 16:46:23,119 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 16:46:23,749 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39234
scm2.org_1   | 2022-04-21 16:43:58,966 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm2.org_1   | 2022-04-21 16:43:59,053 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
scm3.org_1   | 2022-04-21 16:44:18,501 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm3.org_1   | 2022-04-21 16:44:18,555 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
scm3.org_1   | 2022-04-21 16:44:18,585 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm1.org_1   | 2022-04-21 16:43:21,226 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
scm1.org_1   | 2022-04-21 16:43:21,227 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm1.org_1   | 2022-04-21 16:43:21,228 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om3_1        | 2022-04-21 16:45:45,548 [Listener at om3/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om3_1        | 2022-04-21 16:45:45,579 [Listener at om3/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2907d3e8{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-04-21 16:49:47,103 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket3 of layout OBJECT_STORE in volume: 00630-target
om2_1        | 2022-04-21 16:49:50,970 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket3 in volume:00630-target
om2_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om2_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:204)
s3g_1        | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1        | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
s3g_1        | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
s3g_1        | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:874)
s3g_1        | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1        | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1        | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
scm2.org_1   | 2022-04-21 16:43:59,054 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
scm2.org_1   | 2022-04-21 16:43:59,054 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
scm2.org_1   | 2022-04-21 16:43:59,480 [main] INFO ha.SequenceIdGenerator: upgrade localId to 109611004723200000
scm2.org_1   | 2022-04-21 16:43:59,480 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
scm2.org_1   | 2022-04-21 16:43:59,494 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
scm2.org_1   | 2022-04-21 16:43:59,505 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
scm2.org_1   | 2022-04-21 16:43:59,634 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm2.org_1   | 2022-04-21 16:43:59,659 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
om3_1        | 2022-04-21 16:45:45,584 [Listener at om3/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@3f321f8{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm3.org_1   | 2022-04-21 16:44:18,620 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
scm3.org_1   | 2022-04-21 16:44:19,418 [Listener at 0.0.0.0/9961] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm3.org_1   | 2022-04-21 16:44:19,454 [Listener at 0.0.0.0/9961] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm3.org_1   | 2022-04-21 16:44:19,468 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm3.org_1   | 2022-04-21 16:44:19,542 [Listener at 0.0.0.0/9861] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm3.org_1   | 2022-04-21 16:44:19,549 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm3.org_1   | 2022-04-21 16:44:19,553 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm1.org_1   | 2022-04-21 16:43:21,228 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
scm1.org_1   | 2022-04-21 16:43:21,229 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm1.org_1   | 2022-04-21 16:43:21,230 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm1.org_1   | 2022-04-21 16:43:21,236 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm1.org_1   | 2022-04-21 16:43:21,237 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm1.org_1   | 2022-04-21 16:43:21,247 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
scm1.org_1   | 2022-04-21 16:43:21,253 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
scm1.org_1   | 2022-04-21 16:43:21,268 [pool-2-thread-1] INFO segmented.SegmentedRaftLogWorker: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm1.org_1   | 2022-04-21 16:43:21,276 [pool-2-thread-1] INFO segmented.SegmentedRaftLogWorker: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om1_1        | 2022-04-21 16:46:23,769 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 16:46:28,356 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39248
om1_1        | 2022-04-21 16:46:28,382 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 16:46:28,810 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39250
om1_1        | 2022-04-21 16:46:28,815 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 16:46:28,826 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ombg0 of layout LEGACY in volume: vol1
om3_1        | 2022-04-21 16:45:45,986 [Listener at om3/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om3_1        | 2022-04-21 16:45:46,037 [Listener at om3/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@74575124{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-ozone-manager-1_3_0-SNAPSHOT_jar-_-any-1602076671909882180/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/ozoneManager}
om3_1        | 2022-04-21 16:45:46,080 [Listener at om3/9862] INFO server.AbstractConnector: Started ServerConnector@301d1d3c{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
om3_1        | 2022-04-21 16:45:46,080 [Listener at om3/9862] INFO server.Server: Started @44078ms
om3_1        | 2022-04-21 16:45:46,084 [Listener at om3/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om3_1        | 2022-04-21 16:45:46,084 [Listener at om3/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om3_1        | 2022-04-21 16:45:46,090 [Listener at om3/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:514)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:317)
s3g_1        | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1        | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
scm2.org_1   | 2022-04-21 16:43:59,680 [main] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
scm2.org_1   | 2022-04-21 16:43:59,900 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
scm2.org_1   | 2022-04-21 16:43:59,908 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
scm3.org_1   | 2022-04-21 16:44:19,665 [Listener at 0.0.0.0/9863] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
recon_1      | 2022-04-21 16:44:31,602 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 18 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-21 16:44:31,603 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 19 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-21 16:44:31,604 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 20 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-21 16:44:33,605 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 21 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-21 16:44:33,606 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 22 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-21 16:44:33,607 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 23 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-21 16:44:35,610 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 24 failover attempts. Trying to failover immediately.
scm3.org_1   | 2022-04-21 16:44:19,687 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm3.org_1   | 2022-04-21 16:44:19,689 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm3.org_1   | 2022-04-21 16:44:19,771 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: 
scm3.org_1   | Container Balancer status:
om3_1        | 2022-04-21 16:45:46,090 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om3_1        | 2022-04-21 16:45:46,134 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om3_1        | 2022-04-21 16:45:46,261 [Listener at om3/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted will not move to trash
om3_1        | 2022-04-21 16:45:46,397 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@374ba9a8] INFO util.JvmPauseMonitor: Starting JVM pause monitor
s3g_1        | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
recon_1      | 2022-04-21 16:44:35,611 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 25 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-21 16:44:35,613 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 26 failover attempts. Trying to failover after sleeping for 2000ms.
om3_1        | 2022-04-21 16:45:47,521 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:34035
om3_1        | 2022-04-21 16:45:47,525 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-04-21 16:45:48,524 [om3@group-562213E44849-FollowerState] INFO impl.FollowerState: om3@group-562213E44849-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5018519961ns, electionTimeout:5000ms
scm2.org_1   | 2022-04-21 16:43:59,935 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
scm2.org_1   | 2022-04-21 16:43:59,937 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
recon_1      | 2022-04-21 16:44:37,614 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 27 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-21 16:44:37,615 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 28 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-21 16:44:37,616 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 29 failover attempts. Trying to failover after sleeping for 2000ms.
om1_1        | 2022-04-21 16:46:33,341 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39262
om1_1        | 2022-04-21 16:46:33,356 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 16:46:40,953 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39278
om1_1        | 2022-04-21 16:46:40,970 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 16:46:46,317 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39290
scm1.org_1   | 2022-04-21 16:43:21,287 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm1.org_1   | 2022-04-21 16:43:21,288 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
scm1.org_1   | 2022-04-21 16:43:21,289 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
scm1.org_1   | 2022-04-21 16:43:21,290 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm3.org_1   | Key                            Value
scm3.org_1   | Running                        false
scm3.org_1   | Container Balancer Configuration values:
om1_1        | 2022-04-21 16:46:46,336 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 16:46:46,819 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39292
om1_1        | 2022-04-21 16:46:46,866 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 16:46:46,880 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ombr0 of layout LEGACY in volume: vol1
om1_1        | 2022-04-21 16:46:51,505 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39328
om1_1        | 2022-04-21 16:46:51,524 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 16:46:56,127 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39340
om1_1        | 2022-04-21 16:46:56,148 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 16:46:58,041 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:41419
om1_1        | 2022-04-21 16:46:58,061 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 16:47:10,559 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39366
om1_1        | 2022-04-21 16:47:10,585 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 16:47:11,038 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:00630-source for user:testuser
scm3.org_1   | Key                                                Value
scm3.org_1   | Threshold                                          10
scm3.org_1   | Max Datanodes to Involve per Iteration(percent)    20
scm3.org_1   | Max Size to Move per Iteration                     500GB
om2_1        | 2022-04-21 16:50:11,115 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop2 of layout LEGACY in volume: 00630-target
om2_1        | 2022-04-21 16:50:15,084 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop3 of layout LEGACY in volume: 00630-target
om3_1        | 2022-04-21 16:45:48,527 [om3@group-562213E44849-FollowerState] INFO impl.RoleInfo: om3: shutdown om3@group-562213E44849-FollowerState
om3_1        | 2022-04-21 16:45:48,539 [om3@group-562213E44849-FollowerState] INFO server.RaftServer$Division: om3@group-562213E44849: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
om3_1        | 2022-04-21 16:45:48,543 [om3@group-562213E44849-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om3_1        | 2022-04-21 16:45:48,543 [om3@group-562213E44849-FollowerState] INFO impl.RoleInfo: om3: start om3@group-562213E44849-LeaderElection1
om3_1        | 2022-04-21 16:45:48,631 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om3@group-562213E44849-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1        | 2022-04-21 16:45:50,467 [grpc-default-executor-0] INFO server.RaftServer$Division: om3@group-562213E44849: receive requestVote(ELECTION, om1, group-562213E44849, 1, (t:0, i:~))
om3_1        | 2022-04-21 16:45:50,472 [grpc-default-executor-0] INFO impl.VoteContext: om3@group-562213E44849-CANDIDATE: reject ELECTION from om1: already has voted for om3 at current term 1
om2_1        | 2022-04-21 16:50:18,898 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop1 of layout LEGACY in volume: 00630-target
om2_1        | 2022-04-21 16:50:26,985 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link3 of layout LEGACY in volume: 00630-target
om2_1        | 2022-04-21 16:51:27,088 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-1938307693 of layout LEGACY in volume: s3v
om2_1        | 2022-04-21 16:51:33,806 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-3093588181 of layout LEGACY in volume: s3v
om3_1        | 2022-04-21 16:45:50,485 [grpc-default-executor-0] INFO server.RaftServer$Division: om3@group-562213E44849 replies to ELECTION vote request: om1<-om3#0:FAIL-t1. Peer's state: om3@group-562213E44849:t1, leader=null, voted=om3, raftlog=om3@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1        | 2022-04-21 16:45:50,744 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om3@group-562213E44849-LeaderElection1: ELECTION REJECTED received 2 response(s) and 0 exception(s):
om3_1        | 2022-04-21 16:45:50,744 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 0: om3<-om1#0:FAIL-t1
om3_1        | 2022-04-21 16:45:50,744 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 1: om3<-om2#0:FAIL-t1
om3_1        | 2022-04-21 16:45:50,744 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om3@group-562213E44849-LeaderElection1 ELECTION round 0: result REJECTED
om3_1        | 2022-04-21 16:45:50,745 [om3@group-562213E44849-LeaderElection1] INFO server.RaftServer$Division: om3@group-562213E44849: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
om3_1        | 2022-04-21 16:45:50,745 [om3@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om3: shutdown om3@group-562213E44849-LeaderElection1
scm1.org_1   | 2022-04-21 16:43:21,291 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
scm1.org_1   | 2022-04-21 16:43:21,291 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm1.org_1   | 2022-04-21 16:43:21,335 [main] INFO server.RaftServer$Division: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC: start as a follower, conf=-1: [e8ea6b57-c3ba-42bd-9807-0913ca4228d7|rpc:scm1.org:9894|priority:0], old=null
om1_1        | 2022-04-21 16:47:14,592 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39388
om1_1        | 2022-04-21 16:47:14,614 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 16:47:15,224 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:00630-target for user:testuser
om1_1        | 2022-04-21 16:47:18,727 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39426
om1_1        | 2022-04-21 16:47:18,752 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 16:47:19,226 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: readable-bucket of layout OBJECT_STORE in volume: 00630-source
om1_1        | 2022-04-21 16:47:22,556 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39430
om1_1        | 2022-04-21 16:47:22,600 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 16:47:31,387 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39454
om1_1        | 2022-04-21 16:47:31,409 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2022-04-21 16:43:21,337 [main] INFO server.RaftServer$Division: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC: changes role from      null to FOLLOWER at term 0 for startAsFollower
scm1.org_1   | 2022-04-21 16:43:21,338 [main] INFO impl.RoleInfo: e8ea6b57-c3ba-42bd-9807-0913ca4228d7: start e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-FollowerState
om1_1        | 2022-04-21 16:47:31,933 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: unreadable-bucket of layout OBJECT_STORE in volume: 00630-source
om1_1        | 2022-04-21 16:47:35,715 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39458
om1_1        | 2022-04-21 16:47:35,731 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 16:47:36,310 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: readable-link of layout LEGACY in volume: 00630-target
om1_1        | 2022-04-21 16:47:39,642 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39470
om1_1        | 2022-04-21 16:47:39,660 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 16:47:40,106 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: unreadable-link of layout LEGACY in volume: 00630-target
om1_1        | 2022-04-21 16:47:43,390 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39482
om1_1        | 2022-04-21 16:47:43,406 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-04-21 16:51:49,339 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-1324058591 of layout LEGACY in volume: s3v
om2_1        | 2022-04-21 16:51:49,889 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ozone-test-iivwcokihe of layout LEGACY in volume: s3v
om1_1        | 2022-04-21 16:47:43,926 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link-to-unreadable-bucket of layout LEGACY in volume: 00630-target
recon_1      | 2022-04-21 16:44:39,617 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 30 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-21 16:44:39,618 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 31 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-21 16:44:39,619 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 32 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-21 16:44:41,620 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 33 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-21 16:44:41,621 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 34 failover attempts. Trying to failover immediately.
scm1.org_1   | 2022-04-21 16:43:21,343 [main] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-824FABCC98DC,id=e8ea6b57-c3ba-42bd-9807-0913ca4228d7
scm1.org_1   | 2022-04-21 16:43:21,347 [main] INFO server.RaftServer: e8ea6b57-c3ba-42bd-9807-0913ca4228d7: start RPC server
recon_1      | 2022-04-21 16:44:41,622 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 35 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-21 16:44:43,623 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 36 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-21 16:44:43,624 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 37 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-21 16:44:43,626 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 38 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-21 16:44:45,627 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 39 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-21 16:44:45,628 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 40 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-21 16:44:45,629 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 41 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-21 16:44:47,630 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 42 failover attempts. Trying to failover immediately.
scm2.org_1   | 2022-04-21 16:44:00,049 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
scm2.org_1   | 2022-04-21 16:44:00,110 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
om2_1        | 2022-04-21 16:52:05,999 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-miyukjhjbq of layout LEGACY in volume: s3v
om2_1        | 2022-04-21 16:52:21,080 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-4268886784 of layout LEGACY in volume: s3v
scm1.org_1   | 2022-04-21 16:43:21,409 [main] INFO server.GrpcService: e8ea6b57-c3ba-42bd-9807-0913ca4228d7: GrpcService started, listening on 9894
om3_1        | 2022-04-21 16:45:50,745 [om3@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om3: start om3@group-562213E44849-FollowerState
om3_1        | 2022-04-21 16:45:50,899 [grpc-default-executor-0] INFO server.RaftServer$Division: om3@group-562213E44849: receive requestVote(ELECTION, om2, group-562213E44849, 1, (t:0, i:~))
om3_1        | 2022-04-21 16:45:50,899 [grpc-default-executor-0] INFO impl.VoteContext: om3@group-562213E44849-FOLLOWER: reject ELECTION from om2: already has voted for om3 at current term 1
om3_1        | 2022-04-21 16:45:50,899 [grpc-default-executor-0] INFO server.RaftServer$Division: om3@group-562213E44849 replies to ELECTION vote request: om2<-om3#0:FAIL-t1. Peer's state: om3@group-562213E44849:t1, leader=null, voted=om3, raftlog=om3@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1        | 2022-04-21 16:45:55,800 [grpc-default-executor-0] INFO server.RaftServer$Division: om3@group-562213E44849: receive requestVote(ELECTION, om1, group-562213E44849, 2, (t:0, i:~))
scm3.org_1   | Max Size Entering Target per Iteration             26GB
s3g_1        | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
scm1.org_1   | 2022-04-21 16:43:21,411 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$338/0x000000084031fc40@6dab01d9] INFO util.JvmPauseMonitor: JvmPauseMonitor-e8ea6b57-c3ba-42bd-9807-0913ca4228d7: Started
s3g_1        | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
scm2.org_1   | 2022-04-21 16:44:00,164 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
scm3.org_1   | Max Size Leaving Source per Iteration              26GB
scm3.org_1   | 
scm3.org_1   | 2022-04-21 16:44:19,771 [Listener at 0.0.0.0/9860] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
om2_1        | 2022-04-21 16:52:21,697 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-1890813946 of layout LEGACY in volume: s3v
recon_1      | 2022-04-21 16:44:47,634 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 43 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-21 16:44:47,635 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 44 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-21 16:44:49,636 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 45 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-21 16:44:49,637 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 46 failover attempts. Trying to failover immediately.
scm2.org_1   | 2022-04-21 16:44:00,198 [main] INFO container.ReplicationManager: Starting Replication Monitor Thread.
scm3.org_1   | 2022-04-21 16:44:19,771 [Listener at 0.0.0.0/9860] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
om3_1        | 2022-04-21 16:45:55,802 [grpc-default-executor-0] INFO impl.VoteContext: om3@group-562213E44849-FOLLOWER: accept ELECTION from om1: our priority 0 <= candidate's priority 0
om2_1        | 2022-04-21 16:52:22,325 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-8475151662 of layout LEGACY in volume: s3v
om2_1        | 2022-04-21 16:52:22,968 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket-ozone-test-8475151662 in volume:s3v
recon_1      | 2022-04-21 16:44:49,639 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 47 failover attempts. Trying to failover after sleeping for 2000ms.
s3g_1        | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:127)
s3g_1        | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:69)
s3g_1        | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:103)
s3g_1        | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:46)
s3g_1        | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:53)
om3_1        | 2022-04-21 16:45:55,803 [grpc-default-executor-0] INFO server.RaftServer$Division: om3@group-562213E44849: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:om1
om3_1        | 2022-04-21 16:45:55,803 [grpc-default-executor-0] INFO impl.RoleInfo: om3: shutdown om3@group-562213E44849-FollowerState
om3_1        | 2022-04-21 16:45:55,803 [grpc-default-executor-0] INFO impl.RoleInfo: om3: start om3@group-562213E44849-FollowerState
om3_1        | 2022-04-21 16:45:55,803 [om3@group-562213E44849-FollowerState] INFO impl.FollowerState: om3@group-562213E44849-FollowerState was interrupted: {}
scm2.org_1   | 2022-04-21 16:44:00,231 [ReplicationMonitor] INFO container.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm3.org_1   | 2022-04-21 16:44:19,777 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm3.org_1   | 2022-04-21 16:44:19,779 [Listener at 0.0.0.0/9860] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
om1_1        | 2022-04-21 16:47:47,168 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39486
om3_1        | java.lang.InterruptedException: sleep interrupted
om3_1        | 	at java.base/java.lang.Thread.sleep(Native Method)
om3_1        | 	at java.base/java.lang.Thread.sleep(Thread.java:334)
om3_1        | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
om3_1        | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
scm3.org_1   | 2022-04-21 16:44:19,780 [Listener at 0.0.0.0/9860] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: start with initializing state, conf=-1: [], old=null
recon_1      | 2022-04-21 16:44:51,640 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 48 failover attempts. Trying to failover immediately.
scm2.org_1   | 2022-04-21 16:44:00,244 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
om3_1        | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
s3g_1        | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:129)
s3g_1        | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:463)
s3g_1        | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:46)
s3g_1        | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2102)
scm2.org_1   | 2022-04-21 16:44:00,261 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-04-21 16:44:00,274 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
recon_1      | 2022-04-21 16:44:51,642 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 49 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-21 16:44:51,656 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 50 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-21 16:44:53,659 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 51 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-21 16:44:53,661 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 52 failover attempts. Trying to failover immediately.
s3g_1        | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:758)
s3g_1        | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:721)
s3g_1        | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:691)
s3g_1        | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:160)
scm2.org_1   | 2022-04-21 16:44:00,378 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
om3_1        | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
om3_1        | 2022-04-21 16:45:55,827 [grpc-default-executor-0] INFO server.RaftServer$Division: om3@group-562213E44849 replies to ELECTION vote request: om1<-om3#0:OK-t2. Peer's state: om3@group-562213E44849:t2, leader=null, voted=om1, raftlog=om3@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
scm3.org_1   | 2022-04-21 16:44:19,781 [Listener at 0.0.0.0/9860] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: changes role from      null to FOLLOWER at term 0 for startInitializing
scm3.org_1   | 2022-04-21 16:44:19,783 [Listener at 0.0.0.0/9860] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-824FABCC98DC,id=9446a705-8bb9-4eda-8998-a3a4fb23e316
scm2.org_1   | 2022-04-21 16:44:00,514 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
recon_1      | 2022-04-21 16:44:53,662 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 53 failover attempts. Trying to failover after sleeping for 2000ms.
scm3.org_1   | 2022-04-21 16:44:19,855 [Listener at 0.0.0.0/9860] INFO server.RaftServer: 9446a705-8bb9-4eda-8998-a3a4fb23e316: start RPC server
scm3.org_1   | 2022-04-21 16:44:20,020 [Listener at 0.0.0.0/9860] INFO server.GrpcService: 9446a705-8bb9-4eda-8998-a3a4fb23e316: GrpcService started, listening on 9894
scm1.org_1   | 2022-04-21 16:43:26,443 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-FollowerState] INFO impl.FollowerState: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5104896336ns, electionTimeout:5102ms
scm1.org_1   | 2022-04-21 16:43:26,444 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-FollowerState] INFO impl.RoleInfo: e8ea6b57-c3ba-42bd-9807-0913ca4228d7: shutdown e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-FollowerState
scm1.org_1   | 2022-04-21 16:43:26,445 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-FollowerState] INFO server.RaftServer$Division: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
scm1.org_1   | 2022-04-21 16:43:26,447 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
scm2.org_1   | 2022-04-21 16:44:00,654 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
scm2.org_1   | 2022-04-21 16:44:02,313 [Listener at 0.0.0.0/9961] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
s3g_1        | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:30)
s3g_1        | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:105)
s3g_1        | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:260)
s3g_1        | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:51)
s3g_1        | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:86)
scm2.org_1   | 2022-04-21 16:44:02,327 [Listener at 0.0.0.0/9961] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm2.org_1   | 2022-04-21 16:44:02,342 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
om3_1        | 2022-04-21 16:45:56,231 [grpc-default-executor-0] INFO server.RaftServer$Division: om3@group-562213E44849: change Leader from null to om1 at term 2 for appendEntries, leader elected after 16203ms
scm1.org_1   | 2022-04-21 16:43:26,448 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-FollowerState] INFO impl.RoleInfo: e8ea6b57-c3ba-42bd-9807-0913ca4228d7: start e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-LeaderElection1
scm1.org_1   | 2022-04-21 16:43:26,463 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-LeaderElection1] INFO impl.LeaderElection: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [e8ea6b57-c3ba-42bd-9807-0913ca4228d7|rpc:scm1.org:9894|priority:0], old=null
om3_1        | 2022-04-21 16:45:56,322 [grpc-default-executor-0] INFO server.RaftServer$Division: om3@group-562213E44849: set configuration 0: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
recon_1      | 2022-04-21 16:44:55,664 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 54 failover attempts. Trying to failover immediately.
om2_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
scm3.org_1   | 2022-04-21 16:44:20,038 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
scm3.org_1   | 2022-04-21 16:44:20,040 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
scm3.org_1   | 2022-04-21 16:44:20,040 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
s3g_1        | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:89)
s3g_1        | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:89)
scm2.org_1   | 2022-04-21 16:44:02,437 [Listener at 0.0.0.0/9861] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
om3_1        | 2022-04-21 16:45:56,359 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: Starting segment from index:0
om3_1        | 2022-04-21 16:45:56,764 [om3@group-562213E44849-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/current/log_inprogress_0
om2_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:204)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:514)
om1_1        | 2022-04-21 16:47:47,195 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 16:47:50,931 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39498
s3g_1        | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:89)
s3g_1        | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:69)
s3g_1        | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:38)
s3g_1        | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:173)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:317)
scm1.org_1   | 2022-04-21 16:43:26,464 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-LeaderElection1] INFO impl.LeaderElection: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-LeaderElection1 ELECTION round 0: result PASSED (term=1)
scm1.org_1   | 2022-04-21 16:43:26,467 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-LeaderElection1] INFO impl.RoleInfo: e8ea6b57-c3ba-42bd-9807-0913ca4228d7: shutdown e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-LeaderElection1
scm1.org_1   | 2022-04-21 16:43:26,468 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-LeaderElection1] INFO server.RaftServer$Division: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
recon_1      | 2022-04-21 16:44:55,665 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 55 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-21 16:44:55,666 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 56 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-21 16:44:57,667 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 57 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-21 16:44:57,668 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 58 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-21 16:44:57,669 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 59 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-21 16:44:59,670 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 60 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-21 16:44:59,672 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 61 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-21 16:44:59,672 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 62 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-21 16:45:01,675 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 63 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-21 16:45:01,677 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 64 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-21 16:45:01,680 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 65 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-21 16:45:03,683 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 66 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-21 16:45:03,684 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 67 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-21 16:45:03,685 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 68 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-21 16:45:05,688 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 69 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-21 16:45:05,689 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 70 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-21 16:45:05,691 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 71 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-21 16:45:07,694 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 72 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-21 16:45:07,698 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 73 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-21 16:45:07,701 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 74 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-21 16:45:09,709 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 75 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-21 16:45:09,710 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 76 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-21 16:45:09,710 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 77 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-21 16:45:11,712 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 78 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-21 16:45:11,713 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 79 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-21 16:45:11,714 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 80 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-21 16:45:13,717 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 81 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-21 16:45:13,718 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 82 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-21 16:45:13,718 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 83 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-21 16:45:15,720 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 84 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-21 16:45:15,722 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 85 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-21 16:45:15,723 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 86 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-21 16:45:15,878 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:46416
recon_1      | 2022-04-21 16:45:15,905 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:45:17,144 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:32806
recon_1      | 2022-04-21 16:45:17,199 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:45:17,279 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48586
recon_1      | 2022-04-21 16:45:17,314 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:45:17,740 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 87 failover attempts. Trying to failover immediately.
om3_1        | 2022-04-21 16:45:59,848 [om3@group-562213E44849-StateMachineUpdater] INFO ratis.OzoneManagerStateMachine: Received Configuration change notification from Ratis. New Peer list:
om3_1        | [id: "om1"
om3_1        | address: "om1:9872"
om3_1        | , id: "om3"
om1_1        | 2022-04-21 16:47:50,948 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 16:47:54,875 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39510
om1_1        | 2022-04-21 16:47:54,893 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 16:47:58,107 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:39097
om1_1        | 2022-04-21 16:47:58,109 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2022-04-21 16:44:02,455 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm2.org_1   | 2022-04-21 16:44:02,467 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm2.org_1   | 2022-04-21 16:44:02,515 [Listener at 0.0.0.0/9863] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm2.org_1   | 2022-04-21 16:44:02,540 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm2.org_1   | 2022-04-21 16:44:02,542 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm2.org_1   | 2022-04-21 16:44:02,843 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: 
scm3.org_1   | 2022-04-21 16:44:20,041 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$419/0x0000000840527040@1300112e] INFO util.JvmPauseMonitor: JvmPauseMonitor-9446a705-8bb9-4eda-8998-a3a4fb23e316: Started
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:247)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
scm3.org_1   | 2022-04-21 16:44:23,188 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$419/0x0000000840527040@1300112e] WARN util.JvmPauseMonitor: JvmPauseMonitor-9446a705-8bb9-4eda-8998-a3a4fb23e316: Detected pause in JVM or host machine (eg GC): pause of approximately 119063222ns. No GCs detected.
scm3.org_1   | 2022-04-21 16:44:23,557 [grpc-default-executor-0] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: receive installSnapshot: e8ea6b57-c3ba-42bd-9807-0913ca4228d7->9446a705-8bb9-4eda-8998-a3a4fb23e316#0-t2,notify:(t:2, i:12)
scm3.org_1   | 2022-04-21 16:44:23,596 [grpc-default-executor-0] INFO ha.SCMStateMachine: leader changed, yet current SCM is still follower.
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-04-21 16:52:30,696 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-9441853734 of layout LEGACY in volume: s3v
om3_1        | address: "om3:9872"
om3_1        | , id: "om2"
scm1.org_1   | 2022-04-21 16:43:26,468 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-LeaderElection1] INFO server.RaftServer$Division: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC: change Leader from null to e8ea6b57-c3ba-42bd-9807-0913ca4228d7 at term 1 for becomeLeader, leader elected after 5425ms
scm1.org_1   | 2022-04-21 16:43:26,485 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
scm1.org_1   | 2022-04-21 16:43:26,490 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm1.org_1   | 2022-04-21 16:43:26,494 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
scm2.org_1   | Container Balancer status:
scm2.org_1   | Key                            Value
scm2.org_1   | Running                        false
scm2.org_1   | Container Balancer Configuration values:
scm2.org_1   | Key                                                Value
om1_1        | 2022-04-21 16:47:58,974 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39540
om1_1        | 2022-04-21 16:47:58,988 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 16:48:02,420 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39552
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
scm3.org_1   | 2022-04-21 16:44:23,597 [grpc-default-executor-0] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: change Leader from null to e8ea6b57-c3ba-42bd-9807-0913ca4228d7 at term 2 for installSnapshot, leader elected after 5772ms
scm3.org_1   | 2022-04-21 16:44:23,619 [grpc-default-executor-0] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: Received notification to install snapshot at index 12
scm3.org_1   | 2022-04-21 16:44:23,809 [grpc-default-executor-0] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: notifyInstallSnapshot: nextIndex is 0 but the leader's first available index is 12.
om3_1        | address: "om2:9872"
om3_1        | ]
om2_1        | 2022-04-21 16:52:31,306 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-4686250488 of layout LEGACY in volume: s3v
om2_1        | 2022-04-21 16:52:32,532 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketDeleteRequest: Delete bucket failed for bucket:nosuchbucket-ozone-test-5001124069 in volume:s3v
om2_1        | BUCKET_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Bucket not found
om1_1        | 2022-04-21 16:48:02,469 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 16:48:06,838 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39564
om1_1        | 2022-04-21 16:48:06,859 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 16:48:07,363 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: dangling-link of layout LEGACY in volume: 00630-target
om1_1        | 2022-04-21 16:48:10,641 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39568
om1_1        | 2022-04-21 16:48:10,663 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
om3_1        | 2022-04-21 16:46:13,265 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:vol1 for user:testuser
om3_1        | 2022-04-21 16:46:13,348 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket1 of layout LEGACY in volume: vol1
scm1.org_1   | 2022-04-21 16:43:26,505 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
scm3.org_1   | 2022-04-21 16:44:23,821 [grpc-default-executor-0] INFO ha.SCMStateMachine: Received install snapshot notification from SCM leader: scm1.org:9894 with term index: (t:2, i:12)
scm3.org_1   | 2022-04-21 16:44:23,868 [pool-16-thread-1] INFO ha.SCMHAManagerImpl: Downloading checkpoint from leader SCM scm1 and reloading state from the checkpoint.
om2_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.getBucketOwner(OzoneManager.java:2338)
om2_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.getBucketOwner(OzoneManager.java:2308)
om2_1        | 	at org.apache.hadoop.ozone.om.request.OMClientRequest.checkAcls(OMClientRequest.java:200)
om2_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketDeleteRequest.validateAndUpdateCache(OMBucketDeleteRequest.java:102)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
scm2.org_1   | Threshold                                          10
scm2.org_1   | Max Datanodes to Involve per Iteration(percent)    20
scm2.org_1   | Max Size to Move per Iteration                     500GB
scm2.org_1   | Max Size Entering Target per Iteration             26GB
scm2.org_1   | Max Size Leaving Source per Iteration              26GB
scm2.org_1   | 
scm2.org_1   | 2022-04-21 16:44:02,844 [Listener at 0.0.0.0/9860] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
om3_1        | 2022-04-21 16:46:28,855 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ombg0 of layout LEGACY in volume: vol1
om3_1        | 2022-04-21 16:46:46,894 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ombr0 of layout LEGACY in volume: vol1
scm1.org_1   | 2022-04-21 16:43:26,511 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
scm1.org_1   | 2022-04-21 16:43:26,512 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
scm1.org_1   | 2022-04-21 16:43:26,517 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm3.org_1   | 2022-04-21 16:44:25,992 [grpc-default-executor-0] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: set new configuration index: 11
scm3.org_1   | configurationEntry {
scm3.org_1   |   peers {
scm3.org_1   |     id: "d794df5a-ece1-4828-94ba-97e720366f72"
scm3.org_1   |     address: "scm2.org:9894"
scm3.org_1   |   }
scm3.org_1   |   peers {
om1_1        | 2022-04-21 16:48:14,612 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39594
om1_1        | 2022-04-21 16:48:14,630 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 16:48:15,090 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link1 of layout LEGACY in volume: 00630-target
om3_1        | 2022-04-21 16:47:11,046 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:00630-source for user:testuser
om3_1        | 2022-04-21 16:47:15,236 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:00630-target for user:testuser
om3_1        | 2022-04-21 16:47:19,238 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: readable-bucket of layout OBJECT_STORE in volume: 00630-source
om3_1        | 2022-04-21 16:47:31,945 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: unreadable-bucket of layout OBJECT_STORE in volume: 00630-source
scm1.org_1   | 2022-04-21 16:43:26,519 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:514)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:317)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm2.org_1   | 2022-04-21 16:44:02,848 [Listener at 0.0.0.0/9860] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
scm2.org_1   | 2022-04-21 16:44:02,856 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm2.org_1   | 2022-04-21 16:44:02,865 [Listener at 0.0.0.0/9860] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
scm2.org_1   | 2022-04-21 16:44:02,866 [Listener at 0.0.0.0/9860] INFO server.RaftServer$Division: d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC: start with initializing state, conf=-1: [], old=null
scm2.org_1   | 2022-04-21 16:44:02,881 [Listener at 0.0.0.0/9860] INFO server.RaftServer$Division: d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC: changes role from      null to FOLLOWER at term 0 for startInitializing
scm2.org_1   | 2022-04-21 16:44:02,882 [Listener at 0.0.0.0/9860] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-824FABCC98DC,id=d794df5a-ece1-4828-94ba-97e720366f72
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
scm1.org_1   | 2022-04-21 16:43:26,521 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-LeaderElection1] INFO impl.RoleInfo: e8ea6b57-c3ba-42bd-9807-0913ca4228d7: start e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-LeaderStateImpl
scm1.org_1   | 2022-04-21 16:43:26,557 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-SegmentedRaftLogWorker: Starting segment from index:0
scm1.org_1   | 2022-04-21 16:43:26,602 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-LeaderElection1] INFO server.RaftServer$Division: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC: set configuration 0: [e8ea6b57-c3ba-42bd-9807-0913ca4228d7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2022-04-21 16:43:26,636 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/37768e1b-cb4c-49da-b09f-824fabcc98dc/current/log_inprogress_0
om1_1        | 2022-04-21 16:48:18,232 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39598
om1_1        | 2022-04-21 16:48:18,276 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 16:48:18,736 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket1 of layout OBJECT_STORE in volume: 00630-source
om1_1        | 2022-04-21 16:48:21,984 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39612
om3_1        | 2022-04-21 16:47:36,318 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: readable-link of layout LEGACY in volume: 00630-target
om3_1        | 2022-04-21 16:47:40,122 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: unreadable-link of layout LEGACY in volume: 00630-target
om3_1        | 2022-04-21 16:47:43,940 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link-to-unreadable-bucket of layout LEGACY in volume: 00630-target
om3_1        | 2022-04-21 16:48:07,374 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: dangling-link of layout LEGACY in volume: 00630-target
scm3.org_1   |     id: "e8ea6b57-c3ba-42bd-9807-0913ca4228d7"
scm3.org_1   |     address: "scm1.org:9894"
scm3.org_1   |   }
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-04-21 16:52:39,151 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-5308852827 of layout LEGACY in volume: s3v
om2_1        | 2022-04-21 16:52:46,736 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-5640325463 of layout LEGACY in volume: s3v
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1679)
scm1.org_1   | 2022-04-21 16:43:27,413 [main] INFO server.RaftServer: e8ea6b57-c3ba-42bd-9807-0913ca4228d7: close
scm1.org_1   | 2022-04-21 16:43:27,414 [main] INFO server.RaftServer$Division: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC: shutdown
scm1.org_1   | 2022-04-21 16:43:27,414 [main] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-824FABCC98DC,id=e8ea6b57-c3ba-42bd-9807-0913ca4228d7
scm1.org_1   | 2022-04-21 16:43:27,414 [main] INFO impl.RoleInfo: e8ea6b57-c3ba-42bd-9807-0913ca4228d7: shutdown e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-LeaderStateImpl
scm1.org_1   | 2022-04-21 16:43:27,419 [main] INFO impl.PendingRequests: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-PendingRequests: sendNotLeaderResponses
scm1.org_1   | 2022-04-21 16:43:27,422 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-StateMachineUpdater] INFO impl.StateMachineUpdater: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-StateMachineUpdater: Took a snapshot at index 0
om1_1        | 2022-04-21 16:48:21,995 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 16:48:28,804 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39652
om3_1        | 2022-04-21 16:48:15,096 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link1 of layout LEGACY in volume: 00630-target
scm2.org_1   | 2022-04-21 16:44:02,898 [Listener at 0.0.0.0/9860] INFO server.RaftServer: d794df5a-ece1-4828-94ba-97e720366f72: start RPC server
scm2.org_1   | 2022-04-21 16:44:02,987 [Listener at 0.0.0.0/9860] INFO server.GrpcService: d794df5a-ece1-4828-94ba-97e720366f72: GrpcService started, listening on 9894
scm3.org_1   | }
scm3.org_1   |  from snapshot
om3_1        | 2022-04-21 16:48:18,745 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket1 of layout OBJECT_STORE in volume: 00630-source
om3_1        | 2022-04-21 16:49:39,109 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link2 of layout LEGACY in volume: 00630-target
om3_1        | 2022-04-21 16:49:42,953 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:link2 in volume:00630-target
om3_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om3_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:204)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:514)
om2_1        | 2022-04-21 16:52:59,557 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-3979773564 of layout LEGACY in volume: s3v
om2_1        | 2022-04-21 16:53:29,427 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload: /s3v/bucket-ozone-test-3979773564/ozone-test-3619141613/multipartKey2 Part number: 1 size 6  is less than minimum part size 5242880
scm3.org_1   | 2022-04-21 16:44:26,022 [grpc-default-executor-0] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: set configuration 11: [d794df5a-ece1-4828-94ba-97e720366f72|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, e8ea6b57-c3ba-42bd-9807-0913ca4228d7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-04-21 16:44:26,025 [grpc-default-executor-0] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: reply installSnapshot: e8ea6b57-c3ba-42bd-9807-0913ca4228d7<-9446a705-8bb9-4eda-8998-a3a4fb23e316#0:FAIL-t0,IN_PROGRESS
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
scm1.org_1   | 2022-04-21 16:43:27,422 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-StateMachineUpdater] INFO impl.StateMachineUpdater: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
scm1.org_1   | 2022-04-21 16:43:27,426 [main] INFO impl.StateMachineUpdater: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-StateMachineUpdater: set stopIndex = 0
om1_1        | 2022-04-21 16:48:28,820 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 16:48:34,923 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39668
om1_1        | 2022-04-21 16:48:34,952 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 16:48:43,724 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39692
om1_1        | 2022-04-21 16:48:43,738 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2022-04-21 16:44:03,009 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$422/0x0000000840527c40@1300112e] INFO util.JvmPauseMonitor: JvmPauseMonitor-d794df5a-ece1-4828-94ba-97e720366f72: Started
scm2.org_1   | 2022-04-21 16:44:03,052 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
scm2.org_1   | 2022-04-21 16:44:03,052 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
scm2.org_1   | 2022-04-21 16:44:03,052 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
om1_1        | 2022-04-21 16:48:49,625 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39708
om1_1        | 2022-04-21 16:48:49,636 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 16:48:53,725 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39712
om1_1        | 2022-04-21 16:48:53,741 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-04-21 16:53:29,429 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-3619141613/multipartKey2 in Volume/Bucket s3v/bucket-ozone-test-3979773564
om2_1        | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-3979773564 key: ozone-test-3619141613/multipartKey2. Entity too small.
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:517)
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:197)
scm3.org_1   | 2022-04-21 16:44:26,071 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 9446a705-8bb9-4eda-8998-a3a4fb23e316: Completed INSTALL_SNAPSHOT, lastRequest: e8ea6b57-c3ba-42bd-9807-0913ca4228d7->9446a705-8bb9-4eda-8998-a3a4fb23e316#0-t2,notify:(t:2, i:12)
scm3.org_1   | 2022-04-21 16:44:26,160 [grpc-default-executor-1] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: receive installSnapshot: e8ea6b57-c3ba-42bd-9807-0913ca4228d7->9446a705-8bb9-4eda-8998-a3a4fb23e316#0-t2,notify:(t:2, i:12)
om1_1        | 2022-04-21 16:48:58,140 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:35423
om1_1        | 2022-04-21 16:48:58,152 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:514)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:317)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:317)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm2.org_1   | 2022-04-21 16:44:04,724 [grpc-default-executor-0] INFO server.RaftServer$Division: d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC: receive installSnapshot: e8ea6b57-c3ba-42bd-9807-0913ca4228d7->d794df5a-ece1-4828-94ba-97e720366f72#0-t2,notify:(t:2, i:6)
scm2.org_1   | 2022-04-21 16:44:04,733 [grpc-default-executor-0] INFO ha.SCMStateMachine: leader changed, yet current SCM is still follower.
scm2.org_1   | 2022-04-21 16:44:04,733 [grpc-default-executor-0] INFO server.RaftServer$Division: d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC: change Leader from null to e8ea6b57-c3ba-42bd-9807-0913ca4228d7 at term 2 for installSnapshot, leader elected after 6035ms
scm3.org_1   | 2022-04-21 16:44:26,161 [grpc-default-executor-1] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: set new configuration index: 11
scm1.org_1   | 2022-04-21 16:43:27,426 [main] INFO server.RaftServer$Division: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC: closes. applyIndex: 0
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-04-21 16:53:30,799 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-ozone-test-3979773564/ozone-test-2106382736/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 1
scm1.org_1   | 2022-04-21 16:43:27,427 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
scm2.org_1   | 2022-04-21 16:44:04,746 [grpc-default-executor-0] INFO server.RaftServer$Division: d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC: Received notification to install snapshot at index 6
scm2.org_1   | 2022-04-21 16:44:04,836 [grpc-default-executor-0] INFO server.RaftServer$Division: d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC: notifyInstallSnapshot: nextIndex is 0 but the leader's first available index is 6.
scm2.org_1   | 2022-04-21 16:44:04,836 [grpc-default-executor-0] INFO ha.SCMStateMachine: Received install snapshot notification from SCM leader: scm1.org:9894 with term index: (t:2, i:6)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 2022-04-21 16:48:58,337 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39748
om2_1        | partName: "etag1"
recon_1      | 2022-04-21 16:45:17,744 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 88 failover attempts. Trying to failover immediately.
scm3.org_1   | configurationEntry {
scm3.org_1   |   peers {
scm3.org_1   |     id: "d794df5a-ece1-4828-94ba-97e720366f72"
scm1.org_1   | 2022-04-21 16:43:27,428 [main] INFO segmented.SegmentedRaftLogWorker: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-SegmentedRaftLogWorker close()
scm1.org_1   | 2022-04-21 16:43:27,429 [main] INFO server.GrpcService: e8ea6b57-c3ba-42bd-9807-0913ca4228d7: shutdown server with port 9894 now
om2_1        | , partNumber: 2
om2_1        | partName: "etag2"
om2_1        | ]
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
scm1.org_1   | 2022-04-21 16:43:27,433 [main] INFO server.GrpcService: e8ea6b57-c3ba-42bd-9807-0913ca4228d7: shutdown server with port 9894 successfully
scm2.org_1   | 2022-04-21 16:44:04,837 [pool-16-thread-1] INFO ha.SCMHAManagerImpl: Downloading checkpoint from leader SCM scm1 and reloading state from the checkpoint.
scm2.org_1   | 2022-04-21 16:44:05,641 [grpc-default-executor-1] INFO ha.InterSCMGrpcClient: Checkpoint is downloaded to /data/metadata/snapshot/scm.db-scm1-1650559444837.tar.gz
om1_1        | 2022-04-21 16:48:58,364 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
recon_1      | 2022-04-21 16:45:17,752 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 89 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-21 16:45:19,181 [IPC Server handler 54 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/8694db2d-5e51-4888-b1e0-69ff67626e43
recon_1      | 2022-04-21 16:45:19,224 [IPC Server handler 54 on default port 9891] INFO node.SCMNodeManager: Registered Data node : 8694db2d-5e51-4888-b1e0-69ff67626e43{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 952600664327, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-04-21 16:45:19,353 [IPC Server handler 53 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/0ef408af-3ea2-4044-bc54-ad0ae15d84f1
recon_1      | 2022-04-21 16:45:19,359 [IPC Server handler 53 on default port 9891] INFO node.SCMNodeManager: Registered Data node : 0ef408af-3ea2-4044-bc54-ad0ae15d84f1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 953699741549, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-04-21 16:45:19,539 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 8694db2d-5e51-4888-b1e0-69ff67626e43 to Node DB.
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-04-21 16:49:47,098 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket3 of layout OBJECT_STORE in volume: 00630-target
om3_1        | 2022-04-21 16:49:50,980 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket3 in volume:00630-target
om3_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
scm1.org_1   | 2022-04-21 16:43:27,433 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$338/0x000000084031fc40@6dab01d9] INFO util.JvmPauseMonitor: JvmPauseMonitor-e8ea6b57-c3ba-42bd-9807-0913ca4228d7: Stopped
scm2.org_1   | 2022-04-21 16:44:05,730 [pool-16-thread-1] INFO ha.SCMSnapshotProvider: Successfully downloaded latest checkpoint from leader SCM: scm1 path /data/metadata/snapshot/scm.db-scm1-1650559444837
scm2.org_1   | 2022-04-21 16:44:05,737 [pool-16-thread-1] INFO ha.SCMHAManagerImpl: Downloaded checkpoint from Leader scm1 to the location /data/metadata/snapshot/scm.db-scm1-1650559444837
recon_1      | 2022-04-21 16:45:19,545 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 0ef408af-3ea2-4044-bc54-ad0ae15d84f1 to Node DB.
om3_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:204)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:514)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:317)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm1.org_1   | 2022-04-21 16:43:27,433 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2022-04-21 16:44:05,852 [pool-16-thread-1] INFO ha.SCMHAManagerImpl: Installing checkpoint with SCMTransactionInfo 2#6
om2_1        | 2022-04-21 16:53:30,816 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-2106382736/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-3979773564
recon_1      | 2022-04-21 16:45:19,761 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 90 failover attempts. Trying to failover immediately.
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
scm1.org_1   | 2022-04-21 16:43:27,436 [main] INFO server.StorageContainerManager: SCM initialization succeeded. Current cluster id for sd=/data/metadata/scm; cid=CID-37768e1b-cb4c-49da-b09f-824fabcc98dc; layoutVersion=3; scmId=e8ea6b57-c3ba-42bd-9807-0913ca4228d7
scm1.org_1   | 2022-04-21 16:43:27,470 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
om1_1        | 2022-04-21 16:49:02,197 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39762
om1_1        | 2022-04-21 16:49:02,226 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | /************************************************************
om1_1        | 2022-04-21 16:49:06,491 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39766
scm3.org_1   |     address: "scm2.org:9894"
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
scm1.org_1   | SHUTDOWN_MSG: Shutting down StorageContainerManager at scm1.org/172.25.0.116
om1_1        | 2022-04-21 16:49:06,527 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
om2_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-3979773564 key: ozone-test-2106382736/multipartKey3
scm2.org_1   | 2022-04-21 16:44:05,853 [pool-16-thread-1] INFO server.RaftServer$Division: d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC: StateMachine successfully installed snapshot index 6. Reloading the StateMachine.
scm2.org_1   | 2022-04-21 16:44:05,853 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC-SegmentedRaftLogWorker: flushIndex: setUnconditionally -1 -> 6
scm2.org_1   | 2022-04-21 16:44:05,859 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally -1 -> 6
scm2.org_1   | 2022-04-21 16:44:05,860 [pool-16-thread-1] INFO raftlog.RaftLog: d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC-SegmentedRaftLog: snapshotIndex: updateIncreasingly -1 -> 6
om1_1        | 2022-04-21 16:49:10,518 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39778
om1_1        | 2022-04-21 16:49:10,539 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 16:49:14,629 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39800
om1_1        | 2022-04-21 16:49:14,654 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   |   }
scm3.org_1   |   peers {
scm3.org_1   |     id: "e8ea6b57-c3ba-42bd-9807-0913ca4228d7"
scm3.org_1   |     address: "scm1.org:9894"
scm3.org_1   |   }
scm3.org_1   | }
scm3.org_1   |  from snapshot
scm1.org_1   | ************************************************************/
scm3.org_1   | 2022-04-21 16:44:26,163 [grpc-default-executor-1] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: set configuration 11: [d794df5a-ece1-4828-94ba-97e720366f72|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, e8ea6b57-c3ba-42bd-9807-0913ca4228d7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:186)
recon_1      | 2022-04-21 16:45:19,761 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 91 failover attempts. Trying to failover immediately.
om3_1        | 2022-04-21 16:50:11,106 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop2 of layout LEGACY in volume: 00630-target
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:514)
recon_1      | 2022-04-21 16:45:19,762 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 92 failover attempts. Trying to failover after sleeping for 2000ms.
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
om3_1        | 2022-04-21 16:50:15,085 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop3 of layout LEGACY in volume: 00630-target
om3_1        | 2022-04-21 16:50:18,910 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop1 of layout LEGACY in volume: 00630-target
om3_1        | 2022-04-21 16:50:26,980 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link3 of layout LEGACY in volume: 00630-target
scm3.org_1   | 2022-04-21 16:44:26,168 [grpc-default-executor-1] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: reply installSnapshot: e8ea6b57-c3ba-42bd-9807-0913ca4228d7<-9446a705-8bb9-4eda-8998-a3a4fb23e316#0:FAIL-t2,IN_PROGRESS
om1_1        | 2022-04-21 16:49:18,249 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39806
om1_1        | 2022-04-21 16:49:18,281 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm1.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm1.org_1   | 2022-04-21 16:43:28,971 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
om3_1        | 2022-04-21 16:51:27,084 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-1938307693 of layout LEGACY in volume: s3v
recon_1      | 2022-04-21 16:45:20,015 [IPC Server handler 27 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/a9037631-20c7-49ff-8966-d11abf0c09e2
recon_1      | 2022-04-21 16:45:20,015 [IPC Server handler 27 on default port 9891] INFO node.SCMNodeManager: Registered Data node : a9037631-20c7-49ff-8966-d11abf0c09e2{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 952295697655, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-04-21 16:45:20,017 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node a9037631-20c7-49ff-8966-d11abf0c09e2 to Node DB.
scm2.org_1   | 2022-04-21 16:44:06,184 [d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC-StateMachineUpdater] INFO ha.SCMHAManagerImpl: Installing checkpoint with SCMTransactionInfo 2#6
scm2.org_1   | 2022-04-21 16:44:06,215 [d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC-StateMachineUpdater] INFO ha.SCMHAManagerImpl: Replaced DB with checkpoint, term: 2, index: 6
scm2.org_1   | 2022-04-21 16:44:06,218 [d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC-StateMachineUpdater] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2022-04-21 16:44:06,232 [d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC-StateMachineUpdater] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2022-04-21 16:44:06,257 [grpc-default-executor-0] INFO server.RaftServer$Division: d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC: set new configuration index: 1
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:317)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm3.org_1   | 2022-04-21 16:44:26,192 [grpc-default-executor-1] INFO server.GrpcServerProtocolService: 9446a705-8bb9-4eda-8998-a3a4fb23e316: Completed INSTALL_SNAPSHOT, lastRequest: e8ea6b57-c3ba-42bd-9807-0913ca4228d7->9446a705-8bb9-4eda-8998-a3a4fb23e316#0-t2,notify:(t:2, i:12)
om3_1        | 2022-04-21 16:51:33,809 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-3093588181 of layout LEGACY in volume: s3v
om3_1        | 2022-04-21 16:51:49,342 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-1324058591 of layout LEGACY in volume: s3v
om3_1        | 2022-04-21 16:51:49,891 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ozone-test-iivwcokihe of layout LEGACY in volume: s3v
om3_1        | 2022-04-21 16:52:05,997 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-miyukjhjbq of layout LEGACY in volume: s3v
om1_1        | 2022-04-21 16:49:22,272 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39820
om1_1        | 2022-04-21 16:49:22,290 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 16:49:26,430 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39856
om1_1        | 2022-04-21 16:49:26,465 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 16:49:30,413 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39860
om1_1        | 2022-04-21 16:49:30,435 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 16:49:34,548 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39872
scm3.org_1   | 2022-04-21 16:44:26,223 [grpc-default-executor-0] INFO impl.RoleInfo: 9446a705-8bb9-4eda-8998-a3a4fb23e316: start 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC-FollowerState
scm3.org_1   | 2022-04-21 16:44:26,240 [grpc-default-executor-0] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: Failed appendEntries as snapshot (12) installation is in progress
scm3.org_1   | 2022-04-21 16:44:26,242 [grpc-default-executor-0] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: inconsistency entries. Reply:e8ea6b57-c3ba-42bd-9807-0913ca4228d7<-9446a705-8bb9-4eda-8998-a3a4fb23e316#0:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm3.org_1   | 2022-04-21 16:44:26,265 [grpc-default-executor-1] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: receive installSnapshot: e8ea6b57-c3ba-42bd-9807-0913ca4228d7->9446a705-8bb9-4eda-8998-a3a4fb23e316#0-t2,notify:(t:2, i:12)
scm2.org_1   | configurationEntry {
scm1.org_1   | /************************************************************
scm1.org_1   | STARTUP_MSG: Starting StorageContainerManager
om1_1        | 2022-04-21 16:49:34,572 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2022-04-21 16:44:26,269 [grpc-default-executor-1] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: set new configuration index: 11
scm3.org_1   | configurationEntry {
recon_1      | 2022-04-21 16:45:20,739 [IPC Server handler 27 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net
recon_1      | 2022-04-21 16:45:20,926 [IPC Server handler 61 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net
recon_1      | 2022-04-21 16:45:21,542 [IPC Server handler 57 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net
scm2.org_1   |   peers {
scm2.org_1   |     id: "e8ea6b57-c3ba-42bd-9807-0913ca4228d7"
recon_1      | 2022-04-21 16:45:21,774 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 93 failover attempts. Trying to failover immediately.
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
scm1.org_1   | STARTUP_MSG:   host = scm1.org/172.25.0.116
scm1.org_1   | STARTUP_MSG:   args = []
scm1.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
scm1.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.0.4.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm1.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/be5888b907ab03eaf5ec49e88bd592b9f9bd78c4 ; compiled by 'runner' on 2022-04-21T16:20Z
scm1.org_1   | STARTUP_MSG:   java = 11.0.14.1
scm1.org_1   | ************************************************************/
om1_1        | 2022-04-21 16:49:38,582 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39884
om1_1        | 2022-04-21 16:49:38,599 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-04-21 16:53:31,457 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-ozone-test-3979773564/ozone-test-2106382736/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 2
om2_1        | partName: "etag1"
recon_1      | 2022-04-21 16:45:21,776 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 94 failover attempts. Trying to failover immediately.
om3_1        | 2022-04-21 16:52:21,078 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-4268886784 of layout LEGACY in volume: s3v
scm3.org_1   |   peers {
scm3.org_1   |     id: "d794df5a-ece1-4828-94ba-97e720366f72"
om2_1        | , partNumber: 1
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
om3_1        | 2022-04-21 16:52:21,699 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-1890813946 of layout LEGACY in volume: s3v
scm1.org_1   | 2022-04-21 16:43:29,013 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm1.org_1   | 2022-04-21 16:43:29,097 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm2.org_1   |     address: "scm1.org:9894"
scm2.org_1   |   }
om2_1        | partName: "etag2"
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
om3_1        | 2022-04-21 16:52:22,326 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-8475151662 of layout LEGACY in volume: s3v
scm3.org_1   |     address: "scm2.org:9894"
scm3.org_1   |   }
scm3.org_1   |   peers {
scm2.org_1   | }
scm2.org_1   |  from snapshot
scm2.org_1   | 2022-04-21 16:44:06,274 [grpc-default-executor-0] INFO server.RaftServer$Division: d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC: set configuration 1: [e8ea6b57-c3ba-42bd-9807-0913ca4228d7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
recon_1      | 2022-04-21 16:45:21,781 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 95 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-21 16:45:22,970 [IPC Server handler 4 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net
recon_1      | 2022-04-21 16:45:22,972 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=a2956c20-9fda-4457-b767-0b8a33d7fc85. Trying to get from SCM.
om3_1        | 2022-04-21 16:52:22,955 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket-ozone-test-8475151662 in volume:s3v
om3_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
scm3.org_1   |     id: "e8ea6b57-c3ba-42bd-9807-0913ca4228d7"
scm3.org_1   |     address: "scm1.org:9894"
om1_1        | 2022-04-21 16:49:39,096 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link2 of layout LEGACY in volume: 00630-target
om1_1        | 2022-04-21 16:49:42,328 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39888
recon_1      | 2022-04-21 16:45:23,134 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: a2956c20-9fda-4457-b767-0b8a33d7fc85, Nodes: a9037631-20c7-49ff-8966-d11abf0c09e2{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}8694db2d-5e51-4888-b1e0-69ff67626e43{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}0ef408af-3ea2-4044-bc54-ad0ae15d84f1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-04-21T16:45:20.398Z[UTC]] to Recon pipeline metadata.
scm1.org_1   | 2022-04-21 16:43:29,107 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm1.org_1   | 2022-04-21 16:43:29,186 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm1, RPC Address: scm1.org:9894 and Ratis port: 9894
om3_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:204)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:514)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:317)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-04-21 16:52:30,694 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-9441853734 of layout LEGACY in volume: s3v
om2_1        | ]
om1_1        | 2022-04-21 16:49:42,366 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2022-04-21 16:44:06,274 [grpc-default-executor-0] INFO server.RaftServer$Division: d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC: reply installSnapshot: e8ea6b57-c3ba-42bd-9807-0913ca4228d7<-d794df5a-ece1-4828-94ba-97e720366f72#0:FAIL-t0,IN_PROGRESS
scm3.org_1   |   }
scm3.org_1   | }
scm3.org_1   |  from snapshot
scm3.org_1   | 2022-04-21 16:44:26,271 [grpc-default-executor-1] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: set configuration 11: [d794df5a-ece1-4828-94ba-97e720366f72|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, e8ea6b57-c3ba-42bd-9807-0913ca4228d7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-04-21 16:44:26,274 [grpc-default-executor-1] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: reply installSnapshot: e8ea6b57-c3ba-42bd-9807-0913ca4228d7<-9446a705-8bb9-4eda-8998-a3a4fb23e316#0:FAIL-t2,IN_PROGRESS
scm3.org_1   | 2022-04-21 16:44:26,281 [grpc-default-executor-1] INFO server.GrpcServerProtocolService: 9446a705-8bb9-4eda-8998-a3a4fb23e316: Completed INSTALL_SNAPSHOT, lastRequest: e8ea6b57-c3ba-42bd-9807-0913ca4228d7->9446a705-8bb9-4eda-8998-a3a4fb23e316#0-t2,notify:(t:2, i:12)
scm3.org_1   | 2022-04-21 16:44:26,338 [grpc-default-executor-0] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: Failed appendEntries as snapshot (12) installation is in progress
scm3.org_1   | 2022-04-21 16:44:26,338 [grpc-default-executor-0] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: inconsistency entries. Reply:e8ea6b57-c3ba-42bd-9807-0913ca4228d7<-9446a705-8bb9-4eda-8998-a3a4fb23e316#1:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm2.org_1   | 2022-04-21 16:44:06,302 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: d794df5a-ece1-4828-94ba-97e720366f72: Completed INSTALL_SNAPSHOT, lastRequest: e8ea6b57-c3ba-42bd-9807-0913ca4228d7->d794df5a-ece1-4828-94ba-97e720366f72#0-t2,notify:(t:2, i:6)
scm2.org_1   | 2022-04-21 16:44:06,346 [grpc-default-executor-1] INFO server.RaftServer$Division: d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC: receive installSnapshot: e8ea6b57-c3ba-42bd-9807-0913ca4228d7->d794df5a-ece1-4828-94ba-97e720366f72#0-t2,notify:(t:2, i:6)
om2_1        | 2022-04-21 16:53:31,460 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-2106382736/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-3979773564
om2_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-3979773564 key: ozone-test-2106382736/multipartKey3
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:186)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:514)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:317)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm2.org_1   | 2022-04-21 16:44:06,353 [grpc-default-executor-0] INFO impl.RoleInfo: d794df5a-ece1-4828-94ba-97e720366f72: start d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC-FollowerState
scm2.org_1   | 2022-04-21 16:44:06,356 [grpc-default-executor-0] INFO server.RaftServer$Division: d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC: Failed appendEntries as snapshot (6) installation is in progress
scm2.org_1   | 2022-04-21 16:44:06,358 [grpc-default-executor-0] INFO server.RaftServer$Division: d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC: inconsistency entries. Reply:e8ea6b57-c3ba-42bd-9807-0913ca4228d7<-d794df5a-ece1-4828-94ba-97e720366f72#0:FAIL-t2,INCONSISTENCY,nextIndex=7,followerCommit=6
scm1.org_1   | 2022-04-21 16:43:29,187 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm1: scm1.org
scm1.org_1   | 2022-04-21 16:43:29,226 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2022-04-21 16:49:42,929 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:link2 in volume:00630-target
om1_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om1_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:204)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
recon_1      | 2022-04-21 16:45:23,257 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: a2956c20-9fda-4457-b767-0b8a33d7fc85, Nodes: a9037631-20c7-49ff-8966-d11abf0c09e2{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}8694db2d-5e51-4888-b1e0-69ff67626e43{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}0ef408af-3ea2-4044-bc54-ad0ae15d84f1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-04-21T16:45:20.398Z[UTC]].
recon_1      | 2022-04-21 16:45:23,286 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=a2956c20-9fda-4457-b767-0b8a33d7fc85 reported by a9037631-20c7-49ff-8966-d11abf0c09e2{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 952295697655, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-04-21 16:53:37,576 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-2106382736/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-3979773564
scm3.org_1   | 2022-04-21 16:44:26,475 [grpc-default-executor-0] INFO ha.InterSCMGrpcClient: Checkpoint is downloaded to /data/metadata/snapshot/scm.db-scm1-1650559463871.tar.gz
scm3.org_1   | 2022-04-21 16:44:26,556 [grpc-default-executor-0] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: Failed appendEntries as snapshot (12) installation is in progress
scm2.org_1   | 2022-04-21 16:44:06,359 [grpc-default-executor-1] INFO server.RaftServer$Division: d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC: InstallSnapshot notification result: SNAPSHOT_INSTALLED, at index: 6
scm2.org_1   | 2022-04-21 16:44:06,360 [grpc-default-executor-1] INFO server.RaftServer$Division: d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC: set new configuration index: 1
scm2.org_1   | configurationEntry {
scm2.org_1   |   peers {
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1        | Caused by: org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.newError(S3ErrorTable.java:139)
recon_1      | 2022-04-21 16:45:23,782 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 96 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-21 16:45:23,784 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 97 failover attempts. Trying to failover immediately.
om2_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-3979773564 key: ozone-test-2106382736/multipartKey3. Provided Part info is { etag1, 1}, whereas OM has partName /s3v/bucket-ozone-test-3979773564/ozone-test-2106382736/multipartKey3-39d7a4bf-f0b0-432c-9d38-260cf0a0d6fc-108171100822503460-1
scm3.org_1   | 2022-04-21 16:44:26,563 [grpc-default-executor-0] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: inconsistency entries. Reply:e8ea6b57-c3ba-42bd-9807-0913ca4228d7<-9446a705-8bb9-4eda-8998-a3a4fb23e316#2:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.newError(S3ErrorTable.java:126)
s3g_1        | 	at org.apache.hadoop.ozone.s3.signature.AuthorizationV4HeaderParser.parseCredentials(AuthorizationV4HeaderParser.java:171)
s3g_1        | 	at org.apache.hadoop.ozone.s3.signature.AuthorizationV4HeaderParser.parseSignature(AuthorizationV4HeaderParser.java:91)
s3g_1        | 	at org.apache.hadoop.ozone.s3.signature.AWSSignatureProcessor.parseSignature(AWSSignatureProcessor.java:70)
s3g_1        | 	at org.apache.hadoop.ozone.s3.signature.AWSSignatureProcessor$Proxy$_$$_WeldClientProxy.parseSignature(Unknown Source)
recon_1      | 2022-04-21 16:45:23,785 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 98 failover attempts. Trying to failover after sleeping for 2000ms.
scm3.org_1   | 2022-04-21 16:44:26,598 [grpc-default-executor-0] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: receive installSnapshot: e8ea6b57-c3ba-42bd-9807-0913ca4228d7->9446a705-8bb9-4eda-8998-a3a4fb23e316#0-t2,notify:(t:2, i:12)
scm1.org_1   | 2022-04-21 16:43:29,254 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3), software layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3)
scm1.org_1   | 2022-04-21 16:43:29,493 [main] INFO reflections.Reflections: Reflections took 139 ms to scan 3 urls, producing 105 keys and 220 values 
scm1.org_1   | 2022-04-21 16:43:30,053 [main] INFO client.SCMCertificateClient: Loading certificate from location:/data/metadata/scm/sub-ca/certs.
scm1.org_1   | 2022-04-21 16:43:30,141 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/862887965327.crt.
scm1.org_1   | 2022-04-21 16:43:30,145 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/CA-1.crt.
scm1.org_1   | 2022-04-21 16:43:30,150 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/certificate.crt.
scm1.org_1   | 2022-04-21 16:43:30,299 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm1.org_1   | 2022-04-21 16:43:30,299 [main] INFO server.StorageContainerManager: SCM login successful.
scm1.org_1   | 2022-04-21 16:43:30,323 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2022-04-21 16:43:30,485 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2022-04-21 16:43:30,659 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar!/network-topology-default.xml]
scm1.org_1   | 2022-04-21 16:43:30,659 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm1.org_1   | 2022-04-21 16:43:30,704 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm1.org_1   | 2022-04-21 16:43:30,731 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:e8ea6b57-c3ba-42bd-9807-0913ca4228d7
scm1.org_1   | 2022-04-21 16:43:30,829 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
scm1.org_1   | 2022-04-21 16:43:30,903 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
scm1.org_1   | 2022-04-21 16:43:30,903 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2022-04-21 16:43:30,903 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
scm1.org_1   | 2022-04-21 16:43:30,904 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2022-04-21 16:43:30,904 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2022-04-21 16:43:30,904 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
scm1.org_1   | 2022-04-21 16:43:30,906 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2022-04-21 16:43:30,906 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm1.org_1   | 2022-04-21 16:43:30,907 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm1.org_1   | 2022-04-21 16:43:31,335 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
scm1.org_1   | 2022-04-21 16:43:31,337 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm1.org_1   | 2022-04-21 16:43:31,337 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm1.org_1   | 2022-04-21 16:43:31,346 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
recon_1      | 2022-04-21 16:45:25,787 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 99 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-21 16:45:25,788 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 100 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-21 16:45:25,789 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 101 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-21 16:45:27,790 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 102 failover attempts. Trying to failover immediately.
scm2.org_1   |     id: "e8ea6b57-c3ba-42bd-9807-0913ca4228d7"
om3_1        | 2022-04-21 16:52:31,299 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-4686250488 of layout LEGACY in volume: s3v
om3_1        | 2022-04-21 16:52:32,539 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketDeleteRequest: Delete bucket failed for bucket:nosuchbucket-ozone-test-5001124069 in volume:s3v
om3_1        | BUCKET_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Bucket not found
om3_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.getBucketOwner(OzoneManager.java:2338)
om3_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.getBucketOwner(OzoneManager.java:2308)
om3_1        | 	at org.apache.hadoop.ozone.om.request.OMClientRequest.checkAcls(OMClientRequest.java:200)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:514)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:317)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | 2022-04-21 16:45:27,791 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 103 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-21 16:45:27,792 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 104 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-21 16:45:28,083 [IPC Server handler 28 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net
recon_1      | 2022-04-21 16:45:28,088 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=a2956c20-9fda-4457-b767-0b8a33d7fc85 reported by 8694db2d-5e51-4888-b1e0-69ff67626e43{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 952600664327, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-04-21 16:45:29,793 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 105 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-21 16:45:29,794 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 106 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-21 16:45:29,795 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 107 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-21 16:45:30,184 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=a2956c20-9fda-4457-b767-0b8a33d7fc85 reported by a9037631-20c7-49ff-8966-d11abf0c09e2{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 952295697655, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-04-21 16:45:31,798 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 108 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-21 16:45:31,801 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 109 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-21 16:45:31,802 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 110 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-21 16:45:32,380 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48630
s3g_1        | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getSignature(OzoneClientProducer.java:87)
s3g_1        | 	... 114 more
s3g_1        | 
s3g_1        | 
s3g_1        | 2022-04-21 16:52:59,517 [qtp440736059-23] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-3979773564, with testuser as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-04-21 16:52:59,542 [qtp440736059-23] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-3979773564
s3g_1        | 2022-04-21 16:57:17,696 [qtp440736059-22] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: a2956c20-9fda-4457-b767-0b8a33d7fc85, Nodes: a9037631-20c7-49ff-8966-d11abf0c09e2{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}8694db2d-5e51-4888-b1e0-69ff67626e43{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}0ef408af-3ea2-4044-bc54-ad0ae15d84f1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:a9037631-20c7-49ff-8966-d11abf0c09e2, CreationTimestamp2022-04-21T16:45:20.398Z[UTC]]
s3g_1        | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #136 timeout 180s
om3_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketDeleteRequest.validateAndUpdateCache(OMBucketDeleteRequest.java:102)
scm2.org_1   |     address: "scm1.org:9894"
scm2.org_1   |   }
scm2.org_1   | }
scm2.org_1   |  from snapshot
scm2.org_1   | 2022-04-21 16:44:06,361 [grpc-default-executor-1] INFO server.RaftServer$Division: d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC: set configuration 1: [e8ea6b57-c3ba-42bd-9807-0913ca4228d7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2022-04-21 16:44:06,362 [grpc-default-executor-1] INFO server.RaftServer$Division: d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC: reply installSnapshot: e8ea6b57-c3ba-42bd-9807-0913ca4228d7<-d794df5a-ece1-4828-94ba-97e720366f72#0:FAIL-t2,SNAPSHOT_INSTALLED,snapshotIndex=6
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:499)
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:197)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:514)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:317)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-04-21 16:53:38,196 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-2106382736/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-3979773564
om1_1        | 2022-04-21 16:49:46,547 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39902
om1_1        | 2022-04-21 16:49:46,568 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 16:49:47,089 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket3 of layout OBJECT_STORE in volume: 00630-target
om1_1        | 2022-04-21 16:49:50,454 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39914
om1_1        | 2022-04-21 16:49:50,472 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 16:49:50,966 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket3 in volume:00630-target
om1_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om1_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:204)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:514)
recon_1      | 2022-04-21 16:45:32,434 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:45:32,436 [IPC Server handler 57 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net
scm3.org_1   | 2022-04-21 16:44:26,599 [grpc-default-executor-0] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: set new configuration index: 11
scm3.org_1   | configurationEntry {
scm3.org_1   |   peers {
scm3.org_1   |     id: "d794df5a-ece1-4828-94ba-97e720366f72"
scm3.org_1   |     address: "scm2.org:9894"
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:514)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:317)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-04-21 16:52:39,172 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-5308852827 of layout LEGACY in volume: s3v
om3_1        | 2022-04-21 16:52:46,742 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-5640325463 of layout LEGACY in volume: s3v
om3_1        | 2022-04-21 16:52:59,550 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-3979773564 of layout LEGACY in volume: s3v
om3_1        | 2022-04-21 16:53:29,432 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload: /s3v/bucket-ozone-test-3979773564/ozone-test-3619141613/multipartKey2 Part number: 1 size 6  is less than minimum part size 5242880
om3_1        | 2022-04-21 16:53:29,435 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-3619141613/multipartKey2 in Volume/Bucket s3v/bucket-ozone-test-3979773564
om3_1        | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-3979773564 key: ozone-test-3619141613/multipartKey2. Entity too small.
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:517)
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:197)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:514)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:317)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-04-21 16:53:30,801 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-ozone-test-3979773564/ozone-test-2106382736/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 1
om3_1        | partName: "etag1"
om3_1        | , partNumber: 2
om3_1        | partName: "etag2"
om3_1        | ]
om3_1        | 2022-04-21 16:53:30,808 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-2106382736/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-3979773564
om3_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-3979773564 key: ozone-test-2106382736/multipartKey3
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:186)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:514)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:317)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-04-21 16:53:31,451 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-ozone-test-3979773564/ozone-test-2106382736/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 2
om3_1        | partName: "etag1"
om3_1        | , partNumber: 1
om3_1        | partName: "etag2"
om3_1        | ]
om3_1        | 2022-04-21 16:53:31,454 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-2106382736/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-3979773564
om3_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-3979773564 key: ozone-test-2106382736/multipartKey3
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:186)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
recon_1      | 2022-04-21 16:45:32,437 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=a2956c20-9fda-4457-b767-0b8a33d7fc85 reported by 0ef408af-3ea2-4044-bc54-ad0ae15d84f1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 953699741549, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-04-21 16:45:32,437 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: a2956c20-9fda-4457-b767-0b8a33d7fc85, Nodes: a9037631-20c7-49ff-8966-d11abf0c09e2{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}8694db2d-5e51-4888-b1e0-69ff67626e43{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}0ef408af-3ea2-4044-bc54-ad0ae15d84f1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:a9037631-20c7-49ff-8966-d11abf0c09e2, CreationTimestamp2022-04-21T16:45:20.398Z[UTC]] moved to OPEN state
recon_1      | 2022-04-21 16:45:33,512 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=72e20438-e2a5-4ad3-9b38-a5405a44eb65. Trying to get from SCM.
recon_1      | 2022-04-21 16:45:33,712 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: 72e20438-e2a5-4ad3-9b38-a5405a44eb65, Nodes: a9037631-20c7-49ff-8966-d11abf0c09e2{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:a9037631-20c7-49ff-8966-d11abf0c09e2, CreationTimestamp2022-04-21T16:45:20.596Z[UTC]] to Recon pipeline metadata.
recon_1      | 2022-04-21 16:45:33,714 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 72e20438-e2a5-4ad3-9b38-a5405a44eb65, Nodes: a9037631-20c7-49ff-8966-d11abf0c09e2{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:a9037631-20c7-49ff-8966-d11abf0c09e2, CreationTimestamp2022-04-21T16:45:20.596Z[UTC]].
recon_1      | 2022-04-21 16:45:33,794 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=f5f2ffbc-fc63-4015-9163-f38ef2c5977c. Trying to get from SCM.
recon_1      | 2022-04-21 16:45:33,804 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 111 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-21 16:45:33,828 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 112 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-21 16:45:33,831 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 113 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-21 16:45:33,836 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: f5f2ffbc-fc63-4015-9163-f38ef2c5977c, Nodes: a9037631-20c7-49ff-8966-d11abf0c09e2{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}8694db2d-5e51-4888-b1e0-69ff67626e43{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}0ef408af-3ea2-4044-bc54-ad0ae15d84f1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-04-21T16:45:20.722Z[UTC]] to Recon pipeline metadata.
recon_1      | 2022-04-21 16:45:33,837 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: f5f2ffbc-fc63-4015-9163-f38ef2c5977c, Nodes: a9037631-20c7-49ff-8966-d11abf0c09e2{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}8694db2d-5e51-4888-b1e0-69ff67626e43{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}0ef408af-3ea2-4044-bc54-ad0ae15d84f1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-04-21T16:45:20.722Z[UTC]].
scm3.org_1   |   }
scm3.org_1   |   peers {
scm3.org_1   |     id: "e8ea6b57-c3ba-42bd-9807-0913ca4228d7"
om2_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-3979773564 key: ozone-test-2106382736/multipartKey3. Provided Part info is { etag2, 2}, whereas OM has partName /s3v/bucket-ozone-test-3979773564/ozone-test-2106382736/multipartKey3-39d7a4bf-f0b0-432c-9d38-260cf0a0d6fc-108171100822503460-2
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:499)
scm1.org_1   | 2022-04-21 16:43:31,348 [main] INFO server.RaftServer: e8ea6b57-c3ba-42bd-9807-0913ca4228d7: found a subdirectory /data/metadata/scm-ha/37768e1b-cb4c-49da-b09f-824fabcc98dc
recon_1      | 2022-04-21 16:45:33,845 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=f5f2ffbc-fc63-4015-9163-f38ef2c5977c reported by a9037631-20c7-49ff-8966-d11abf0c09e2{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 952295697655, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-04-21 16:45:34,787 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=f5f2ffbc-fc63-4015-9163-f38ef2c5977c reported by 8694db2d-5e51-4888-b1e0-69ff67626e43{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 952600664327, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-04-21 16:45:35,554 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=f5f2ffbc-fc63-4015-9163-f38ef2c5977c reported by 0ef408af-3ea2-4044-bc54-ad0ae15d84f1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 953699741549, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-04-21 16:45:35,833 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 114 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-21 16:45:35,834 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 115 failover attempts. Trying to failover immediately.
scm2.org_1   | 2022-04-21 16:44:06,367 [grpc-default-executor-1] INFO server.GrpcServerProtocolService: d794df5a-ece1-4828-94ba-97e720366f72: Completed INSTALL_SNAPSHOT, lastRequest: e8ea6b57-c3ba-42bd-9807-0913ca4228d7->d794df5a-ece1-4828-94ba-97e720366f72#0-t2,notify:(t:2, i:6)
scm2.org_1   | 2022-04-21 16:44:06,404 [d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC-StateMachineUpdater] INFO ha.SequenceIdGenerator: reinitialize SequenceIdGenerator.
scm2.org_1   | 2022-04-21 16:44:06,425 [d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
scm2.org_1   | 2022-04-21 16:44:06,432 [d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC-StateMachineUpdater] INFO ha.SCMHAManagerImpl: Reloaded SCM state with Term: 2 and Index: 6
scm2.org_1   | 2022-04-21 16:44:06,433 [d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC-StateMachineUpdater] INFO impl.StateMachineUpdater: d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC-StateMachineUpdater: snapshotIndex: setUnconditionally -1 -> 6
scm2.org_1   | 2022-04-21 16:44:06,433 [d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC-StateMachineUpdater] INFO impl.StateMachineUpdater: d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC-StateMachineUpdater: appliedIndex: setUnconditionally -1 -> 6
scm2.org_1   | 2022-04-21 16:44:08,888 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC-SegmentedRaftLogWorker: Starting segment from index:7
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1        | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:263)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.RatisBlockOutputStream.sendWatchForCommit(RatisBlockOutputStream.java:101)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:392)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:552)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:566)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:137)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:494)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:468)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:521)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:258)
s3g_1        | 	at jdk.internal.reflect.GeneratedMethodAccessor28.invoke(Unknown Source)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
scm3.org_1   |     address: "scm1.org:9894"
scm3.org_1   |   }
scm3.org_1   | }
scm3.org_1   |  from snapshot
scm3.org_1   | 2022-04-21 16:44:26,604 [grpc-default-executor-0] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: set configuration 11: [d794df5a-ece1-4828-94ba-97e720366f72|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, e8ea6b57-c3ba-42bd-9807-0913ca4228d7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-04-21 16:44:26,612 [grpc-default-executor-0] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: reply installSnapshot: e8ea6b57-c3ba-42bd-9807-0913ca4228d7<-9446a705-8bb9-4eda-8998-a3a4fb23e316#0:FAIL-t2,IN_PROGRESS
scm3.org_1   | 2022-04-21 16:44:26,620 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 9446a705-8bb9-4eda-8998-a3a4fb23e316: Completed INSTALL_SNAPSHOT, lastRequest: e8ea6b57-c3ba-42bd-9807-0913ca4228d7->9446a705-8bb9-4eda-8998-a3a4fb23e316#0-t2,notify:(t:2, i:12)
scm3.org_1   | 2022-04-21 16:44:26,664 [pool-16-thread-1] INFO ha.SCMSnapshotProvider: Successfully downloaded latest checkpoint from leader SCM: scm1 path /data/metadata/snapshot/scm.db-scm1-1650559463871
scm3.org_1   | 2022-04-21 16:44:26,666 [pool-16-thread-1] INFO ha.SCMHAManagerImpl: Downloaded checkpoint from Leader scm1 to the location /data/metadata/snapshot/scm.db-scm1-1650559463871
scm3.org_1   | 2022-04-21 16:44:26,766 [grpc-default-executor-0] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: Failed appendEntries as snapshot (12) installation is in progress
scm3.org_1   | 2022-04-21 16:44:26,767 [grpc-default-executor-0] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: inconsistency entries. Reply:e8ea6b57-c3ba-42bd-9807-0913ca4228d7<-9446a705-8bb9-4eda-8998-a3a4fb23e316#3:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm3.org_1   | 2022-04-21 16:44:26,774 [grpc-default-executor-0] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: receive installSnapshot: e8ea6b57-c3ba-42bd-9807-0913ca4228d7->9446a705-8bb9-4eda-8998-a3a4fb23e316#0-t2,notify:(t:2, i:12)
scm3.org_1   | 2022-04-21 16:44:26,774 [grpc-default-executor-0] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: set new configuration index: 11
scm3.org_1   | configurationEntry {
scm3.org_1   |   peers {
scm3.org_1   |     id: "d794df5a-ece1-4828-94ba-97e720366f72"
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:317)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:197)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:514)
scm2.org_1   | 2022-04-21 16:44:09,127 [d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/37768e1b-cb4c-49da-b09f-824fabcc98dc/current/log_inprogress_7
scm2.org_1   | 2022-04-21 16:44:09,170 [grpc-default-executor-0] INFO server.RaftServer$Division: d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC: set configuration 9: [d794df5a-ece1-4828-94ba-97e720366f72|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, e8ea6b57-c3ba-42bd-9807-0913ca4228d7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=[e8ea6b57-c3ba-42bd-9807-0913ca4228d7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-04-21 16:49:54,273 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39918
om1_1        | 2022-04-21 16:49:54,294 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2022-04-21 16:43:31,352 [main] INFO server.RaftServer: e8ea6b57-c3ba-42bd-9807-0913ca4228d7: addNew group-824FABCC98DC:[] returns group-824FABCC98DC:java.util.concurrent.CompletableFuture@147efd9[Not completed]
scm1.org_1   | 2022-04-21 16:43:31,377 [pool-14-thread-1] INFO server.RaftServer$Division: e8ea6b57-c3ba-42bd-9807-0913ca4228d7: new RaftServerImpl for group-824FABCC98DC:[] with SCMStateMachine:uninitialized
scm1.org_1   | 2022-04-21 16:43:31,379 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm2.org_1   | 2022-04-21 16:44:09,205 [grpc-default-executor-0] INFO server.RaftServer$Division: d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC: set configuration 11: [d794df5a-ece1-4828-94ba-97e720366f72|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, e8ea6b57-c3ba-42bd-9807-0913ca4228d7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2022-04-21 16:44:09,498 [Listener at 0.0.0.0/9860] INFO ha.SCMHAManagerImpl: Successfully added SCM scm2 to group group-824FABCC98DC:[d794df5a-ece1-4828-94ba-97e720366f72|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, e8ea6b57-c3ba-42bd-9807-0913ca4228d7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm2.org_1   | 2022-04-21 16:44:09,499 [Listener at 0.0.0.0/9860] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
scm2.org_1   | 2022-04-21 16:44:09,504 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Starting token manager
recon_1      | 2022-04-21 16:45:35,835 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 116 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-21 16:45:37,836 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 117 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-21 16:45:37,838 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 118 failover attempts. Trying to failover immediately.
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:514)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:317)
recon_1      | 2022-04-21 16:45:37,838 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 119 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-21 16:45:38,844 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=f5f2ffbc-fc63-4015-9163-f38ef2c5977c reported by a9037631-20c7-49ff-8966-d11abf0c09e2{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 952295697655, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-04-21 16:45:39,840 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 120 failover attempts. Trying to failover immediately.
scm3.org_1   |     address: "scm2.org:9894"
scm3.org_1   |   }
scm3.org_1   |   peers {
scm3.org_1   |     id: "e8ea6b57-c3ba-42bd-9807-0913ca4228d7"
recon_1      | 2022-04-21 16:45:39,840 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 121 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-21 16:45:39,841 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 122 failover attempts. Trying to failover after sleeping for 2000ms.
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:317)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm1.org_1   | 2022-04-21 16:43:31,380 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm1.org_1   | 2022-04-21 16:43:31,380 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm3.org_1   |     address: "scm1.org:9894"
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-04-21 16:53:37,574 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-2106382736/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-3979773564
om3_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-3979773564 key: ozone-test-2106382736/multipartKey3. Provided Part info is { etag1, 1}, whereas OM has partName /s3v/bucket-ozone-test-3979773564/ozone-test-2106382736/multipartKey3-39d7a4bf-f0b0-432c-9d38-260cf0a0d6fc-108171100822503460-1
scm1.org_1   | 2022-04-21 16:43:31,381 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm1.org_1   | 2022-04-21 16:43:31,381 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm1.org_1   | 2022-04-21 16:43:31,381 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
scm1.org_1   | 2022-04-21 16:43:31,382 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm1.org_1   | 2022-04-21 16:43:31,386 [pool-14-thread-1] INFO server.RaftServer$Division: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
scm1.org_1   | 2022-04-21 16:43:31,386 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm1.org_1   | 2022-04-21 16:43:31,389 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm1.org_1   | 2022-04-21 16:43:31,390 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
scm1.org_1   | 2022-04-21 16:43:31,416 [pool-14-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/37768e1b-cb4c-49da-b09f-824fabcc98dc/in_use.lock acquired by nodename 8@scm1.org
scm1.org_1   | 2022-04-21 16:43:31,421 [pool-14-thread-1] INFO storage.RaftStorage: Read RaftStorageMetadata{term=1, votedFor=e8ea6b57-c3ba-42bd-9807-0913ca4228d7} from /data/metadata/scm-ha/37768e1b-cb4c-49da-b09f-824fabcc98dc/current/raft-meta
scm1.org_1   | 2022-04-21 16:43:31,469 [pool-14-thread-1] INFO server.RaftServer$Division: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC: set configuration 0: [e8ea6b57-c3ba-42bd-9807-0913ca4228d7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2022-04-21 16:43:31,469 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm1.org_1   | 2022-04-21 16:43:31,470 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om2_1        | 2022-04-21 16:53:38,824 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: PartNumber at index 1 is 2, and its previous partNumber at index 0 is 4 for ozonekey is /s3v/bucket-ozone-test-3979773564/ozone-test-2106382736/multipartKey3
om2_1        | 2022-04-21 16:53:38,827 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-2106382736/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-3979773564
om2_1        | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-3979773564 key: ozone-test-2106382736/multipartKey3 because parts are in Invalid order.
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getPartsListSize(S3MultipartUploadCompleteRequest.java:465)
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:193)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:514)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:317)
om1_1        | 2022-04-21 16:49:58,192 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:41477
om1_1        | 2022-04-21 16:49:58,202 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 16:49:58,767 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39956
om1_1        | 2022-04-21 16:49:58,788 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2022-04-21 16:44:09,506 [Listener at 0.0.0.0/9860] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
scm2.org_1   | 2022-04-21 16:44:09,580 [d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-04-21 16:44:09,587 [d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
scm2.org_1   | 2022-04-21 16:44:09,588 [d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:499)
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:197)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:514)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm2.org_1   | 2022-04-21 16:44:09,588 [d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9861
scm2.org_1   | 2022-04-21 16:44:09,877 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm2.org_1   | 2022-04-21 16:44:09,937 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm2.org_1   | 2022-04-21 16:44:09,937 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:317)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm2.org_1   | 2022-04-21 16:44:10,329 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm2.org_1   | 2022-04-21 16:44:10,340 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm1.org_1   | 2022-04-21 16:43:31,480 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm1.org_1   | 2022-04-21 16:43:31,480 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2022-04-21 16:43:31,495 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm1.org_1   | 2022-04-21 16:43:31,502 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm1.org_1   | 2022-04-21 16:43:31,502 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
scm1.org_1   | 2022-04-21 16:43:31,506 [pool-14-thread-1] INFO segmented.SegmentedRaftLogWorker: new e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/37768e1b-cb4c-49da-b09f-824fabcc98dc
scm1.org_1   | 2022-04-21 16:43:31,507 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
scm1.org_1   | 2022-04-21 16:43:31,508 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm1.org_1   | 2022-04-21 16:43:31,509 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm1.org_1   | 2022-04-21 16:43:31,510 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
scm1.org_1   | 2022-04-21 16:43:31,510 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm1.org_1   | 2022-04-21 16:43:31,512 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
recon_1      | 2022-04-21 16:45:46,686 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om1 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:222)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1        | 2022-04-21 16:49:59,163 [IPC Server handler 53 on default port 9862] WARN om.OzoneManager: User testuser2/scm@EXAMPLE.COM doesn't have READ permission to access bucket Volume:00630-target Bucket:unreadable-link 
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-04-21 16:53:42,323 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadAbortRequest: Abort Multipart request is failed for KeyName ozone-test-6281006145/multipartKey5 in VolumeName/Bucket s3v/bucket-ozone-test-3979773564
om2_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: s3vbucket: bucket-ozone-test-3979773564key: ozone-test-6281006145/multipartKey5
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:161)
scm3.org_1   |   }
scm3.org_1   | }
scm3.org_1   |  from snapshot
scm3.org_1   | 2022-04-21 16:44:26,782 [grpc-default-executor-0] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: set configuration 11: [d794df5a-ece1-4828-94ba-97e720366f72|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, e8ea6b57-c3ba-42bd-9807-0913ca4228d7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-04-21 16:44:26,784 [grpc-default-executor-0] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: reply installSnapshot: e8ea6b57-c3ba-42bd-9807-0913ca4228d7<-9446a705-8bb9-4eda-8998-a3a4fb23e316#0:FAIL-t2,IN_PROGRESS
scm3.org_1   | 2022-04-21 16:44:26,786 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 9446a705-8bb9-4eda-8998-a3a4fb23e316: Completed INSTALL_SNAPSHOT, lastRequest: e8ea6b57-c3ba-42bd-9807-0913ca4228d7->9446a705-8bb9-4eda-8998-a3a4fb23e316#0-t2,notify:(t:2, i:12)
scm3.org_1   | 2022-04-21 16:44:26,839 [grpc-default-executor-0] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: Failed appendEntries as snapshot (12) installation is in progress
scm3.org_1   | 2022-04-21 16:44:26,840 [grpc-default-executor-0] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: inconsistency entries. Reply:e8ea6b57-c3ba-42bd-9807-0913ca4228d7<-9446a705-8bb9-4eda-8998-a3a4fb23e316#4:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm3.org_1   | 2022-04-21 16:44:26,844 [grpc-default-executor-0] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: receive installSnapshot: e8ea6b57-c3ba-42bd-9807-0913ca4228d7->9446a705-8bb9-4eda-8998-a3a4fb23e316#0-t2,notify:(t:2, i:12)
scm3.org_1   | 2022-04-21 16:44:26,860 [grpc-default-executor-0] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: set new configuration index: 11
scm3.org_1   | configurationEntry {
scm3.org_1   |   peers {
scm3.org_1   |     id: "d794df5a-ece1-4828-94ba-97e720366f72"
scm3.org_1   |     address: "scm2.org:9894"
scm3.org_1   |   }
scm3.org_1   |   peers {
scm3.org_1   |     id: "e8ea6b57-c3ba-42bd-9807-0913ca4228d7"
scm3.org_1   |     address: "scm1.org:9894"
scm3.org_1   |   }
scm3.org_1   | }
scm3.org_1   |  from snapshot
scm3.org_1   | 2022-04-21 16:44:26,863 [grpc-default-executor-0] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: set configuration 11: [d794df5a-ece1-4828-94ba-97e720366f72|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, e8ea6b57-c3ba-42bd-9807-0913ca4228d7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-04-21 16:44:26,864 [grpc-default-executor-0] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: reply installSnapshot: e8ea6b57-c3ba-42bd-9807-0913ca4228d7<-9446a705-8bb9-4eda-8998-a3a4fb23e316#0:FAIL-t2,IN_PROGRESS
om1_1        | 2022-04-21 16:50:02,750 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39968
om1_1        | 2022-04-21 16:50:02,784 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 16:50:06,797 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39972
om1_1        | 2022-04-21 16:50:06,819 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2022-04-21 16:43:31,512 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm2.org_1   | 2022-04-21 16:44:10,472 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:174)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-04-21 16:50:07,316 [IPC Server handler 92 on default port 9862] WARN om.OzoneManager: User testuser2/scm@EXAMPLE.COM doesn't have LIST permission to access bucket Volume:00630-source Bucket:unreadable-bucket Key:
om1_1        | 2022-04-21 16:50:10,617 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39984
om1_1        | 2022-04-21 16:50:10,628 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 16:50:11,097 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop2 of layout LEGACY in volume: 00630-target
scm1.org_1   | 2022-04-21 16:43:31,512 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:146)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
scm1.org_1   | 2022-04-21 16:43:31,519 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:514)
om1_1        | 2022-04-21 16:50:14,517 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40006
om1_1        | 2022-04-21 16:50:14,532 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 16:50:15,063 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop3 of layout LEGACY in volume: 00630-target
om1_1        | 2022-04-21 16:50:18,347 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40010
om1_1        | 2022-04-21 16:50:18,364 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2022-04-21 16:43:31,520 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:317)
om1_1        | 2022-04-21 16:50:18,887 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop1 of layout LEGACY in volume: 00630-target
om1_1        | 2022-04-21 16:50:22,182 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40024
om1_1        | 2022-04-21 16:50:22,207 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2022-04-21 16:43:31,541 [pool-14-thread-1] INFO server.RaftServer$Division: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC: set configuration 0: [e8ea6b57-c3ba-42bd-9807-0913ca4228d7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm1.org_1   | 2022-04-21 16:43:31,541 [pool-14-thread-1] INFO segmented.LogSegment: Successfully read 1 entries from segment file /data/metadata/scm-ha/37768e1b-cb4c-49da-b09f-824fabcc98dc/current/log_inprogress_0
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm2.org_1   | 2022-04-21 16:44:10,474 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm2.org_1   | 2022-04-21 16:44:10,480 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm2.org_1   | 2022-04-21 16:44:10,545 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm2.org_1   | 2022-04-21 16:44:10,551 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm2.org_1   | 2022-04-21 16:44:10,569 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm2.org_1   | 2022-04-21 16:44:10,592 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm2.org_1   | 2022-04-21 16:44:10,670 [Listener at 0.0.0.0/9860] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
scm1.org_1   | 2022-04-21 16:43:31,543 [pool-14-thread-1] INFO segmented.SegmentedRaftLogWorker: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 0
om2_1        | 2022-04-21 16:53:42,988 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyCreateRequest: Key creation failed. Volume:s3v, Bucket:bucket-ozone-test-3979773564, Key:ozone-test-4122654440/multipartKey. 
om2_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartFileInfo(OMKeyRequest.java:754)
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareFileInfo(OMKeyRequest.java:645)
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:622)
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyCreateRequest.validateAndUpdateCache(OMKeyCreateRequest.java:277)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:514)
scm1.org_1   | 2022-04-21 16:43:31,544 [pool-14-thread-1] INFO segmented.SegmentedRaftLogWorker: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:317)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-04-21 16:57:39,412 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-5032629137 of layout LEGACY in volume: s3v
om2_1        | 2022-04-21 16:57:40,159 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: destbucket-85240 of layout LEGACY in volume: s3v
om2_1        | 2022-04-21 17:00:00,684 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-5639337117 of layout LEGACY in volume: s3v
scm1.org_1   | 2022-04-21 16:43:31,627 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om2_1        | 2022-04-21 17:00:26,431 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-1676201683 of layout LEGACY in volume: s3v
scm1.org_1   | 2022-04-21 16:43:31,627 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
scm1.org_1   | 2022-04-21 16:43:31,629 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om3_1        | 2022-04-21 16:53:38,192 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-2106382736/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-3979773564
om3_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-3979773564 key: ozone-test-2106382736/multipartKey3. Provided Part info is { etag2, 2}, whereas OM has partName /s3v/bucket-ozone-test-3979773564/ozone-test-2106382736/multipartKey3-39d7a4bf-f0b0-432c-9d38-260cf0a0d6fc-108171100822503460-2
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:499)
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:197)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:514)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:317)
scm1.org_1   | 2022-04-21 16:43:31,631 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm1.org_1   | 2022-04-21 16:43:31,632 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
om1_1        | 2022-04-21 16:50:26,437 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40060
scm1.org_1   | 2022-04-21 16:43:31,632 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om1_1        | 2022-04-21 16:50:26,461 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 16:50:26,971 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link3 of layout LEGACY in volume: 00630-target
om1_1        | 2022-04-21 16:50:30,271 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40064
om1_1        | 2022-04-21 16:50:30,302 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 16:50:36,575 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40080
om1_1        | 2022-04-21 16:50:36,589 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 16:50:42,638 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40096
scm2.org_1   | 2022-04-21 16:44:10,698 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm1.org_1   | 2022-04-21 16:43:31,663 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
scm1.org_1   | 2022-04-21 16:43:31,664 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
scm1.org_1   | 2022-04-21 16:43:31,664 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
scm2.org_1   | 2022-04-21 16:44:10,721 [Listener at 0.0.0.0/9860] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService starting
scm1.org_1   | 2022-04-21 16:43:31,813 [main] INFO ha.SequenceIdGenerator: upgrade localId to 109611004723200000
scm2.org_1   | 2022-04-21 16:44:10,722 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
scm2.org_1   | 2022-04-21 16:44:10,951 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
scm2.org_1   | 2022-04-21 16:44:10,951 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
scm2.org_1   | 2022-04-21 16:44:10,951 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
scm2.org_1   | 2022-04-21 16:44:11,384 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2f0dae44] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm2.org_1   | 2022-04-21 16:44:11,480 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm2.org_1   | 2022-04-21 16:44:11,481 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
scm2.org_1   | 2022-04-21 16:44:11,482 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
scm2.org_1   | 2022-04-21 16:44:11,664 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @22376ms to org.eclipse.jetty.util.log.Slf4jLog
scm1.org_1   | 2022-04-21 16:43:31,813 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
scm2.org_1   | 2022-04-21 16:44:12,032 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm2.org_1   | 2022-04-21 16:44:12,040 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm2.org_1   | 2022-04-21 16:44:12,045 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
scm1.org_1   | 2022-04-21 16:43:31,817 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
scm1.org_1   | 2022-04-21 16:43:31,819 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
om1_1        | 2022-04-21 16:50:42,660 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 16:50:46,620 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40108
om1_1        | 2022-04-21 16:50:46,640 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 16:50:50,677 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40120
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
scm1.org_1   | 2022-04-21 16:43:31,883 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm2.org_1   | 2022-04-21 16:44:12,045 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
om1_1        | 2022-04-21 16:50:50,704 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 16:50:58,250 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:34889
om1_1        | 2022-04-21 16:50:58,269 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 16:51:21,919 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40380
om1_1        | 2022-04-21 16:51:21,936 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 16:51:26,575 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:39957
om1_1        | 2022-04-21 16:51:26,598 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2022-04-21 16:44:26,874 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 9446a705-8bb9-4eda-8998-a3a4fb23e316: Completed INSTALL_SNAPSHOT, lastRequest: e8ea6b57-c3ba-42bd-9807-0913ca4228d7->9446a705-8bb9-4eda-8998-a3a4fb23e316#0-t2,notify:(t:2, i:12)
scm1.org_1   | 2022-04-21 16:43:31,905 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 123 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-21 16:45:47,415 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
scm3.org_1   | 2022-04-21 16:44:26,940 [grpc-default-executor-0] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: Failed appendEntries as snapshot (12) installation is in progress
scm3.org_1   | 2022-04-21 16:44:26,947 [grpc-default-executor-0] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: inconsistency entries. Reply:e8ea6b57-c3ba-42bd-9807-0913ca4228d7<-9446a705-8bb9-4eda-8998-a3a4fb23e316#5:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm1.org_1   | 2022-04-21 16:43:31,913 [main] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
scm3.org_1   | 2022-04-21 16:44:26,952 [grpc-default-executor-0] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: receive installSnapshot: e8ea6b57-c3ba-42bd-9807-0913ca4228d7->9446a705-8bb9-4eda-8998-a3a4fb23e316#0-t2,notify:(t:2, i:12)
scm1.org_1   | 2022-04-21 16:43:31,956 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
scm2.org_1   | 2022-04-21 16:44:12,045 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
scm2.org_1   | 2022-04-21 16:44:12,050 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
scm2.org_1   | 2022-04-21 16:44:12,121 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
scm2.org_1   | 2022-04-21 16:44:12,134 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
scm2.org_1   | 2022-04-21 16:44:12,260 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm3.org_1   | 2022-04-21 16:44:26,965 [grpc-default-executor-0] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: set new configuration index: 11
scm3.org_1   | configurationEntry {
scm1.org_1   | 2022-04-21 16:43:31,957 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
om1_1        | 2022-04-21 16:51:26,995 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:51:27,063 [IPC Server handler 46 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm3.org_1   |   peers {
scm3.org_1   |     id: "d794df5a-ece1-4828-94ba-97e720366f72"
scm3.org_1   |     address: "scm2.org:9894"
scm3.org_1   |   }
scm3.org_1   |   peers {
scm3.org_1   |     id: "e8ea6b57-c3ba-42bd-9807-0913ca4228d7"
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-04-21 16:53:38,813 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: PartNumber at index 1 is 2, and its previous partNumber at index 0 is 4 for ozonekey is /s3v/bucket-ozone-test-3979773564/ozone-test-2106382736/multipartKey3
om3_1        | 2022-04-21 16:53:38,814 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-2106382736/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-3979773564
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:222)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:215)
scm2.org_1   | 2022-04-21 16:44:12,263 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm2.org_1   | 2022-04-21 16:44:12,276 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 660000ms
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:174)
scm3.org_1   |     address: "scm1.org:9894"
scm2.org_1   | 2022-04-21 16:44:12,355 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm2.org_1   | 2022-04-21 16:44:12,358 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2c7e2c5{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm1.org_1   | 2022-04-21 16:43:31,969 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
scm1.org_1   | 2022-04-21 16:43:31,970 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
scm1.org_1   | 2022-04-21 16:43:32,005 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
scm1.org_1   | 2022-04-21 16:43:32,027 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
scm1.org_1   | 2022-04-21 16:43:32,067 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
scm1.org_1   | 2022-04-21 16:43:32,096 [main] INFO container.ReplicationManager: Starting Replication Monitor Thread.
scm1.org_1   | 2022-04-21 16:43:32,108 [ReplicationMonitor] INFO container.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm1.org_1   | 2022-04-21 16:43:32,108 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
scm1.org_1   | 2022-04-21 16:43:32,111 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-04-21 16:43:32,114 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm1.org_1   | 2022-04-21 16:43:32,148 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
scm1.org_1   | 2022-04-21 16:43:32,158 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
scm1.org_1   | 2022-04-21 16:43:32,161 [main] INFO server.StorageContainerManager: Storing sub-ca certificate serialId 862887965327 on primary SCM
scm1.org_1   | 2022-04-21 16:43:32,168 [main] INFO server.StorageContainerManager: Storing root certificate serialId 1
scm1.org_1   | 2022-04-21 16:43:32,199 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:146)
scm1.org_1   | 2022-04-21 16:43:32,246 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
scm1.org_1   | 2022-04-21 16:43:33,011 [Listener at 0.0.0.0/9961] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm1.org_1   | 2022-04-21 16:43:33,021 [Listener at 0.0.0.0/9961] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om2_1        | 2022-04-21 17:00:30,958 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:s3v, Bucket:bucket-ozone-test-1676201683, Key:ozone-test-5348923844/multidelete/key=value/f4.
om2_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:146)
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:92)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
scm3.org_1   |   }
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om3_1        | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-3979773564 key: ozone-test-2106382736/multipartKey3 because parts are in Invalid order.
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getPartsListSize(S3MultipartUploadCompleteRequest.java:465)
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:193)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:514)
scm2.org_1   | 2022-04-21 16:44:12,365 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@45ec6bb3{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm3.org_1   | }
om1_1        | 2022-04-21 16:51:27,074 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-1938307693 of layout LEGACY in volume: s3v
om1_1        | 2022-04-21 16:51:30,569 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40418
om1_1        | 2022-04-21 16:51:30,585 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 16:51:33,785 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:51:33,790 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:51:33,799 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-3093588181 of layout LEGACY in volume: s3v
scm1.org_1   | 2022-04-21 16:43:33,026 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:514)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:317)
scm1.org_1   | 2022-04-21 16:43:33,058 [Listener at 0.0.0.0/9861] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
om1_1        | 2022-04-21 16:51:34,417 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:51:34,424 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:51:34,465 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:51:36,211 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:317)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
scm3.org_1   |  from snapshot
scm3.org_1   | 2022-04-21 16:44:26,968 [grpc-default-executor-0] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: set configuration 11: [d794df5a-ece1-4828-94ba-97e720366f72|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, e8ea6b57-c3ba-42bd-9807-0913ca4228d7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-04-21 16:44:26,971 [grpc-default-executor-0] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: reply installSnapshot: e8ea6b57-c3ba-42bd-9807-0913ca4228d7<-9446a705-8bb9-4eda-8998-a3a4fb23e316#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2022-04-21 16:43:33,065 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1679)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm3.org_1   | 2022-04-21 16:44:27,003 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 9446a705-8bb9-4eda-8998-a3a4fb23e316: Completed INSTALL_SNAPSHOT, lastRequest: e8ea6b57-c3ba-42bd-9807-0913ca4228d7->9446a705-8bb9-4eda-8998-a3a4fb23e316#0-t2,notify:(t:2, i:12)
scm3.org_1   | 2022-04-21 16:44:27,036 [grpc-default-executor-0] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: Failed appendEntries as snapshot (12) installation is in progress
scm1.org_1   | 2022-04-21 16:43:33,067 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-04-21 16:53:42,316 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadAbortRequest: Abort Multipart request is failed for KeyName ozone-test-6281006145/multipartKey5 in VolumeName/Bucket s3v/bucket-ozone-test-3979773564
om3_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: s3vbucket: bucket-ozone-test-3979773564key: ozone-test-6281006145/multipartKey5
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-04-21 17:00:39,805 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-4595663119 of layout LEGACY in volume: s3v
om2_1        | 2022-04-21 17:01:05,454 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-4385489974 of layout LEGACY in volume: s3v
scm1.org_1   | 2022-04-21 16:43:33,165 [Listener at 0.0.0.0/9863] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:161)
om1_1        | 2022-04-21 16:51:36,843 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:51:36,850 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:51:36,857 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:51:36,997 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:51:37,636 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:51:37,639 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:51:37,669 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
scm2.org_1   | 2022-04-21 16:44:12,626 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm3.org_1   | 2022-04-21 16:44:27,046 [grpc-default-executor-0] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: inconsistency entries. Reply:e8ea6b57-c3ba-42bd-9807-0913ca4228d7<-9446a705-8bb9-4eda-8998-a3a4fb23e316#6:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm3.org_1   | 2022-04-21 16:44:27,091 [grpc-default-executor-0] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: receive installSnapshot: e8ea6b57-c3ba-42bd-9807-0913ca4228d7->9446a705-8bb9-4eda-8998-a3a4fb23e316#0-t2,notify:(t:2, i:12)
scm1.org_1   | 2022-04-21 16:43:33,189 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om1_1        | 2022-04-21 16:51:37,677 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:51:38,305 [IPC Server handler 73 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:51:38,309 [IPC Server handler 79 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:51:38,312 [IPC Server handler 84 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm2.org_1   | 2022-04-21 16:44:12,676 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@6846e4e8{scm,/,file:///tmp/jetty-0_0_0_0-9876-hdds-server-scm-1_3_0-SNAPSHOT_jar-_-any-7505421517035760238/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/scm}
scm2.org_1   | 2022-04-21 16:44:12,701 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@252d690{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
om1_1        | 2022-04-21 16:51:38,316 [IPC Server handler 85 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:51:38,909 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm1.org_1   | 2022-04-21 16:43:33,207 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm1.org_1   | 2022-04-21 16:43:33,331 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: 
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
om1_1        | 2022-04-21 16:51:38,916 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:51:38,920 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:51:38,924 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm1.org_1   | Container Balancer status:
scm1.org_1   | Key                            Value
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
scm3.org_1   | 2022-04-21 16:44:27,098 [grpc-default-executor-0] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: set new configuration index: 11
scm2.org_1   | 2022-04-21 16:44:12,716 [Listener at 0.0.0.0/9860] INFO server.Server: Started @23429ms
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
scm1.org_1   | Running                        false
scm1.org_1   | Container Balancer Configuration values:
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:514)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
scm3.org_1   | configurationEntry {
scm2.org_1   | 2022-04-21 16:44:12,719 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm2.org_1   | 2022-04-21 16:44:12,719 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm2.org_1   | 2022-04-21 16:44:12,721 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm1.org_1   | Key                                                Value
scm1.org_1   | Threshold                                          10
scm1.org_1   | Max Datanodes to Involve per Iteration(percent)    20
scm1.org_1   | Max Size to Move per Iteration                     500GB
scm1.org_1   | Max Size Entering Target per Iteration             26GB
om1_1        | 2022-04-21 16:51:39,557 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:51:39,561 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:51:39,566 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 124 failover attempts. Trying to failover immediately.
scm1.org_1   | Max Size Leaving Source per Iteration              26GB
scm2.org_1   | 2022-04-21 16:44:30,233 [grpc-default-executor-0] INFO server.RaftServer$Division: d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC: set configuration 13: [9446a705-8bb9-4eda-8998-a3a4fb23e316|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0, d794df5a-ece1-4828-94ba-97e720366f72|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, e8ea6b57-c3ba-42bd-9807-0913ca4228d7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=[d794df5a-ece1-4828-94ba-97e720366f72|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, e8ea6b57-c3ba-42bd-9807-0913ca4228d7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
om1_1        | 2022-04-21 16:51:42,225 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:51:42,839 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
scm3.org_1   |   peers {
om1_1        | 2022-04-21 16:51:42,843 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:51:42,848 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:51:42,851 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:51:46,098 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40468
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:317)
recon_1      | 2022-04-21 16:45:48,711 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om3 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
scm2.org_1   | 2022-04-21 16:44:30,277 [grpc-default-executor-0] INFO server.RaftServer$Division: d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC: set configuration 15: [9446a705-8bb9-4eda-8998-a3a4fb23e316|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0, d794df5a-ece1-4828-94ba-97e720366f72|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, e8ea6b57-c3ba-42bd-9807-0913ca4228d7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2022-04-21 16:44:49,817 [d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-04-21 16:44:49,820 [d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC-StateMachineUpdater] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
om1_1        | 2022-04-21 16:51:46,112 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:222)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:215)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:174)
om1_1        | 2022-04-21 16:51:49,305 [IPC Server handler 73 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:51:49,312 [IPC Server handler 84 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:51:49,322 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-1324058591 of layout LEGACY in volume: s3v
om1_1        | 2022-04-21 16:51:49,866 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:146)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
om1_1        | 2022-04-21 16:51:49,873 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:51:49,884 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ozone-test-iivwcokihe of layout LEGACY in volume: s3v
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm1.org_1   | 
scm1.org_1   | 2022-04-21 16:43:33,331 [Listener at 0.0.0.0/9860] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm1.org_1   | 2022-04-21 16:43:33,331 [Listener at 0.0.0.0/9860] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
scm1.org_1   | 2022-04-21 16:43:33,340 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm1.org_1   | 2022-04-21 16:43:33,341 [Listener at 0.0.0.0/9860] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
scm1.org_1   | 2022-04-21 16:43:33,342 [Listener at 0.0.0.0/9860] INFO server.RaftServer$Division: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC: start as a follower, conf=0: [e8ea6b57-c3ba-42bd-9807-0913ca4228d7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2022-04-21 16:43:33,357 [Listener at 0.0.0.0/9860] INFO server.RaftServer$Division: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC: changes role from      null to FOLLOWER at term 1 for startAsFollower
scm1.org_1   | 2022-04-21 16:43:33,361 [Listener at 0.0.0.0/9860] INFO impl.RoleInfo: e8ea6b57-c3ba-42bd-9807-0913ca4228d7: start e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-FollowerState
scm1.org_1   | 2022-04-21 16:43:33,368 [Listener at 0.0.0.0/9860] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-824FABCC98DC,id=e8ea6b57-c3ba-42bd-9807-0913ca4228d7
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
scm1.org_1   | 2022-04-21 16:43:33,380 [Listener at 0.0.0.0/9860] INFO server.RaftServer: e8ea6b57-c3ba-42bd-9807-0913ca4228d7: start RPC server
scm1.org_1   | 2022-04-21 16:43:33,440 [Listener at 0.0.0.0/9860] INFO server.GrpcService: e8ea6b57-c3ba-42bd-9807-0913ca4228d7: GrpcService started, listening on 9894
scm1.org_1   | 2022-04-21 16:43:33,447 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$438/0x000000084053f040@47a68e3f] INFO util.JvmPauseMonitor: JvmPauseMonitor-e8ea6b57-c3ba-42bd-9807-0913ca4228d7: Started
scm1.org_1   | 2022-04-21 16:43:33,447 [Listener at 0.0.0.0/9860] INFO ha.SCMHAManagerImpl:  scm role is FOLLOWER peers [e8ea6b57-c3ba-42bd-9807-0913ca4228d7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 125 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-21 16:45:50,715 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om1 is not the leader. Could not determine the leader node.
om1_1        | 2022-04-21 16:51:49,912 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:51:49,917 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm2.org_1   | 2022-04-21 16:44:49,820 [d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC-StateMachineUpdater] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:222)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1        | 2022-04-21 16:51:49,921 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm1.org_1   | 2022-04-21 16:43:33,451 [Listener at 0.0.0.0/9860] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
scm3.org_1   |     id: "d794df5a-ece1-4828-94ba-97e720366f72"
scm3.org_1   |     address: "scm2.org:9894"
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-04-21 16:51:52,571 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:174)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:146)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
om1_1        | 2022-04-21 16:51:52,619 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:51:52,622 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:51:52,626 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:51:55,225 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:51:55,308 [IPC Server handler 73 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:51:55,332 [IPC Server handler 84 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:51:55,344 [IPC Server handler 96 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om3_1        | 2022-04-21 16:53:42,985 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyCreateRequest: Key creation failed. Volume:s3v, Bucket:bucket-ozone-test-3979773564, Key:ozone-test-4122654440/multipartKey. 
om3_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
om1_1        | 2022-04-21 16:51:58,076 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:51:58,117 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:51:58,125 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm1.org_1   | 2022-04-21 16:43:33,453 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Starting token manager
scm1.org_1   | 2022-04-21 16:43:33,454 [Listener at 0.0.0.0/9860] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartFileInfo(OMKeyRequest.java:754)
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareFileInfo(OMKeyRequest.java:645)
om1_1        | 2022-04-21 16:51:58,157 [IPC Server handler 63 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:51:58,348 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:39397
scm2.org_1   | 2022-04-21 16:44:50,213 [d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-04-21 16:44:51,390 [d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-04-21 16:43:33,567 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm1.org_1   | 2022-04-21 16:43:33,579 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm1.org_1   | 2022-04-21 16:43:33,580 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm1.org_1   | 2022-04-21 16:43:33,850 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm1.org_1   | 2022-04-21 16:43:33,851 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm3.org_1   |   }
scm3.org_1   |   peers {
scm3.org_1   |     id: "e8ea6b57-c3ba-42bd-9807-0913ca4228d7"
scm2.org_1   | 2022-04-21 16:44:57,777 [d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-04-21 16:44:59,080 [d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-04-21 16:43:33,853 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm1.org_1   | 2022-04-21 16:43:33,878 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm3.org_1   |     address: "scm1.org:9894"
scm3.org_1   |   }
scm3.org_1   | }
scm2.org_1   | 2022-04-21 16:45:00,131 [d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-04-21 16:45:15,928 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59494
scm3.org_1   |  from snapshot
scm3.org_1   | 2022-04-21 16:44:27,119 [grpc-default-executor-0] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: set configuration 11: [d794df5a-ece1-4828-94ba-97e720366f72|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, e8ea6b57-c3ba-42bd-9807-0913ca4228d7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-04-21 16:44:27,122 [grpc-default-executor-0] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: reply installSnapshot: e8ea6b57-c3ba-42bd-9807-0913ca4228d7<-9446a705-8bb9-4eda-8998-a3a4fb23e316#0:FAIL-t2,IN_PROGRESS
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:622)
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyCreateRequest.validateAndUpdateCache(OMKeyCreateRequest.java:277)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
scm3.org_1   | 2022-04-21 16:44:27,143 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 9446a705-8bb9-4eda-8998-a3a4fb23e316: Completed INSTALL_SNAPSHOT, lastRequest: e8ea6b57-c3ba-42bd-9807-0913ca4228d7->9446a705-8bb9-4eda-8998-a3a4fb23e316#0-t2,notify:(t:2, i:12)
scm3.org_1   | 2022-04-21 16:44:27,181 [grpc-default-executor-1] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: Failed appendEntries as snapshot (12) installation is in progress
scm3.org_1   | 2022-04-21 16:44:27,187 [grpc-default-executor-1] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: inconsistency entries. Reply:e8ea6b57-c3ba-42bd-9807-0913ca4228d7<-9446a705-8bb9-4eda-8998-a3a4fb23e316#7:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm3.org_1   | 2022-04-21 16:44:27,218 [grpc-default-executor-0] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: receive installSnapshot: e8ea6b57-c3ba-42bd-9807-0913ca4228d7->9446a705-8bb9-4eda-8998-a3a4fb23e316#0-t2,notify:(t:2, i:12)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:514)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:317)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1        | 2022-04-21 16:51:58,352 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 16:51:58,424 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:51:58,428 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:51:58,433 [IPC Server handler 96 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:51:58,499 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:51:58,531 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:51:58,537 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:51:58,547 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 2022-04-21 16:51:58,605 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:51:59,304 [IPC Server handler 78 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:02,068 [IPC Server handler 46 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:02,152 [IPC Server handler 56 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:02,156 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:02,178 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm3.org_1   | 2022-04-21 16:44:27,270 [grpc-default-executor-0] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: set new configuration index: 11
scm3.org_1   | configurationEntry {
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-04-21 16:52:02,309 [IPC Server handler 69 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:02,316 [IPC Server handler 70 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
scm3.org_1   |   peers {
scm3.org_1   |     id: "d794df5a-ece1-4828-94ba-97e720366f72"
scm3.org_1   |     address: "scm2.org:9894"
scm3.org_1   |   }
scm3.org_1   |   peers {
scm3.org_1   |     id: "e8ea6b57-c3ba-42bd-9807-0913ca4228d7"
scm3.org_1   |     address: "scm1.org:9894"
scm3.org_1   |   }
om1_1        | 2022-04-21 16:52:02,335 [IPC Server handler 92 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm2.org_1   | 2022-04-21 16:45:15,961 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
scm3.org_1   | }
scm3.org_1   |  from snapshot
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 126 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-21 16:45:50,719 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:222)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:215)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:174)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:146)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
scm3.org_1   | 2022-04-21 16:44:27,278 [grpc-default-executor-0] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: set configuration 11: [d794df5a-ece1-4828-94ba-97e720366f72|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, e8ea6b57-c3ba-42bd-9807-0913ca4228d7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-04-21 16:44:27,279 [grpc-default-executor-0] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: reply installSnapshot: e8ea6b57-c3ba-42bd-9807-0913ca4228d7<-9446a705-8bb9-4eda-8998-a3a4fb23e316#0:FAIL-t2,IN_PROGRESS
scm3.org_1   | 2022-04-21 16:44:27,295 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 9446a705-8bb9-4eda-8998-a3a4fb23e316: Completed INSTALL_SNAPSHOT, lastRequest: e8ea6b57-c3ba-42bd-9807-0913ca4228d7->9446a705-8bb9-4eda-8998-a3a4fb23e316#0-t2,notify:(t:2, i:12)
scm3.org_1   | 2022-04-21 16:44:27,364 [grpc-default-executor-1] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: Failed appendEntries as snapshot (12) installation is in progress
scm3.org_1   | 2022-04-21 16:44:27,366 [grpc-default-executor-1] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: inconsistency entries. Reply:e8ea6b57-c3ba-42bd-9807-0913ca4228d7<-9446a705-8bb9-4eda-8998-a3a4fb23e316#8:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm3.org_1   | 2022-04-21 16:44:27,381 [grpc-default-executor-0] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: receive installSnapshot: e8ea6b57-c3ba-42bd-9807-0913ca4228d7->9446a705-8bb9-4eda-8998-a3a4fb23e316#0-t2,notify:(t:2, i:12)
scm3.org_1   | 2022-04-21 16:44:27,386 [grpc-default-executor-0] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: set new configuration index: 11
scm3.org_1   | configurationEntry {
scm3.org_1   |   peers {
scm3.org_1   |     id: "d794df5a-ece1-4828-94ba-97e720366f72"
scm3.org_1   |     address: "scm2.org:9894"
scm3.org_1   |   }
scm3.org_1   |   peers {
scm3.org_1   |     id: "e8ea6b57-c3ba-42bd-9807-0913ca4228d7"
scm3.org_1   |     address: "scm1.org:9894"
scm3.org_1   |   }
scm3.org_1   | }
scm3.org_1   |  from snapshot
scm3.org_1   | 2022-04-21 16:44:27,391 [grpc-default-executor-0] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: set configuration 11: [d794df5a-ece1-4828-94ba-97e720366f72|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, e8ea6b57-c3ba-42bd-9807-0913ca4228d7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-04-21 16:44:27,396 [grpc-default-executor-0] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: reply installSnapshot: e8ea6b57-c3ba-42bd-9807-0913ca4228d7<-9446a705-8bb9-4eda-8998-a3a4fb23e316#0:FAIL-t2,IN_PROGRESS
scm3.org_1   | 2022-04-21 16:44:27,401 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 9446a705-8bb9-4eda-8998-a3a4fb23e316: Completed INSTALL_SNAPSHOT, lastRequest: e8ea6b57-c3ba-42bd-9807-0913ca4228d7->9446a705-8bb9-4eda-8998-a3a4fb23e316#0-t2,notify:(t:2, i:12)
scm3.org_1   | 2022-04-21 16:44:27,442 [pool-16-thread-1] INFO ha.SCMHAManagerImpl: Installing checkpoint with SCMTransactionInfo 2#12
scm3.org_1   | 2022-04-21 16:44:27,451 [pool-16-thread-1] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: StateMachine successfully installed snapshot index 12. Reloading the StateMachine.
scm3.org_1   | 2022-04-21 16:44:27,452 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC-SegmentedRaftLogWorker: flushIndex: setUnconditionally -1 -> 12
scm3.org_1   | 2022-04-21 16:44:27,462 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally -1 -> 12
scm3.org_1   | 2022-04-21 16:44:27,473 [pool-16-thread-1] INFO raftlog.RaftLog: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC-SegmentedRaftLog: snapshotIndex: updateIncreasingly -1 -> 12
scm3.org_1   | 2022-04-21 16:44:27,481 [grpc-default-executor-1] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: receive installSnapshot: e8ea6b57-c3ba-42bd-9807-0913ca4228d7->9446a705-8bb9-4eda-8998-a3a4fb23e316#0-t2,notify:(t:2, i:12)
scm3.org_1   | 2022-04-21 16:44:27,453 [grpc-default-executor-0] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: Failed appendEntries as snapshot (12) installation is in progress
scm3.org_1   | 2022-04-21 16:44:27,503 [grpc-default-executor-0] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: inconsistency entries. Reply:e8ea6b57-c3ba-42bd-9807-0913ca4228d7<-9446a705-8bb9-4eda-8998-a3a4fb23e316#9:FAIL-t2,INCONSISTENCY,nextIndex=13,followerCommit=-1
scm3.org_1   | 2022-04-21 16:44:27,505 [grpc-default-executor-1] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: InstallSnapshot notification result: SNAPSHOT_INSTALLED, at index: 12
scm3.org_1   | 2022-04-21 16:44:27,512 [grpc-default-executor-1] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: set new configuration index: 11
scm3.org_1   | configurationEntry {
scm3.org_1   |   peers {
scm3.org_1   |     id: "d794df5a-ece1-4828-94ba-97e720366f72"
scm3.org_1   |     address: "scm2.org:9894"
scm3.org_1   |   }
scm3.org_1   |   peers {
scm3.org_1   |     id: "e8ea6b57-c3ba-42bd-9807-0913ca4228d7"
scm3.org_1   |     address: "scm1.org:9894"
scm3.org_1   |   }
scm3.org_1   | }
scm3.org_1   |  from snapshot
scm3.org_1   | 2022-04-21 16:44:27,515 [grpc-default-executor-1] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: set configuration 11: [d794df5a-ece1-4828-94ba-97e720366f72|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, e8ea6b57-c3ba-42bd-9807-0913ca4228d7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-04-21 16:44:27,516 [grpc-default-executor-1] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: reply installSnapshot: e8ea6b57-c3ba-42bd-9807-0913ca4228d7<-9446a705-8bb9-4eda-8998-a3a4fb23e316#0:FAIL-t2,SNAPSHOT_INSTALLED,snapshotIndex=12
scm3.org_1   | 2022-04-21 16:44:27,522 [grpc-default-executor-1] INFO server.GrpcServerProtocolService: 9446a705-8bb9-4eda-8998-a3a4fb23e316: Completed INSTALL_SNAPSHOT, lastRequest: e8ea6b57-c3ba-42bd-9807-0913ca4228d7->9446a705-8bb9-4eda-8998-a3a4fb23e316#0-t2,notify:(t:2, i:12)
scm3.org_1   | 2022-04-21 16:44:27,852 [9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC-StateMachineUpdater] INFO ha.SCMHAManagerImpl: Installing checkpoint with SCMTransactionInfo 2#12
scm3.org_1   | 2022-04-21 16:44:27,895 [9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC-StateMachineUpdater] INFO ha.SCMHAManagerImpl: Replaced DB with checkpoint, term: 2, index: 12
scm3.org_1   | 2022-04-21 16:44:27,910 [9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC-StateMachineUpdater] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm3.org_1   | 2022-04-21 16:44:27,918 [9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC-StateMachineUpdater] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm3.org_1   | 2022-04-21 16:44:28,122 [9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC-StateMachineUpdater] INFO ha.SequenceIdGenerator: reinitialize SequenceIdGenerator.
scm3.org_1   | 2022-04-21 16:44:28,215 [9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
scm3.org_1   | 2022-04-21 16:44:28,232 [9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC-StateMachineUpdater] INFO ha.SCMHAManagerImpl: Reloaded SCM state with Term: 2 and Index: 12
scm3.org_1   | 2022-04-21 16:44:28,233 [9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC-StateMachineUpdater] INFO impl.StateMachineUpdater: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC-StateMachineUpdater: snapshotIndex: setUnconditionally -1 -> 12
scm3.org_1   | 2022-04-21 16:44:28,233 [9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC-StateMachineUpdater] INFO impl.StateMachineUpdater: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC-StateMachineUpdater: appliedIndex: setUnconditionally -1 -> 12
scm3.org_1   | 2022-04-21 16:44:30,250 [grpc-default-executor-0] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: set configuration 13: [9446a705-8bb9-4eda-8998-a3a4fb23e316|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0, d794df5a-ece1-4828-94ba-97e720366f72|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, e8ea6b57-c3ba-42bd-9807-0913ca4228d7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=[d794df5a-ece1-4828-94ba-97e720366f72|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, e8ea6b57-c3ba-42bd-9807-0913ca4228d7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm3.org_1   | 2022-04-21 16:44:30,262 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC-SegmentedRaftLogWorker: Starting segment from index:13
scm3.org_1   | 2022-04-21 16:44:30,510 [grpc-default-executor-0] INFO server.RaftServer$Division: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC: set configuration 15: [9446a705-8bb9-4eda-8998-a3a4fb23e316|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0, d794df5a-ece1-4828-94ba-97e720366f72|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, e8ea6b57-c3ba-42bd-9807-0913ca4228d7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-04-21 16:44:30,823 [Listener at 0.0.0.0/9860] INFO ha.SCMHAManagerImpl: Successfully added SCM scm3 to group group-824FABCC98DC:[9446a705-8bb9-4eda-8998-a3a4fb23e316|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0, d794df5a-ece1-4828-94ba-97e720366f72|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, e8ea6b57-c3ba-42bd-9807-0913ca4228d7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm3.org_1   | 2022-04-21 16:44:30,860 [Listener at 0.0.0.0/9860] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
scm3.org_1   | 2022-04-21 16:44:30,908 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Starting token manager
scm3.org_1   | 2022-04-21 16:44:30,908 [Listener at 0.0.0.0/9860] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
scm3.org_1   | 2022-04-21 16:44:31,681 [9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/37768e1b-cb4c-49da-b09f-824fabcc98dc/current/log_inprogress_13
scm3.org_1   | 2022-04-21 16:44:31,929 [9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-04-21 16:44:31,944 [9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
scm3.org_1   | 2022-04-21 16:44:31,976 [9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm3.org_1   | 2022-04-21 16:44:31,982 [9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9861
scm3.org_1   | 2022-04-21 16:44:32,071 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm3.org_1   | 2022-04-21 16:44:32,194 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm3.org_1   | 2022-04-21 16:44:32,195 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm3.org_1   | 2022-04-21 16:44:34,005 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm3.org_1   | 2022-04-21 16:44:34,023 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm3.org_1   | 2022-04-21 16:44:34,376 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm3.org_1   | 2022-04-21 16:44:34,414 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm3.org_1   | 2022-04-21 16:44:34,418 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm3.org_1   | 2022-04-21 16:44:34,603 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm3.org_1   | 2022-04-21 16:44:34,603 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm3.org_1   | 2022-04-21 16:44:34,632 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm3.org_1   | 2022-04-21 16:44:34,632 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm3.org_1   | 2022-04-21 16:44:34,923 [Listener at 0.0.0.0/9860] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
scm3.org_1   | 2022-04-21 16:44:34,938 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm3.org_1   | 2022-04-21 16:44:34,940 [Listener at 0.0.0.0/9860] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService starting
scm3.org_1   | 2022-04-21 16:44:35,027 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
scm3.org_1   | 2022-04-21 16:44:35,329 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
scm3.org_1   | 2022-04-21 16:44:35,337 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
scm3.org_1   | 2022-04-21 16:44:35,356 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
scm3.org_1   | 2022-04-21 16:44:36,650 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@47db20e0] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm3.org_1   | 2022-04-21 16:44:36,868 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm3.org_1   | 2022-04-21 16:44:36,868 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
scm3.org_1   | 2022-04-21 16:44:36,869 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
scm3.org_1   | 2022-04-21 16:44:37,286 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @27295ms to org.eclipse.jetty.util.log.Slf4jLog
scm3.org_1   | 2022-04-21 16:44:38,080 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm3.org_1   | 2022-04-21 16:44:38,148 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm3.org_1   | 2022-04-21 16:44:38,169 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
scm3.org_1   | 2022-04-21 16:44:38,175 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
scm3.org_1   | 2022-04-21 16:44:38,176 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
scm3.org_1   | 2022-04-21 16:44:38,195 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
scm3.org_1   | 2022-04-21 16:44:38,511 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
scm3.org_1   | 2022-04-21 16:44:38,519 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
om1_1        | 2022-04-21 16:52:02,393 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:02,398 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:02,406 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:02,427 [IPC Server handler 96 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:02,509 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1        | 2022-04-21 16:52:02,514 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:02,529 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:02,557 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:05,858 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:05,897 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 127 failover attempts. Trying to failover immediately.
om1_1        | 2022-04-21 16:52:05,933 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm1.org_1   | 2022-04-21 16:43:33,890 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
om3_1        | 2022-04-21 16:57:39,414 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-5032629137 of layout LEGACY in volume: s3v
om3_1        | 2022-04-21 16:57:40,160 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: destbucket-85240 of layout LEGACY in volume: s3v
scm3.org_1   | 2022-04-21 16:44:38,852 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm3.org_1   | 2022-04-21 16:44:38,852 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm3.org_1   | 2022-04-21 16:44:38,853 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 600000ms
recon_1      | 2022-04-21 16:45:50,722 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om3 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:222)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:215)
scm1.org_1   | 2022-04-21 16:43:33,892 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om1_1        | 2022-04-21 16:52:05,935 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm3.org_1   | 2022-04-21 16:44:39,010 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm3.org_1   | 2022-04-21 16:44:39,037 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@72dc9f9d{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:174)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:146)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
om1_1        | 2022-04-21 16:52:05,938 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm3.org_1   | 2022-04-21 16:44:39,038 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5b6b5888{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm2.org_1   | 2022-04-21 16:45:17,145 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:51072
scm2.org_1   | 2022-04-21 16:45:17,270 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:45:17,333 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48532
scm2.org_1   | 2022-04-21 16:45:17,414 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:45:19,326 [IPC Server handler 5 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/8694db2d-5e51-4888-b1e0-69ff67626e43
om1_1        | 2022-04-21 16:52:05,970 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:05,977 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:05,990 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-miyukjhjbq of layout LEGACY in volume: s3v
scm2.org_1   | 2022-04-21 16:45:19,341 [IPC Server handler 5 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 8694db2d-5e51-4888-b1e0-69ff67626e43{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 952600664327, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 128 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-21 16:45:51,766 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:32930
recon_1      | 2022-04-21 16:45:51,847 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om1_1        | 2022-04-21 16:52:06,016 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:06,021 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:06,026 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:06,044 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:06,050 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:06,065 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:06,072 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:06,112 [IPC Server handler 42 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:06,121 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:06,130 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:06,307 [IPC Server handler 67 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:06,363 [IPC Server handler 92 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:06,378 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:06,388 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:06,412 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:06,418 [IPC Server handler 96 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:06,428 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:06,448 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:06,455 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:06,459 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:06,500 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:06,704 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:06,708 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:06,712 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:06,733 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:06,772 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:06,777 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:06,780 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:06,792 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:06,795 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:06,798 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:06,844 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:06,856 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:06,861 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:06,882 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:06,887 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:06,890 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:06,907 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:06,911 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:06,913 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:06,983 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:10,684 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:10,734 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:10,737 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:10,740 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:10,762 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:10,765 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:10,767 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:10,778 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:10,781 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:10,784 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:10,839 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:14,236 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
recon_1      | 2022-04-21 16:45:51,851 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=f5f2ffbc-fc63-4015-9163-f38ef2c5977c reported by 8694db2d-5e51-4888-b1e0-69ff67626e43{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 952600664327, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-04-21 16:45:51,852 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=39b933e3-a932-4461-b956-63989fd6333f. Trying to get from SCM.
recon_1      | 2022-04-21 16:45:51,921 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48708
recon_1      | 2022-04-21 16:45:52,050 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:45:52,101 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: 39b933e3-a932-4461-b956-63989fd6333f, Nodes: 8694db2d-5e51-4888-b1e0-69ff67626e43{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:8694db2d-5e51-4888-b1e0-69ff67626e43, CreationTimestamp2022-04-21T16:45:19.660Z[UTC]] to Recon pipeline metadata.
recon_1      | 2022-04-21 16:45:52,102 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 39b933e3-a932-4461-b956-63989fd6333f, Nodes: 8694db2d-5e51-4888-b1e0-69ff67626e43{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:8694db2d-5e51-4888-b1e0-69ff67626e43, CreationTimestamp2022-04-21T16:45:19.660Z[UTC]].
recon_1      | 2022-04-21 16:45:52,102 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=d5d7df1a-3895-4b52-8476-24d42ba70f8f. Trying to get from SCM.
scm2.org_1   | 2022-04-21 16:45:19,377 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm2.org_1   | 2022-04-21 16:45:19,387 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
scm2.org_1   | 2022-04-21 16:45:19,475 [IPC Server handler 43 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/0ef408af-3ea2-4044-bc54-ad0ae15d84f1
scm2.org_1   | 2022-04-21 16:45:19,544 [IPC Server handler 43 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 0ef408af-3ea2-4044-bc54-ad0ae15d84f1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 953699741549, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm2.org_1   | 2022-04-21 16:45:19,545 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm2.org_1   | 2022-04-21 16:45:19,566 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
scm2.org_1   | 2022-04-21 16:45:20,094 [IPC Server handler 15 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/a9037631-20c7-49ff-8966-d11abf0c09e2
scm2.org_1   | 2022-04-21 16:45:20,152 [IPC Server handler 15 on default port 9861] INFO node.SCMNodeManager: Registered Data node : a9037631-20c7-49ff-8966-d11abf0c09e2{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 952295697655, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm2.org_1   | 2022-04-21 16:45:20,152 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm2.org_1   | 2022-04-21 16:45:20,159 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
scm2.org_1   | 2022-04-21 16:45:20,159 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm2.org_1   | 2022-04-21 16:45:20,160 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm2.org_1   | 2022-04-21 16:45:20,160 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm2.org_1   | 2022-04-21 16:45:20,160 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
scm2.org_1   | 2022-04-21 16:45:20,160 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm2.org_1   | 2022-04-21 16:45:20,503 [d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 39b933e3-a932-4461-b956-63989fd6333f, Nodes: 8694db2d-5e51-4888-b1e0-69ff67626e43{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-04-21T16:45:19.660Z[UTC]].
scm2.org_1   | 2022-04-21 16:45:20,512 [d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
recon_1      | 2022-04-21 16:45:52,115 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: d5d7df1a-3895-4b52-8476-24d42ba70f8f, Nodes: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:0ef408af-3ea2-4044-bc54-ad0ae15d84f1, CreationTimestamp2022-04-21T16:45:20.942Z[UTC]] to Recon pipeline metadata.
recon_1      | 2022-04-21 16:45:52,116 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: d5d7df1a-3895-4b52-8476-24d42ba70f8f, Nodes: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:0ef408af-3ea2-4044-bc54-ad0ae15d84f1, CreationTimestamp2022-04-21T16:45:20.942Z[UTC]].
recon_1      | 2022-04-21 16:45:52,116 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/ONE PipelineID=d5d7df1a-3895-4b52-8476-24d42ba70f8f reported by 0ef408af-3ea2-4044-bc54-ad0ae15d84f1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 953699741549, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-04-21 16:45:52,116 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: d5d7df1a-3895-4b52-8476-24d42ba70f8f, Nodes: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:0ef408af-3ea2-4044-bc54-ad0ae15d84f1, CreationTimestamp2022-04-21T16:45:20.942Z[UTC]] moved to OPEN state
recon_1      | 2022-04-21 16:45:52,117 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=f5f2ffbc-fc63-4015-9163-f38ef2c5977c reported by 0ef408af-3ea2-4044-bc54-ad0ae15d84f1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 953699741549, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-04-21 16:45:52,726 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om1 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:222)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:215)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:174)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:146)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 129 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-21 16:45:52,730 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:222)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:215)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:174)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:146)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 130 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-21 16:45:52,735 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om3 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:222)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:215)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:174)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:146)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 131 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-21 16:45:54,739 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om1 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:222)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:215)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:174)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:146)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
scm2.org_1   | 2022-04-21 16:45:20,588 [d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: a2956c20-9fda-4457-b767-0b8a33d7fc85, Nodes: a9037631-20c7-49ff-8966-d11abf0c09e2{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}8694db2d-5e51-4888-b1e0-69ff67626e43{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}0ef408af-3ea2-4044-bc54-ad0ae15d84f1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-04-21T16:45:20.398Z[UTC]].
scm2.org_1   | 2022-04-21 16:45:20,618 [d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-04-21 16:45:20,867 [d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 72e20438-e2a5-4ad3-9b38-a5405a44eb65, Nodes: a9037631-20c7-49ff-8966-d11abf0c09e2{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-04-21T16:45:20.596Z[UTC]].
scm2.org_1   | 2022-04-21 16:45:20,877 [d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-04-21 16:45:20,936 [d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: f5f2ffbc-fc63-4015-9163-f38ef2c5977c, Nodes: a9037631-20c7-49ff-8966-d11abf0c09e2{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}8694db2d-5e51-4888-b1e0-69ff67626e43{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}0ef408af-3ea2-4044-bc54-ad0ae15d84f1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-04-21T16:45:20.722Z[UTC]].
scm2.org_1   | 2022-04-21 16:45:20,953 [d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-04-21 16:45:21,085 [d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: d5d7df1a-3895-4b52-8476-24d42ba70f8f, Nodes: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-04-21T16:45:20.942Z[UTC]].
scm2.org_1   | 2022-04-21 16:45:21,087 [d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-04-21 16:45:32,667 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48586
scm2.org_1   | 2022-04-21 16:45:32,733 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2022-04-21 16:52:14,282 [IPC Server handler 88 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm2.org_1   | 2022-04-21 16:45:32,736 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: a2956c20-9fda-4457-b767-0b8a33d7fc85, Nodes: a9037631-20c7-49ff-8966-d11abf0c09e2{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}8694db2d-5e51-4888-b1e0-69ff67626e43{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}0ef408af-3ea2-4044-bc54-ad0ae15d84f1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:a9037631-20c7-49ff-8966-d11abf0c09e2, CreationTimestamp2022-04-21T16:45:20.398Z[UTC]] moved to OPEN state
scm2.org_1   | 2022-04-21 16:45:32,903 [d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
scm2.org_1   | 2022-04-21 16:45:33,537 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 72e20438-e2a5-4ad3-9b38-a5405a44eb65, Nodes: a9037631-20c7-49ff-8966-d11abf0c09e2{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:a9037631-20c7-49ff-8966-d11abf0c09e2, CreationTimestamp2022-04-21T16:45:20.596Z[UTC]] moved to OPEN state
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1        | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #136 timeout 180s
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:368)
s3g_1        | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:373)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:368)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:357)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1        | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1        | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1        | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1        | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1        | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1        | 	... 1 more
s3g_1        | 2022-04-21 16:57:17,707 [qtp440736059-22] INFO scm.XceiverClientRatis: Could not commit index 130 on pipeline Pipeline[ Id: a2956c20-9fda-4457-b767-0b8a33d7fc85, Nodes: a9037631-20c7-49ff-8966-d11abf0c09e2{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}8694db2d-5e51-4888-b1e0-69ff67626e43{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}0ef408af-3ea2-4044-bc54-ad0ae15d84f1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:a9037631-20c7-49ff-8966-d11abf0c09e2, CreationTimestamp2022-04-21T16:45:20.398Z[UTC]] to all the nodes. Server 0ef408af-3ea2-4044-bc54-ad0ae15d84f1 has failed. Committed by majority.
s3g_1        | 2022-04-21 16:57:17,707 [qtp440736059-22] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 2 locID: 109611004723200042 bcsId: 130 on Pipeline[ Id: a2956c20-9fda-4457-b767-0b8a33d7fc85, Nodes: a9037631-20c7-49ff-8966-d11abf0c09e2{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}8694db2d-5e51-4888-b1e0-69ff67626e43{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}0ef408af-3ea2-4044-bc54-ad0ae15d84f1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:a9037631-20c7-49ff-8966-d11abf0c09e2, CreationTimestamp2022-04-21T16:45:20.398Z[UTC]]. Failed nodes: [0ef408af-3ea2-4044-bc54-ad0ae15d84f1{ip: null, host: null, ports: [], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1        | 2022-04-21 16:57:39,383 [qtp440736059-22] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-5032629137, with testuser as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-04-21 16:57:39,394 [qtp440736059-22] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-5032629137
s3g_1        | 2022-04-21 16:57:40,141 [qtp440736059-24] INFO rpc.RpcClient: Creating Bucket: s3v/destbucket-85240, with testuser as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-04-21 16:57:40,150 [qtp440736059-24] INFO endpoint.BucketEndpoint: Location is /destbucket-85240
s3g_1        | 2022-04-21 16:58:18,702 [qtp440736059-17] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: a2956c20-9fda-4457-b767-0b8a33d7fc85, Nodes: a9037631-20c7-49ff-8966-d11abf0c09e2{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}8694db2d-5e51-4888-b1e0-69ff67626e43{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}0ef408af-3ea2-4044-bc54-ad0ae15d84f1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:a9037631-20c7-49ff-8966-d11abf0c09e2, CreationTimestamp2022-04-21T16:45:20.398Z[UTC]]
s3g_1        | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #142 timeout 180s
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1        | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:263)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.RatisBlockOutputStream.sendWatchForCommit(RatisBlockOutputStream.java:101)
om1_1        | 2022-04-21 16:52:14,285 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:14,289 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:17,790 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40570
om1_1        | 2022-04-21 16:52:17,813 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2022-04-21 16:45:33,552 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
scm2.org_1   | 2022-04-21 16:45:33,552 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm3.org_1   | 2022-04-21 16:44:39,860 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm3.org_1   | 2022-04-21 16:44:40,014 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@189e986f{scm,/,file:///tmp/jetty-0_0_0_0-9876-hdds-server-scm-1_3_0-SNAPSHOT_jar-_-any-4048657856466972661/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/scm}
scm3.org_1   | 2022-04-21 16:44:40,107 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@24bf95ec{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
scm3.org_1   | 2022-04-21 16:44:40,107 [Listener at 0.0.0.0/9860] INFO server.Server: Started @30115ms
scm3.org_1   | 2022-04-21 16:44:40,159 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm3.org_1   | 2022-04-21 16:44:40,159 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm3.org_1   | 2022-04-21 16:44:40,161 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm3.org_1   | 2022-04-21 16:44:50,138 [9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-04-21 16:44:50,138 [9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC-StateMachineUpdater] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm3.org_1   | 2022-04-21 16:44:50,138 [9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC-StateMachineUpdater] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm3.org_1   | 2022-04-21 16:44:50,364 [9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om1_1        | 2022-04-21 16:52:21,059 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm1.org_1   | 2022-04-21 16:43:33,892 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm1.org_1   | 2022-04-21 16:43:33,912 [Listener at 0.0.0.0/9860] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
scm1.org_1   | 2022-04-21 16:43:33,919 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm1.org_1   | 2022-04-21 16:43:33,919 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
scm1.org_1   | 2022-04-21 16:43:33,920 [Listener at 0.0.0.0/9860] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService starting
scm1.org_1   | 2022-04-21 16:43:33,987 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2801ccb3] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm1.org_1   | 2022-04-21 16:43:34,003 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm1.org_1   | 2022-04-21 16:43:34,003 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
scm1.org_1   | 2022-04-21 16:43:34,005 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
scm1.org_1   | 2022-04-21 16:43:34,028 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @6078ms to org.eclipse.jetty.util.log.Slf4jLog
scm1.org_1   | 2022-04-21 16:43:34,119 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm1.org_1   | 2022-04-21 16:43:34,124 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om1_1        | 2022-04-21 16:52:21,065 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm1.org_1   | 2022-04-21 16:43:34,125 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
scm1.org_1   | 2022-04-21 16:43:34,126 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
scm1.org_1   | 2022-04-21 16:43:34,126 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
scm1.org_1   | 2022-04-21 16:43:34,128 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
om1_1        | 2022-04-21 16:52:21,072 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-4268886784 of layout LEGACY in volume: s3v
scm2.org_1   | 2022-04-21 16:45:33,588 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm2.org_1   | 2022-04-21 16:45:33,591 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
scm2.org_1   | 2022-04-21 16:45:33,638 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
om3_1        | 2022-04-21 17:00:00,694 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-5639337117 of layout LEGACY in volume: s3v
om3_1        | 2022-04-21 17:00:26,445 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-1676201683 of layout LEGACY in volume: s3v
om3_1        | 2022-04-21 17:00:30,954 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:s3v, Bucket:bucket-ozone-test-1676201683, Key:ozone-test-5348923844/multidelete/key=value/f4.
om3_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:146)
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:92)
scm2.org_1   | 2022-04-21 16:45:33,678 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
scm2.org_1   | 2022-04-21 16:45:33,684 [d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC-StateMachineUpdater] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm2.org_1   | 2022-04-21 16:45:33,689 [d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC-StateMachineUpdater] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
scm2.org_1   | 2022-04-21 16:45:33,690 [d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC-StateMachineUpdater] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm2.org_1   | 2022-04-21 16:45:33,691 [d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC-StateMachineUpdater] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=false, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
scm2.org_1   | 2022-04-21 16:45:51,764 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:51200
scm2.org_1   | 2022-04-21 16:45:51,823 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:45:51,826 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 39b933e3-a932-4461-b956-63989fd6333f, Nodes: 8694db2d-5e51-4888-b1e0-69ff67626e43{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:8694db2d-5e51-4888-b1e0-69ff67626e43, CreationTimestamp2022-04-21T16:45:19.660Z[UTC]] moved to OPEN state
scm2.org_1   | 2022-04-21 16:45:51,988 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48658
scm2.org_1   | 2022-04-21 16:45:52,079 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:45:52,081 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: d5d7df1a-3895-4b52-8476-24d42ba70f8f, Nodes: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:0ef408af-3ea2-4044-bc54-ad0ae15d84f1, CreationTimestamp2022-04-21T16:45:20.942Z[UTC]] moved to OPEN state
scm2.org_1   | 2022-04-21 16:45:59,953 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: f5f2ffbc-fc63-4015-9163-f38ef2c5977c, Nodes: a9037631-20c7-49ff-8966-d11abf0c09e2{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}8694db2d-5e51-4888-b1e0-69ff67626e43{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}0ef408af-3ea2-4044-bc54-ad0ae15d84f1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:0ef408af-3ea2-4044-bc54-ad0ae15d84f1, CreationTimestamp2022-04-21T16:45:20.722Z[UTC]] moved to OPEN state
scm2.org_1   | 2022-04-21 16:46:08,902 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59674
scm2.org_1   | 2022-04-21 16:46:08,937 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:46:13,776 [d794df5a-ece1-4828-94ba-97e720366f72@group-824FABCC98DC-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 109611004723200000.
scm2.org_1   | 2022-04-21 16:46:17,025 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48732
scm2.org_1   | 2022-04-21 16:46:17,060 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:46:17,323 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:51288
scm2.org_1   | 2022-04-21 16:46:17,404 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:46:46,912 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48822
scm2.org_1   | 2022-04-21 16:46:46,946 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:46:47,271 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:51384
scm2.org_1   | 2022-04-21 16:46:47,286 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:46:47,453 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59822
scm2.org_1   | 2022-04-21 16:46:47,484 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:47:16,896 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48924
scm2.org_1   | 2022-04-21 16:47:16,905 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:47:17,254 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:51480
scm2.org_1   | 2022-04-21 16:47:17,328 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:47:17,454 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59918
om1_1        | 2022-04-21 16:52:21,675 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:21,683 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:514)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:317)
om1_1        | 2022-04-21 16:52:21,694 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-1890813946 of layout LEGACY in volume: s3v
om1_1        | 2022-04-21 16:52:22,302 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm2.org_1   | 2022-04-21 16:47:17,516 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:47:55,227 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:51592
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:392)
scm3.org_1   | 2022-04-21 16:44:51,389 [9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-04-21 16:43:34,162 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
scm2.org_1   | 2022-04-21 16:47:55,288 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49060
om1_1        | 2022-04-21 16:52:22,312 [IPC Server handler 71 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:22,323 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-8475151662 of layout LEGACY in volume: s3v
scm3.org_1   | 2022-04-21 16:44:57,765 [9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-04-21 16:44:59,120 [9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-04-21 16:45:00,103 [9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 2022-04-21 16:52:22,935 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:552)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:566)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:137)
scm1.org_1   | 2022-04-21 16:43:34,163 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-04-21 17:00:39,800 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-4595663119 of layout LEGACY in volume: s3v
scm2.org_1   | 2022-04-21 16:47:55,419 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:47:55,428 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:45:15,724 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49514
scm3.org_1   | 2022-04-21 16:45:15,819 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:45:17,221 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36574
scm3.org_1   | 2022-04-21 16:45:17,244 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:45:17,329 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:36394
scm3.org_1   | 2022-04-21 16:45:17,416 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:45:19,281 [IPC Server handler 27 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/8694db2d-5e51-4888-b1e0-69ff67626e43
om3_1        | 2022-04-21 17:01:05,457 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-4385489974 of layout LEGACY in volume: s3v
scm2.org_1   | 2022-04-21 16:47:55,436 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:60040
scm3.org_1   | 2022-04-21 16:45:19,318 [IPC Server handler 27 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 8694db2d-5e51-4888-b1e0-69ff67626e43{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 952600664327, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm3.org_1   | 2022-04-21 16:45:19,346 [IPC Server handler 42 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/0ef408af-3ea2-4044-bc54-ad0ae15d84f1
scm3.org_1   | 2022-04-21 16:45:19,363 [IPC Server handler 42 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 0ef408af-3ea2-4044-bc54-ad0ae15d84f1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 953699741549, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm1.org_1   | 2022-04-21 16:43:34,201 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
om1_1        | 2022-04-21 16:52:22,938 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:22,953 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket-ozone-test-8475151662 in volume:s3v
om1_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om1_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:204)
scm1.org_1   | 2022-04-21 16:43:34,201 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:514)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:317)
scm3.org_1   | 2022-04-21 16:45:19,412 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
scm3.org_1   | 2022-04-21 16:45:19,465 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm1.org_1   | 2022-04-21 16:43:34,203 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 660000ms
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm1.org_1   | 2022-04-21 16:43:34,216 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
om1_1        | 2022-04-21 16:52:23,653 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:27,435 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40626
om1_1        | 2022-04-21 16:52:27,453 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2022-04-21 16:45:19,508 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm1.org_1   | 2022-04-21 16:43:34,221 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5f160341{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm3.org_1   | 2022-04-21 16:45:19,547 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
scm3.org_1   | 2022-04-21 16:45:20,000 [IPC Server handler 28 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/a9037631-20c7-49ff-8966-d11abf0c09e2
scm3.org_1   | 2022-04-21 16:45:20,000 [IPC Server handler 28 on default port 9861] INFO node.SCMNodeManager: Registered Data node : a9037631-20c7-49ff-8966-d11abf0c09e2{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 952295697655, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm3.org_1   | 2022-04-21 16:45:20,001 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
om1_1        | 2022-04-21 16:52:30,663 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:30,676 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:30,684 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-9441853734 of layout LEGACY in volume: s3v
scm3.org_1   | 2022-04-21 16:45:20,002 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 132 failover attempts. Trying to failover immediately.
scm1.org_1   | 2022-04-21 16:43:34,222 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@49aa6081{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm1.org_1   | 2022-04-21 16:43:34,300 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm3.org_1   | 2022-04-21 16:45:20,002 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
recon_1      | 2022-04-21 16:45:54,744 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
scm2.org_1   | 2022-04-21 16:47:55,465 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:48:25,221 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:51704
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:494)
scm1.org_1   | 2022-04-21 16:43:34,309 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@65208c91{scm,/,file:///tmp/jetty-0_0_0_0-9876-hdds-server-scm-1_3_0-SNAPSHOT_jar-_-any-8318932631644882717/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/scm}
scm1.org_1   | 2022-04-21 16:43:34,317 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@19203ff3{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
scm3.org_1   | 2022-04-21 16:45:20,002 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
scm2.org_1   | 2022-04-21 16:48:25,342 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:468)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:521)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
scm1.org_1   | 2022-04-21 16:43:34,317 [Listener at 0.0.0.0/9860] INFO server.Server: Started @6367ms
scm3.org_1   | 2022-04-21 16:45:20,002 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm3.org_1   | 2022-04-21 16:45:20,002 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
scm2.org_1   | 2022-04-21 16:48:25,387 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49172
scm2.org_1   | 2022-04-21 16:48:25,388 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:60144
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:258)
s3g_1        | 	at jdk.internal.reflect.GeneratedMethodAccessor28.invoke(Unknown Source)
scm1.org_1   | 2022-04-21 16:43:34,320 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm3.org_1   | 2022-04-21 16:45:20,002 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm3.org_1   | 2022-04-21 16:45:20,394 [9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 39b933e3-a932-4461-b956-63989fd6333f, Nodes: 8694db2d-5e51-4888-b1e0-69ff67626e43{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-04-21T16:45:19.660Z[UTC]].
scm2.org_1   | 2022-04-21 16:48:25,436 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:48:25,476 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om1_1        | 2022-04-21 16:52:31,284 [IPC Server handler 88 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:31,288 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:222)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:215)
scm2.org_1   | 2022-04-21 16:48:55,265 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:51804
scm2.org_1   | 2022-04-21 16:48:55,347 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49272
scm2.org_1   | 2022-04-21 16:48:55,360 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:48:55,376 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:48:55,393 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:60244
scm2.org_1   | 2022-04-21 16:48:55,448 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:49:00,240 [ReplicationMonitor] INFO container.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm2.org_1   | 2022-04-21 16:49:25,240 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:51912
scm2.org_1   | 2022-04-21 16:49:25,340 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:49:25,365 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49382
scm2.org_1   | 2022-04-21 16:49:25,393 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:60350
om1_1        | 2022-04-21 16:52:31,294 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-4686250488 of layout LEGACY in volume: s3v
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:174)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
om1_1        | 2022-04-21 16:52:31,904 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:31,907 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
scm2.org_1   | 2022-04-21 16:49:25,403 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2022-04-21 16:52:32,513 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:32,516 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:32,526 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketDeleteRequest: Delete bucket failed for bucket:nosuchbucket-ozone-test-5001124069 in volume:s3v
om1_1        | BUCKET_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Bucket not found
om1_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.getBucketOwner(OzoneManager.java:2338)
om1_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.getBucketOwner(OzoneManager.java:2308)
om1_1        | 	at org.apache.hadoop.ozone.om.request.OMClientRequest.checkAcls(OMClientRequest.java:200)
om1_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketDeleteRequest.validateAndUpdateCache(OMBucketDeleteRequest.java:102)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:514)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:317)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:146)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
scm3.org_1   | 2022-04-21 16:45:20,419 [9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-04-21 16:45:20,598 [9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: a2956c20-9fda-4457-b767-0b8a33d7fc85, Nodes: a9037631-20c7-49ff-8966-d11abf0c09e2{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}8694db2d-5e51-4888-b1e0-69ff67626e43{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}0ef408af-3ea2-4044-bc54-ad0ae15d84f1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-04-21T16:45:20.398Z[UTC]].
scm3.org_1   | 2022-04-21 16:45:20,607 [9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-04-21 16:45:20,756 [9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 72e20438-e2a5-4ad3-9b38-a5405a44eb65, Nodes: a9037631-20c7-49ff-8966-d11abf0c09e2{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-04-21T16:45:20.596Z[UTC]].
scm3.org_1   | 2022-04-21 16:45:20,761 [9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-04-21 16:45:20,981 [9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: f5f2ffbc-fc63-4015-9163-f38ef2c5977c, Nodes: a9037631-20c7-49ff-8966-d11abf0c09e2{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}8694db2d-5e51-4888-b1e0-69ff67626e43{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}0ef408af-3ea2-4044-bc54-ad0ae15d84f1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-04-21T16:45:20.722Z[UTC]].
scm3.org_1   | 2022-04-21 16:45:20,994 [9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-04-21 16:45:21,068 [9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: d5d7df1a-3895-4b52-8476-24d42ba70f8f, Nodes: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-04-21T16:45:20.942Z[UTC]].
scm3.org_1   | 2022-04-21 16:45:21,069 [9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-04-21 16:45:32,677 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:36448
scm3.org_1   | 2022-04-21 16:45:32,734 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:45:32,737 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: a2956c20-9fda-4457-b767-0b8a33d7fc85, Nodes: a9037631-20c7-49ff-8966-d11abf0c09e2{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}8694db2d-5e51-4888-b1e0-69ff67626e43{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}0ef408af-3ea2-4044-bc54-ad0ae15d84f1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:a9037631-20c7-49ff-8966-d11abf0c09e2, CreationTimestamp2022-04-21T16:45:20.398Z[UTC]] moved to OPEN state
scm3.org_1   | 2022-04-21 16:45:32,825 [9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
scm3.org_1   | 2022-04-21 16:45:33,493 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 72e20438-e2a5-4ad3-9b38-a5405a44eb65, Nodes: a9037631-20c7-49ff-8966-d11abf0c09e2{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:a9037631-20c7-49ff-8966-d11abf0c09e2, CreationTimestamp2022-04-21T16:45:20.596Z[UTC]] moved to OPEN state
scm1.org_1   | 2022-04-21 16:43:34,320 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm1.org_1   | 2022-04-21 16:43:34,322 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm1.org_1   | 2022-04-21 16:43:35,907 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:34761
scm1.org_1   | 2022-04-21 16:43:35,951 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-04-21 16:43:36,118 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:35228
scm1.org_1   | 2022-04-21 16:43:36,154 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-04-21 16:43:36,266 [IPC Server handler 0 on default port 9961] INFO ipc.Server: IPC Server handler 0 on default port 9961, call Call#0 Retry#9 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from 172.25.0.115:34761
scm1.org_1   | org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:e8ea6b57-c3ba-42bd-9807-0913ca4228d7 is not the leader. Could not determine the leader node.
scm1.org_1   | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:93)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm2.org_1   | 2022-04-21 16:49:25,417 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:49:55,269 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:52008
scm2.org_1   | 2022-04-21 16:49:55,335 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:49:55,423 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49478
scm2.org_1   | 2022-04-21 16:49:55,429 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:60444
scm2.org_1   | 2022-04-21 16:49:55,435 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:49:55,473 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:50:25,228 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:52114
scm2.org_1   | 2022-04-21 16:50:25,236 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:50:25,378 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:60562
scm2.org_1   | 2022-04-21 16:50:25,388 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49576
scm1.org_1   | 	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:16080)
scm1.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
scm1.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
scm1.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
scm1.org_1   | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
scm1.org_1   | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm1.org_1   | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm1.org_1   | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
scm1.org_1   | 2022-04-21 16:43:38,563 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-FollowerState] INFO impl.FollowerState: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5202630761ns, electionTimeout:5194ms
scm1.org_1   | 2022-04-21 16:43:38,564 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-FollowerState] INFO impl.RoleInfo: e8ea6b57-c3ba-42bd-9807-0913ca4228d7: shutdown e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-FollowerState
scm1.org_1   | 2022-04-21 16:43:38,565 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-FollowerState] INFO server.RaftServer$Division: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
scm1.org_1   | 2022-04-21 16:43:38,568 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
scm1.org_1   | 2022-04-21 16:43:38,568 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-FollowerState] INFO impl.RoleInfo: e8ea6b57-c3ba-42bd-9807-0913ca4228d7: start e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-LeaderElection1
scm1.org_1   | 2022-04-21 16:43:38,581 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-LeaderElection1] INFO impl.LeaderElection: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-LeaderElection1 ELECTION round 0: submit vote requests at term 2 for 0: [e8ea6b57-c3ba-42bd-9807-0913ca4228d7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2022-04-21 16:43:38,582 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-LeaderElection1] INFO impl.LeaderElection: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-LeaderElection1 ELECTION round 0: result PASSED (term=2)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-04-21 16:52:35,820 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40646
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
scm3.org_1   | 2022-04-21 16:45:33,498 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
scm3.org_1   | 2022-04-21 16:45:33,498 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm3.org_1   | 2022-04-21 16:45:33,499 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm3.org_1   | 2022-04-21 16:45:33,499 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
scm3.org_1   | 2022-04-21 16:45:33,499 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm3.org_1   | 2022-04-21 16:45:33,501 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
scm3.org_1   | 2022-04-21 16:45:51,809 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36692
scm3.org_1   | 2022-04-21 16:45:51,863 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:45:51,864 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 39b933e3-a932-4461-b956-63989fd6333f, Nodes: 8694db2d-5e51-4888-b1e0-69ff67626e43{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:8694db2d-5e51-4888-b1e0-69ff67626e43, CreationTimestamp2022-04-21T16:45:19.660Z[UTC]] moved to OPEN state
scm3.org_1   | 2022-04-21 16:45:51,972 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:36516
scm3.org_1   | 2022-04-21 16:45:52,053 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:45:52,054 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: d5d7df1a-3895-4b52-8476-24d42ba70f8f, Nodes: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:0ef408af-3ea2-4044-bc54-ad0ae15d84f1, CreationTimestamp2022-04-21T16:45:20.942Z[UTC]] moved to OPEN state
scm3.org_1   | 2022-04-21 16:46:08,901 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49694
scm3.org_1   | 2022-04-21 16:46:08,942 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:46:13,767 [9446a705-8bb9-4eda-8998-a3a4fb23e316@group-824FABCC98DC-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 109611004723200000.
scm3.org_1   | 2022-04-21 16:46:16,890 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:36596
scm3.org_1   | 2022-04-21 16:46:17,029 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:46:17,328 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36788
scm3.org_1   | 2022-04-21 16:46:17,405 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:46:46,861 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:36688
scm3.org_1   | 2022-04-21 16:46:46,927 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:46:47,281 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36876
scm3.org_1   | 2022-04-21 16:46:47,298 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:50:25,399 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:50:25,421 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
scm2.org_1   | 2022-04-21 16:50:55,242 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:52212
scm2.org_1   | 2022-04-21 16:50:55,284 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:50:55,391 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49680
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
om1_1        | 2022-04-21 16:52:35,840 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 16:52:39,137 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
scm2.org_1   | 2022-04-21 16:50:55,461 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:60648
scm2.org_1   | 2022-04-21 16:50:55,506 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 133 failover attempts. Trying to failover immediately.
recon_1      | 2022-04-21 16:45:54,748 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om3 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
scm1.org_1   | 2022-04-21 16:43:38,582 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-LeaderElection1] INFO impl.RoleInfo: e8ea6b57-c3ba-42bd-9807-0913ca4228d7: shutdown e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-LeaderElection1
scm1.org_1   | 2022-04-21 16:43:38,583 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-LeaderElection1] INFO server.RaftServer$Division: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
scm1.org_1   | 2022-04-21 16:43:38,583 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-LeaderElection1] INFO ha.SCMStateMachine: current SCM becomes leader of term 2.
om1_1        | 2022-04-21 16:52:39,140 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:39,148 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-5308852827 of layout LEGACY in volume: s3v
om1_1        | 2022-04-21 16:52:39,772 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:39,775 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:40,373 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm1.org_1   | 2022-04-21 16:43:38,583 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-LeaderElection1] INFO ha.SCMContext: update <isLeader,term> from <false,0> to <true,2>
scm1.org_1   | 2022-04-21 16:43:38,585 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-LeaderElection1] INFO server.RaftServer$Division: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC: change Leader from null to e8ea6b57-c3ba-42bd-9807-0913ca4228d7 at term 2 for becomeLeader, leader elected after 7113ms
scm1.org_1   | 2022-04-21 16:43:38,590 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
scm1.org_1   | 2022-04-21 16:43:38,594 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm1.org_1   | 2022-04-21 16:43:38,595 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
om1_1        | 2022-04-21 16:52:40,376 [IPC Server handler 78 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:43,537 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40666
om1_1        | 2022-04-21 16:52:43,553 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 16:52:46,719 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:46,722 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:46,733 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-5640325463 of layout LEGACY in volume: s3v
om1_1        | 2022-04-21 16:52:47,331 [IPC Server handler 79 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:47,333 [IPC Server handler 85 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:47,336 [IPC Server handler 62 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:52:50,642 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40690
om1_1        | 2022-04-21 16:52:50,657 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 16:52:56,225 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40728
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1679)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:222)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:215)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:174)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
scm3.org_1   | 2022-04-21 16:46:47,458 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49838
scm3.org_1   | 2022-04-21 16:46:47,489 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:146)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
scm3.org_1   | 2022-04-21 16:47:16,898 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:36780
scm2.org_1   | 2022-04-21 16:50:55,508 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:51:25,267 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:52460
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
scm3.org_1   | 2022-04-21 16:47:16,921 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:47:17,276 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36972
scm3.org_1   | 2022-04-21 16:47:17,305 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:47:17,460 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49938
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
scm3.org_1   | 2022-04-21 16:47:17,516 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:51:25,307 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:60908
scm2.org_1   | 2022-04-21 16:51:25,351 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49936
scm2.org_1   | 2022-04-21 16:51:25,374 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:51:25,408 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:51:25,434 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:51:55,243 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:52570
scm2.org_1   | 2022-04-21 16:51:55,373 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:32770
scm2.org_1   | 2022-04-21 16:51:55,389 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 16:43:38,599 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm2.org_1   | 2022-04-21 16:51:55,409 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50046
scm2.org_1   | 2022-04-21 16:51:55,465 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2022-04-21 16:52:56,241 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 16:52:58,389 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:43943
om1_1        | 2022-04-21 16:52:58,400 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
scm1.org_1   | 2022-04-21 16:43:38,600 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
scm1.org_1   | 2022-04-21 16:43:38,600 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
scm1.org_1   | 2022-04-21 16:43:38,605 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm1.org_1   | 2022-04-21 16:43:38,606 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
scm1.org_1   | 2022-04-21 16:43:38,608 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-LeaderElection1] INFO impl.RoleInfo: e8ea6b57-c3ba-42bd-9807-0913ca4228d7: start e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-LeaderStateImpl
scm1.org_1   | 2022-04-21 16:43:38,614 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
scm3.org_1   | 2022-04-21 16:47:55,212 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37084
scm3.org_1   | 2022-04-21 16:47:55,429 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:36918
scm3.org_1   | 2022-04-21 16:47:55,432 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:47:55,440 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:47:55,446 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50046
om1_1        | 2022-04-21 16:52:59,504 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:35801
om1_1        | 2022-04-21 16:52:59,510 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 16:52:59,511 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm1.org_1   | 2022-04-21 16:43:38,621 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/37768e1b-cb4c-49da-b09f-824fabcc98dc/current/log_inprogress_0 to /data/metadata/scm-ha/37768e1b-cb4c-49da-b09f-824fabcc98dc/current/log_0-0
scm3.org_1   | 2022-04-21 16:47:55,467 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:48:25,215 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37202
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 134 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-04-21 16:45:56,794 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=f5f2ffbc-fc63-4015-9163-f38ef2c5977c reported by 8694db2d-5e51-4888-b1e0-69ff67626e43{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 952600664327, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
om1_1        | 2022-04-21 16:52:59,518 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
om1_1        | 2022-04-21 16:52:59,538 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-3979773564 of layout LEGACY in volume: s3v
om1_1        | 2022-04-21 16:53:00,242 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:00,245 [IPC Server handler 52 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:00,248 [IPC Server handler 65 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm1.org_1   | 2022-04-21 16:43:38,633 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-LeaderElection1] INFO server.RaftServer$Division: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC: set configuration 1: [e8ea6b57-c3ba-42bd-9807-0913ca4228d7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
om1_1        | 2022-04-21 16:53:00,948 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm2.org_1   | 2022-04-21 16:51:55,520 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:52:25,217 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:52676
scm2.org_1   | 2022-04-21 16:52:25,250 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:48:25,232 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:48:25,362 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:37030
scm3.org_1   | 2022-04-21 16:48:25,388 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50160
scm3.org_1   | 2022-04-21 16:48:25,450 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 2022-04-21 16:45:57,304 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=f5f2ffbc-fc63-4015-9163-f38ef2c5977c reported by 0ef408af-3ea2-4044-bc54-ad0ae15d84f1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 953699741549, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-04-21 16:45:58,020 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
scm1.org_1   | 2022-04-21 16:43:38,642 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/37768e1b-cb4c-49da-b09f-824fabcc98dc/current/log_inprogress_1
scm1.org_1   | 2022-04-21 16:43:38,649 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-StateMachineUpdater] INFO ha.SCMContext: update <isLeaderReady> from <false> to <true>
scm1.org_1   | 2022-04-21 16:43:38,652 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-StateMachineUpdater] INFO pipeline.BackgroundPipelineCreator: Service BackgroundPipelineCreator transitions to RUNNING.
scm1.org_1   | 2022-04-21 16:43:38,655 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-04-21 16:43:38,657 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
scm1.org_1   | 2022-04-21 16:43:38,658 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm1.org_1   | 2022-04-21 16:43:38,658 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9861
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
scm3.org_1   | 2022-04-21 16:48:25,463 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:48:55,305 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37302
scm3.org_1   | 2022-04-21 16:48:55,350 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:52:25,370 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:32880
om1_1        | 2022-04-21 16:53:00,951 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:00,960 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:00,982 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:01,373 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:02,132 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:02,136 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:02,139 [IPC Server handler 56 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:02,166 [IPC Server handler 63 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:02,284 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
scm2.org_1   | 2022-04-21 16:52:25,379 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50140
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
scm1.org_1   | 2022-04-21 16:43:38,671 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm1.org_1   | 2022-04-21 16:43:38,701 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm1.org_1   | 2022-04-21 16:43:38,878 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49384
scm1.org_1   | 2022-04-21 16:43:38,901 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-04-21 16:43:42,339 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for RECON recon, UUID: 2424f40f-d14e-462e-99f8-dedd28b79552
scm1.org_1   | 2022-04-21 16:43:43,102 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-04-21 16:48:55,365 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:37130
scm3.org_1   | 2022-04-21 16:48:55,376 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50256
scm2.org_1   | 2022-04-21 16:52:25,384 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
scm3.org_1   | 2022-04-21 16:48:55,385 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:48:55,429 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1        | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #142 timeout 180s
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:368)
s3g_1        | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
om1_1        | 2022-04-21 16:53:02,966 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:02,969 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:02,971 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:03,609 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm2.org_1   | 2022-04-21 16:52:25,392 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:49:18,479 [ReplicationMonitor] INFO container.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm3.org_1   | 2022-04-21 16:49:25,269 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37404
scm3.org_1   | 2022-04-21 16:49:25,306 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:49:25,348 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50370
scm1.org_1   | 2022-04-21 16:43:43,104 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-StateMachineUpdater] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm1.org_1   | 2022-04-21 16:43:43,107 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-StateMachineUpdater] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm2.org_1   | 2022-04-21 16:52:55,228 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:52776
scm2.org_1   | 2022-04-21 16:52:55,252 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm3.org_1   | 2022-04-21 16:49:25,399 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:49:25,412 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:37240
scm1.org_1   | 2022-04-21 16:43:46,041 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:50326
scm1.org_1   | 2022-04-21 16:43:46,061 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
om1_1        | 2022-04-21 16:53:03,611 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:03,615 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:03,647 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:04,584 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:04,589 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:04,592 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:373)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:368)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:357)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
scm2.org_1   | 2022-04-21 16:52:55,372 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:32982
scm2.org_1   | 2022-04-21 16:52:55,395 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:52:55,450 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50242
scm2.org_1   | 2022-04-21 16:52:55,572 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:53:25,224 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:52906
scm2.org_1   | 2022-04-21 16:53:25,284 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:53:25,300 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:33112
scm1.org_1   | 2022-04-21 16:43:46,062 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for scm scm2.org, nodeId: d794df5a-ece1-4828-94ba-97e720366f72
scm1.org_1   | 2022-04-21 16:43:48,347 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-04-21 16:43:53,549 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49612
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
scm1.org_1   | 2022-04-21 16:43:53,575 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
om1_1        | 2022-04-21 16:53:05,250 [IPC Server handler 65 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:05,254 [IPC Server handler 59 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:05,257 [IPC Server handler 88 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm3.org_1   | 2022-04-21 16:49:25,434 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:49:55,257 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37502
scm3.org_1   | 2022-04-21 16:49:55,296 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
s3g_1        | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
scm1.org_1   | 2022-04-21 16:43:59,602 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:33443
scm1.org_1   | 2022-04-21 16:43:59,612 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-04-21 16:44:03,823 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:35668
scm1.org_1   | 2022-04-21 16:44:03,898 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm3.org_1   | 2022-04-21 16:49:55,352 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50464
scm3.org_1   | 2022-04-21 16:49:55,358 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:37336
scm3.org_1   | 2022-04-21 16:49:55,377 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:49:55,382 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:50:25,243 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37614
scm3.org_1   | 2022-04-21 16:50:25,252 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:53:25,313 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50374
scm2.org_1   | 2022-04-21 16:53:25,337 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:53:25,363 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:53:55,272 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:53040
scm2.org_1   | 2022-04-21 16:53:55,330 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2022-04-21 16:53:05,996 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:06,001 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:06,003 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:06,024 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:08,795 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:09,513 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
scm1.org_1   | 2022-04-21 16:44:03,905 [IPC Server handler 14 on default port 9863] INFO ha.SCMRatisServerImpl: e8ea6b57-c3ba-42bd-9807-0913ca4228d7: Submitting SetConfiguration request to Ratis server with new SCM peers list: [e8ea6b57-c3ba-42bd-9807-0913ca4228d7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, d794df5a-ece1-4828-94ba-97e720366f72|rpc:scm2.org:9894|priority:0]
scm1.org_1   | 2022-04-21 16:44:03,912 [IPC Server handler 14 on default port 9863] INFO server.RaftServer$Division: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC: receive setConfiguration SetConfigurationRequest:client-FCC0E45B3274->e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC, cid=1, seq=0, RW, null, peers:[e8ea6b57-c3ba-42bd-9807-0913ca4228d7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, d794df5a-ece1-4828-94ba-97e720366f72|rpc:scm2.org:9894|priority:0]
om1_1        | 2022-04-21 16:53:09,516 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm2.org_1   | 2022-04-21 16:53:55,405 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50494
scm1.org_1   | 2022-04-21 16:44:03,913 [IPC Server handler 14 on default port 9863] INFO server.RaftServer$Division: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-LeaderStateImpl: startSetConfiguration SetConfigurationRequest:client-FCC0E45B3274->e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC, cid=1, seq=0, RW, null, peers:[e8ea6b57-c3ba-42bd-9807-0913ca4228d7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, d794df5a-ece1-4828-94ba-97e720366f72|rpc:scm2.org:9894|priority:0]
scm1.org_1   | 2022-04-21 16:44:03,946 [IPC Server handler 14 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
scm1.org_1   | 2022-04-21 16:44:03,947 [IPC Server handler 14 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2022-04-21 16:44:03,952 [IPC Server handler 14 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
scm1.org_1   | 2022-04-21 16:44:03,962 [IPC Server handler 14 on default port 9863] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
scm3.org_1   | 2022-04-21 16:50:25,279 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:37446
scm3.org_1   | 2022-04-21 16:50:25,330 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:50:25,343 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50578
scm3.org_1   | 2022-04-21 16:50:25,364 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1        | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1        | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1        | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm2.org_1   | 2022-04-21 16:53:55,460 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
om1_1        | 2022-04-21 16:53:09,519 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:09,543 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:12,411 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:13,040 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:13,045 [IPC Server handler 43 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:13,047 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:13,779 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:13,781 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm2.org_1   | 2022-04-21 16:53:55,512 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:33250
scm2.org_1   | 2022-04-21 16:53:55,600 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:54:00,240 [ReplicationMonitor] INFO container.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm3.org_1   | 2022-04-21 16:50:55,282 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37704
scm3.org_1   | 2022-04-21 16:50:55,340 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:50:55,378 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:37536
scm3.org_1   | 2022-04-21 16:50:55,417 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50668
scm3.org_1   | 2022-04-21 16:50:55,435 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:50:55,440 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:51:25,274 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37954
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1        | 	... 1 more
s3g_1        | 2022-04-21 16:58:18,708 [qtp440736059-17] INFO scm.XceiverClientRatis: Could not commit index 139 on pipeline Pipeline[ Id: a2956c20-9fda-4457-b767-0b8a33d7fc85, Nodes: a9037631-20c7-49ff-8966-d11abf0c09e2{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}8694db2d-5e51-4888-b1e0-69ff67626e43{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}0ef408af-3ea2-4044-bc54-ad0ae15d84f1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:a9037631-20c7-49ff-8966-d11abf0c09e2, CreationTimestamp2022-04-21T16:45:20.398Z[UTC]] to all the nodes. Server 0ef408af-3ea2-4044-bc54-ad0ae15d84f1 has failed. Committed by majority.
s3g_1        | 2022-04-21 16:58:18,709 [qtp440736059-17] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 2 locID: 109611004723200043 bcsId: 139 on Pipeline[ Id: a2956c20-9fda-4457-b767-0b8a33d7fc85, Nodes: a9037631-20c7-49ff-8966-d11abf0c09e2{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}8694db2d-5e51-4888-b1e0-69ff67626e43{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}0ef408af-3ea2-4044-bc54-ad0ae15d84f1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:a9037631-20c7-49ff-8966-d11abf0c09e2, CreationTimestamp2022-04-21T16:45:20.398Z[UTC]]. Failed nodes: [0ef408af-3ea2-4044-bc54-ad0ae15d84f1{ip: null, host: null, ports: [], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
scm1.org_1   | 2022-04-21 16:44:03,974 [IPC Server handler 14 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm1.org_1   | 2022-04-21 16:44:03,978 [IPC Server handler 14 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm1.org_1   | 2022-04-21 16:44:04,047 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->d794df5a-ece1-4828-94ba-97e720366f72-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->d794df5a-ece1-4828-94ba-97e720366f72-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:6)
scm1.org_1   | 2022-04-21 16:44:04,108 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->d794df5a-ece1-4828-94ba-97e720366f72-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->d794df5a-ece1-4828-94ba-97e720366f72-GrpcLogAppender: send e8ea6b57-c3ba-42bd-9807-0913ca4228d7->d794df5a-ece1-4828-94ba-97e720366f72#0-t2,notify:(t:2, i:6)
scm1.org_1   | 2022-04-21 16:44:05,448 [grpc-default-executor-2] INFO ha.SCMDBCheckpointProvider: Received request to obtain SCM DB checkpoint snapshot
scm1.org_1   | 2022-04-21 16:44:05,499 [grpc-default-executor-2] INFO db.RDBCheckpointManager: Created checkpoint at /data/metadata/db.checkpoints/scm.db_checkpoint_1650559445449 in 50 milliseconds
scm1.org_1   | 2022-04-21 16:44:05,628 [grpc-default-executor-2] INFO ha.SCMGrpcOutputStream: Sent 8864 bytes for cluster CID-37768e1b-cb4c-49da-b09f-824fabcc98dc
scm1.org_1   | 2022-04-21 16:44:05,630 [grpc-default-executor-2] INFO ha.SCMDBCheckpointProvider: Time taken to write the checkpoint to response output stream: 126 milliseconds
scm1.org_1   | 2022-04-21 16:44:05,631 [grpc-default-executor-2] INFO db.RocksDBCheckpoint: Cleaning up RocksDB checkpoint at /data/metadata/db.checkpoints/scm.db_checkpoint_1650559445449
scm1.org_1   | 2022-04-21 16:44:05,837 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49802
scm1.org_1   | 2022-04-21 16:44:05,988 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-04-21 16:44:06,299 [grpc-default-executor-2] INFO server.GrpcLogAppender: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->d794df5a-ece1-4828-94ba-97e720366f72-InstallSnapshotResponseHandler: received the first reply e8ea6b57-c3ba-42bd-9807-0913ca4228d7<-d794df5a-ece1-4828-94ba-97e720366f72#0:FAIL-t0,IN_PROGRESS
scm1.org_1   | 2022-04-21 16:44:06,303 [grpc-default-executor-2] INFO server.GrpcLogAppender: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->d794df5a-ece1-4828-94ba-97e720366f72-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm2.org_1   | 2022-04-21 16:54:25,217 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:53164
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-04-21 16:45:59,937 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=f5f2ffbc-fc63-4015-9163-f38ef2c5977c reported by 0ef408af-3ea2-4044-bc54-ad0ae15d84f1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 953699741549, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-04-21 16:45:59,938 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: f5f2ffbc-fc63-4015-9163-f38ef2c5977c, Nodes: a9037631-20c7-49ff-8966-d11abf0c09e2{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}8694db2d-5e51-4888-b1e0-69ff67626e43{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}0ef408af-3ea2-4044-bc54-ad0ae15d84f1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:0ef408af-3ea2-4044-bc54-ad0ae15d84f1, CreationTimestamp2022-04-21T16:45:20.722Z[UTC]] moved to OPEN state
recon_1      | 2022-04-21 16:46:08,907 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:46590
recon_1      | 2022-04-21 16:46:08,938 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:46:16,882 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48782
recon_1      | 2022-04-21 16:46:17,054 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:46:17,089 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #1 got from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net.
recon_1      | 2022-04-21 16:46:17,256 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: Successfully added container #1 to Recon.
recon_1      | 2022-04-21 16:46:17,376 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33022
recon_1      | 2022-04-21 16:46:17,411 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
s3g_1        | 2022-04-21 16:59:26,148 [qtp440736059-21] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: a2956c20-9fda-4457-b767-0b8a33d7fc85, Nodes: a9037631-20c7-49ff-8966-d11abf0c09e2{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}8694db2d-5e51-4888-b1e0-69ff67626e43{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}0ef408af-3ea2-4044-bc54-ad0ae15d84f1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:a9037631-20c7-49ff-8966-d11abf0c09e2, CreationTimestamp2022-04-21T16:45:20.398Z[UTC]]
s3g_1        | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #157 timeout 180s
scm3.org_1   | 2022-04-21 16:51:25,312 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50928
scm1.org_1   | 2022-04-21 16:44:06,332 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->d794df5a-ece1-4828-94ba-97e720366f72-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->d794df5a-ece1-4828-94ba-97e720366f72-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:6)
scm2.org_1   | 2022-04-21 16:54:25,288 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:51:25,330 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:54:25,298 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:33370
scm2.org_1   | 2022-04-21 16:54:25,351 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50634
scm2.org_1   | 2022-04-21 16:54:25,369 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:54:25,375 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:54:55,235 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:53228
scm2.org_1   | 2022-04-21 16:54:55,298 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:33440
scm2.org_1   | 2022-04-21 16:54:55,325 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50700
scm3.org_1   | 2022-04-21 16:51:25,365 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:37798
scm2.org_1   | 2022-04-21 16:54:55,339 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:51:25,402 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:54:55,374 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:54:55,402 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:55:25,224 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:53316
scm2.org_1   | 2022-04-21 16:55:25,250 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:55:25,285 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:33520
scm3.org_1   | 2022-04-21 16:51:25,441 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
scm2.org_1   | 2022-04-21 16:55:25,304 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:55:25,339 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50784
scm2.org_1   | 2022-04-21 16:55:25,390 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:55:55,321 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:53376
scm2.org_1   | 2022-04-21 16:55:55,336 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:55:55,350 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:33584
scm2.org_1   | 2022-04-21 16:55:55,361 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:55:55,366 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50846
scm2.org_1   | 2022-04-21 16:55:55,375 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:56:25,231 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:53476
scm2.org_1   | 2022-04-21 16:56:25,313 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:56:25,323 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:33686
scm2.org_1   | 2022-04-21 16:56:25,329 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50944
scm2.org_1   | 2022-04-21 16:56:25,340 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:56:25,383 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:56:55,229 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:53546
scm2.org_1   | 2022-04-21 16:56:55,313 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:33754
scm2.org_1   | 2022-04-21 16:56:55,319 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:56:55,366 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2022-04-21 16:53:13,784 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:13,806 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
scm2.org_1   | 2022-04-21 16:56:55,389 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51012
scm2.org_1   | 2022-04-21 16:56:55,423 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2022-04-21 16:53:16,650 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:17,320 [IPC Server handler 80 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:17,322 [IPC Server handler 81 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:17,325 [IPC Server handler 87 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:17,346 [IPC Server handler 73 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:19,921 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
s3g_1        | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:263)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.RatisBlockOutputStream.sendWatchForCommit(RatisBlockOutputStream.java:101)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:392)
scm2.org_1   | 2022-04-21 16:57:25,220 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:53626
scm2.org_1   | 2022-04-21 16:57:25,244 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:57:25,331 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51086
scm2.org_1   | 2022-04-21 16:57:25,352 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:33836
scm2.org_1   | 2022-04-21 16:57:25,362 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:57:25,369 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 2022-04-21 16:46:46,916 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48874
recon_1      | 2022-04-21 16:46:46,953 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:46:47,269 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33110
recon_1      | 2022-04-21 16:46:47,298 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om1_1        | 2022-04-21 16:53:20,594 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:20,598 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:20,602 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:21,209 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:21,214 [IPC Server handler 52 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:552)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:566)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:137)
scm1.org_1   | 2022-04-21 16:44:06,333 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->d794df5a-ece1-4828-94ba-97e720366f72-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->d794df5a-ece1-4828-94ba-97e720366f72-GrpcLogAppender: send e8ea6b57-c3ba-42bd-9807-0913ca4228d7->d794df5a-ece1-4828-94ba-97e720366f72#0-t2,notify:(t:2, i:6)
scm3.org_1   | 2022-04-21 16:51:55,277 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38064
scm3.org_1   | 2022-04-21 16:51:55,369 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:37894
recon_1      | 2022-04-21 16:46:47,457 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:46736
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:494)
scm2.org_1   | 2022-04-21 16:57:55,221 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:53718
scm2.org_1   | 2022-04-21 16:57:55,240 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:57:55,407 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51182
scm2.org_1   | 2022-04-21 16:57:55,407 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:33924
scm3.org_1   | 2022-04-21 16:51:55,374 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51024
scm3.org_1   | 2022-04-21 16:51:55,390 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:51:55,475 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2022-04-21 16:53:21,216 [IPC Server handler 65 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:21,265 [IPC Server handler 88 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:22,135 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm1.org_1   | 2022-04-21 16:44:06,377 [grpc-default-executor-2] INFO server.GrpcLogAppender: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->d794df5a-ece1-4828-94ba-97e720366f72-InstallSnapshotResponseHandler: received a reply e8ea6b57-c3ba-42bd-9807-0913ca4228d7<-d794df5a-ece1-4828-94ba-97e720366f72#0:FAIL-t2,SNAPSHOT_INSTALLED,snapshotIndex=6
scm3.org_1   | 2022-04-21 16:51:55,551 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:57:55,420 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:57:55,422 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:58:25,217 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:53796
scm2.org_1   | 2022-04-21 16:58:25,279 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:58:25,315 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:34004
recon_1      | 2022-04-21 16:46:47,493 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:46:58,022 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-04-21 16:46:58,023 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-04-21 16:46:58,077 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
scm1.org_1   | 2022-04-21 16:44:06,377 [grpc-default-executor-2] INFO server.GrpcLogAppender: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->d794df5a-ece1-4828-94ba-97e720366f72-InstallSnapshotResponseHandler: Follower installed snapshot at index 6
scm2.org_1   | 2022-04-21 16:58:25,328 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51260
recon_1      | java.lang.reflect.UndeclaredThrowableException
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:468)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:521)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.createMultipartKey(ObjectEndpoint.java:770)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:190)
s3g_1        | 	at jdk.internal.reflect.GeneratedMethodAccessor28.invoke(Unknown Source)
om1_1        | 2022-04-21 16:53:22,137 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:22,140 [IPC Server handler 56 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:22,827 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm1.org_1   | 2022-04-21 16:44:06,390 [grpc-default-executor-2] INFO leader.FollowerInfo: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->d794df5a-ece1-4828-94ba-97e720366f72: snapshotIndex: setUnconditionally 0 -> 6
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om1_1        | 2022-04-21 16:53:22,830 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:22,834 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:22,855 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:25,433 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm3.org_1   | 2022-04-21 16:52:25,213 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38168
scm3.org_1   | 2022-04-21 16:52:25,252 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:52:25,318 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51128
scm3.org_1   | 2022-04-21 16:52:25,345 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:52:25,368 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:38004
scm3.org_1   | 2022-04-21 16:52:25,390 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:52:55,238 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38270
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
scm2.org_1   | 2022-04-21 16:58:25,346 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:58:25,356 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:58:55,218 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:53880
scm2.org_1   | 2022-04-21 16:58:55,262 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:58:55,355 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51348
scm3.org_1   | 2022-04-21 16:52:55,290 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:52:55,355 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51230
scm3.org_1   | 2022-04-21 16:52:55,384 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2022-04-21 16:53:26,122 [IPC Server handler 61 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
scm3.org_1   | 2022-04-21 16:52:55,420 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:38104
scm3.org_1   | 2022-04-21 16:52:55,538 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:53:25,209 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38406
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
scm1.org_1   | 2022-04-21 16:44:06,390 [grpc-default-executor-2] INFO leader.FollowerInfo: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->d794df5a-ece1-4828-94ba-97e720366f72: matchIndex: setUnconditionally 0 -> 6
scm1.org_1   | 2022-04-21 16:44:06,391 [grpc-default-executor-2] INFO leader.FollowerInfo: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->d794df5a-ece1-4828-94ba-97e720366f72: nextIndex: setUnconditionally 7 -> 7
scm1.org_1   | 2022-04-21 16:44:06,393 [grpc-default-executor-2] INFO leader.FollowerInfo: Follower e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->d794df5a-ece1-4828-94ba-97e720366f72 acknowledged installing snapshot
scm1.org_1   | 2022-04-21 16:44:06,399 [grpc-default-executor-2] INFO leader.FollowerInfo: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->d794df5a-ece1-4828-94ba-97e720366f72: nextIndex: updateToMax old=7, new=7, updated? false
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
scm1.org_1   | 2022-04-21 16:44:06,391 [grpc-default-executor-0] INFO leader.FollowerInfo: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->d794df5a-ece1-4828-94ba-97e720366f72: nextIndex: updateUnconditionally 0 -> 7
scm2.org_1   | 2022-04-21 16:58:55,363 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:34086
om1_1        | 2022-04-21 16:53:26,125 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm3.org_1   | 2022-04-21 16:53:25,254 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:53:25,320 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:38238
scm3.org_1   | 2022-04-21 16:53:25,323 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51366
scm3.org_1   | 2022-04-21 16:53:25,348 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:53:25,368 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:53:55,275 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38530
scm2.org_1   | 2022-04-21 16:58:55,378 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
scm2.org_1   | 2022-04-21 16:58:55,407 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 16:44:07,363 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.118:44676
scm1.org_1   | 2022-04-21 16:44:07,381 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
scm2.org_1   | 2022-04-21 16:59:00,240 [ReplicationMonitor] INFO container.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
om1_1        | 2022-04-21 16:53:26,127 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:26,147 [IPC Server handler 56 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:28,750 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:29,403 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm1.org_1   | 2022-04-21 16:44:08,751 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.118:57978
scm1.org_1   | 2022-04-21 16:44:08,759 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-04-21 16:44:08,760 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for scm scm3.org, nodeId: 9446a705-8bb9-4eda-8998-a3a4fb23e316
scm1.org_1   | 2022-04-21 16:44:08,890 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-04-21 16:44:09,147 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-LeaderStateImpl] INFO server.RaftServer$Division: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC: set configuration 9: [d794df5a-ece1-4828-94ba-97e720366f72|rpc:scm2.org:9894|priority:0, e8ea6b57-c3ba-42bd-9807-0913ca4228d7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=[e8ea6b57-c3ba-42bd-9807-0913ca4228d7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm1.org_1   | 2022-04-21 16:44:09,196 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-LeaderStateImpl] INFO server.RaftServer$Division: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC: set configuration 11: [d794df5a-ece1-4828-94ba-97e720366f72|rpc:scm2.org:9894|priority:0, e8ea6b57-c3ba-42bd-9807-0913ca4228d7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2022-04-21 16:59:25,230 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:53958
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1679)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1        | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #157 timeout 180s
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:368)
s3g_1        | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:373)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:368)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:357)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1        | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
om1_1        | 2022-04-21 16:53:29,406 [IPC Server handler 96 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:29,414 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm3.org_1   | 2022-04-21 16:53:55,338 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:53:55,424 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:38358
scm3.org_1   | 2022-04-21 16:53:55,461 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:53:55,530 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51498
scm3.org_1   | 2022-04-21 16:53:55,601 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:54:18,480 [ReplicationMonitor] INFO container.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm3.org_1   | 2022-04-21 16:54:25,233 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38662
scm3.org_1   | 2022-04-21 16:54:25,301 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:54:25,313 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51618
scm3.org_1   | 2022-04-21 16:54:25,357 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:38496
scm3.org_1   | 2022-04-21 16:54:25,386 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:54:25,389 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:54:55,320 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38730
scm3.org_1   | 2022-04-21 16:54:55,325 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51688
scm3.org_1   | 2022-04-21 16:54:55,341 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:38562
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
om1_1        | 2022-04-21 16:53:29,424 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload: /s3v/bucket-ozone-test-3979773564/ozone-test-3619141613/multipartKey2 Part number: 1 size 6  is less than minimum part size 5242880
om1_1        | 2022-04-21 16:53:29,440 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-3619141613/multipartKey2 in Volume/Bucket s3v/bucket-ozone-test-3979773564
om1_1        | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-3979773564 key: ozone-test-3619141613/multipartKey2. Entity too small.
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:517)
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:197)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:514)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:317)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-04-21 16:53:30,103 [IPC Server handler 46 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:30,106 [IPC Server handler 42 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:30,109 [IPC Server handler 61 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:30,780 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:30,783 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:30,786 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:30,794 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-ozone-test-3979773564/ozone-test-2106382736/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 1
om1_1        | partName: "etag1"
om1_1        | , partNumber: 2
om1_1        | partName: "etag2"
om1_1        | ]
om1_1        | 2022-04-21 16:53:30,807 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-2106382736/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-3979773564
om1_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-3979773564 key: ozone-test-2106382736/multipartKey3
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:186)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:514)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:317)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-04-21 16:53:31,425 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:31,428 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:31,438 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:31,447 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-ozone-test-3979773564/ozone-test-2106382736/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 2
om1_1        | partName: "etag1"
om1_1        | , partNumber: 1
om1_1        | partName: "etag2"
om1_1        | ]
scm1.org_1   | 2022-04-21 16:44:09,326 [IPC Server handler 14 on default port 9863] INFO ha.SCMRatisServerImpl: Successfully added new SCM: d794df5a-ece1-4828-94ba-97e720366f72.
scm1.org_1   | 2022-04-21 16:44:11,241 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:50728
scm1.org_1   | 2022-04-21 16:44:11,258 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-04-21 16:44:17,319 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49984
scm1.org_1   | 2022-04-21 16:44:17,344 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-04-21 16:44:21,605 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.118:44876
scm1.org_1   | 2022-04-21 16:44:21,783 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-04-21 16:44:21,788 [IPC Server handler 9 on default port 9863] INFO ha.SCMRatisServerImpl: e8ea6b57-c3ba-42bd-9807-0913ca4228d7: Submitting SetConfiguration request to Ratis server with new SCM peers list: [d794df5a-ece1-4828-94ba-97e720366f72|rpc:scm2.org:9894|priority:0, e8ea6b57-c3ba-42bd-9807-0913ca4228d7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 9446a705-8bb9-4eda-8998-a3a4fb23e316|rpc:scm3.org:9894|priority:0]
scm1.org_1   | 2022-04-21 16:44:21,790 [IPC Server handler 9 on default port 9863] INFO server.RaftServer$Division: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC: receive setConfiguration SetConfigurationRequest:client-FCC0E45B3274->e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC, cid=2, seq=0, RW, null, peers:[d794df5a-ece1-4828-94ba-97e720366f72|rpc:scm2.org:9894|priority:0, e8ea6b57-c3ba-42bd-9807-0913ca4228d7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 9446a705-8bb9-4eda-8998-a3a4fb23e316|rpc:scm3.org:9894|priority:0]
scm1.org_1   | 2022-04-21 16:44:21,797 [IPC Server handler 9 on default port 9863] INFO server.RaftServer$Division: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-LeaderStateImpl: startSetConfiguration SetConfigurationRequest:client-FCC0E45B3274->e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC, cid=2, seq=0, RW, null, peers:[d794df5a-ece1-4828-94ba-97e720366f72|rpc:scm2.org:9894|priority:0, e8ea6b57-c3ba-42bd-9807-0913ca4228d7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 9446a705-8bb9-4eda-8998-a3a4fb23e316|rpc:scm3.org:9894|priority:0]
scm1.org_1   | 2022-04-21 16:44:21,798 [IPC Server handler 9 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
scm1.org_1   | 2022-04-21 16:44:21,798 [IPC Server handler 9 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2022-04-21 16:44:21,798 [IPC Server handler 9 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
scm1.org_1   | 2022-04-21 16:44:21,809 [IPC Server handler 9 on default port 9863] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
scm1.org_1   | 2022-04-21 16:44:21,810 [IPC Server handler 9 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm1.org_1   | 2022-04-21 16:44:21,810 [IPC Server handler 9 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm1.org_1   | 2022-04-21 16:44:21,824 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:12)
scm1.org_1   | 2022-04-21 16:44:21,831 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316-GrpcLogAppender: send e8ea6b57-c3ba-42bd-9807-0913ca4228d7->9446a705-8bb9-4eda-8998-a3a4fb23e316#0-t2,notify:(t:2, i:12)
scm1.org_1   | 2022-04-21 16:44:25,876 [grpc-default-executor-0] INFO ha.SCMDBCheckpointProvider: Received request to obtain SCM DB checkpoint snapshot
scm1.org_1   | 2022-04-21 16:44:26,046 [grpc-default-executor-0] INFO db.RDBCheckpointManager: Created checkpoint at /data/metadata/db.checkpoints/scm.db_checkpoint_1650559465946 in 91 milliseconds
scm1.org_1   | 2022-04-21 16:44:26,103 [grpc-default-executor-2] INFO server.GrpcLogAppender: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316-InstallSnapshotResponseHandler: received the first reply e8ea6b57-c3ba-42bd-9807-0913ca4228d7<-9446a705-8bb9-4eda-8998-a3a4fb23e316#0:FAIL-t0,IN_PROGRESS
scm1.org_1   | 2022-04-21 16:44:26,112 [grpc-default-executor-2] INFO server.GrpcLogAppender: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2022-04-21 16:44:26,129 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:12)
scm1.org_1   | 2022-04-21 16:44:26,129 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316-GrpcLogAppender: send e8ea6b57-c3ba-42bd-9807-0913ca4228d7->9446a705-8bb9-4eda-8998-a3a4fb23e316#0-t2,notify:(t:2, i:12)
scm1.org_1   | 2022-04-21 16:44:26,235 [grpc-default-executor-2] INFO server.GrpcLogAppender: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316-InstallSnapshotResponseHandler: received a reply e8ea6b57-c3ba-42bd-9807-0913ca4228d7<-9446a705-8bb9-4eda-8998-a3a4fb23e316#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2022-04-21 16:44:26,236 [grpc-default-executor-2] INFO server.GrpcLogAppender: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2022-04-21 16:44:26,240 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:12)
scm1.org_1   | 2022-04-21 16:44:26,243 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316-GrpcLogAppender: send e8ea6b57-c3ba-42bd-9807-0913ca4228d7->9446a705-8bb9-4eda-8998-a3a4fb23e316#0-t2,notify:(t:2, i:12)
scm1.org_1   | 2022-04-21 16:44:26,305 [grpc-default-executor-1] INFO leader.FollowerInfo: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2022-04-21 16:44:26,305 [grpc-default-executor-2] INFO server.GrpcLogAppender: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316-InstallSnapshotResponseHandler: received a reply e8ea6b57-c3ba-42bd-9807-0913ca4228d7<-9446a705-8bb9-4eda-8998-a3a4fb23e316#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2022-04-21 16:44:26,331 [grpc-default-executor-2] INFO server.GrpcLogAppender: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2022-04-21 16:44:26,336 [grpc-default-executor-0] INFO ha.SCMGrpcOutputStream: Sent 10024 bytes for cluster CID-37768e1b-cb4c-49da-b09f-824fabcc98dc
scm1.org_1   | 2022-04-21 16:44:26,340 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:12)
scm1.org_1   | 2022-04-21 16:44:26,343 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316-GrpcLogAppender: send e8ea6b57-c3ba-42bd-9807-0913ca4228d7->9446a705-8bb9-4eda-8998-a3a4fb23e316#0-t2,notify:(t:2, i:12)
scm1.org_1   | 2022-04-21 16:44:26,355 [grpc-default-executor-2] INFO leader.FollowerInfo: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2022-04-21 16:44:26,416 [grpc-default-executor-0] INFO ha.SCMDBCheckpointProvider: Time taken to write the checkpoint to response output stream: 289 milliseconds
scm1.org_1   | 2022-04-21 16:44:26,416 [grpc-default-executor-0] INFO db.RocksDBCheckpoint: Cleaning up RocksDB checkpoint at /data/metadata/db.checkpoints/scm.db_checkpoint_1650559465946
scm1.org_1   | 2022-04-21 16:44:26,623 [grpc-default-executor-2] INFO leader.FollowerInfo: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2022-04-21 16:44:26,624 [grpc-default-executor-0] INFO server.GrpcLogAppender: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316-InstallSnapshotResponseHandler: received a reply e8ea6b57-c3ba-42bd-9807-0913ca4228d7<-9446a705-8bb9-4eda-8998-a3a4fb23e316#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2022-04-21 16:44:26,631 [grpc-default-executor-0] INFO server.GrpcLogAppender: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2022-04-21 16:44:26,632 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:12)
scm1.org_1   | 2022-04-21 16:44:26,640 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316-GrpcLogAppender: send e8ea6b57-c3ba-42bd-9807-0913ca4228d7->9446a705-8bb9-4eda-8998-a3a4fb23e316#0-t2,notify:(t:2, i:12)
scm1.org_1   | 2022-04-21 16:44:26,792 [grpc-default-executor-2] INFO leader.FollowerInfo: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316: nextIndex: updateUnconditionally 0 -> 0
scm2.org_1   | 2022-04-21 16:59:25,268 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:34168
scm2.org_1   | 2022-04-21 16:59:25,277 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:59:25,300 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:59:25,326 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51428
scm2.org_1   | 2022-04-21 16:59:25,372 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:59:55,242 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:54050
scm2.org_1   | 2022-04-21 16:59:55,293 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:34258
scm2.org_1   | 2022-04-21 16:59:55,354 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:59:55,355 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 16:59:55,395 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51514
scm2.org_1   | 2022-04-21 16:59:55,460 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 17:00:25,258 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:54180
scm2.org_1   | 2022-04-21 17:00:25,328 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 17:00:25,343 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:34384
scm2.org_1   | 2022-04-21 17:00:25,393 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51646
scm2.org_1   | 2022-04-21 17:00:25,405 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 17:00:25,462 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 17:00:55,219 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:54314
scm2.org_1   | 2022-04-21 17:00:55,247 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 17:00:55,316 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:34522
scm2.org_1   | 2022-04-21 17:00:55,339 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 17:00:55,368 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51782
scm2.org_1   | 2022-04-21 17:00:55,375 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 17:01:25,243 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:54404
scm2.org_1   | 2022-04-21 17:01:25,333 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-04-21 17:01:25,353 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51874
scm2.org_1   | 2022-04-21 17:01:25,360 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:34610
scm2.org_1   | 2022-04-21 17:01:25,395 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
scm3.org_1   | 2022-04-21 16:54:55,363 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:54:55,381 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:54:55,401 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:55:25,228 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38814
scm3.org_1   | 2022-04-21 16:55:25,260 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:55:25,337 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51772
scm3.org_1   | 2022-04-21 16:55:25,350 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:38646
scm3.org_1   | 2022-04-21 16:55:25,375 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:55:25,391 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:55:55,249 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38874
scm3.org_1   | 2022-04-21 16:55:55,319 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:55:55,334 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51836
scm3.org_1   | 2022-04-21 16:55:55,346 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:38704
scm3.org_1   | 2022-04-21 16:55:55,357 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:55:55,372 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:56:25,236 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38976
scm3.org_1   | 2022-04-21 16:56:25,327 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51932
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
scm2.org_1   | 2022-04-21 17:01:25,409 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-04-21 16:47:16,901 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48970
recon_1      | 2022-04-21 16:47:16,927 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:47:17,277 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33210
recon_1      | 2022-04-21 16:47:17,329 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:47:17,455 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:46834
recon_1      | 2022-04-21 16:47:17,515 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:47:25,189 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #2 got from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net.
recon_1      | 2022-04-21 16:47:25,225 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: Successfully added container #2 to Recon.
recon_1      | 2022-04-21 16:47:55,215 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33322
recon_1      | 2022-04-21 16:47:55,310 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:46944
recon_1      | 2022-04-21 16:47:55,326 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:47:55,342 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49104
recon_1      | 2022-04-21 16:47:55,351 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:47:55,386 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:47:58,078 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-04-21 16:47:58,078 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-04-21 16:47:58,126 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
scm3.org_1   | 2022-04-21 16:56:25,330 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:38808
scm3.org_1   | 2022-04-21 16:56:25,334 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:56:25,369 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:56:25,384 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:56:55,222 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:39046
scm3.org_1   | 2022-04-21 16:56:55,288 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:56:55,366 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52002
scm3.org_1   | 2022-04-21 16:56:55,376 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:56:55,415 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:38874
scm3.org_1   | 2022-04-21 16:56:55,433 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:57:25,228 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:39118
scm3.org_1   | 2022-04-21 16:57:25,246 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:57:25,325 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:38944
scm3.org_1   | 2022-04-21 16:57:25,354 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52088
scm3.org_1   | 2022-04-21 16:57:25,358 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:57:25,372 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:57:55,228 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:39210
scm3.org_1   | 2022-04-21 16:57:55,241 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:57:55,324 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39046
scm3.org_1   | 2022-04-21 16:57:55,368 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52176
scm3.org_1   | 2022-04-21 16:57:55,378 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:57:55,384 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:58:25,224 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:39290
scm3.org_1   | 2022-04-21 16:58:25,316 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:58:25,355 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39126
scm3.org_1   | 2022-04-21 16:58:25,364 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52252
scm3.org_1   | 2022-04-21 16:58:25,371 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:58:25,379 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:58:55,232 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:39378
scm3.org_1   | 2022-04-21 16:58:55,289 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39210
scm3.org_1   | 2022-04-21 16:58:55,334 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:58:55,383 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52338
scm3.org_1   | 2022-04-21 16:58:55,384 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:58:55,404 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:59:18,480 [ReplicationMonitor] INFO container.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm3.org_1   | 2022-04-21 16:59:25,227 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:39458
scm3.org_1   | 2022-04-21 16:59:25,274 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:59:25,331 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52416
scm3.org_1   | 2022-04-21 16:59:25,342 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39284
scm3.org_1   | 2022-04-21 16:59:25,347 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:59:25,374 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:59:55,264 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:39544
om1_1        | 2022-04-21 16:53:31,447 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-2106382736/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-3979773564
om1_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-3979773564 key: ozone-test-2106382736/multipartKey3
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:186)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:514)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:317)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-04-21 16:53:32,141 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:32,145 [IPC Server handler 56 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:32,148 [IPC Server handler 63 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:32,165 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:35,024 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:35,741 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:35,745 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:35,749 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:35,765 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:36,047 [IPC Server handler 43 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:36,735 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:36,737 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:36,743 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:36,764 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:36,871 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:37,547 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:37,554 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:37,557 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm1.org_1   | 2022-04-21 16:44:26,793 [grpc-default-executor-0] INFO server.GrpcLogAppender: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316-InstallSnapshotResponseHandler: received a reply e8ea6b57-c3ba-42bd-9807-0913ca4228d7<-9446a705-8bb9-4eda-8998-a3a4fb23e316#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2022-04-21 16:44:26,803 [grpc-default-executor-0] INFO server.GrpcLogAppender: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2022-04-21 16:44:26,808 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:12)
scm1.org_1   | 2022-04-21 16:44:26,827 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316-GrpcLogAppender: send e8ea6b57-c3ba-42bd-9807-0913ca4228d7->9446a705-8bb9-4eda-8998-a3a4fb23e316#0-t2,notify:(t:2, i:12)
scm1.org_1   | 2022-04-21 16:44:26,877 [grpc-default-executor-0] INFO leader.FollowerInfo: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2022-04-21 16:44:26,878 [grpc-default-executor-0] INFO server.GrpcLogAppender: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316-InstallSnapshotResponseHandler: received a reply e8ea6b57-c3ba-42bd-9807-0913ca4228d7<-9446a705-8bb9-4eda-8998-a3a4fb23e316#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2022-04-21 16:44:26,878 [grpc-default-executor-0] INFO server.GrpcLogAppender: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2022-04-21 16:44:26,904 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:12)
scm1.org_1   | 2022-04-21 16:44:26,912 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316-GrpcLogAppender: send e8ea6b57-c3ba-42bd-9807-0913ca4228d7->9446a705-8bb9-4eda-8998-a3a4fb23e316#0-t2,notify:(t:2, i:12)
scm1.org_1   | 2022-04-21 16:44:26,989 [grpc-default-executor-0] INFO server.GrpcLogAppender: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316-InstallSnapshotResponseHandler: received a reply e8ea6b57-c3ba-42bd-9807-0913ca4228d7<-9446a705-8bb9-4eda-8998-a3a4fb23e316#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2022-04-21 16:44:26,989 [grpc-default-executor-0] INFO server.GrpcLogAppender: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2022-04-21 16:44:26,992 [grpc-default-executor-2] INFO leader.FollowerInfo: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2022-04-21 16:44:27,017 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:12)
scm1.org_1   | 2022-04-21 16:44:27,028 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316-GrpcLogAppender: send e8ea6b57-c3ba-42bd-9807-0913ca4228d7->9446a705-8bb9-4eda-8998-a3a4fb23e316#0-t2,notify:(t:2, i:12)
scm1.org_1   | 2022-04-21 16:44:27,066 [grpc-default-executor-2] INFO leader.FollowerInfo: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2022-04-21 16:44:27,167 [grpc-default-executor-2] INFO server.GrpcLogAppender: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316-InstallSnapshotResponseHandler: received a reply e8ea6b57-c3ba-42bd-9807-0913ca4228d7<-9446a705-8bb9-4eda-8998-a3a4fb23e316#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2022-04-21 16:44:27,174 [grpc-default-executor-2] INFO server.GrpcLogAppender: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2022-04-21 16:44:27,175 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:12)
scm1.org_1   | 2022-04-21 16:44:27,175 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316-GrpcLogAppender: send e8ea6b57-c3ba-42bd-9807-0913ca4228d7->9446a705-8bb9-4eda-8998-a3a4fb23e316#0-t2,notify:(t:2, i:12)
scm1.org_1   | 2022-04-21 16:44:27,228 [grpc-default-executor-2] INFO leader.FollowerInfo: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2022-04-21 16:44:27,321 [grpc-default-executor-2] INFO server.GrpcLogAppender: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316-InstallSnapshotResponseHandler: received a reply e8ea6b57-c3ba-42bd-9807-0913ca4228d7<-9446a705-8bb9-4eda-8998-a3a4fb23e316#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2022-04-21 16:44:27,324 [grpc-default-executor-2] INFO server.GrpcLogAppender: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2022-04-21 16:44:27,330 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:12)
scm1.org_1   | 2022-04-21 16:44:27,335 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316-GrpcLogAppender: send e8ea6b57-c3ba-42bd-9807-0913ca4228d7->9446a705-8bb9-4eda-8998-a3a4fb23e316#0-t2,notify:(t:2, i:12)
scm1.org_1   | 2022-04-21 16:44:27,404 [grpc-default-executor-2] INFO server.GrpcLogAppender: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316-InstallSnapshotResponseHandler: received a reply e8ea6b57-c3ba-42bd-9807-0913ca4228d7<-9446a705-8bb9-4eda-8998-a3a4fb23e316#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2022-04-21 16:44:27,432 [grpc-default-executor-2] INFO server.GrpcLogAppender: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2022-04-21 16:44:27,432 [grpc-default-executor-0] INFO leader.FollowerInfo: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2022-04-21 16:44:27,452 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:12)
scm1.org_1   | 2022-04-21 16:44:27,453 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316-GrpcLogAppender: send e8ea6b57-c3ba-42bd-9807-0913ca4228d7->9446a705-8bb9-4eda-8998-a3a4fb23e316#0-t2,notify:(t:2, i:12)
scm1.org_1   | 2022-04-21 16:44:27,571 [grpc-default-executor-0] INFO server.GrpcLogAppender: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316-InstallSnapshotResponseHandler: received a reply e8ea6b57-c3ba-42bd-9807-0913ca4228d7<-9446a705-8bb9-4eda-8998-a3a4fb23e316#0:FAIL-t2,SNAPSHOT_INSTALLED,snapshotIndex=12
scm1.org_1   | 2022-04-21 16:44:27,577 [grpc-default-executor-0] INFO server.GrpcLogAppender: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316-InstallSnapshotResponseHandler: Follower installed snapshot at index 12
s3g_1        | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1        | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1        | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1        | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1        | 	... 1 more
s3g_1        | 2022-04-21 16:59:26,157 [qtp440736059-21] INFO scm.XceiverClientRatis: Could not commit index 144 on pipeline Pipeline[ Id: a2956c20-9fda-4457-b767-0b8a33d7fc85, Nodes: a9037631-20c7-49ff-8966-d11abf0c09e2{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}8694db2d-5e51-4888-b1e0-69ff67626e43{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}0ef408af-3ea2-4044-bc54-ad0ae15d84f1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:a9037631-20c7-49ff-8966-d11abf0c09e2, CreationTimestamp2022-04-21T16:45:20.398Z[UTC]] to all the nodes. Server 0ef408af-3ea2-4044-bc54-ad0ae15d84f1 has failed. Committed by majority.
s3g_1        | 2022-04-21 16:59:26,158 [qtp440736059-21] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 2 locID: 109611004723200046 bcsId: 144 on Pipeline[ Id: a2956c20-9fda-4457-b767-0b8a33d7fc85, Nodes: a9037631-20c7-49ff-8966-d11abf0c09e2{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}8694db2d-5e51-4888-b1e0-69ff67626e43{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}0ef408af-3ea2-4044-bc54-ad0ae15d84f1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:a9037631-20c7-49ff-8966-d11abf0c09e2, CreationTimestamp2022-04-21T16:45:20.398Z[UTC]]. Failed nodes: [0ef408af-3ea2-4044-bc54-ad0ae15d84f1{ip: null, host: null, ports: [], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1        | 2022-04-21 17:00:00,660 [qtp440736059-23] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-5639337117, with testuser as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-04-21 17:00:00,696 [qtp440736059-23] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-5639337117
s3g_1        | 2022-04-21 17:00:26,414 [qtp440736059-21] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-1676201683, with testuser as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-04-21 17:00:26,436 [qtp440736059-21] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-1676201683
s3g_1        | 2022-04-21 17:00:39,770 [qtp440736059-23] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-4595663119, with testuser as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-04-21 17:00:39,779 [qtp440736059-23] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-4595663119
om1_1        | 2022-04-21 16:53:37,564 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-2106382736/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-3979773564
om1_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-3979773564 key: ozone-test-2106382736/multipartKey3. Provided Part info is { etag1, 1}, whereas OM has partName /s3v/bucket-ozone-test-3979773564/ozone-test-2106382736/multipartKey3-39d7a4bf-f0b0-432c-9d38-260cf0a0d6fc-108171100822503460-1
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:499)
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:197)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:514)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:317)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-04-21 16:53:38,175 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:38,177 [IPC Server handler 52 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:38,180 [IPC Server handler 59 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:38,193 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-2106382736/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-3979773564
om1_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-3979773564 key: ozone-test-2106382736/multipartKey3. Provided Part info is { etag2, 2}, whereas OM has partName /s3v/bucket-ozone-test-3979773564/ozone-test-2106382736/multipartKey3-39d7a4bf-f0b0-432c-9d38-260cf0a0d6fc-108171100822503460-2
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:499)
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:197)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:514)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:317)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-04-21 16:53:38,795 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:38,797 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm3.org_1   | 2022-04-21 16:59:55,293 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52506
scm3.org_1   | 2022-04-21 16:59:55,332 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:59:55,368 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 16:59:55,414 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39376
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
scm3.org_1   | 2022-04-21 16:59:55,476 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 17:00:25,215 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:39678
scm3.org_1   | 2022-04-21 17:00:25,331 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 17:00:25,345 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52646
scm3.org_1   | 2022-04-21 17:00:25,371 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39508
scm3.org_1   | 2022-04-21 17:00:25,387 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 17:00:25,405 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 17:00:55,223 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:39812
scm3.org_1   | 2022-04-21 17:00:55,246 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 17:00:55,315 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52768
scm3.org_1   | 2022-04-21 17:00:55,334 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 17:00:55,384 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39644
scm3.org_1   | 2022-04-21 17:00:55,394 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 17:01:25,353 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:39902
scm3.org_1   | 2022-04-21 17:01:25,359 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39728
scm3.org_1   | 2022-04-21 17:01:25,384 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 17:01:25,394 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52856
scm3.org_1   | 2022-04-21 17:01:25,408 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-04-21 17:01:25,431 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 16:44:27,578 [grpc-default-executor-0] INFO leader.FollowerInfo: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316: snapshotIndex: setUnconditionally 0 -> 12
scm1.org_1   | 2022-04-21 16:44:27,578 [grpc-default-executor-0] INFO leader.FollowerInfo: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316: matchIndex: setUnconditionally 0 -> 12
scm1.org_1   | 2022-04-21 16:44:27,578 [grpc-default-executor-0] INFO leader.FollowerInfo: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316: nextIndex: setUnconditionally 0 -> 13
scm1.org_1   | 2022-04-21 16:44:27,578 [grpc-default-executor-0] INFO leader.FollowerInfo: Follower e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316 acknowledged installing snapshot
scm1.org_1   | 2022-04-21 16:44:27,597 [grpc-default-executor-2] INFO leader.FollowerInfo: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316: nextIndex: updateUnconditionally 13 -> 13
scm1.org_1   | 2022-04-21 16:44:27,603 [grpc-default-executor-0] INFO leader.FollowerInfo: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC->9446a705-8bb9-4eda-8998-a3a4fb23e316: nextIndex: updateToMax old=13, new=13, updated? false
scm1.org_1   | 2022-04-21 16:44:30,224 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-LeaderStateImpl] INFO server.RaftServer$Division: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC: set configuration 13: [9446a705-8bb9-4eda-8998-a3a4fb23e316|rpc:scm3.org:9894|priority:0, d794df5a-ece1-4828-94ba-97e720366f72|rpc:scm2.org:9894|priority:0, e8ea6b57-c3ba-42bd-9807-0913ca4228d7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=[d794df5a-ece1-4828-94ba-97e720366f72|rpc:scm2.org:9894|priority:0, e8ea6b57-c3ba-42bd-9807-0913ca4228d7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm1.org_1   | 2022-04-21 16:44:30,263 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-LeaderStateImpl] INFO server.RaftServer$Division: e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC: set configuration 15: [9446a705-8bb9-4eda-8998-a3a4fb23e316|rpc:scm3.org:9894|priority:0, d794df5a-ece1-4828-94ba-97e720366f72|rpc:scm2.org:9894|priority:0, e8ea6b57-c3ba-42bd-9807-0913ca4228d7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2022-04-21 16:44:30,301 [IPC Server handler 9 on default port 9863] INFO ha.SCMRatisServerImpl: Successfully added new SCM: 9446a705-8bb9-4eda-8998-a3a4fb23e316.
scm1.org_1   | 2022-04-21 16:44:36,165 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.118:58210
scm1.org_1   | 2022-04-21 16:44:36,198 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-04-21 16:44:45,354 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:48160
scm1.org_1   | 2022-04-21 16:44:45,450 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
s3g_1        | 2022-04-21 17:00:41,028 [qtp440736059-22] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: a2956c20-9fda-4457-b767-0b8a33d7fc85, Nodes: a9037631-20c7-49ff-8966-d11abf0c09e2{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}8694db2d-5e51-4888-b1e0-69ff67626e43{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}0ef408af-3ea2-4044-bc54-ad0ae15d84f1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:a9037631-20c7-49ff-8966-d11abf0c09e2, CreationTimestamp2022-04-21T16:45:20.398Z[UTC]]
s3g_1        | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #162 timeout 180s
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1        | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:263)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.RatisBlockOutputStream.sendWatchForCommit(RatisBlockOutputStream.java:101)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:392)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:552)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:566)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:137)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:494)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:468)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:521)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:258)
s3g_1        | 	at jdk.internal.reflect.GeneratedMethodAccessor28.invoke(Unknown Source)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
scm1.org_1   | 2022-04-21 16:44:45,792 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:55166
scm1.org_1   | 2022-04-21 16:44:45,896 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-04-21 16:44:46,173 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:49600
scm1.org_1   | 2022-04-21 16:44:46,488 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-04-21 16:44:49,389 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:57282
scm1.org_1   | 2022-04-21 16:44:49,491 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43386
scm1.org_1   | 2022-04-21 16:44:49,542 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-04-21 16:44:49,542 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn 2fbb6e549361, UUID: a9037631-20c7-49ff-8966-d11abf0c09e2
scm1.org_1   | 2022-04-21 16:44:49,633 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-04-21 16:44:49,641 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn 95934f1cb1a3, UUID: 8694db2d-5e51-4888-b1e0-69ff67626e43
scm1.org_1   | 2022-04-21 16:44:49,807 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-04-21 16:44:50,188 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-04-21 16:44:50,728 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:36686
scm1.org_1   | 2022-04-21 16:44:50,939 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-04-21 16:44:50,942 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn 4703807bf00c, UUID: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1
scm1.org_1   | 2022-04-21 16:44:51,374 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-04-21 16:44:54,982 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50118
scm1.org_1   | 2022-04-21 16:44:55,143 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-04-21 16:44:56,960 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:39662
scm1.org_1   | 2022-04-21 16:44:56,984 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-04-21 16:44:57,129 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for om om1, UUID: 1901df08-b056-4653-96b0-d0bf0ce082b7
scm1.org_1   | 2022-04-21 16:44:57,745 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-04-21 16:44:58,849 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:46134
scm1.org_1   | 2022-04-21 16:44:58,884 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-04-21 16:44:58,884 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for om om2, UUID: 3e55b8e6-c3b9-433d-b0f1-3721f102b77d
scm1.org_1   | 2022-04-21 16:44:59,075 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-04-21 16:44:59,903 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:50258
scm1.org_1   | 2022-04-21 16:45:00,005 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-04-21 16:45:00,005 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for om om3, UUID: c60b5c71-8d4b-4ecc-a481-3b1d12ef5c93
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
om1_1        | 2022-04-21 16:53:38,799 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:38,816 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: PartNumber at index 1 is 2, and its previous partNumber at index 0 is 4 for ozonekey is /s3v/bucket-ozone-test-3979773564/ozone-test-2106382736/multipartKey3
om1_1        | 2022-04-21 16:53:38,817 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-2106382736/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-3979773564
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
om1_1        | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-3979773564 key: ozone-test-2106382736/multipartKey3 because parts are in Invalid order.
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getPartsListSize(S3MultipartUploadCompleteRequest.java:465)
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:193)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:514)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:317)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-04-21 16:53:39,428 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:39,431 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:39,434 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1679)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
om1_1        | 2022-04-21 16:53:40,076 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:40,078 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:40,080 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:40,138 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:40,988 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:40,990 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:40,994 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:41,659 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:41,661 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:41,665 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:42,301 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:42,303 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:42,305 [IPC Server handler 69 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:42,313 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadAbortRequest: Abort Multipart request is failed for KeyName ozone-test-6281006145/multipartKey5 in VolumeName/Bucket s3v/bucket-ozone-test-3979773564
om1_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: s3vbucket: bucket-ozone-test-3979773564key: ozone-test-6281006145/multipartKey5
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:161)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:514)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:317)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-04-21 16:53:42,969 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:42,972 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:42,974 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:42,982 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyCreateRequest: Key creation failed. Volume:s3v, Bucket:bucket-ozone-test-3979773564, Key:ozone-test-4122654440/multipartKey. 
om1_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartFileInfo(OMKeyRequest.java:754)
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareFileInfo(OMKeyRequest.java:645)
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:622)
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyCreateRequest.validateAndUpdateCache(OMKeyCreateRequest.java:277)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:514)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:317)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-04-21 16:48:25,288 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47064
recon_1      | 2022-04-21 16:48:25,312 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33440
recon_1      | 2022-04-21 16:48:25,340 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:48:25,354 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:48:25,369 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49222
recon_1      | 2022-04-21 16:48:25,458 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:48:55,219 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33534
recon_1      | 2022-04-21 16:48:55,276 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47158
recon_1      | 2022-04-21 16:48:55,323 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49316
recon_1      | 2022-04-21 16:48:55,327 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:48:55,339 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:48:55,339 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:48:58,127 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-04-21 16:48:58,127 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-04-21 16:48:58,180 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
scm1.org_1   | 2022-04-21 16:45:00,093 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-04-21 16:45:00,481 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43418
scm1.org_1   | 2022-04-21 16:45:00,510 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-04-21 16:45:00,660 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:57318
scm1.org_1   | 2022-04-21 16:45:00,687 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-04-21 16:45:01,200 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:36722
scm1.org_1   | 2022-04-21 16:45:01,272 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-04-21 16:45:15,719 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:57576
scm1.org_1   | 2022-04-21 16:45:15,825 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 16:45:17,128 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33352
scm1.org_1   | 2022-04-21 16:45:17,168 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 16:45:17,229 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:55544
scm1.org_1   | 2022-04-21 16:45:17,289 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 16:45:19,440 [IPC Server handler 56 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/0ef408af-3ea2-4044-bc54-ad0ae15d84f1
scm1.org_1   | 2022-04-21 16:45:19,480 [IPC Server handler 56 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 0ef408af-3ea2-4044-bc54-ad0ae15d84f1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 953699741549, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm1.org_1   | 2022-04-21 16:45:19,532 [IPC Server handler 25 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/8694db2d-5e51-4888-b1e0-69ff67626e43
scm1.org_1   | 2022-04-21 16:45:19,610 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm1.org_1   | 2022-04-21 16:45:19,586 [IPC Server handler 25 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 8694db2d-5e51-4888-b1e0-69ff67626e43{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 952600664327, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm1.org_1   | 2022-04-21 16:45:19,674 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm1.org_1   | 2022-04-21 16:45:19,720 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=39b933e3-a932-4461-b956-63989fd6333f to datanode:8694db2d-5e51-4888-b1e0-69ff67626e43
scm1.org_1   | 2022-04-21 16:45:19,740 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
scm1.org_1   | 2022-04-21 16:45:19,784 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
scm1.org_1   | 2022-04-21 16:45:20,019 [IPC Server handler 95 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/a9037631-20c7-49ff-8966-d11abf0c09e2
scm1.org_1   | 2022-04-21 16:45:20,024 [IPC Server handler 95 on default port 9861] INFO node.SCMNodeManager: Registered Data node : a9037631-20c7-49ff-8966-d11abf0c09e2{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 952295697655, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm1.org_1   | 2022-04-21 16:45:20,032 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm1.org_1   | 2022-04-21 16:45:20,033 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
scm1.org_1   | 2022-04-21 16:45:20,040 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm1.org_1   | 2022-04-21 16:45:20,041 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-04-21 16:53:43,633 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:43,636 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:43,640 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:44,379 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:44,382 [IPC Server handler 92 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:44,384 [IPC Server handler 78 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:44,406 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:47,197 [IPC Server handler 59 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:47,873 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:47,876 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:47,879 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:47,898 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:50,486 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:51,150 [IPC Server handler 63 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:51,156 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
scm1.org_1   | 2022-04-21 16:45:20,042 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm1.org_1   | 2022-04-21 16:45:20,042 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
scm1.org_1   | 2022-04-21 16:45:20,042 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm1.org_1   | 2022-04-21 16:45:20,180 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 39b933e3-a932-4461-b956-63989fd6333f, Nodes: 8694db2d-5e51-4888-b1e0-69ff67626e43{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-04-21T16:45:19.660Z[UTC]].
scm1.org_1   | 2022-04-21 16:45:20,184 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-04-21 16:45:20,398 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=a2956c20-9fda-4457-b767-0b8a33d7fc85 to datanode:a9037631-20c7-49ff-8966-d11abf0c09e2
scm1.org_1   | 2022-04-21 16:45:20,415 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=a2956c20-9fda-4457-b767-0b8a33d7fc85 to datanode:8694db2d-5e51-4888-b1e0-69ff67626e43
scm1.org_1   | 2022-04-21 16:45:20,416 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=a2956c20-9fda-4457-b767-0b8a33d7fc85 to datanode:0ef408af-3ea2-4044-bc54-ad0ae15d84f1
scm1.org_1   | 2022-04-21 16:45:20,562 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: a2956c20-9fda-4457-b767-0b8a33d7fc85, Nodes: a9037631-20c7-49ff-8966-d11abf0c09e2{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}8694db2d-5e51-4888-b1e0-69ff67626e43{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}0ef408af-3ea2-4044-bc54-ad0ae15d84f1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-04-21T16:45:20.398Z[UTC]].
scm1.org_1   | 2022-04-21 16:45:20,581 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-04-21 16:45:20,596 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=72e20438-e2a5-4ad3-9b38-a5405a44eb65 to datanode:a9037631-20c7-49ff-8966-d11abf0c09e2
scm1.org_1   | 2022-04-21 16:45:20,705 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 72e20438-e2a5-4ad3-9b38-a5405a44eb65, Nodes: a9037631-20c7-49ff-8966-d11abf0c09e2{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-04-21T16:45:20.596Z[UTC]].
scm1.org_1   | 2022-04-21 16:45:20,719 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-04-21 16:45:20,722 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=f5f2ffbc-fc63-4015-9163-f38ef2c5977c to datanode:a9037631-20c7-49ff-8966-d11abf0c09e2
scm1.org_1   | 2022-04-21 16:45:20,755 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=f5f2ffbc-fc63-4015-9163-f38ef2c5977c to datanode:8694db2d-5e51-4888-b1e0-69ff67626e43
scm1.org_1   | 2022-04-21 16:45:20,761 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=f5f2ffbc-fc63-4015-9163-f38ef2c5977c to datanode:0ef408af-3ea2-4044-bc54-ad0ae15d84f1
scm1.org_1   | 2022-04-21 16:45:20,885 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: f5f2ffbc-fc63-4015-9163-f38ef2c5977c, Nodes: a9037631-20c7-49ff-8966-d11abf0c09e2{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}8694db2d-5e51-4888-b1e0-69ff67626e43{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}0ef408af-3ea2-4044-bc54-ad0ae15d84f1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-04-21T16:45:20.722Z[UTC]].
scm1.org_1   | 2022-04-21 16:45:20,914 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-04-21 16:45:20,917 [RatisPipelineUtilsThread - 0] INFO pipeline.PipelineManagerImpl: Pipeline: PipelineID=f5f2ffbc-fc63-4015-9163-f38ef2c5977c contains same datanodes as previous pipelines: PipelineID=a2956c20-9fda-4457-b767-0b8a33d7fc85 nodeIds: a9037631-20c7-49ff-8966-d11abf0c09e2, 8694db2d-5e51-4888-b1e0-69ff67626e43, 0ef408af-3ea2-4044-bc54-ad0ae15d84f1
scm1.org_1   | 2022-04-21 16:45:20,942 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=d5d7df1a-3895-4b52-8476-24d42ba70f8f to datanode:0ef408af-3ea2-4044-bc54-ad0ae15d84f1
scm1.org_1   | 2022-04-21 16:45:21,017 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: d5d7df1a-3895-4b52-8476-24d42ba70f8f, Nodes: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-04-21T16:45:20.942Z[UTC]].
scm1.org_1   | 2022-04-21 16:45:21,037 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-04-21 16:45:23,051 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:33827
scm1.org_1   | 2022-04-21 16:45:23,075 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-04-21 16:45:24,949 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:49726
scm1.org_1   | 2022-04-21 16:45:25,010 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-04-21 16:45:26,596 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:55298
scm1.org_1   | 2022-04-21 16:45:26,729 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:48296
scm1.org_1   | 2022-04-21 16:45:26,729 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-04-21 16:45:26,840 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-04-21 16:45:30,378 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50236
scm1.org_1   | 2022-04-21 16:45:30,486 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-04-21 16:45:32,696 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:55598
scm1.org_1   | 2022-04-21 16:45:32,770 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 16:45:32,772 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: a2956c20-9fda-4457-b767-0b8a33d7fc85, Nodes: a9037631-20c7-49ff-8966-d11abf0c09e2{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}8694db2d-5e51-4888-b1e0-69ff67626e43{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}0ef408af-3ea2-4044-bc54-ad0ae15d84f1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:a9037631-20c7-49ff-8966-d11abf0c09e2, CreationTimestamp2022-04-21T16:45:20.398Z[UTC]] moved to OPEN state
scm1.org_1   | 2022-04-21 16:45:32,795 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
scm1.org_1   | 2022-04-21 16:45:32,802 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
scm1.org_1   | 2022-04-21 16:45:32,816 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm1.org_1   | 2022-04-21 16:45:32,816 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm1.org_1   | 2022-04-21 16:45:32,816 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
scm1.org_1   | 2022-04-21 16:45:32,816 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm1.org_1   | 2022-04-21 16:45:32,822 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
scm1.org_1   | 2022-04-21 16:45:32,823 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO container.ReplicationManager: Service ReplicationManager transitions to RUNNING.
scm1.org_1   | 2022-04-21 16:45:33,539 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 72e20438-e2a5-4ad3-9b38-a5405a44eb65, Nodes: a9037631-20c7-49ff-8966-d11abf0c09e2{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:a9037631-20c7-49ff-8966-d11abf0c09e2, CreationTimestamp2022-04-21T16:45:20.596Z[UTC]] moved to OPEN state
scm1.org_1   | 2022-04-21 16:45:33,608 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:36855
scm1.org_1   | 2022-04-21 16:45:33,631 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-04-21 16:45:34,044 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:39796
scm1.org_1   | 2022-04-21 16:45:34,053 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-04-21 16:45:36,305 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:46280
scm1.org_1   | 2022-04-21 16:45:36,325 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-04-21 16:45:36,701 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:50400
scm1.org_1   | 2022-04-21 16:45:36,718 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-04-21 16:45:50,146 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50306
scm1.org_1   | 2022-04-21 16:45:50,230 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-04-21 16:45:51,768 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33470
scm1.org_1   | 2022-04-21 16:45:51,843 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 16:45:51,845 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 39b933e3-a932-4461-b956-63989fd6333f, Nodes: 8694db2d-5e51-4888-b1e0-69ff67626e43{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:8694db2d-5e51-4888-b1e0-69ff67626e43, CreationTimestamp2022-04-21T16:45:19.660Z[UTC]] moved to OPEN state
scm1.org_1   | 2022-04-21 16:45:51,996 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:55662
scm1.org_1   | 2022-04-21 16:45:52,049 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:42729
scm1.org_1   | 2022-04-21 16:45:52,073 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-04-21 16:45:52,085 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 16:45:52,104 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: d5d7df1a-3895-4b52-8476-24d42ba70f8f, Nodes: 0ef408af-3ea2-4044-bc54-ad0ae15d84f1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:0ef408af-3ea2-4044-bc54-ad0ae15d84f1, CreationTimestamp2022-04-21T16:45:20.942Z[UTC]] moved to OPEN state
scm1.org_1   | 2022-04-21 16:45:59,877 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: f5f2ffbc-fc63-4015-9163-f38ef2c5977c, Nodes: a9037631-20c7-49ff-8966-d11abf0c09e2{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}8694db2d-5e51-4888-b1e0-69ff67626e43{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}0ef408af-3ea2-4044-bc54-ad0ae15d84f1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:0ef408af-3ea2-4044-bc54-ad0ae15d84f1, CreationTimestamp2022-04-21T16:45:20.722Z[UTC]] moved to OPEN state
scm1.org_1   | 2022-04-21 16:46:08,912 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:57754
scm1.org_1   | 2022-04-21 16:46:08,944 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 16:46:13,405 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:49890
scm1.org_1   | 2022-04-21 16:46:13,434 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
om1_1        | 2022-04-21 16:53:51,164 [IPC Server handler 52 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:51,859 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:51,863 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:51,865 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:52,556 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:52,558 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:52,564 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:53,213 [IPC Server handler 65 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:53,217 [IPC Server handler 88 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:53,220 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:54,039 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:54,041 [IPC Server handler 43 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:54,044 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:54,119 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:54,122 [IPC Server handler 61 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1        | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #162 timeout 180s
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:368)
s3g_1        | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:373)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:368)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:357)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1        | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1        | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1        | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1        | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1        | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1        | 	... 1 more
s3g_1        | 2022-04-21 17:00:41,034 [qtp440736059-22] INFO scm.XceiverClientRatis: Could not commit index 148 on pipeline Pipeline[ Id: a2956c20-9fda-4457-b767-0b8a33d7fc85, Nodes: a9037631-20c7-49ff-8966-d11abf0c09e2{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}8694db2d-5e51-4888-b1e0-69ff67626e43{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}0ef408af-3ea2-4044-bc54-ad0ae15d84f1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:a9037631-20c7-49ff-8966-d11abf0c09e2, CreationTimestamp2022-04-21T16:45:20.398Z[UTC]] to all the nodes. Server 0ef408af-3ea2-4044-bc54-ad0ae15d84f1 has failed. Committed by majority.
s3g_1        | 2022-04-21 17:00:41,035 [qtp440736059-22] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 2 locID: 109611004723200047 bcsId: 148 on Pipeline[ Id: a2956c20-9fda-4457-b767-0b8a33d7fc85, Nodes: a9037631-20c7-49ff-8966-d11abf0c09e2{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}8694db2d-5e51-4888-b1e0-69ff67626e43{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}0ef408af-3ea2-4044-bc54-ad0ae15d84f1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:a9037631-20c7-49ff-8966-d11abf0c09e2, CreationTimestamp2022-04-21T16:45:20.398Z[UTC]]. Failed nodes: [0ef408af-3ea2-4044-bc54-ad0ae15d84f1{ip: null, host: null, ports: [], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1        | 2022-04-21 17:01:05,442 [qtp440736059-23] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-4385489974, with testuser as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-04-21 17:01:05,459 [qtp440736059-23] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-4385489974
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-04-21 16:49:00,195 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 47 milliseconds to process 0 existing database records.
recon_1      | 2022-04-21 16:49:00,225 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 30 milliseconds for processing 2 containers.
recon_1      | 2022-04-21 16:49:00,378 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 5 pipelines in house.
recon_1      | 2022-04-21 16:49:00,394 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 51 milliseconds.
recon_1      | 2022-04-21 16:49:25,262 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33642
recon_1      | 2022-04-21 16:49:25,328 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:49:25,351 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47266
recon_1      | 2022-04-21 16:49:25,351 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49426
recon_1      | 2022-04-21 16:49:25,388 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:49:25,399 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:49:55,302 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33742
recon_1      | 2022-04-21 16:49:55,363 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:49:55,411 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49522
om1_1        | 2022-04-21 16:53:54,127 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:54,150 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:54,232 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:54,242 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:54,247 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:54,265 [IPC Server handler 69 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:54,267 [IPC Server handler 80 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:54,274 [IPC Server handler 77 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:54,339 [IPC Server handler 68 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:54,368 [IPC Server handler 91 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:55,368 [IPC Server handler 94 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:58,441 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:42285
om1_1        | 2022-04-21 16:53:58,449 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 16:53:58,573 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:58,622 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:58,668 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:58,673 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:58,676 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:59,302 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:59,305 [IPC Server handler 72 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:59,307 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:59,343 [IPC Server handler 79 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:59,344 [IPC Server handler 71 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:59,347 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:59,347 [IPC Server handler 67 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:59,347 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:59,350 [IPC Server handler 89 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:59,353 [IPC Server handler 76 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:59,354 [IPC Server handler 99 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:59,354 [IPC Server handler 84 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:59,427 [IPC Server handler 91 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:59,430 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:53:59,436 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:54:00,770 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
recon_1      | 2022-04-21 16:49:55,417 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47366
recon_1      | 2022-04-21 16:49:55,430 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:49:55,460 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:49:58,182 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-04-21 16:49:58,183 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-04-21 16:49:58,222 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
om1_1        | 2022-04-21 16:54:00,772 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:54:00,775 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:54:00,789 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:54:01,656 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:54:01,658 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:54:01,676 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:54:02,066 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:54:02,760 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:54:02,764 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:54:02,766 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:54:03,452 [IPC Server handler 94 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:54:03,454 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:54:03,457 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:54:03,482 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:54:03,485 [IPC Server handler 91 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:54:03,487 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:54:03,504 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:54:03,507 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:54:03,510 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:54:03,570 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:54:06,450 [IPC Server handler 94 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:54:07,122 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:54:07,124 [IPC Server handler 61 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm1.org_1   | 2022-04-21 16:46:13,548 [IPC Server handler 52 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for containerId, change lastId from 0 to 1000.
scm1.org_1   | 2022-04-21 16:46:13,709 [e8ea6b57-c3ba-42bd-9807-0913ca4228d7@group-824FABCC98DC-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 109611004723200000.
om1_1        | 2022-04-21 16:54:07,129 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:54:07,796 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:54:07,799 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm1.org_1   | 2022-04-21 16:46:13,761 [IPC Server handler 52 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for localId, change lastId from 109611004723200000 to 109611004723201000.
scm1.org_1   | 2022-04-21 16:46:16,407 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:36966
scm1.org_1   | 2022-04-21 16:46:16,426 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-04-21 16:46:16,676 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43670
scm1.org_1   | 2022-04-21 16:46:16,687 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-04-21 16:46:16,749 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:57570
scm1.org_1   | 2022-04-21 16:46:16,763 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-04-21 16:46:16,894 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:55746
om1_1        | 2022-04-21 16:54:07,801 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm1.org_1   | 2022-04-21 16:46:17,059 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 16:46:17,164 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:35293
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
scm1.org_1   | 2022-04-21 16:46:17,181 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
om1_1        | 2022-04-21 16:54:07,810 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:54:08,778 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:54:08,781 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
om1_1        | 2022-04-21 16:54:08,787 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:54:09,416 [IPC Server handler 78 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
scm1.org_1   | 2022-04-21 16:46:17,322 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33570
scm1.org_1   | 2022-04-21 16:46:17,411 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 16:46:23,784 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:49932
scm1.org_1   | 2022-04-21 16:46:23,792 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-04-21 16:46:33,983 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:49960
om1_1        | 2022-04-21 16:54:10,052 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm1.org_1   | 2022-04-21 16:46:33,987 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-04-21 16:46:42,988 [IPC Server handler 14 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for delTxnId, change lastId from 0 to 1000.
scm1.org_1   | 2022-04-21 16:46:46,855 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:55832
scm1.org_1   | 2022-04-21 16:46:46,946 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 16:46:47,262 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33658
scm1.org_1   | 2022-04-21 16:46:47,295 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2022-04-21 16:54:10,057 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:54:10,061 [IPC Server handler 46 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
om1_1        | 2022-04-21 16:54:10,763 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
scm1.org_1   | 2022-04-21 16:46:47,459 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:57892
om1_1        | 2022-04-21 16:54:10,766 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm1.org_1   | 2022-04-21 16:46:47,486 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 16:46:56,688 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:42510
om1_1        | 2022-04-21 16:54:10,769 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:54:10,790 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:54:10,792 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:54:10,793 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm1.org_1   | 2022-04-21 16:46:56,699 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
om1_1        | 2022-04-21 16:54:10,801 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
recon_1      | 	... 12 more
scm1.org_1   | 2022-04-21 16:47:16,912 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:55934
scm1.org_1   | 2022-04-21 16:47:16,928 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2022-04-21 16:54:10,802 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
om1_1        | 2022-04-21 16:54:10,803 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm1.org_1   | 2022-04-21 16:47:17,233 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33758
scm1.org_1   | 2022-04-21 16:47:17,304 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 16:47:17,469 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:57990
om1_1        | 2022-04-21 16:54:10,861 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:54:14,023 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm1.org_1   | 2022-04-21 16:47:17,526 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	... 19 more
om1_1        | 2022-04-21 16:54:14,703 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:54:14,705 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:54:14,707 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
scm1.org_1   | 2022-04-21 16:47:23,121 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:50128
scm1.org_1   | 2022-04-21 16:47:23,128 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm1.org_1   | 2022-04-21 16:47:25,212 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:41603
om1_1        | 2022-04-21 16:54:14,728 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:54:14,735 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:54:14,741 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:54:14,750 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm1.org_1   | 2022-04-21 16:47:25,220 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-04-21 16:47:55,270 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33870
scm1.org_1   | 2022-04-21 16:47:55,400 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
scm1.org_1   | 2022-04-21 16:47:55,423 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58106
scm1.org_1   | 2022-04-21 16:47:55,466 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56062
om1_1        | 2022-04-21 16:54:14,752 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:54:14,753 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm1.org_1   | 2022-04-21 16:47:55,478 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 16:47:55,491 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 16:48:22,504 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:50310
om1_1        | 2022-04-21 16:54:14,782 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
scm1.org_1   | 2022-04-21 16:48:22,507 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om1_1        | 2022-04-21 16:54:14,877 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:54:15,564 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
om1_1        | 2022-04-21 16:54:15,566 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
om1_1        | 2022-04-21 16:54:15,570 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:54:16,204 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm1.org_1   | 2022-04-21 16:48:25,224 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33978
scm1.org_1   | 2022-04-21 16:48:25,271 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2022-04-21 16:54:16,206 [IPC Server handler 59 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:54:16,208 [IPC Server handler 65 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm1.org_1   | 2022-04-21 16:48:25,290 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58216
scm1.org_1   | 2022-04-21 16:48:25,333 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56184
scm1.org_1   | 2022-04-21 16:48:25,378 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 16:48:25,464 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 16:48:29,273 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:42822
scm1.org_1   | 2022-04-21 16:48:29,280 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-04-21 16:48:32,108 [ReplicationMonitor] INFO container.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm1.org_1   | 2022-04-21 16:48:35,457 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:50366
scm1.org_1   | 2022-04-21 16:48:35,469 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-04-21 16:48:44,181 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:42862
scm1.org_1   | 2022-04-21 16:48:44,184 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-04-21 16:48:55,224 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34076
scm1.org_1   | 2022-04-21 16:48:55,257 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58318
scm1.org_1   | 2022-04-21 16:48:55,342 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 16:48:55,386 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
om1_1        | 2022-04-21 16:54:16,220 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:54:17,311 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:54:17,315 [IPC Server handler 77 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:54:17,319 [IPC Server handler 93 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:54:58,481 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:45445
om1_1        | 2022-04-21 16:54:58,483 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 16:55:18,211 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:36293
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
om1_1        | 2022-04-21 16:55:18,214 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 16:55:18,215 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:55:18,220 [IPC Server handler 65 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:55:18,234 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:55:58,529 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:40427
om1_1        | 2022-04-21 16:55:58,534 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 16:56:19,247 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:36077
om1_1        | 2022-04-21 16:56:19,249 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 16:56:19,250 [IPC Server handler 69 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
om1_1        | 2022-04-21 16:56:19,253 [IPC Server handler 80 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:56:19,266 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:56:19,986 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:56:20,745 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:56:20,747 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
om1_1        | 2022-04-21 16:56:20,750 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:56:21,553 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm1.org_1   | 2022-04-21 16:48:55,391 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56282
scm1.org_1   | 2022-04-21 16:48:55,450 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2022-04-21 16:56:21,555 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm1.org_1   | 2022-04-21 16:49:00,365 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:42977
scm1.org_1   | 2022-04-21 16:49:00,372 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
om1_1        | 2022-04-21 16:56:21,558 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:56:22,616 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:56:22,621 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:56:22,625 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:56:22,645 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:56:22,648 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:56:22,653 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
om1_1        | 2022-04-21 16:56:22,697 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:56:23,404 [IPC Server handler 84 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:56:23,406 [IPC Server handler 76 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm1.org_1   | 2022-04-21 16:49:25,219 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34190
recon_1      | 2022-04-21 16:50:25,212 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33848
recon_1      | 2022-04-21 16:50:25,228 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om1_1        | 2022-04-21 16:56:23,410 [IPC Server handler 95 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
recon_1      | 2022-04-21 16:50:25,320 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49626
recon_1      | 2022-04-21 16:50:25,334 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47470
scm1.org_1   | 2022-04-21 16:49:25,304 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 16:49:25,415 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56384
scm1.org_1   | 2022-04-21 16:49:25,428 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58422
scm1.org_1   | 2022-04-21 16:49:25,444 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 16:49:25,455 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2022-04-21 16:56:23,428 [IPC Server handler 92 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm1.org_1   | 2022-04-21 16:49:42,986 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:50594
scm1.org_1   | 2022-04-21 16:49:42,990 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-04-21 16:49:55,221 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34280
recon_1      | 2022-04-21 16:50:25,346 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:50:25,379 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om1_1        | 2022-04-21 16:56:23,434 [IPC Server handler 98 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm1.org_1   | 2022-04-21 16:49:55,256 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 2022-04-21 16:50:55,212 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33942
recon_1      | 2022-04-21 16:50:55,220 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:50:55,427 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49726
om1_1        | 2022-04-21 16:56:23,449 [IPC Server handler 99 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
recon_1      | 2022-04-21 16:50:55,444 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47564
recon_1      | 2022-04-21 16:50:55,453 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om1_1        | 2022-04-21 16:56:23,465 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
recon_1      | 2022-04-21 16:50:55,471 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:50:58,223 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
scm1.org_1   | 2022-04-21 16:49:55,322 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56480
om1_1        | 2022-04-21 16:56:24,265 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm1.org_1   | 2022-04-21 16:49:55,348 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 2022-04-21 16:50:58,224 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
scm1.org_1   | 2022-04-21 16:49:55,406 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58518
scm1.org_1   | 2022-04-21 16:49:55,425 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2022-04-21 16:56:24,267 [IPC Server handler 72 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:56:24,272 [IPC Server handler 77 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm1.org_1   | 2022-04-21 16:50:25,280 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34388
recon_1      | 2022-04-21 16:50:58,296 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
om1_1        | 2022-04-21 16:56:24,289 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:56:24,293 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm1.org_1   | 2022-04-21 16:50:25,284 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2022-04-21 16:56:24,297 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:56:24,309 [IPC Server handler 74 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
scm1.org_1   | 2022-04-21 16:50:25,369 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56588
om1_1        | 2022-04-21 16:56:24,311 [IPC Server handler 70 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:56:24,316 [IPC Server handler 66 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
om1_1        | 2022-04-21 16:56:24,388 [IPC Server handler 73 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:56:24,979 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm1.org_1   | 2022-04-21 16:50:25,373 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58626
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 2022-04-21 16:56:25,965 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:56:25,967 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:56:25,972 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm1.org_1   | 2022-04-21 16:50:25,384 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 16:50:25,389 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2022-04-21 16:56:25,995 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:56:25,997 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm1.org_1   | 2022-04-21 16:50:30,905 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:50762
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
om1_1        | 2022-04-21 16:56:26,000 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm1.org_1   | 2022-04-21 16:50:30,907 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om1_1        | 2022-04-21 16:56:26,009 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:56:26,010 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:56:26,012 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:56:26,056 [IPC Server handler 43 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
om1_1        | 2022-04-21 16:56:58,572 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:44999
om1_1        | 2022-04-21 16:56:58,579 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 16:57:18,322 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:43947
om1_1        | 2022-04-21 16:57:18,335 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2022-04-21 16:50:37,075 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:43258
om1_1        | 2022-04-21 16:57:18,339 [IPC Server handler 66 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
scm1.org_1   | 2022-04-21 16:50:37,088 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
om1_1        | 2022-04-21 16:57:26,805 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm1.org_1   | 2022-04-21 16:50:55,253 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34482
scm1.org_1   | 2022-04-21 16:50:55,291 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2022-04-21 16:57:26,809 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:57:26,828 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:57:26,849 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:57:26,853 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm1.org_1   | 2022-04-21 16:50:55,430 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56682
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
scm1.org_1   | 2022-04-21 16:50:55,457 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58720
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
om1_1        | 2022-04-21 16:57:26,860 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:57:26,890 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:57:27,611 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:57:27,613 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:57:27,616 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm1.org_1   | 2022-04-21 16:50:55,488 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2022-04-21 16:57:28,360 [IPC Server handler 81 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:57:28,363 [IPC Server handler 64 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:57:28,365 [IPC Server handler 71 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:57:29,156 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:57:29,158 [IPC Server handler 52 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm1.org_1   | 2022-04-21 16:50:55,510 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
scm1.org_1   | 2022-04-21 16:51:25,308 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58980
scm1.org_1   | 2022-04-21 16:51:25,357 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56948
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
scm1.org_1   | 2022-04-21 16:51:25,375 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34738
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
scm1.org_1   | 2022-04-21 16:51:25,376 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 16:51:25,411 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2022-04-21 16:57:29,166 [IPC Server handler 56 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:57:35,478 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41602
scm1.org_1   | 2022-04-21 16:51:25,437 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2022-04-21 16:57:35,507 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 16:57:39,372 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:42611
om1_1        | 2022-04-21 16:57:39,377 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
scm1.org_1   | 2022-04-21 16:51:34,497 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:51128
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
scm1.org_1   | 2022-04-21 16:51:34,504 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-04-21 16:51:49,939 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:51178
om1_1        | 2022-04-21 16:57:39,378 [IPC Server handler 79 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:57:39,384 [IPC Server handler 66 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:57:39,391 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-5032629137 of layout LEGACY in volume: s3v
scm1.org_1   | 2022-04-21 16:51:49,946 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
scm1.org_1   | 2022-04-21 16:51:55,334 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34840
scm1.org_1   | 2022-04-21 16:51:55,383 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59084
scm1.org_1   | 2022-04-21 16:51:55,403 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 16:51:55,406 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:57052
scm1.org_1   | 2022-04-21 16:51:55,484 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 16:51:55,547 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 16:52:06,485 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:43702
om1_1        | 2022-04-21 16:57:40,136 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:57:40,143 [IPC Server handler 61 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm1.org_1   | 2022-04-21 16:52:06,489 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-04-21 16:52:25,237 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34946
om1_1        | 2022-04-21 16:57:40,149 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: destbucket-85240 of layout LEGACY in volume: s3v
om1_1        | 2022-04-21 16:57:40,895 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:57:40,897 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:57:40,899 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm1.org_1   | 2022-04-21 16:52:25,273 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2022-04-21 16:57:58,618 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:38627
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
scm1.org_1   | 2022-04-21 16:52:25,343 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59184
om1_1        | 2022-04-21 16:57:58,624 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 16:58:19,305 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:42143
om1_1        | 2022-04-21 16:58:19,315 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2022-04-21 16:52:25,356 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2022-04-21 16:58:19,316 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
scm1.org_1   | 2022-04-21 16:52:25,378 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:57146
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
scm1.org_1   | 2022-04-21 16:52:25,411 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2022-04-21 16:58:41,494 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:44063
om1_1        | 2022-04-21 16:58:41,496 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 16:58:41,497 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm1.org_1   | 2022-04-21 16:52:42,936 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:51360
om1_1        | 2022-04-21 16:58:41,501 [IPC Server handler 91 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
scm1.org_1   | 2022-04-21 16:52:42,946 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-04-21 16:52:55,261 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35048
recon_1      | 2022-04-21 16:51:25,303 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49982
om1_1        | 2022-04-21 16:58:41,516 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:58:41,678 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:58:42,453 [IPC Server handler 78 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
recon_1      | 2022-04-21 16:51:25,311 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47824
recon_1      | 2022-04-21 16:51:25,318 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om1_1        | 2022-04-21 16:58:42,455 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:58:42,457 [IPC Server handler 99 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:58:42,463 [IPC Server handler 94 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:58:43,194 [IPC Server handler 56 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:58:43,198 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:58:43,200 [IPC Server handler 63 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm1.org_1   | 2022-04-21 16:52:55,301 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 16:52:55,333 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59286
scm1.org_1   | 2022-04-21 16:52:55,366 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 16:52:55,471 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:57248
scm1.org_1   | 2022-04-21 16:52:55,542 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 16:53:01,009 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:51434
scm1.org_1   | 2022-04-21 16:53:01,013 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-04-21 16:53:03,628 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:43924
recon_1      | 2022-04-21 16:51:25,355 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34196
recon_1      | 2022-04-21 16:51:25,360 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:51:25,439 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:51:55,283 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34298
recon_1      | 2022-04-21 16:51:55,376 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47922
recon_1      | 2022-04-21 16:51:55,386 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50080
recon_1      | 2022-04-21 16:51:55,391 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:51:55,527 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:51:55,548 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:51:58,305 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-04-21 16:51:58,305 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
om1_1        | 2022-04-21 16:58:43,201 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:58:43,205 [IPC Server handler 59 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:58:43,230 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:58:43,243 [IPC Server handler 88 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:58:43,396 [IPC Server handler 67 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:58:43,426 [IPC Server handler 76 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:58:44,271 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm1.org_1   | 2022-04-21 16:53:03,637 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-04-21 16:53:21,250 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:43986
scm1.org_1   | 2022-04-21 16:53:21,256 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-04-21 16:53:25,223 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35180
scm1.org_1   | 2022-04-21 16:53:25,283 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 16:53:25,299 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59418
scm1.org_1   | 2022-04-21 16:53:25,316 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:57380
recon_1      | 2022-04-21 16:51:58,377 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
om1_1        | 2022-04-21 16:58:44,276 [IPC Server handler 72 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:58:44,278 [IPC Server handler 88 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:58:44,281 [IPC Server handler 77 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:58:45,089 [IPC Server handler 46 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:58:45,091 [IPC Server handler 42 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm1.org_1   | 2022-04-21 16:53:25,330 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 16:53:25,374 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
scm1.org_1   | 2022-04-21 16:53:32,112 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 3 milliseconds for processing 2 containers.
scm1.org_1   | 2022-04-21 16:53:40,125 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:44072
scm1.org_1   | 2022-04-21 16:53:40,127 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-04-21 16:53:55,269 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35314
scm1.org_1   | 2022-04-21 16:53:55,311 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:57504
scm1.org_1   | 2022-04-21 16:53:55,354 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2022-04-21 16:58:45,094 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:58:45,096 [IPC Server handler 61 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:58:45,097 [IPC Server handler 52 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
om1_1        | 2022-04-21 16:58:45,107 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:58:45,118 [IPC Server handler 56 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm1.org_1   | 2022-04-21 16:53:55,358 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 16:53:55,400 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59562
scm1.org_1   | 2022-04-21 16:53:55,542 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 16:53:59,376 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:44168
scm1.org_1   | 2022-04-21 16:53:59,398 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-04-21 16:54:00,419 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:37849
scm1.org_1   | 2022-04-21 16:54:00,433 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
om1_1        | 2022-04-21 16:58:58,660 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:33469
om1_1        | 2022-04-21 16:58:58,663 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 16:59:26,317 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:40059
om1_1        | 2022-04-21 16:59:26,325 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 16:59:26,326 [IPC Server handler 74 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:59:45,287 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:44411
om1_1        | 2022-04-21 16:59:45,292 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 16:59:45,293 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:59:45,296 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm1.org_1   | 2022-04-21 16:54:25,241 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35438
scm1.org_1   | 2022-04-21 16:54:25,285 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
scm1.org_1   | 2022-04-21 16:54:25,299 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59680
scm1.org_1   | 2022-04-21 16:54:25,353 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:57638
scm1.org_1   | 2022-04-21 16:54:25,367 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 16:54:25,412 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 16:54:42,948 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:51830
om1_1        | 2022-04-21 16:59:45,298 [IPC Server handler 70 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:59:45,299 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:59:45,301 [IPC Server handler 74 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:59:45,329 [IPC Server handler 81 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:59:45,356 [IPC Server handler 64 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:59:45,554 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:59:45,572 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:59:46,422 [IPC Server handler 84 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:59:46,424 [IPC Server handler 67 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:59:46,425 [IPC Server handler 73 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:59:46,427 [IPC Server handler 76 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:59:47,167 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:59:47,169 [IPC Server handler 63 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:59:47,907 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:59:47,909 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:59:47,911 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:59:47,912 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:59:48,712 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:59:48,716 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:59:49,402 [IPC Server handler 66 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:59:49,405 [IPC Server handler 84 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:59:49,407 [IPC Server handler 67 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:59:49,408 [IPC Server handler 73 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:59:49,410 [IPC Server handler 76 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 16:59:55,930 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41994
om1_1        | 2022-04-21 16:59:55,969 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 16:59:58,691 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:41885
om1_1        | 2022-04-21 16:59:58,694 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 17:00:00,649 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:43181
om1_1        | 2022-04-21 17:00:00,656 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 17:00:00,657 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:00,662 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:00,687 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-5639337117 of layout LEGACY in volume: s3v
om1_1        | 2022-04-21 17:00:01,409 [IPC Server handler 67 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:01,411 [IPC Server handler 76 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
scm1.org_1   | 2022-04-21 16:54:42,959 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-04-21 16:54:55,276 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35506
scm1.org_1   | 2022-04-21 16:54:55,301 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59742
scm1.org_1   | 2022-04-21 16:54:55,343 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:57704
scm1.org_1   | 2022-04-21 16:54:55,345 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 16:54:55,396 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 16:54:55,398 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 16:55:18,258 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:51918
scm1.org_1   | 2022-04-21 16:55:18,262 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
scm1.org_1   | 2022-04-21 16:55:25,214 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35588
scm1.org_1   | 2022-04-21 16:55:25,233 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 16:55:25,326 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59826
scm1.org_1   | 2022-04-21 16:55:25,340 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:57788
scm1.org_1   | 2022-04-21 16:55:25,377 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 16:55:25,393 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 16:55:55,255 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35656
scm1.org_1   | 2022-04-21 16:55:55,310 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:57856
scm1.org_1   | 2022-04-21 16:55:55,311 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59890
scm1.org_1   | 2022-04-21 16:55:55,316 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 16:55:55,340 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 16:55:55,347 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 16:56:19,285 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:52066
scm1.org_1   | 2022-04-21 16:56:19,291 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-04-21 16:56:22,665 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:44558
scm1.org_1   | 2022-04-21 16:56:22,674 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-04-21 16:56:25,264 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35750
scm1.org_1   | 2022-04-21 16:56:25,292 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59988
scm1.org_1   | 2022-04-21 16:56:25,295 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2022-04-21 17:00:01,413 [IPC Server handler 95 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
om1_1        | 2022-04-21 17:00:01,562 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:02,370 [IPC Server handler 86 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:02,372 [IPC Server handler 93 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:02,374 [IPC Server handler 62 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:02,377 [IPC Server handler 87 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:03,094 [IPC Server handler 46 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm1.org_1   | 2022-04-21 16:56:25,335 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:57950
scm1.org_1   | 2022-04-21 16:56:25,336 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 16:56:25,364 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
scm1.org_1   | 2022-04-21 16:56:42,953 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:52146
scm1.org_1   | 2022-04-21 16:56:42,959 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-04-21 16:56:55,302 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35820
scm1.org_1   | 2022-04-21 16:56:55,324 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 16:56:55,386 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:60064
scm1.org_1   | 2022-04-21 16:56:55,388 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:58024
scm1.org_1   | 2022-04-21 16:56:55,402 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 16:56:55,429 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 16:57:25,221 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35904
scm1.org_1   | 2022-04-21 16:57:25,252 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	... 35 more
recon_1      | 2022-04-21 16:52:25,216 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34406
om1_1        | 2022-04-21 17:00:03,096 [IPC Server handler 42 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:03,099 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:03,118 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:03,981 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:03,984 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:03,986 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:04,710 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:04,716 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:04,718 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:05,440 [IPC Server handler 92 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:05,443 [IPC Server handler 97 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:05,445 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:06,107 [IPC Server handler 61 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
recon_1      | 2022-04-21 16:52:25,245 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:52:25,309 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48032
recon_1      | 2022-04-21 16:52:25,332 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:52:25,341 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50190
recon_1      | 2022-04-21 16:52:25,380 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:52:55,214 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34510
recon_1      | 2022-04-21 16:52:55,236 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm1.org_1   | 2022-04-21 16:57:25,316 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:60148
scm1.org_1   | 2022-04-21 16:57:25,321 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:58090
scm1.org_1   | 2022-04-21 16:57:25,334 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 16:57:25,338 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 16:57:26,882 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:44748
scm1.org_1   | 2022-04-21 16:57:26,884 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
recon_1      | 2022-04-21 16:52:55,340 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48134
recon_1      | 2022-04-21 16:52:55,381 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:52:55,445 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50294
recon_1      | 2022-04-21 16:52:55,562 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:52:58,378 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
om1_1        | 2022-04-21 17:00:06,109 [IPC Server handler 52 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:06,114 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm1.org_1   | 2022-04-21 16:57:40,919 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:52314
scm1.org_1   | 2022-04-21 16:57:40,921 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
recon_1      | 2022-04-21 16:52:58,378 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-04-21 16:52:58,422 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
om1_1        | 2022-04-21 17:00:06,909 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:06,911 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
scm1.org_1   | 2022-04-21 16:57:55,224 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35996
scm1.org_1   | 2022-04-21 16:57:55,240 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 16:57:55,340 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:60228
scm1.org_1   | 2022-04-21 16:57:55,348 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:58192
scm1.org_1   | 2022-04-21 16:57:55,363 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2022-04-21 17:00:06,916 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:07,029 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:07,757 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:07,760 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:07,761 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:07,765 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:08,554 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm1.org_1   | 2022-04-21 16:57:55,388 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 16:58:25,253 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36068
scm1.org_1   | 2022-04-21 16:58:25,283 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 16:58:25,330 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:58272
scm1.org_1   | 2022-04-21 16:58:25,349 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:60306
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
om1_1        | 2022-04-21 17:00:08,556 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:08,558 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:09,314 [IPC Server handler 74 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:09,319 [IPC Server handler 81 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:09,321 [IPC Server handler 86 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:09,323 [IPC Server handler 93 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm1.org_1   | 2022-04-21 16:58:25,358 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 16:58:25,374 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 16:58:32,112 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 2 containers.
scm1.org_1   | 2022-04-21 16:58:41,540 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:52462
scm1.org_1   | 2022-04-21 16:58:41,543 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-04-21 16:58:43,214 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:44942
scm1.org_1   | 2022-04-21 16:58:43,224 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 2022-04-21 17:00:10,113 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
scm1.org_1   | 2022-04-21 16:58:55,231 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36152
scm1.org_1   | 2022-04-21 16:58:55,323 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 16:58:55,361 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:60390
scm1.org_1   | 2022-04-21 16:58:55,399 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 16:58:55,405 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:58354
scm1.org_1   | 2022-04-21 16:58:55,416 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 16:59:00,455 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:43195
scm1.org_1   | 2022-04-21 16:59:00,460 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-04-21 16:59:25,234 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36232
scm1.org_1   | 2022-04-21 16:59:25,281 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2022-04-21 17:00:10,115 [IPC Server handler 56 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:10,117 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:10,127 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:10,922 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:10,924 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:10,926 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
om1_1        | 2022-04-21 17:00:11,073 [IPC Server handler 43 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:11,807 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:11,810 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:11,817 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:11,821 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:12,492 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:12,494 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:12,496 [IPC Server handler 91 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
scm1.org_1   | 2022-04-21 16:59:25,333 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:60470
scm1.org_1   | 2022-04-21 16:59:25,349 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
scm1.org_1   | 2022-04-21 16:59:25,356 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:58434
scm1.org_1   | 2022-04-21 16:59:25,377 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 16:59:42,954 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:52624
om1_1        | 2022-04-21 17:00:13,236 [IPC Server handler 59 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:13,239 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:13,241 [IPC Server handler 65 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:13,243 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:13,889 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm1.org_1   | 2022-04-21 16:59:42,956 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-04-21 16:59:45,313 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:45108
scm1.org_1   | 2022-04-21 16:59:45,323 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-04-21 16:59:55,372 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:60560
scm1.org_1   | 2022-04-21 16:59:55,376 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 16:59:55,384 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:58526
scm1.org_1   | 2022-04-21 16:59:55,388 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36322
scm1.org_1   | 2022-04-21 16:59:55,420 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
om1_1        | 2022-04-21 17:00:13,891 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:13,893 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:13,901 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:14,520 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
scm1.org_1   | 2022-04-21 16:59:55,478 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 17:00:01,430 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:52706
om1_1        | 2022-04-21 17:00:14,524 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:20,769 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42088
om1_1        | 2022-04-21 17:00:20,806 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 17:00:26,390 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:39513
om1_1        | 2022-04-21 17:00:26,400 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 17:00:26,401 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:26,416 [IPC Server handler 92 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:26,424 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-1676201683 of layout LEGACY in volume: s3v
om1_1        | 2022-04-21 17:00:27,256 [IPC Server handler 80 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:27,260 [IPC Server handler 69 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
scm1.org_1   | 2022-04-21 17:00:01,432 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-04-21 17:00:03,108 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:45194
scm1.org_1   | 2022-04-21 17:00:03,112 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-04-21 17:00:25,360 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36452
scm1.org_1   | 2022-04-21 17:00:25,370 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 17:00:25,418 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:60690
scm1.org_1   | 2022-04-21 17:00:25,466 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:58650
scm1.org_1   | 2022-04-21 17:00:25,472 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 17:00:25,566 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 17:00:27,274 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:52832
scm1.org_1   | 2022-04-21 17:00:27,282 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-04-21 17:00:40,596 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:52870
scm1.org_1   | 2022-04-21 17:00:40,610 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-04-21 17:00:43,825 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:45354
scm1.org_1   | 2022-04-21 17:00:43,830 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-04-21 17:00:55,237 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36586
scm1.org_1   | 2022-04-21 17:00:55,267 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 17:00:55,338 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:60828
scm1.org_1   | 2022-04-21 17:00:55,358 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 17:00:55,381 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:58786
scm1.org_1   | 2022-04-21 17:00:55,394 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 17:01:25,286 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36676
scm1.org_1   | 2022-04-21 17:01:25,336 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 17:01:25,351 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:58880
scm1.org_1   | 2022-04-21 17:01:25,382 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:60920
scm1.org_1   | 2022-04-21 17:01:25,406 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-04-21 17:01:25,421 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
om1_1        | 2022-04-21 17:00:27,263 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:27,425 [IPC Server handler 92 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:28,204 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:28,211 [IPC Server handler 59 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:28,213 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:28,318 [IPC Server handler 81 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:29,278 [IPC Server handler 72 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:29,281 [IPC Server handler 88 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:29,284 [IPC Server handler 77 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:29,402 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:30,172 [IPC Server handler 63 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:30,174 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:30,183 [IPC Server handler 59 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:30,186 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:30,880 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:30,885 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:30,891 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:30,907 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:30,925 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:30,946 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:s3v, Bucket:bucket-ozone-test-1676201683, Key:ozone-test-5348923844/multidelete/key=value/f4.
om1_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
recon_1      | 	... 35 more
recon_1      | 2022-04-21 16:53:25,220 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34640
recon_1      | 2022-04-21 16:53:25,288 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50424
recon_1      | 2022-04-21 16:53:25,291 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:53:25,297 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48264
recon_1      | 2022-04-21 16:53:25,312 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:53:25,336 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:53:55,219 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34768
recon_1      | 2022-04-21 16:53:55,280 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:53:55,317 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50548
recon_1      | 2022-04-21 16:53:55,398 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48402
recon_1      | 2022-04-21 16:53:55,454 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:53:55,543 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:53:58,425 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-04-21 16:53:58,425 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-04-21 16:53:58,461 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:146)
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:92)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:514)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:317)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
om1_1        | 2022-04-21 17:00:31,744 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:31,746 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:31,751 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:31,756 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:35,730 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42160
om1_1        | 2022-04-21 17:00:35,758 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 17:00:39,768 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:39,771 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:39,777 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-4595663119 of layout LEGACY in volume: s3v
om1_1        | 2022-04-21 17:00:40,573 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:40,575 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:40,577 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:40,712 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:41,288 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:41,499 [IPC Server handler 91 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:41,501 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:41,504 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:41,507 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:42,317 [IPC Server handler 74 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:42,319 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:42,321 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:42,347 [IPC Server handler 87 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:43,085 [IPC Server handler 46 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:43,087 [IPC Server handler 42 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:43,090 [IPC Server handler 52 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:43,094 [IPC Server handler 61 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:43,810 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:43,812 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:43,814 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:43,838 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:44,704 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:44,706 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:44,707 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:44,717 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:45,455 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:45,457 [IPC Server handler 78 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:45,460 [IPC Server handler 96 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:45,471 [IPC Server handler 94 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:46,174 [IPC Server handler 63 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:46,176 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:46,178 [IPC Server handler 59 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:46,188 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:47,061 [IPC Server handler 43 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:47,063 [IPC Server handler 46 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:47,064 [IPC Server handler 42 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
om1_1        | 2022-04-21 17:00:47,822 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:47,824 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:47,826 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:47,838 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:48,653 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:48,656 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:48,659 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:48,668 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:49,432 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:49,435 [IPC Server handler 92 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:49,437 [IPC Server handler 97 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:49,448 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:50,210 [IPC Server handler 65 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:50,212 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:50,214 [IPC Server handler 80 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:50,223 [IPC Server handler 69 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:51,058 [IPC Server handler 43 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
om1_1        | 2022-04-21 17:00:51,061 [IPC Server handler 46 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:51,063 [IPC Server handler 42 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-04-21 16:54:00,227 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 2 milliseconds to process 0 existing database records.
recon_1      | 2022-04-21 16:54:00,232 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 5 milliseconds for processing 2 containers.
recon_1      | 2022-04-21 16:54:00,437 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 5 pipelines in house.
recon_1      | 2022-04-21 16:54:00,439 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 38 milliseconds.
recon_1      | 2022-04-21 16:54:25,218 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34900
om1_1        | 2022-04-21 17:00:51,071 [IPC Server handler 52 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:51,837 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:51,841 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:51,843 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:51,858 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:52,670 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:52,675 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:52,677 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:52,687 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
recon_1      | 2022-04-21 16:54:25,283 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:54:25,289 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48524
recon_1      | 2022-04-21 16:54:25,338 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:54:25,381 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50680
recon_1      | 2022-04-21 16:54:25,416 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:54:55,278 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34964
recon_1      | 2022-04-21 16:54:55,299 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48586
om1_1        | 2022-04-21 17:00:53,456 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:53,458 [IPC Server handler 78 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:53,460 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:53,471 [IPC Server handler 94 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:54,261 [IPC Server handler 72 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:54,264 [IPC Server handler 88 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:54,266 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
recon_1      | 2022-04-21 16:54:55,333 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50746
recon_1      | 2022-04-21 16:54:55,345 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:54:55,367 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:54:55,386 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:54:58,462 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-04-21 16:54:58,462 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-04-21 16:54:58,499 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
om1_1        | 2022-04-21 17:00:54,985 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:54,987 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:54,991 [IPC Server handler 43 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:55,969 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:55,972 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 2022-04-21 17:00:55,975 [IPC Server handler 43 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:00:58,757 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:46739
om1_1        | 2022-04-21 17:00:58,762 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 17:01:02,152 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42272
om1_1        | 2022-04-21 17:01:02,176 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-04-21 17:01:05,425 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:01:05,444 [IPC Server handler 97 on default port 9862] INFO security.AWSV4AuthValidator: 8d12d061953b5f82f12a13b229cb0561256f4eb01f0e54ebe561ae40286bfef3
om1_1        | 2022-04-21 17:01:05,450 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-4385489974 of layout LEGACY in volume: s3v
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-04-21 16:55:25,242 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35046
recon_1      | 2022-04-21 16:55:25,276 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:55:25,339 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50830
recon_1      | 2022-04-21 16:55:25,355 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48674
recon_1      | 2022-04-21 16:55:25,386 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:55:25,398 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:55:55,273 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35114
recon_1      | 2022-04-21 16:55:55,311 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48738
recon_1      | 2022-04-21 16:55:55,320 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:55:55,347 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50898
recon_1      | 2022-04-21 16:55:55,356 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:55:55,369 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:55:58,504 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-04-21 16:55:58,504 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-04-21 16:55:58,553 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-04-21 16:56:25,236 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35210
recon_1      | 2022-04-21 16:56:25,319 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:56:25,330 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50994
recon_1      | 2022-04-21 16:56:25,331 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48834
recon_1      | 2022-04-21 16:56:25,365 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:56:25,389 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:56:55,225 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35280
recon_1      | 2022-04-21 16:56:55,342 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:56:55,380 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48900
recon_1      | 2022-04-21 16:56:55,387 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51066
recon_1      | 2022-04-21 16:56:55,396 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:56:55,423 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:56:58,554 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-04-21 16:56:58,554 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-04-21 16:56:58,595 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-04-21 16:57:25,201 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35356
recon_1      | 2022-04-21 16:57:25,213 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:57:25,296 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51136
recon_1      | 2022-04-21 16:57:25,338 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:57:25,349 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48992
recon_1      | 2022-04-21 16:57:25,369 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:57:55,205 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35448
recon_1      | 2022-04-21 16:57:55,209 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:57:55,284 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49072
recon_1      | 2022-04-21 16:57:55,318 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51236
recon_1      | 2022-04-21 16:57:55,362 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:57:55,379 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:57:58,596 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-04-21 16:57:58,596 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-04-21 16:57:58,637 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-04-21 16:58:25,209 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35530
recon_1      | 2022-04-21 16:58:25,251 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:58:25,304 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51310
recon_1      | 2022-04-21 16:58:25,314 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49150
recon_1      | 2022-04-21 16:58:25,356 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:58:25,363 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:58:55,203 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35610
recon_1      | 2022-04-21 16:58:55,212 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:58:55,299 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51392
recon_1      | 2022-04-21 16:58:55,344 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49232
recon_1      | 2022-04-21 16:58:55,378 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:58:55,385 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:58:58,638 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-04-21 16:58:58,639 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-04-21 16:58:58,675 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-04-21 16:59:00,234 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 1 milliseconds to process 0 existing database records.
recon_1      | 2022-04-21 16:59:00,238 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 5 milliseconds for processing 2 containers.
recon_1      | 2022-04-21 16:59:00,464 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 5 pipelines in house.
recon_1      | 2022-04-21 16:59:00,467 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 26 milliseconds.
recon_1      | 2022-04-21 16:59:25,203 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35692
recon_1      | 2022-04-21 16:59:25,228 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:59:25,317 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49314
recon_1      | 2022-04-21 16:59:25,327 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:59:25,339 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51478
recon_1      | 2022-04-21 16:59:25,371 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:59:55,286 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35784
recon_1      | 2022-04-21 16:59:55,341 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49404
recon_1      | 2022-04-21 16:59:55,359 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:59:55,388 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:59:55,406 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51568
recon_1      | 2022-04-21 16:59:55,469 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 16:59:58,676 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-04-21 16:59:58,676 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-04-21 16:59:58,728 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-04-21 17:00:25,255 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35910
recon_1      | 2022-04-21 17:00:25,307 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51692
recon_1      | 2022-04-21 17:00:25,326 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 17:00:25,352 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 17:00:25,385 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49536
recon_1      | 2022-04-21 17:00:25,567 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 17:00:55,213 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36044
recon_1      | 2022-04-21 17:00:55,243 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 17:00:55,277 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49666
recon_1      | 2022-04-21 17:00:55,283 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 17:00:55,362 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51828
recon_1      | 2022-04-21 17:00:55,366 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 17:00:58,733 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-04-21 17:00:58,733 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-04-21 17:00:58,783 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-04-21 17:01:25,245 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36134
recon_1      | 2022-04-21 17:01:25,343 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 17:01:25,356 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51918
recon_1      | 2022-04-21 17:01:25,367 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49758
recon_1      | 2022-04-21 17:01:25,408 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-04-21 17:01:25,422 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
